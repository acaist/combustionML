# p1
## Abstract
nerual networks are universal function proximates. When used in regression modelling it exibits superial performance than converntional tabulation technichs. Compare to table interpolation, nerual network inference is not bound by dimenstionalty. Besides the network only takes MBs of memory which is much smaller than its tabulation counterpart. In this work a speical type of nerual network, residual network is used to represent a mixture fraction progress variable flamelet tabulation model for premixed flame. The desigen residual network takes 1000X less memory compares to the tabulation. Unlike the previous attempt that creates a optimized network for each species in the FPV table, We have demonstrated in this work that one single network can represent all the species. This single network is much easier to train and depoly and provides a over 10x performance increase.  
## 1. Introduction
Deep learning is applied to flamelet modelling in combustion simulation.
## 2. FPV tabulation
## 2. Deep residual network
since the great sucess of Alex net, our understanding of network design has improved over years. In general, with a deeper network's prediction performace is better than the shellower one. But as we stacking more and more layers, we start to see a performance drop. residual network creates a skip connection structure that helps to ensure the performance gain of the deeper network.
### 2.1 residual learning and skip connection
### 2.2 residual blocks
A residual block is designed by having to hidden layers. The input of the first hidden layer is added to the output of the second hidden layer. This creates the 'skip' connection that allows the information flow that by pass the first layer. 
## 3. scaling transformation and loss function selection
The FPV tabulation records the mass fraction of all species as well as the Temperature and related source term. All items in the tabluation have different ranges. It is every important to have them scaled so that one network could cover all of them. And for many species their distribution are highly skewed. The selection of the loss function must take such data specific distribution into consideration. 
### 3.1 box-cox scaling transformation
bc transformation can  scale a non normal distribution.
### 3.2 loss function selection for outliers
mse places more focus on the outliers than mae
## 4 network performance
### 4.1 FPV tables

## 5. numerical simulations
## 6. Results
## 7. conclusion
A deep residual network is desiged for FPV modelling. This one network is capable of replace the conventional tabulation with 1000th memory footprint. Comparing to the previous adaption, there is no special optimazation required for the network design. The performancd of this one network is over 10x better than the previous multi network solution. To ensure the accuracy of the network training, a box-cox transformation has also been applied. By taking a close look into the statistics of the FPV tabluation, insight of the scaling for combustion tabulation is discussed. The success aplication of the network for FPV combustion simulation shows a promising future of nerual network application in high dimention combustion tabulation that is in practical in combustion simulation so far. 
