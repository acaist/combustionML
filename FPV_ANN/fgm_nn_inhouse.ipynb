{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hEx9lga_dfcL"
   },
   "source": [
    "## import fgm tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "PHI6QIc3cbGi",
    "outputId": "73cb5719-67ed-4d22-f712-a799c3d26c2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown) (2.18.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.11.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.28.1)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (1.22)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2018.11.29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1XHPF7hUqT-zp__qkGwHg8noRazRnPqb0\n",
      "To: <_io.BufferedWriter name='/content/tables_of_fgm.h5'>\n",
      "982MB [00:06, 153MB/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown\n",
    "!mkdir ./data\n",
    "import gdown\n",
    "\n",
    "def data_import():\n",
    "  ids = {\n",
    "      \"tables_of_fgm.h5\":\"1XHPF7hUqT-zp__qkGwHg8noRazRnPqb0\"\n",
    "  }\n",
    "\n",
    "  url = 'https://drive.google.com/uc?id='\n",
    "\n",
    "  for title, g_id in ids.items(): \n",
    "    try:\n",
    "      output_file = open(\"/content/data/\" + title, 'wb')\n",
    "      gdown.download(url + g_id, output_file, quiet=False)\n",
    "    except IOError as e:\n",
    "      print(e, file=sys.stderr)\n",
    "    finally:\n",
    "      output_file.close()\n",
    "      \n",
    "data_import()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_6gx8jhVr0nJ"
   },
   "source": [
    "# Function libaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8FU0iHDKeIzy"
   },
   "source": [
    "## ResBlock\n",
    "\n",
    "```res_block``` is the backbone of the resnet structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IPWK5TtaeFkd"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Activation, Input, BatchNormalization, Dropout\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def res_block(input_tensor, n_neuron, stage, block, bn=False):\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Dense(7 * n_neuron, name=conv_name_base + '2a')(input_tensor)\n",
    "    if bn:\n",
    "        x = BatchNormalization(axis=-1, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.)(x)\n",
    "\n",
    "    x = Dense(n_neuron, name=conv_name_base + '2b')(x)\n",
    "    if bn:\n",
    "        x = BatchNormalization(axis=-1, name=bn_name_base + '2b')(x)\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-npu4GM0eLnq"
   },
   "source": [
    "## data_reader\n",
    "The ```read_h5_data``` function read the table from the hdf5 file. \n",
    "\n",
    "In the FGM case we chose not to scale the input features, since they all falls between 0 and 1. There are a great variety in the output features. In the reaction region close to stoichiometry the gradient in the output properties are great. A good example is the source term for progress variable, which rises from 0 to 1e5. So the output features are first transformed to logrithmic scale and then rearranged between  0 and 1. The outputs are normalised by its variance. This way the output value will be large where the gradient is great. So during training more focus would be put. The same 'focus design' has been put on the loss function selection as well. mse is selected over mae for that the squared error put more weights on the data samples that shows great changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L7S43SoweOHL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "\n",
    "class data_scaler(object):\n",
    "    def __init__(self):\n",
    "        self.norm = None\n",
    "        self.norm_1 = None\n",
    "        self.std = None\n",
    "        self.case = None\n",
    "        self.scale = 1\n",
    "        self.bias = 1e-20\n",
    "#         self.bias = 1\n",
    "\n",
    "\n",
    "        self.switcher = {\n",
    "            'std': 'std',\n",
    "            'std2': 'std2',\n",
    "            'std_min':'std_min',\n",
    "            'min': 'min',\n",
    "            'no':'no',\n",
    "            'log': 'log',\n",
    "            'log_min':'log_min',\n",
    "            'log2': 'log2',\n",
    "            'tan': 'tan'\n",
    "        }\n",
    "\n",
    "    def fit_transform(self, input_data, case):\n",
    "        self.case = case\n",
    "        if self.switcher.get(self.case) == 'std':\n",
    "            self.norm = MinMaxScaler()\n",
    "            self.norm_1 = MinMaxScaler()\n",
    "            self.std = StandardScaler()\n",
    "            out = self.norm_1.fit_transform(input_data)\n",
    "            out = self.std.fit_transform(out)\n",
    "            out = self.norm.fit_transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'std2':\n",
    "            self.std = StandardScaler()\n",
    "            out = self.std.fit_transform(input_data)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'std_min':\n",
    "            self.norm = MinMaxScaler()\n",
    "            self.std = StandardScaler()\n",
    "            out = self.std.fit_transform(input_data)\n",
    "            out = self.norm.fit_transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'min':\n",
    "            self.norm = MinMaxScaler()\n",
    "            out = self.norm.fit_transform(input_data)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'no':\n",
    "            self.norm = MinMaxScaler()\n",
    "            self.std = StandardScaler()\n",
    "            out = input_data\n",
    "\n",
    "        if self.switcher.get(self.case) == 'log':\n",
    "            out = - np.log(np.asarray(input_data / self.scale) + self.bias)\n",
    "            self.std = StandardScaler()\n",
    "            out = self.std.fit_transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'log_min':\n",
    "            out = - np.log(np.asarray(input_data / self.scale) + self.bias)\n",
    "            self.norm = MinMaxScaler()\n",
    "            out = self.norm.fit_transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'log2':\n",
    "            self.norm = MinMaxScaler()\n",
    "            self.norm_1 = MinMaxScaler()\n",
    "            out = self.norm.fit_transform(input_data)\n",
    "            out = np.log(np.asarray(out) + self.bias)\n",
    "            out = self.norm_1.fit_transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'tan':\n",
    "            self.norm = MaxAbsScaler()\n",
    "            self.std = StandardScaler()\n",
    "            out = self.std.fit_transform(input_data)\n",
    "            out = self.norm.fit_transform(out)\n",
    "            out = np.tan(out / (2 * np.pi + self.bias))\n",
    "\n",
    "        return out\n",
    "\n",
    "    def transform(self, input_data):\n",
    "        if self.switcher.get(self.case) == 'std':\n",
    "            out = self.norm_1.transform(input_data)\n",
    "            out = self.std.transform(out)\n",
    "            out = self.norm.transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'std2':\n",
    "            out = self.std.transform(input_data)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'std_min':\n",
    "            out = self.std.transform(input_data)\n",
    "            out = self.norm.transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'min':\n",
    "            out = self.norm.transform(input_data)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'no':\n",
    "            out = input_data\n",
    "\n",
    "        if self.switcher.get(self.case) == 'log':\n",
    "            out = - np.log(np.asarray(input_data / self.scale) + self.bias)\n",
    "            out = self.std.transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'log_min':\n",
    "            out = - np.log(np.asarray(input_data / self.scale) + self.bias)\n",
    "            out = self.norm.transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'log2':\n",
    "            out = self.norm.transform(input_data)\n",
    "            out = np.log(np.asarray(out) + self.bias)\n",
    "            out = self.norm_1.transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'tan':\n",
    "            out = self.std.transform(input_data)\n",
    "            out = self.norm.transform(out)\n",
    "            out = np.tan(out / (2 * np.pi + self.bias))\n",
    "\n",
    "        return out\n",
    "\n",
    "    def inverse_transform(self, input_data):\n",
    "\n",
    "        if self.switcher.get(self.case) == 'std':\n",
    "            out = self.norm.inverse_transform(input_data)\n",
    "            out = self.std.inverse_transform(out)\n",
    "            out = self.norm_1.inverse_transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'std2':\n",
    "            out = self.std.inverse_transform(input_data)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'std_min':\n",
    "            out = self.norm.inverse_transform(input_data)\n",
    "            out = self.std.inverse_transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'min':\n",
    "            out = self.norm.inverse_transform(input_data)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'no':\n",
    "            out = input_data\n",
    "\n",
    "        if self.switcher.get(self.case) == 'log':\n",
    "            out = self.std.inverse_transform(input_data)\n",
    "            out = (np.exp(-out) - self.bias) * self.scale\n",
    "\n",
    "        if self.switcher.get(self.case) == 'log_min':\n",
    "            out = self.norm.inverse_transform(input_data)\n",
    "            out = (np.exp(-out) - self.bias) * self.scale\n",
    "\n",
    "        if self.switcher.get(self.case) == 'log2':\n",
    "            out = self.norm_1.inverse_transform(input_data)\n",
    "            out = np.exp(out) - self.bias\n",
    "            out = self.norm.inverse_transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'tan':\n",
    "            out = (2 * np.pi + self.bias) * np.arctan(input_data)\n",
    "            out = self.norm.inverse_transform(out)\n",
    "            out = self.std.inverse_transform(out)\n",
    "\n",
    "        return out\n",
    "      \n",
    "\n",
    "def read_h5_data(fileName, input_features, labels):\n",
    "    df = pd.read_hdf(fileName)\n",
    "\n",
    "    input_df=df[input_features]\n",
    "    in_scaler = data_scaler()\n",
    "    input_np = in_scaler.fit_transform(input_df.values,'no')\n",
    "\n",
    "    label_df=df[labels].clip(0)\n",
    "#     if 'PVs' in labels:\n",
    "#       label_df['PVs']=np.log(label_df['PVs']+1)\n",
    "    out_scaler = data_scaler()\n",
    "    label_np = out_scaler.fit_transform(label_df.values,'std2')\n",
    "\n",
    "    return input_np, label_np, df, in_scaler, out_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b79h08yydz9O"
   },
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5QOYVBxarmdx"
   },
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kIcqhM0Jd1s8"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# define the labels\n",
    "\n",
    "# labels = ['T','PVs']\n",
    "labels = ['T','CH4','O2','CO2','CO','H2O','H2','OH','PVs']\n",
    "# labels = ['C2H3', 'C2H6', 'CH2', 'H2CN', 'C2H4', 'H2O2', 'C2H',\n",
    "#           'CN', 'heatRelease', 'NCO', 'NNH', 'N2', 'AR', 'psi', 'CO', 'CH4',\n",
    "#           'HNCO', 'CH2OH', 'HCCO', 'CH2CO', 'CH', 'mu', 'C2H2', 'C2H5', 'H2',\n",
    "#           'T','PVs', 'O', 'O2', 'N2O', 'C', 'C3H7', 'CH2(S)', 'NH3', 'HO2',\n",
    "#           'NO','HCO', 'NO2', 'OH', 'HCNO', 'CH3CHO', 'CH3', 'NH', 'alpha', 'CH3O',\n",
    "#           'CO2', 'CH3OH', 'CH2CHO', 'CH2O', 'C3H8', 'HNO', 'NH2', 'HCN', 'H',\n",
    "#           'N','H2O', 'HCCOH', 'HCNN']\n",
    "\n",
    "input_features=['f','pv','zeta']\n",
    "\n",
    "# read in the data\n",
    "x_input, y_label, df, in_scaler, out_scaler = read_h5_data('./data/tables_of_fgm.h5',input_features=input_features, labels = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pS7__AaAf5N7"
   },
   "source": [
    "## build neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "colab_type": "code",
    "id": "-Gu_HjgHrYTI",
    "outputId": "886def55-6cce-481b-8003-5b45833d9dde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set up ANN\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 20)           80          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res1a_branch2a (Dense)          (None, 140)          2940        dense_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 140)          0           res1a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_120 (Dropout)           (None, 140)          0           activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res1a_branch2b (Dense)          (None, 20)           2820        dropout_120[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_60 (Add)                    (None, 20)           0           res1a_branch2b[0][0]             \n",
      "                                                                 dense_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 20)           0           add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_121 (Dropout)           (None, 20)           0           activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res1b_branch2a (Dense)          (None, 140)          2940        dropout_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 140)          0           res1b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_122 (Dropout)           (None, 140)          0           activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res1b_branch2b (Dense)          (None, 20)           2820        dropout_122[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_61 (Add)                    (None, 20)           0           res1b_branch2b[0][0]             \n",
      "                                                                 dropout_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 20)           0           add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_123 (Dropout)           (None, 20)           0           activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_1 (Dense)                (None, 9)            189         dropout_123[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 11,789\n",
      "Trainable params: 11,789\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# split into train and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_input,y_label, test_size=0.01)\n",
    "\n",
    "n_neuron = 20\n",
    "# %%\n",
    "print('set up ANN')\n",
    "# ANN parameters\n",
    "dim_input = x_train.shape[1]\n",
    "dim_label = y_train.shape[1]\n",
    "\n",
    "batch_norm = False\n",
    "\n",
    "# This returns a tensor\n",
    "inputs = Input(shape=(dim_input,),name='input_1')\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = Dense(n_neuron, activation='relu')(inputs)\n",
    "\n",
    "# less then 2 res_block, there will be variance\n",
    "x = res_block(x, n_neuron, stage=1, block='a', bn=batch_norm)\n",
    "x = res_block(x, n_neuron, stage=1, block='b', bn=batch_norm)\n",
    "\n",
    "predictions = Dense(dim_label, activation='linear', name='output_1')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGL0ggq-gDLW"
   },
   "source": [
    "# model training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_qQf8H5BtlhY"
   },
   "source": [
    "## gpu training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def cubic_loss(y_true, y_pred):\n",
    "    return K.mean(K.square(y_true - y_pred)*K.abs(y_true - y_pred), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187034
    },
    "colab_type": "code",
    "id": "Tjb1VXRefKZ3",
    "outputId": "0dc41c38-759b-45b0-a874-350a511629ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1987927 samples, validate on 496982 samples\n",
      "Epoch 1/3000\n",
      " - 13s - loss: 0.6425 - acc: 0.4852 - val_loss: 0.3626 - val_acc: 0.6667\n",
      "Epoch 2/3000\n",
      " - 1s - loss: 0.2655 - acc: 0.7656 - val_loss: 0.2039 - val_acc: 0.8450\n",
      "Epoch 3/3000\n",
      " - 1s - loss: 0.1763 - acc: 0.8678 - val_loss: 0.1583 - val_acc: 0.8771\n",
      "Epoch 4/3000\n",
      " - 1s - loss: 0.1458 - acc: 0.8806 - val_loss: 0.1366 - val_acc: 0.8837\n",
      "Epoch 5/3000\n",
      " - 1s - loss: 0.1285 - acc: 0.8865 - val_loss: 0.1217 - val_acc: 0.8903\n",
      "Epoch 6/3000\n",
      " - 2s - loss: 0.1150 - acc: 0.8925 - val_loss: 0.1088 - val_acc: 0.8959\n",
      "Epoch 7/3000\n",
      " - 1s - loss: 0.1032 - acc: 0.8971 - val_loss: 0.0980 - val_acc: 0.8985\n",
      "Epoch 8/3000\n",
      " - 1s - loss: 0.0927 - acc: 0.9004 - val_loss: 0.0878 - val_acc: 0.8983\n",
      "Epoch 9/3000\n",
      " - 1s - loss: 0.0832 - acc: 0.9048 - val_loss: 0.0786 - val_acc: 0.9049\n",
      "Epoch 10/3000\n",
      " - 1s - loss: 0.0757 - acc: 0.9110 - val_loss: 0.0728 - val_acc: 0.9086\n",
      "Epoch 11/3000\n",
      " - 2s - loss: 0.0681 - acc: 0.9172 - val_loss: 0.0634 - val_acc: 0.9200\n",
      "Epoch 12/3000\n",
      " - 1s - loss: 0.0609 - acc: 0.9224 - val_loss: 0.0566 - val_acc: 0.9229\n",
      "Epoch 13/3000\n",
      " - 1s - loss: 0.0540 - acc: 0.9267 - val_loss: 0.0505 - val_acc: 0.9274\n",
      "Epoch 14/3000\n",
      " - 1s - loss: 0.0469 - acc: 0.9325 - val_loss: 0.0428 - val_acc: 0.9397\n",
      "Epoch 15/3000\n",
      " - 1s - loss: 0.0405 - acc: 0.9391 - val_loss: 0.0375 - val_acc: 0.9384\n",
      "Epoch 16/3000\n",
      " - 1s - loss: 0.0350 - acc: 0.9443 - val_loss: 0.0319 - val_acc: 0.9429\n",
      "Epoch 17/3000\n",
      " - 1s - loss: 0.0305 - acc: 0.9485 - val_loss: 0.0276 - val_acc: 0.9496\n",
      "Epoch 18/3000\n",
      " - 1s - loss: 0.0268 - acc: 0.9512 - val_loss: 0.0246 - val_acc: 0.9511\n",
      "Epoch 19/3000\n",
      " - 1s - loss: 0.0241 - acc: 0.9528 - val_loss: 0.0222 - val_acc: 0.9545\n",
      "Epoch 20/3000\n",
      "\n",
      "Epoch 00020: val_loss improved from inf to 0.01987, saving model to ./weights.best.cntk.hdf5\n",
      " - 13s - loss: 0.0214 - acc: 0.9542 - val_loss: 0.0199 - val_acc: 0.9535\n",
      "Epoch 21/3000\n",
      " - 1s - loss: 0.0193 - acc: 0.9544 - val_loss: 0.0178 - val_acc: 0.9534\n",
      "Epoch 22/3000\n",
      " - 1s - loss: 0.0176 - acc: 0.9547 - val_loss: 0.0164 - val_acc: 0.9523\n",
      "Epoch 23/3000\n",
      " - 1s - loss: 0.0162 - acc: 0.9552 - val_loss: 0.0153 - val_acc: 0.9558\n",
      "Epoch 24/3000\n",
      " - 1s - loss: 0.0154 - acc: 0.9548 - val_loss: 0.0139 - val_acc: 0.9559\n",
      "Epoch 25/3000\n",
      " - 1s - loss: 0.0142 - acc: 0.9557 - val_loss: 0.0134 - val_acc: 0.9566\n",
      "Epoch 26/3000\n",
      " - 1s - loss: 0.0135 - acc: 0.9556 - val_loss: 0.0129 - val_acc: 0.9566\n",
      "Epoch 27/3000\n",
      " - 2s - loss: 0.0127 - acc: 0.9566 - val_loss: 0.0118 - val_acc: 0.9565\n",
      "Epoch 28/3000\n",
      " - 1s - loss: 0.0119 - acc: 0.9575 - val_loss: 0.0117 - val_acc: 0.9578\n",
      "Epoch 29/3000\n",
      " - 1s - loss: 0.0116 - acc: 0.9578 - val_loss: 0.0110 - val_acc: 0.9535\n",
      "Epoch 30/3000\n",
      " - 1s - loss: 0.0109 - acc: 0.9590 - val_loss: 0.0107 - val_acc: 0.9614\n",
      "Epoch 31/3000\n",
      " - 1s - loss: 0.0107 - acc: 0.9597 - val_loss: 0.0101 - val_acc: 0.9609\n",
      "Epoch 32/3000\n",
      " - 1s - loss: 0.0101 - acc: 0.9610 - val_loss: 0.0099 - val_acc: 0.9627\n",
      "Epoch 33/3000\n",
      " - 1s - loss: 0.0100 - acc: 0.9614 - val_loss: 0.0094 - val_acc: 0.9598\n",
      "Epoch 34/3000\n",
      " - 2s - loss: 0.0096 - acc: 0.9626 - val_loss: 0.0090 - val_acc: 0.9638\n",
      "Epoch 35/3000\n",
      " - 1s - loss: 0.0094 - acc: 0.9634 - val_loss: 0.0087 - val_acc: 0.9635\n",
      "Epoch 36/3000\n",
      " - 1s - loss: 0.0091 - acc: 0.9645 - val_loss: 0.0087 - val_acc: 0.9657\n",
      "Epoch 37/3000\n",
      " - 2s - loss: 0.0091 - acc: 0.9649 - val_loss: 0.0085 - val_acc: 0.9662\n",
      "Epoch 38/3000\n",
      " - 1s - loss: 0.0086 - acc: 0.9664 - val_loss: 0.0081 - val_acc: 0.9633\n",
      "Epoch 39/3000\n",
      " - 1s - loss: 0.0085 - acc: 0.9671 - val_loss: 0.0083 - val_acc: 0.9694\n",
      "Epoch 40/3000\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.01987 to 0.00827, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 0.0084 - acc: 0.9677 - val_loss: 0.0083 - val_acc: 0.9641\n",
      "Epoch 41/3000\n",
      " - 1s - loss: 0.0082 - acc: 0.9684 - val_loss: 0.0085 - val_acc: 0.9676\n",
      "Epoch 42/3000\n",
      " - 1s - loss: 0.0082 - acc: 0.9692 - val_loss: 0.0080 - val_acc: 0.9647\n",
      "Epoch 43/3000\n",
      " - 1s - loss: 0.0082 - acc: 0.9691 - val_loss: 0.0079 - val_acc: 0.9728\n",
      "Epoch 44/3000\n",
      " - 1s - loss: 0.0078 - acc: 0.9704 - val_loss: 0.0075 - val_acc: 0.9698\n",
      "Epoch 45/3000\n",
      " - 1s - loss: 0.0076 - acc: 0.9708 - val_loss: 0.0072 - val_acc: 0.9722\n",
      "Epoch 46/3000\n",
      " - 2s - loss: 0.0075 - acc: 0.9713 - val_loss: 0.0072 - val_acc: 0.9711\n",
      "Epoch 47/3000\n",
      " - 1s - loss: 0.0077 - acc: 0.9705 - val_loss: 0.0074 - val_acc: 0.9687\n",
      "Epoch 48/3000\n",
      " - 1s - loss: 0.0074 - acc: 0.9721 - val_loss: 0.0069 - val_acc: 0.9706\n",
      "Epoch 49/3000\n",
      " - 1s - loss: 0.0074 - acc: 0.9719 - val_loss: 0.0067 - val_acc: 0.9721\n",
      "Epoch 50/3000\n",
      " - 1s - loss: 0.0072 - acc: 0.9729 - val_loss: 0.0072 - val_acc: 0.9696\n",
      "Epoch 51/3000\n",
      " - 1s - loss: 0.0072 - acc: 0.9725 - val_loss: 0.0073 - val_acc: 0.9726\n",
      "Epoch 52/3000\n",
      " - 1s - loss: 0.0072 - acc: 0.9730 - val_loss: 0.0072 - val_acc: 0.9728\n",
      "Epoch 53/3000\n",
      " - 1s - loss: 0.0068 - acc: 0.9738 - val_loss: 0.0064 - val_acc: 0.9740\n",
      "Epoch 54/3000\n",
      " - 1s - loss: 0.0067 - acc: 0.9742 - val_loss: 0.0062 - val_acc: 0.9753\n",
      "Epoch 55/3000\n",
      " - 1s - loss: 0.0065 - acc: 0.9752 - val_loss: 0.0061 - val_acc: 0.9745\n",
      "Epoch 56/3000\n",
      " - 1s - loss: 0.0065 - acc: 0.9752 - val_loss: 0.0067 - val_acc: 0.9725\n",
      "Epoch 57/3000\n",
      " - 2s - loss: 0.0065 - acc: 0.9754 - val_loss: 0.0065 - val_acc: 0.9729\n",
      "Epoch 58/3000\n",
      " - 1s - loss: 0.0063 - acc: 0.9753 - val_loss: 0.0058 - val_acc: 0.9776\n",
      "Epoch 59/3000\n",
      " - 2s - loss: 0.0061 - acc: 0.9758 - val_loss: 0.0059 - val_acc: 0.9757\n",
      "Epoch 60/3000\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00827 to 0.00567, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 0.0060 - acc: 0.9764 - val_loss: 0.0057 - val_acc: 0.9762\n",
      "Epoch 61/3000\n",
      " - 2s - loss: 0.0059 - acc: 0.9765 - val_loss: 0.0057 - val_acc: 0.9739\n",
      "Epoch 62/3000\n",
      " - 1s - loss: 0.0057 - acc: 0.9767 - val_loss: 0.0058 - val_acc: 0.9770\n",
      "Epoch 63/3000\n",
      " - 1s - loss: 0.0057 - acc: 0.9767 - val_loss: 0.0053 - val_acc: 0.9769\n",
      "Epoch 64/3000\n",
      " - 1s - loss: 0.0058 - acc: 0.9766 - val_loss: 0.0055 - val_acc: 0.9735\n",
      "Epoch 65/3000\n",
      " - 1s - loss: 0.0053 - acc: 0.9774 - val_loss: 0.0050 - val_acc: 0.9779\n",
      "Epoch 66/3000\n",
      " - 1s - loss: 0.0053 - acc: 0.9777 - val_loss: 0.0057 - val_acc: 0.9733\n",
      "Epoch 67/3000\n",
      " - 1s - loss: 0.0052 - acc: 0.9777 - val_loss: 0.0051 - val_acc: 0.9780\n",
      "Epoch 68/3000\n",
      " - 1s - loss: 0.0053 - acc: 0.9776 - val_loss: 0.0050 - val_acc: 0.9770\n",
      "Epoch 69/3000\n",
      " - 2s - loss: 0.0050 - acc: 0.9781 - val_loss: 0.0049 - val_acc: 0.9792\n",
      "Epoch 70/3000\n",
      " - 1s - loss: 0.0049 - acc: 0.9786 - val_loss: 0.0049 - val_acc: 0.9773\n",
      "Epoch 71/3000\n",
      " - 2s - loss: 0.0048 - acc: 0.9786 - val_loss: 0.0047 - val_acc: 0.9773\n",
      "Epoch 72/3000\n",
      " - 1s - loss: 0.0047 - acc: 0.9785 - val_loss: 0.0050 - val_acc: 0.9783\n",
      "Epoch 73/3000\n",
      " - 2s - loss: 0.0047 - acc: 0.9786 - val_loss: 0.0043 - val_acc: 0.9790\n",
      "Epoch 74/3000\n",
      " - 1s - loss: 0.0046 - acc: 0.9785 - val_loss: 0.0047 - val_acc: 0.9752\n",
      "Epoch 75/3000\n",
      " - 1s - loss: 0.0045 - acc: 0.9787 - val_loss: 0.0041 - val_acc: 0.9785\n",
      "Epoch 76/3000\n",
      " - 1s - loss: 0.0048 - acc: 0.9783 - val_loss: 0.0045 - val_acc: 0.9794\n",
      "Epoch 77/3000\n",
      " - 1s - loss: 0.0047 - acc: 0.9782 - val_loss: 0.0044 - val_acc: 0.9785\n",
      "Epoch 78/3000\n",
      " - 1s - loss: 0.0043 - acc: 0.9791 - val_loss: 0.0040 - val_acc: 0.9794\n",
      "Epoch 79/3000\n",
      " - 1s - loss: 0.0041 - acc: 0.9796 - val_loss: 0.0041 - val_acc: 0.9796\n",
      "Epoch 80/3000\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.00567 to 0.00423, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 0.0042 - acc: 0.9789 - val_loss: 0.0042 - val_acc: 0.9772\n",
      "Epoch 81/3000\n",
      " - 2s - loss: 0.0043 - acc: 0.9784 - val_loss: 0.0038 - val_acc: 0.9790\n",
      "Epoch 82/3000\n",
      " - 1s - loss: 0.0040 - acc: 0.9794 - val_loss: 0.0039 - val_acc: 0.9794\n",
      "Epoch 83/3000\n",
      " - 2s - loss: 0.0039 - acc: 0.9795 - val_loss: 0.0036 - val_acc: 0.9802\n",
      "Epoch 84/3000\n",
      " - 2s - loss: 0.0037 - acc: 0.9798 - val_loss: 0.0038 - val_acc: 0.9801\n",
      "Epoch 85/3000\n",
      " - 1s - loss: 0.0037 - acc: 0.9797 - val_loss: 0.0036 - val_acc: 0.9801\n",
      "Epoch 86/3000\n",
      " - 2s - loss: 0.0035 - acc: 0.9801 - val_loss: 0.0043 - val_acc: 0.9788\n",
      "Epoch 87/3000\n",
      " - 1s - loss: 0.0036 - acc: 0.9798 - val_loss: 0.0037 - val_acc: 0.9790\n",
      "Epoch 88/3000\n",
      " - 2s - loss: 0.0034 - acc: 0.9804 - val_loss: 0.0034 - val_acc: 0.9797\n",
      "Epoch 89/3000\n",
      " - 2s - loss: 0.0034 - acc: 0.9801 - val_loss: 0.0036 - val_acc: 0.9781\n",
      "Epoch 90/3000\n",
      " - 1s - loss: 0.0034 - acc: 0.9799 - val_loss: 0.0034 - val_acc: 0.9812\n",
      "Epoch 91/3000\n",
      " - 1s - loss: 0.0033 - acc: 0.9802 - val_loss: 0.0032 - val_acc: 0.9809\n",
      "Epoch 92/3000\n",
      " - 1s - loss: 0.0032 - acc: 0.9803 - val_loss: 0.0032 - val_acc: 0.9794\n",
      "Epoch 93/3000\n",
      " - 1s - loss: 0.0031 - acc: 0.9810 - val_loss: 0.0031 - val_acc: 0.9810\n",
      "Epoch 94/3000\n",
      " - 1s - loss: 0.0031 - acc: 0.9809 - val_loss: 0.0030 - val_acc: 0.9816\n",
      "Epoch 95/3000\n",
      " - 1s - loss: 0.0030 - acc: 0.9810 - val_loss: 0.0032 - val_acc: 0.9789\n",
      "Epoch 96/3000\n",
      " - 2s - loss: 0.0030 - acc: 0.9809 - val_loss: 0.0029 - val_acc: 0.9810\n",
      "Epoch 97/3000\n",
      " - 2s - loss: 0.0029 - acc: 0.9812 - val_loss: 0.0028 - val_acc: 0.9818\n",
      "Epoch 98/3000\n",
      " - 1s - loss: 0.0028 - acc: 0.9816 - val_loss: 0.0029 - val_acc: 0.9816\n",
      "Epoch 99/3000\n",
      " - 1s - loss: 0.0028 - acc: 0.9815 - val_loss: 0.0027 - val_acc: 0.9816\n",
      "Epoch 100/3000\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.00423 to 0.00308, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 0.0028 - acc: 0.9814 - val_loss: 0.0031 - val_acc: 0.9797\n",
      "Epoch 101/3000\n",
      " - 2s - loss: 0.0028 - acc: 0.9812 - val_loss: 0.0026 - val_acc: 0.9806\n",
      "Epoch 102/3000\n",
      " - 2s - loss: 0.0027 - acc: 0.9815 - val_loss: 0.0028 - val_acc: 0.9818\n",
      "Epoch 103/3000\n",
      " - 1s - loss: 0.0027 - acc: 0.9818 - val_loss: 0.0027 - val_acc: 0.9825\n",
      "Epoch 104/3000\n",
      " - 1s - loss: 0.0028 - acc: 0.9816 - val_loss: 0.0027 - val_acc: 0.9827\n",
      "Epoch 105/3000\n",
      " - 1s - loss: 0.0026 - acc: 0.9819 - val_loss: 0.0027 - val_acc: 0.9816\n",
      "Epoch 106/3000\n",
      " - 2s - loss: 0.0026 - acc: 0.9820 - val_loss: 0.0029 - val_acc: 0.9820\n",
      "Epoch 107/3000\n",
      " - 1s - loss: 0.0026 - acc: 0.9819 - val_loss: 0.0024 - val_acc: 0.9815\n",
      "Epoch 108/3000\n",
      " - 1s - loss: 0.0026 - acc: 0.9818 - val_loss: 0.0025 - val_acc: 0.9809\n",
      "Epoch 109/3000\n",
      " - 1s - loss: 0.0025 - acc: 0.9820 - val_loss: 0.0027 - val_acc: 0.9825\n",
      "Epoch 110/3000\n",
      " - 1s - loss: 0.0025 - acc: 0.9821 - val_loss: 0.0024 - val_acc: 0.9822\n",
      "Epoch 111/3000\n",
      " - 1s - loss: 0.0025 - acc: 0.9824 - val_loss: 0.0025 - val_acc: 0.9818\n",
      "Epoch 112/3000\n",
      " - 2s - loss: 0.0024 - acc: 0.9824 - val_loss: 0.0023 - val_acc: 0.9830\n",
      "Epoch 113/3000\n",
      " - 1s - loss: 0.0024 - acc: 0.9824 - val_loss: 0.0025 - val_acc: 0.9819\n",
      "Epoch 114/3000\n",
      " - 1s - loss: 0.0024 - acc: 0.9822 - val_loss: 0.0023 - val_acc: 0.9817\n",
      "Epoch 115/3000\n",
      " - 1s - loss: 0.0023 - acc: 0.9825 - val_loss: 0.0023 - val_acc: 0.9826\n",
      "Epoch 116/3000\n",
      " - 1s - loss: 0.0023 - acc: 0.9826 - val_loss: 0.0023 - val_acc: 0.9830\n",
      "Epoch 117/3000\n",
      " - 1s - loss: 0.0023 - acc: 0.9827 - val_loss: 0.0023 - val_acc: 0.9825\n",
      "Epoch 118/3000\n",
      " - 1s - loss: 0.0023 - acc: 0.9828 - val_loss: 0.0022 - val_acc: 0.9830\n",
      "Epoch 119/3000\n",
      " - 1s - loss: 0.0022 - acc: 0.9827 - val_loss: 0.0024 - val_acc: 0.9818\n",
      "Epoch 120/3000\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.00308 to 0.00229, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 0.0023 - acc: 0.9826 - val_loss: 0.0023 - val_acc: 0.9818\n",
      "Epoch 121/3000\n",
      " - 1s - loss: 0.0022 - acc: 0.9829 - val_loss: 0.0022 - val_acc: 0.9823\n",
      "Epoch 122/3000\n",
      " - 1s - loss: 0.0022 - acc: 0.9828 - val_loss: 0.0021 - val_acc: 0.9829\n",
      "Epoch 123/3000\n",
      " - 1s - loss: 0.0021 - acc: 0.9830 - val_loss: 0.0021 - val_acc: 0.9828\n",
      "Epoch 124/3000\n",
      " - 1s - loss: 0.0021 - acc: 0.9831 - val_loss: 0.0021 - val_acc: 0.9831\n",
      "Epoch 125/3000\n",
      " - 1s - loss: 0.0022 - acc: 0.9828 - val_loss: 0.0021 - val_acc: 0.9824\n",
      "Epoch 126/3000\n",
      " - 1s - loss: 0.0021 - acc: 0.9829 - val_loss: 0.0021 - val_acc: 0.9829\n",
      "Epoch 127/3000\n",
      " - 1s - loss: 0.0021 - acc: 0.9828 - val_loss: 0.0021 - val_acc: 0.9830\n",
      "Epoch 128/3000\n",
      " - 1s - loss: 0.0021 - acc: 0.9829 - val_loss: 0.0020 - val_acc: 0.9833\n",
      "Epoch 129/3000\n",
      " - 1s - loss: 0.0021 - acc: 0.9829 - val_loss: 0.0020 - val_acc: 0.9831\n",
      "Epoch 130/3000\n",
      " - 1s - loss: 0.0021 - acc: 0.9830 - val_loss: 0.0020 - val_acc: 0.9828\n",
      "Epoch 131/3000\n",
      " - 2s - loss: 0.0020 - acc: 0.9834 - val_loss: 0.0020 - val_acc: 0.9834\n",
      "Epoch 132/3000\n",
      " - 2s - loss: 0.0020 - acc: 0.9835 - val_loss: 0.0020 - val_acc: 0.9820\n",
      "Epoch 133/3000\n",
      " - 1s - loss: 0.0020 - acc: 0.9835 - val_loss: 0.0019 - val_acc: 0.9834\n",
      "Epoch 134/3000\n",
      " - 1s - loss: 0.0020 - acc: 0.9833 - val_loss: 0.0019 - val_acc: 0.9834\n",
      "Epoch 135/3000\n",
      " - 1s - loss: 0.0020 - acc: 0.9835 - val_loss: 0.0021 - val_acc: 0.9839\n",
      "Epoch 136/3000\n",
      " - 2s - loss: 0.0021 - acc: 0.9829 - val_loss: 0.0020 - val_acc: 0.9828\n",
      "Epoch 137/3000\n",
      " - 1s - loss: 0.0019 - acc: 0.9835 - val_loss: 0.0019 - val_acc: 0.9834\n",
      "Epoch 138/3000\n",
      " - 1s - loss: 0.0020 - acc: 0.9835 - val_loss: 0.0021 - val_acc: 0.9841\n",
      "Epoch 139/3000\n",
      " - 1s - loss: 0.0019 - acc: 0.9835 - val_loss: 0.0018 - val_acc: 0.9834\n",
      "Epoch 140/3000\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.00229 to 0.00188, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 0.0019 - acc: 0.9836 - val_loss: 0.0019 - val_acc: 0.9835\n",
      "Epoch 141/3000\n",
      " - 1s - loss: 0.0020 - acc: 0.9834 - val_loss: 0.0019 - val_acc: 0.9841\n",
      "Epoch 142/3000\n",
      " - 2s - loss: 0.0019 - acc: 0.9838 - val_loss: 0.0019 - val_acc: 0.9839\n",
      "Epoch 143/3000\n",
      " - 1s - loss: 0.0018 - acc: 0.9840 - val_loss: 0.0018 - val_acc: 0.9840\n",
      "Epoch 144/3000\n",
      " - 1s - loss: 0.0018 - acc: 0.9841 - val_loss: 0.0018 - val_acc: 0.9840\n",
      "Epoch 145/3000\n",
      " - 1s - loss: 0.0019 - acc: 0.9839 - val_loss: 0.0018 - val_acc: 0.9842\n",
      "Epoch 146/3000\n",
      " - 2s - loss: 0.0019 - acc: 0.9835 - val_loss: 0.0019 - val_acc: 0.9835\n",
      "Epoch 147/3000\n",
      " - 1s - loss: 0.0018 - acc: 0.9839 - val_loss: 0.0017 - val_acc: 0.9838\n",
      "Epoch 148/3000\n",
      " - 1s - loss: 0.0018 - acc: 0.9841 - val_loss: 0.0017 - val_acc: 0.9834\n",
      "Epoch 149/3000\n",
      " - 1s - loss: 0.0018 - acc: 0.9842 - val_loss: 0.0017 - val_acc: 0.9843\n",
      "Epoch 150/3000\n",
      " - 2s - loss: 0.0018 - acc: 0.9842 - val_loss: 0.0018 - val_acc: 0.9839\n",
      "Epoch 151/3000\n",
      " - 1s - loss: 0.0017 - acc: 0.9843 - val_loss: 0.0017 - val_acc: 0.9843\n",
      "Epoch 152/3000\n",
      " - 2s - loss: 0.0017 - acc: 0.9844 - val_loss: 0.0017 - val_acc: 0.9847\n",
      "Epoch 153/3000\n",
      " - 1s - loss: 0.0017 - acc: 0.9846 - val_loss: 0.0017 - val_acc: 0.9836\n",
      "Epoch 154/3000\n",
      " - 2s - loss: 0.0017 - acc: 0.9843 - val_loss: 0.0017 - val_acc: 0.9845\n",
      "Epoch 155/3000\n",
      " - 1s - loss: 0.0017 - acc: 0.9843 - val_loss: 0.0017 - val_acc: 0.9842\n",
      "Epoch 156/3000\n",
      " - 1s - loss: 0.0017 - acc: 0.9846 - val_loss: 0.0018 - val_acc: 0.9842\n",
      "Epoch 157/3000\n",
      " - 1s - loss: 0.0017 - acc: 0.9846 - val_loss: 0.0017 - val_acc: 0.9849\n",
      "Epoch 158/3000\n",
      " - 1s - loss: 0.0017 - acc: 0.9845 - val_loss: 0.0019 - val_acc: 0.9820\n",
      "Epoch 159/3000\n",
      " - 1s - loss: 0.0017 - acc: 0.9845 - val_loss: 0.0017 - val_acc: 0.9838\n",
      "Epoch 160/3000\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.00188 to 0.00169, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 0.0018 - acc: 0.9844 - val_loss: 0.0017 - val_acc: 0.9848\n",
      "Epoch 161/3000\n",
      " - 2s - loss: 0.0017 - acc: 0.9847 - val_loss: 0.0016 - val_acc: 0.9842\n",
      "Epoch 162/3000\n",
      " - 1s - loss: 0.0016 - acc: 0.9849 - val_loss: 0.0016 - val_acc: 0.9848\n",
      "Epoch 163/3000\n",
      " - 1s - loss: 0.0016 - acc: 0.9849 - val_loss: 0.0016 - val_acc: 0.9843\n",
      "Epoch 164/3000\n",
      " - 1s - loss: 0.0017 - acc: 0.9848 - val_loss: 0.0016 - val_acc: 0.9836\n",
      "Epoch 165/3000\n",
      " - 2s - loss: 0.0016 - acc: 0.9850 - val_loss: 0.0017 - val_acc: 0.9843\n",
      "Epoch 166/3000\n",
      " - 1s - loss: 0.0017 - acc: 0.9848 - val_loss: 0.0017 - val_acc: 0.9845\n",
      "Epoch 167/3000\n",
      " - 1s - loss: 0.0017 - acc: 0.9847 - val_loss: 0.0016 - val_acc: 0.9840\n",
      "Epoch 168/3000\n",
      " - 1s - loss: 0.0016 - acc: 0.9849 - val_loss: 0.0016 - val_acc: 0.9848\n",
      "Epoch 169/3000\n",
      " - 2s - loss: 0.0017 - acc: 0.9846 - val_loss: 0.0017 - val_acc: 0.9852\n",
      "Epoch 170/3000\n",
      " - 2s - loss: 0.0016 - acc: 0.9848 - val_loss: 0.0016 - val_acc: 0.9851\n",
      "Epoch 171/3000\n",
      " - 1s - loss: 0.0016 - acc: 0.9849 - val_loss: 0.0016 - val_acc: 0.9848\n",
      "Epoch 172/3000\n",
      " - 1s - loss: 0.0016 - acc: 0.9849 - val_loss: 0.0016 - val_acc: 0.9848\n",
      "Epoch 173/3000\n",
      " - 1s - loss: 0.0016 - acc: 0.9847 - val_loss: 0.0016 - val_acc: 0.9854\n",
      "Epoch 174/3000\n",
      " - 1s - loss: 0.0016 - acc: 0.9850 - val_loss: 0.0015 - val_acc: 0.9849\n",
      "Epoch 175/3000\n",
      " - 1s - loss: 0.0015 - acc: 0.9854 - val_loss: 0.0016 - val_acc: 0.9851\n",
      "Epoch 176/3000\n",
      " - 1s - loss: 0.0016 - acc: 0.9852 - val_loss: 0.0016 - val_acc: 0.9855\n",
      "Epoch 177/3000\n",
      " - 1s - loss: 0.0016 - acc: 0.9851 - val_loss: 0.0015 - val_acc: 0.9851\n",
      "Epoch 178/3000\n",
      " - 1s - loss: 0.0016 - acc: 0.9851 - val_loss: 0.0015 - val_acc: 0.9857\n",
      "Epoch 179/3000\n",
      " - 1s - loss: 0.0016 - acc: 0.9850 - val_loss: 0.0016 - val_acc: 0.9839\n",
      "Epoch 180/3000\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.00169 to 0.00153, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 0.0016 - acc: 0.9852 - val_loss: 0.0015 - val_acc: 0.9849\n",
      "Epoch 181/3000\n",
      " - 1s - loss: 0.0015 - acc: 0.9854 - val_loss: 0.0015 - val_acc: 0.9849\n",
      "Epoch 182/3000\n",
      " - 1s - loss: 0.0015 - acc: 0.9855 - val_loss: 0.0015 - val_acc: 0.9854\n",
      "Epoch 183/3000\n",
      " - 1s - loss: 0.0015 - acc: 0.9854 - val_loss: 0.0016 - val_acc: 0.9857\n",
      "Epoch 184/3000\n",
      " - 1s - loss: 0.0016 - acc: 0.9851 - val_loss: 0.0016 - val_acc: 0.9853\n",
      "Epoch 185/3000\n",
      " - 1s - loss: 0.0016 - acc: 0.9853 - val_loss: 0.0015 - val_acc: 0.9856\n",
      "Epoch 186/3000\n",
      " - 1s - loss: 0.0015 - acc: 0.9854 - val_loss: 0.0016 - val_acc: 0.9857\n",
      "Epoch 187/3000\n",
      " - 1s - loss: 0.0015 - acc: 0.9857 - val_loss: 0.0015 - val_acc: 0.9856\n",
      "Epoch 188/3000\n",
      " - 1s - loss: 0.0015 - acc: 0.9855 - val_loss: 0.0015 - val_acc: 0.9858\n",
      "Epoch 189/3000\n",
      " - 1s - loss: 0.0015 - acc: 0.9854 - val_loss: 0.0016 - val_acc: 0.9858\n",
      "Epoch 190/3000\n",
      " - 1s - loss: 0.0015 - acc: 0.9854 - val_loss: 0.0014 - val_acc: 0.9861\n",
      "Epoch 191/3000\n",
      " - 1s - loss: 0.0015 - acc: 0.9858 - val_loss: 0.0014 - val_acc: 0.9861\n",
      "Epoch 192/3000\n",
      " - 1s - loss: 0.0015 - acc: 0.9855 - val_loss: 0.0014 - val_acc: 0.9860\n",
      "Epoch 193/3000\n",
      " - 1s - loss: 0.0014 - acc: 0.9858 - val_loss: 0.0014 - val_acc: 0.9855\n",
      "Epoch 194/3000\n",
      " - 1s - loss: 0.0015 - acc: 0.9858 - val_loss: 0.0014 - val_acc: 0.9865\n",
      "Epoch 195/3000\n",
      " - 1s - loss: 0.0015 - acc: 0.9855 - val_loss: 0.0014 - val_acc: 0.9851\n",
      "Epoch 196/3000\n",
      " - 1s - loss: 0.0015 - acc: 0.9853 - val_loss: 0.0015 - val_acc: 0.9854\n",
      "Epoch 197/3000\n",
      " - 1s - loss: 0.0015 - acc: 0.9856 - val_loss: 0.0016 - val_acc: 0.9850\n",
      "Epoch 198/3000\n",
      " - 1s - loss: 0.0015 - acc: 0.9856 - val_loss: 0.0014 - val_acc: 0.9864\n",
      "Epoch 199/3000\n",
      " - 1s - loss: 0.0014 - acc: 0.9857 - val_loss: 0.0014 - val_acc: 0.9866\n",
      "Epoch 200/3000\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.00153 to 0.00146, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 0.0015 - acc: 0.9857 - val_loss: 0.0015 - val_acc: 0.9849\n",
      "Epoch 201/3000\n",
      " - 1s - loss: 0.0014 - acc: 0.9858 - val_loss: 0.0014 - val_acc: 0.9860\n",
      "Epoch 202/3000\n",
      " - 1s - loss: 0.0014 - acc: 0.9860 - val_loss: 0.0015 - val_acc: 0.9856\n",
      "Epoch 203/3000\n",
      " - 1s - loss: 0.0014 - acc: 0.9859 - val_loss: 0.0015 - val_acc: 0.9856\n",
      "Epoch 204/3000\n",
      " - 1s - loss: 0.0014 - acc: 0.9858 - val_loss: 0.0014 - val_acc: 0.9859\n",
      "Epoch 205/3000\n",
      " - 1s - loss: 0.0014 - acc: 0.9859 - val_loss: 0.0014 - val_acc: 0.9855\n",
      "Epoch 206/3000\n",
      " - 1s - loss: 0.0015 - acc: 0.9857 - val_loss: 0.0014 - val_acc: 0.9852\n",
      "Epoch 207/3000\n",
      " - 1s - loss: 0.0014 - acc: 0.9858 - val_loss: 0.0016 - val_acc: 0.9835\n",
      "Epoch 208/3000\n",
      " - 1s - loss: 0.0014 - acc: 0.9858 - val_loss: 0.0014 - val_acc: 0.9863\n",
      "Epoch 209/3000\n",
      " - 2s - loss: 0.0014 - acc: 0.9861 - val_loss: 0.0014 - val_acc: 0.9859\n",
      "Epoch 210/3000\n",
      " - 1s - loss: 0.0014 - acc: 0.9858 - val_loss: 0.0014 - val_acc: 0.9856\n",
      "Epoch 211/3000\n",
      " - 1s - loss: 0.0014 - acc: 0.9859 - val_loss: 0.0014 - val_acc: 0.9864\n",
      "Epoch 212/3000\n",
      " - 1s - loss: 0.0014 - acc: 0.9859 - val_loss: 0.0015 - val_acc: 0.9858\n",
      "Epoch 213/3000\n",
      " - 1s - loss: 0.0014 - acc: 0.9858 - val_loss: 0.0013 - val_acc: 0.9860\n",
      "Epoch 214/3000\n",
      " - 2s - loss: 0.0014 - acc: 0.9862 - val_loss: 0.0013 - val_acc: 0.9862\n",
      "Epoch 215/3000\n",
      " - 1s - loss: 0.0014 - acc: 0.9858 - val_loss: 0.0013 - val_acc: 0.9861\n",
      "Epoch 216/3000\n",
      " - 1s - loss: 0.0014 - acc: 0.9861 - val_loss: 0.0013 - val_acc: 0.9862\n",
      "Epoch 217/3000\n",
      " - 1s - loss: 0.0013 - acc: 0.9864 - val_loss: 0.0013 - val_acc: 0.9868\n",
      "Epoch 218/3000\n",
      " - 1s - loss: 0.0013 - acc: 0.9864 - val_loss: 0.0013 - val_acc: 0.9867\n",
      "Epoch 219/3000\n",
      " - 2s - loss: 0.0013 - acc: 0.9863 - val_loss: 0.0013 - val_acc: 0.9866\n",
      "Epoch 220/3000\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.00146\n",
      " - 2s - loss: 0.0013 - acc: 0.9864 - val_loss: 0.0015 - val_acc: 0.9857\n",
      "Epoch 221/3000\n",
      " - 1s - loss: 0.0014 - acc: 0.9862 - val_loss: 0.0013 - val_acc: 0.9860\n",
      "Epoch 222/3000\n",
      " - 1s - loss: 0.0013 - acc: 0.9864 - val_loss: 0.0014 - val_acc: 0.9858\n",
      "Epoch 223/3000\n",
      " - 1s - loss: 0.0014 - acc: 0.9861 - val_loss: 0.0013 - val_acc: 0.9855\n",
      "Epoch 224/3000\n",
      " - 1s - loss: 0.0013 - acc: 0.9863 - val_loss: 0.0013 - val_acc: 0.9860\n",
      "Epoch 225/3000\n",
      " - 1s - loss: 0.0014 - acc: 0.9862 - val_loss: 0.0013 - val_acc: 0.9863\n",
      "Epoch 226/3000\n",
      " - 1s - loss: 0.0013 - acc: 0.9865 - val_loss: 0.0013 - val_acc: 0.9859\n",
      "Epoch 227/3000\n",
      " - 1s - loss: 0.0013 - acc: 0.9863 - val_loss: 0.0013 - val_acc: 0.9865\n",
      "Epoch 228/3000\n",
      " - 2s - loss: 0.0014 - acc: 0.9859 - val_loss: 0.0013 - val_acc: 0.9866\n",
      "Epoch 229/3000\n",
      " - 1s - loss: 0.0013 - acc: 0.9862 - val_loss: 0.0013 - val_acc: 0.9861\n",
      "Epoch 230/3000\n",
      " - 1s - loss: 0.0013 - acc: 0.9866 - val_loss: 0.0013 - val_acc: 0.9865\n",
      "Epoch 231/3000\n",
      " - 1s - loss: 0.0013 - acc: 0.9866 - val_loss: 0.0013 - val_acc: 0.9864\n",
      "Epoch 232/3000\n",
      " - 1s - loss: 0.0013 - acc: 0.9863 - val_loss: 0.0015 - val_acc: 0.9857\n",
      "Epoch 233/3000\n",
      " - 2s - loss: 0.0013 - acc: 0.9863 - val_loss: 0.0013 - val_acc: 0.9865\n",
      "Epoch 234/3000\n",
      " - 2s - loss: 0.0013 - acc: 0.9862 - val_loss: 0.0013 - val_acc: 0.9867\n",
      "Epoch 235/3000\n",
      " - 2s - loss: 0.0013 - acc: 0.9865 - val_loss: 0.0012 - val_acc: 0.9865\n",
      "Epoch 236/3000\n",
      " - 1s - loss: 0.0013 - acc: 0.9866 - val_loss: 0.0012 - val_acc: 0.9866\n",
      "Epoch 237/3000\n",
      " - 2s - loss: 0.0013 - acc: 0.9865 - val_loss: 0.0013 - val_acc: 0.9860\n",
      "Epoch 238/3000\n",
      " - 1s - loss: 0.0013 - acc: 0.9866 - val_loss: 0.0013 - val_acc: 0.9867\n",
      "Epoch 239/3000\n",
      " - 2s - loss: 0.0013 - acc: 0.9865 - val_loss: 0.0012 - val_acc: 0.9872\n",
      "Epoch 240/3000\n",
      "\n",
      "Epoch 00240: val_loss improved from 0.00146 to 0.00121, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 0.0013 - acc: 0.9864 - val_loss: 0.0012 - val_acc: 0.9867\n",
      "Epoch 241/3000\n",
      " - 1s - loss: 0.0013 - acc: 0.9865 - val_loss: 0.0014 - val_acc: 0.9859\n",
      "Epoch 242/3000\n",
      " - 2s - loss: 0.0013 - acc: 0.9863 - val_loss: 0.0012 - val_acc: 0.9869\n",
      "Epoch 243/3000\n",
      " - 2s - loss: 0.0013 - acc: 0.9865 - val_loss: 0.0013 - val_acc: 0.9859\n",
      "Epoch 244/3000\n",
      " - 1s - loss: 0.0013 - acc: 0.9867 - val_loss: 0.0013 - val_acc: 0.9863\n",
      "Epoch 245/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9866 - val_loss: 0.0012 - val_acc: 0.9866\n",
      "Epoch 246/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9867 - val_loss: 0.0012 - val_acc: 0.9869\n",
      "Epoch 247/3000\n",
      " - 1s - loss: 0.0013 - acc: 0.9866 - val_loss: 0.0012 - val_acc: 0.9869\n",
      "Epoch 248/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9868 - val_loss: 0.0012 - val_acc: 0.9873\n",
      "Epoch 249/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9867 - val_loss: 0.0012 - val_acc: 0.9867\n",
      "Epoch 250/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9868 - val_loss: 0.0012 - val_acc: 0.9865\n",
      "Epoch 251/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9868 - val_loss: 0.0012 - val_acc: 0.9867\n",
      "Epoch 252/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9867 - val_loss: 0.0012 - val_acc: 0.9867\n",
      "Epoch 253/3000\n",
      " - 1s - loss: 0.0013 - acc: 0.9864 - val_loss: 0.0013 - val_acc: 0.9859\n",
      "Epoch 254/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9868 - val_loss: 0.0012 - val_acc: 0.9869\n",
      "Epoch 255/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9868 - val_loss: 0.0012 - val_acc: 0.9859\n",
      "Epoch 256/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9869 - val_loss: 0.0012 - val_acc: 0.9864\n",
      "Epoch 257/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9868 - val_loss: 0.0012 - val_acc: 0.9874\n",
      "Epoch 258/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9865 - val_loss: 0.0012 - val_acc: 0.9871\n",
      "Epoch 259/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9867 - val_loss: 0.0012 - val_acc: 0.9868\n",
      "Epoch 260/3000\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.00121\n",
      " - 1s - loss: 0.0012 - acc: 0.9868 - val_loss: 0.0012 - val_acc: 0.9863\n",
      "Epoch 261/3000\n",
      " - 1s - loss: 0.0013 - acc: 0.9864 - val_loss: 0.0012 - val_acc: 0.9859\n",
      "Epoch 262/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9869 - val_loss: 0.0011 - val_acc: 0.9871\n",
      "Epoch 263/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9870 - val_loss: 0.0012 - val_acc: 0.9867\n",
      "Epoch 264/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9870 - val_loss: 0.0012 - val_acc: 0.9870\n",
      "Epoch 265/3000\n",
      " - 2s - loss: 0.0012 - acc: 0.9871 - val_loss: 0.0011 - val_acc: 0.9866\n",
      "Epoch 266/3000\n",
      " - 2s - loss: 0.0012 - acc: 0.9868 - val_loss: 0.0012 - val_acc: 0.9876\n",
      "Epoch 267/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9869 - val_loss: 0.0012 - val_acc: 0.9867\n",
      "Epoch 268/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9870 - val_loss: 0.0012 - val_acc: 0.9867\n",
      "Epoch 269/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9870 - val_loss: 0.0012 - val_acc: 0.9864\n",
      "Epoch 270/3000\n",
      " - 2s - loss: 0.0012 - acc: 0.9869 - val_loss: 0.0012 - val_acc: 0.9872\n",
      "Epoch 271/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9870 - val_loss: 0.0013 - val_acc: 0.9863\n",
      "Epoch 272/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9869 - val_loss: 0.0011 - val_acc: 0.9873\n",
      "Epoch 273/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9868 - val_loss: 0.0012 - val_acc: 0.9869\n",
      "Epoch 274/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9870 - val_loss: 0.0011 - val_acc: 0.9870\n",
      "Epoch 275/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9870 - val_loss: 0.0011 - val_acc: 0.9869\n",
      "Epoch 276/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9869 - val_loss: 0.0012 - val_acc: 0.9867\n",
      "Epoch 277/3000\n",
      " - 2s - loss: 0.0012 - acc: 0.9870 - val_loss: 0.0011 - val_acc: 0.9874\n",
      "Epoch 278/3000\n",
      " - 2s - loss: 0.0011 - acc: 0.9872 - val_loss: 0.0012 - val_acc: 0.9863\n",
      "Epoch 279/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9870 - val_loss: 0.0011 - val_acc: 0.9873\n",
      "Epoch 280/3000\n",
      "\n",
      "Epoch 00280: val_loss improved from 0.00121 to 0.00109, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 0.0012 - acc: 0.9870 - val_loss: 0.0011 - val_acc: 0.9878\n",
      "Epoch 281/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9873 - val_loss: 0.0012 - val_acc: 0.9862\n",
      "Epoch 282/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9871 - val_loss: 0.0012 - val_acc: 0.9874\n",
      "Epoch 283/3000\n",
      " - 2s - loss: 0.0011 - acc: 0.9872 - val_loss: 0.0012 - val_acc: 0.9869\n",
      "Epoch 284/3000\n",
      " - 1s - loss: 0.0012 - acc: 0.9870 - val_loss: 0.0012 - val_acc: 0.9871\n",
      "Epoch 285/3000\n",
      " - 2s - loss: 0.0012 - acc: 0.9869 - val_loss: 0.0012 - val_acc: 0.9870\n",
      "Epoch 286/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9871 - val_loss: 0.0011 - val_acc: 0.9871\n",
      "Epoch 287/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9873 - val_loss: 0.0011 - val_acc: 0.9879\n",
      "Epoch 288/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9874 - val_loss: 0.0011 - val_acc: 0.9872\n",
      "Epoch 289/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9872 - val_loss: 0.0011 - val_acc: 0.9870\n",
      "Epoch 290/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9873 - val_loss: 0.0011 - val_acc: 0.9874\n",
      "Epoch 291/3000\n",
      " - 2s - loss: 0.0011 - acc: 0.9871 - val_loss: 0.0011 - val_acc: 0.9876\n",
      "Epoch 292/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9872 - val_loss: 0.0011 - val_acc: 0.9877\n",
      "Epoch 293/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9872 - val_loss: 0.0011 - val_acc: 0.9874\n",
      "Epoch 294/3000\n",
      " - 2s - loss: 0.0011 - acc: 0.9873 - val_loss: 0.0011 - val_acc: 0.9872\n",
      "Epoch 295/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9871 - val_loss: 0.0011 - val_acc: 0.9868\n",
      "Epoch 296/3000\n",
      " - 2s - loss: 0.0011 - acc: 0.9871 - val_loss: 0.0011 - val_acc: 0.9871\n",
      "Epoch 297/3000\n",
      " - 2s - loss: 0.0011 - acc: 0.9873 - val_loss: 0.0011 - val_acc: 0.9873\n",
      "Epoch 298/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9874 - val_loss: 0.0011 - val_acc: 0.9875\n",
      "Epoch 299/3000\n",
      " - 2s - loss: 0.0011 - acc: 0.9873 - val_loss: 0.0011 - val_acc: 0.9873\n",
      "Epoch 300/3000\n",
      "\n",
      "Epoch 00300: val_loss improved from 0.00109 to 0.00104, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 0.0011 - acc: 0.9875 - val_loss: 0.0010 - val_acc: 0.9875\n",
      "Epoch 301/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9873 - val_loss: 0.0011 - val_acc: 0.9870\n",
      "Epoch 302/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9872 - val_loss: 0.0012 - val_acc: 0.9878\n",
      "Epoch 303/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9873 - val_loss: 0.0010 - val_acc: 0.9878\n",
      "Epoch 304/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9875 - val_loss: 0.0011 - val_acc: 0.9869\n",
      "Epoch 305/3000\n",
      " - 2s - loss: 0.0011 - acc: 0.9870 - val_loss: 0.0010 - val_acc: 0.9880\n",
      "Epoch 306/3000\n",
      " - 2s - loss: 0.0011 - acc: 0.9875 - val_loss: 0.0011 - val_acc: 0.9877\n",
      "Epoch 307/3000\n",
      " - 2s - loss: 0.0011 - acc: 0.9875 - val_loss: 0.0010 - val_acc: 0.9883\n",
      "Epoch 308/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9877 - val_loss: 0.0010 - val_acc: 0.9874\n",
      "Epoch 309/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9875 - val_loss: 0.0011 - val_acc: 0.9869\n",
      "Epoch 310/3000\n",
      " - 2s - loss: 0.0011 - acc: 0.9875 - val_loss: 0.0010 - val_acc: 0.9876\n",
      "Epoch 311/3000\n",
      " - 2s - loss: 0.0011 - acc: 0.9874 - val_loss: 0.0011 - val_acc: 0.9878\n",
      "Epoch 312/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9875 - val_loss: 0.0010 - val_acc: 0.9876\n",
      "Epoch 313/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9874 - val_loss: 0.0010 - val_acc: 0.9878\n",
      "Epoch 314/3000\n",
      " - 1s - loss: 0.0010 - acc: 0.9875 - val_loss: 0.0011 - val_acc: 0.9874\n",
      "Epoch 315/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9876 - val_loss: 0.0011 - val_acc: 0.9878\n",
      "Epoch 316/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9876 - val_loss: 0.0010 - val_acc: 0.9869\n",
      "Epoch 317/3000\n",
      " - 2s - loss: 0.0011 - acc: 0.9873 - val_loss: 0.0011 - val_acc: 0.9874\n",
      "Epoch 318/3000\n",
      " - 2s - loss: 0.0011 - acc: 0.9876 - val_loss: 0.0010 - val_acc: 0.9872\n",
      "Epoch 319/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9876 - val_loss: 0.0010 - val_acc: 0.9877\n",
      "Epoch 320/3000\n",
      "\n",
      "Epoch 00320: val_loss improved from 0.00104 to 0.00101, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 0.0011 - acc: 0.9876 - val_loss: 0.0010 - val_acc: 0.9877\n",
      "Epoch 321/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9875 - val_loss: 0.0010 - val_acc: 0.9876\n",
      "Epoch 322/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9876 - val_loss: 0.0010 - val_acc: 0.9877\n",
      "Epoch 323/3000\n",
      " - 2s - loss: 0.0010 - acc: 0.9877 - val_loss: 9.9156e-04 - val_acc: 0.9875\n",
      "Epoch 324/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9873 - val_loss: 0.0012 - val_acc: 0.9863\n",
      "Epoch 325/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9875 - val_loss: 0.0010 - val_acc: 0.9879\n",
      "Epoch 326/3000\n",
      " - 1s - loss: 0.0010 - acc: 0.9876 - val_loss: 0.0011 - val_acc: 0.9878\n",
      "Epoch 327/3000\n",
      " - 1s - loss: 0.0010 - acc: 0.9876 - val_loss: 0.0010 - val_acc: 0.9876\n",
      "Epoch 328/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9876 - val_loss: 0.0010 - val_acc: 0.9879\n",
      "Epoch 329/3000\n",
      " - 1s - loss: 0.0010 - acc: 0.9878 - val_loss: 0.0011 - val_acc: 0.9876\n",
      "Epoch 330/3000\n",
      " - 1s - loss: 0.0010 - acc: 0.9876 - val_loss: 0.0010 - val_acc: 0.9873\n",
      "Epoch 331/3000\n",
      " - 1s - loss: 0.0010 - acc: 0.9877 - val_loss: 9.9076e-04 - val_acc: 0.9880\n",
      "Epoch 332/3000\n",
      " - 1s - loss: 0.0010 - acc: 0.9879 - val_loss: 0.0010 - val_acc: 0.9878\n",
      "Epoch 333/3000\n",
      " - 1s - loss: 0.0010 - acc: 0.9878 - val_loss: 0.0010 - val_acc: 0.9877\n",
      "Epoch 334/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9876 - val_loss: 0.0011 - val_acc: 0.9876\n",
      "Epoch 335/3000\n",
      " - 1s - loss: 0.0010 - acc: 0.9876 - val_loss: 0.0011 - val_acc: 0.9875\n",
      "Epoch 336/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9874 - val_loss: 0.0010 - val_acc: 0.9875\n",
      "Epoch 337/3000\n",
      " - 1s - loss: 0.0010 - acc: 0.9876 - val_loss: 0.0010 - val_acc: 0.9880\n",
      "Epoch 338/3000\n",
      " - 1s - loss: 0.0010 - acc: 0.9879 - val_loss: 0.0010 - val_acc: 0.9881\n",
      "Epoch 339/3000\n",
      " - 1s - loss: 0.0010 - acc: 0.9879 - val_loss: 9.8590e-04 - val_acc: 0.9880\n",
      "Epoch 340/3000\n",
      "\n",
      "Epoch 00340: val_loss improved from 0.00101 to 0.00100, saving model to ./weights.best.cntk.hdf5\n",
      " - 1s - loss: 0.0010 - acc: 0.9876 - val_loss: 9.9765e-04 - val_acc: 0.9879\n",
      "Epoch 341/3000\n",
      " - 1s - loss: 0.0010 - acc: 0.9877 - val_loss: 0.0010 - val_acc: 0.9874\n",
      "Epoch 342/3000\n",
      " - 1s - loss: 0.0010 - acc: 0.9877 - val_loss: 0.0010 - val_acc: 0.9878\n",
      "Epoch 343/3000\n",
      " - 1s - loss: 0.0010 - acc: 0.9875 - val_loss: 9.5897e-04 - val_acc: 0.9884\n",
      "Epoch 344/3000\n",
      " - 1s - loss: 0.0010 - acc: 0.9879 - val_loss: 9.7436e-04 - val_acc: 0.9881\n",
      "Epoch 345/3000\n",
      " - 1s - loss: 9.9890e-04 - acc: 0.9877 - val_loss: 9.5921e-04 - val_acc: 0.9880\n",
      "Epoch 346/3000\n",
      " - 1s - loss: 0.0010 - acc: 0.9878 - val_loss: 9.4840e-04 - val_acc: 0.9882\n",
      "Epoch 347/3000\n",
      " - 1s - loss: 0.0011 - acc: 0.9874 - val_loss: 0.0010 - val_acc: 0.9878\n",
      "Epoch 348/3000\n",
      " - 1s - loss: 0.0010 - acc: 0.9879 - val_loss: 9.6009e-04 - val_acc: 0.9880\n",
      "Epoch 349/3000\n",
      " - 1s - loss: 9.7121e-04 - acc: 0.9881 - val_loss: 9.8883e-04 - val_acc: 0.9879\n",
      "Epoch 350/3000\n",
      " - 2s - loss: 0.0010 - acc: 0.9877 - val_loss: 9.7086e-04 - val_acc: 0.9877\n",
      "Epoch 351/3000\n",
      " - 2s - loss: 0.0010 - acc: 0.9878 - val_loss: 9.9135e-04 - val_acc: 0.9879\n",
      "Epoch 352/3000\n",
      " - 2s - loss: 0.0010 - acc: 0.9878 - val_loss: 9.4476e-04 - val_acc: 0.9883\n",
      "Epoch 353/3000\n",
      " - 1s - loss: 9.7807e-04 - acc: 0.9880 - val_loss: 9.5600e-04 - val_acc: 0.9884\n",
      "Epoch 354/3000\n",
      " - 1s - loss: 9.8295e-04 - acc: 0.9880 - val_loss: 0.0010 - val_acc: 0.9876\n",
      "Epoch 355/3000\n",
      " - 2s - loss: 9.6975e-04 - acc: 0.9880 - val_loss: 9.9930e-04 - val_acc: 0.9880\n",
      "Epoch 356/3000\n",
      " - 1s - loss: 9.9519e-04 - acc: 0.9878 - val_loss: 9.8649e-04 - val_acc: 0.9882\n",
      "Epoch 357/3000\n",
      " - 2s - loss: 9.6847e-04 - acc: 0.9881 - val_loss: 9.9060e-04 - val_acc: 0.9875\n",
      "Epoch 358/3000\n",
      " - 2s - loss: 9.7290e-04 - acc: 0.9880 - val_loss: 9.6561e-04 - val_acc: 0.9883\n",
      "Epoch 359/3000\n",
      " - 1s - loss: 9.7043e-04 - acc: 0.9881 - val_loss: 9.3639e-04 - val_acc: 0.9882\n",
      "Epoch 360/3000\n",
      "\n",
      "Epoch 00360: val_loss improved from 0.00100 to 0.00095, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 9.6848e-04 - acc: 0.9881 - val_loss: 9.5096e-04 - val_acc: 0.9883\n",
      "Epoch 361/3000\n",
      " - 2s - loss: 9.5498e-04 - acc: 0.9881 - val_loss: 9.5206e-04 - val_acc: 0.9883\n",
      "Epoch 362/3000\n",
      " - 1s - loss: 9.6038e-04 - acc: 0.9881 - val_loss: 9.4801e-04 - val_acc: 0.9883\n",
      "Epoch 363/3000\n",
      " - 1s - loss: 9.7249e-04 - acc: 0.9879 - val_loss: 9.4497e-04 - val_acc: 0.9881\n",
      "Epoch 364/3000\n",
      " - 2s - loss: 9.9808e-04 - acc: 0.9879 - val_loss: 0.0010 - val_acc: 0.9871\n",
      "Epoch 365/3000\n",
      " - 1s - loss: 9.7092e-04 - acc: 0.9880 - val_loss: 9.5053e-04 - val_acc: 0.9879\n",
      "Epoch 366/3000\n",
      " - 1s - loss: 9.6654e-04 - acc: 0.9881 - val_loss: 9.5523e-04 - val_acc: 0.9875\n",
      "Epoch 367/3000\n",
      " - 1s - loss: 9.5799e-04 - acc: 0.9880 - val_loss: 9.3731e-04 - val_acc: 0.9880\n",
      "Epoch 368/3000\n",
      " - 2s - loss: 9.7253e-04 - acc: 0.9880 - val_loss: 9.4436e-04 - val_acc: 0.9879\n",
      "Epoch 369/3000\n",
      " - 2s - loss: 9.4760e-04 - acc: 0.9882 - val_loss: 9.2611e-04 - val_acc: 0.9880\n",
      "Epoch 370/3000\n",
      " - 1s - loss: 9.6304e-04 - acc: 0.9882 - val_loss: 9.8382e-04 - val_acc: 0.9877\n",
      "Epoch 371/3000\n",
      " - 1s - loss: 9.7281e-04 - acc: 0.9880 - val_loss: 9.4544e-04 - val_acc: 0.9876\n",
      "Epoch 372/3000\n",
      " - 1s - loss: 9.5829e-04 - acc: 0.9881 - val_loss: 9.4795e-04 - val_acc: 0.9885\n",
      "Epoch 373/3000\n",
      " - 1s - loss: 9.5697e-04 - acc: 0.9880 - val_loss: 9.1130e-04 - val_acc: 0.9884\n",
      "Epoch 374/3000\n",
      " - 2s - loss: 9.3006e-04 - acc: 0.9883 - val_loss: 9.6225e-04 - val_acc: 0.9884\n",
      "Epoch 375/3000\n",
      " - 1s - loss: 9.4069e-04 - acc: 0.9882 - val_loss: 9.3719e-04 - val_acc: 0.9881\n",
      "Epoch 376/3000\n",
      " - 1s - loss: 9.4426e-04 - acc: 0.9881 - val_loss: 9.6600e-04 - val_acc: 0.9882\n",
      "Epoch 377/3000\n",
      " - 1s - loss: 9.6429e-04 - acc: 0.9881 - val_loss: 9.7306e-04 - val_acc: 0.9880\n",
      "Epoch 378/3000\n",
      " - 1s - loss: 0.0010 - acc: 0.9877 - val_loss: 0.0010 - val_acc: 0.9882\n",
      "Epoch 379/3000\n",
      " - 1s - loss: 9.5472e-04 - acc: 0.9880 - val_loss: 9.4821e-04 - val_acc: 0.9878\n",
      "Epoch 380/3000\n",
      "\n",
      "Epoch 00380: val_loss improved from 0.00095 to 0.00092, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 9.5244e-04 - acc: 0.9879 - val_loss: 9.1951e-04 - val_acc: 0.9883\n",
      "Epoch 381/3000\n",
      " - 1s - loss: 9.3082e-04 - acc: 0.9882 - val_loss: 9.1882e-04 - val_acc: 0.9876\n",
      "Epoch 382/3000\n",
      " - 1s - loss: 9.4213e-04 - acc: 0.9881 - val_loss: 8.9236e-04 - val_acc: 0.9886\n",
      "Epoch 383/3000\n",
      " - 1s - loss: 9.2582e-04 - acc: 0.9884 - val_loss: 0.0011 - val_acc: 0.9874\n",
      "Epoch 384/3000\n",
      " - 1s - loss: 9.5821e-04 - acc: 0.9880 - val_loss: 9.4573e-04 - val_acc: 0.9880\n",
      "Epoch 385/3000\n",
      " - 1s - loss: 9.4952e-04 - acc: 0.9881 - val_loss: 0.0010 - val_acc: 0.9882\n",
      "Epoch 386/3000\n",
      " - 2s - loss: 9.3894e-04 - acc: 0.9882 - val_loss: 9.2314e-04 - val_acc: 0.9878\n",
      "Epoch 387/3000\n",
      " - 2s - loss: 9.2159e-04 - acc: 0.9883 - val_loss: 9.2662e-04 - val_acc: 0.9885\n",
      "Epoch 388/3000\n",
      " - 2s - loss: 9.1955e-04 - acc: 0.9883 - val_loss: 9.2515e-04 - val_acc: 0.9879\n",
      "Epoch 389/3000\n",
      " - 1s - loss: 9.2237e-04 - acc: 0.9883 - val_loss: 0.0010 - val_acc: 0.9885\n",
      "Epoch 390/3000\n",
      " - 1s - loss: 9.4095e-04 - acc: 0.9882 - val_loss: 9.6096e-04 - val_acc: 0.9879\n",
      "Epoch 391/3000\n",
      " - 1s - loss: 9.4156e-04 - acc: 0.9882 - val_loss: 8.8704e-04 - val_acc: 0.9882\n",
      "Epoch 392/3000\n",
      " - 2s - loss: 9.1323e-04 - acc: 0.9883 - val_loss: 9.1638e-04 - val_acc: 0.9885\n",
      "Epoch 393/3000\n",
      " - 2s - loss: 9.2915e-04 - acc: 0.9883 - val_loss: 9.1552e-04 - val_acc: 0.9876\n",
      "Epoch 394/3000\n",
      " - 1s - loss: 9.3994e-04 - acc: 0.9881 - val_loss: 9.3757e-04 - val_acc: 0.9877\n",
      "Epoch 395/3000\n",
      " - 1s - loss: 9.2837e-04 - acc: 0.9882 - val_loss: 9.3728e-04 - val_acc: 0.9883\n",
      "Epoch 396/3000\n",
      " - 1s - loss: 9.2270e-04 - acc: 0.9883 - val_loss: 8.8687e-04 - val_acc: 0.9881\n",
      "Epoch 397/3000\n",
      " - 1s - loss: 9.2134e-04 - acc: 0.9882 - val_loss: 8.9869e-04 - val_acc: 0.9883\n",
      "Epoch 398/3000\n",
      " - 1s - loss: 9.2161e-04 - acc: 0.9882 - val_loss: 9.0578e-04 - val_acc: 0.9880\n",
      "Epoch 399/3000\n",
      " - 1s - loss: 8.9910e-04 - acc: 0.9885 - val_loss: 9.1516e-04 - val_acc: 0.9883\n",
      "Epoch 400/3000\n",
      "\n",
      "Epoch 00400: val_loss improved from 0.00092 to 0.00092, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 9.0771e-04 - acc: 0.9884 - val_loss: 9.1720e-04 - val_acc: 0.9885\n",
      "Epoch 401/3000\n",
      " - 1s - loss: 9.0728e-04 - acc: 0.9884 - val_loss: 8.7123e-04 - val_acc: 0.9886\n",
      "Epoch 402/3000\n",
      " - 1s - loss: 9.1152e-04 - acc: 0.9883 - val_loss: 8.7033e-04 - val_acc: 0.9887\n",
      "Epoch 403/3000\n",
      " - 1s - loss: 9.0140e-04 - acc: 0.9885 - val_loss: 8.8381e-04 - val_acc: 0.9886\n",
      "Epoch 404/3000\n",
      " - 1s - loss: 8.9474e-04 - acc: 0.9885 - val_loss: 8.7934e-04 - val_acc: 0.9883\n",
      "Epoch 405/3000\n",
      " - 2s - loss: 8.9805e-04 - acc: 0.9884 - val_loss: 8.8073e-04 - val_acc: 0.9884\n",
      "Epoch 406/3000\n",
      " - 2s - loss: 9.0786e-04 - acc: 0.9883 - val_loss: 8.9398e-04 - val_acc: 0.9884\n",
      "Epoch 407/3000\n",
      " - 1s - loss: 9.0006e-04 - acc: 0.9883 - val_loss: 9.3882e-04 - val_acc: 0.9882\n",
      "Epoch 408/3000\n",
      " - 1s - loss: 9.0855e-04 - acc: 0.9883 - val_loss: 8.8948e-04 - val_acc: 0.9885\n",
      "Epoch 409/3000\n",
      " - 1s - loss: 9.2126e-04 - acc: 0.9882 - val_loss: 8.9812e-04 - val_acc: 0.9880\n",
      "Epoch 410/3000\n",
      " - 1s - loss: 8.9692e-04 - acc: 0.9884 - val_loss: 8.7436e-04 - val_acc: 0.9883\n",
      "Epoch 411/3000\n",
      " - 1s - loss: 9.2212e-04 - acc: 0.9882 - val_loss: 9.0826e-04 - val_acc: 0.9881\n",
      "Epoch 412/3000\n",
      " - 1s - loss: 8.9406e-04 - acc: 0.9884 - val_loss: 8.7046e-04 - val_acc: 0.9887\n",
      "Epoch 413/3000\n",
      " - 1s - loss: 8.7604e-04 - acc: 0.9887 - val_loss: 8.8825e-04 - val_acc: 0.9885\n",
      "Epoch 414/3000\n",
      " - 2s - loss: 9.0840e-04 - acc: 0.9883 - val_loss: 8.9922e-04 - val_acc: 0.9885\n",
      "Epoch 415/3000\n",
      " - 1s - loss: 8.9636e-04 - acc: 0.9884 - val_loss: 9.0252e-04 - val_acc: 0.9880\n",
      "Epoch 416/3000\n",
      " - 1s - loss: 8.9927e-04 - acc: 0.9885 - val_loss: 8.9608e-04 - val_acc: 0.9883\n",
      "Epoch 417/3000\n",
      " - 1s - loss: 8.8607e-04 - acc: 0.9885 - val_loss: 8.5277e-04 - val_acc: 0.9886\n",
      "Epoch 418/3000\n",
      " - 1s - loss: 8.9012e-04 - acc: 0.9885 - val_loss: 8.6118e-04 - val_acc: 0.9885\n",
      "Epoch 419/3000\n",
      " - 1s - loss: 8.8902e-04 - acc: 0.9884 - val_loss: 8.5087e-04 - val_acc: 0.9888\n",
      "Epoch 420/3000\n",
      "\n",
      "Epoch 00420: val_loss improved from 0.00092 to 0.00087, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 8.7876e-04 - acc: 0.9886 - val_loss: 8.6640e-04 - val_acc: 0.9885\n",
      "Epoch 421/3000\n",
      " - 1s - loss: 8.8522e-04 - acc: 0.9885 - val_loss: 8.6930e-04 - val_acc: 0.9889\n",
      "Epoch 422/3000\n",
      " - 2s - loss: 8.9814e-04 - acc: 0.9885 - val_loss: 8.7587e-04 - val_acc: 0.9886\n",
      "Epoch 423/3000\n",
      " - 1s - loss: 8.6711e-04 - acc: 0.9887 - val_loss: 8.3421e-04 - val_acc: 0.9887\n",
      "Epoch 424/3000\n",
      " - 2s - loss: 8.7958e-04 - acc: 0.9886 - val_loss: 9.0182e-04 - val_acc: 0.9884\n",
      "Epoch 425/3000\n",
      " - 1s - loss: 8.9431e-04 - acc: 0.9884 - val_loss: 9.0313e-04 - val_acc: 0.9884\n",
      "Epoch 426/3000\n",
      " - 1s - loss: 8.7834e-04 - acc: 0.9886 - val_loss: 8.5880e-04 - val_acc: 0.9886\n",
      "Epoch 427/3000\n",
      " - 1s - loss: 8.8436e-04 - acc: 0.9885 - val_loss: 8.6395e-04 - val_acc: 0.9882\n",
      "Epoch 428/3000\n",
      " - 1s - loss: 8.7704e-04 - acc: 0.9885 - val_loss: 9.1221e-04 - val_acc: 0.9887\n",
      "Epoch 429/3000\n",
      " - 1s - loss: 8.7831e-04 - acc: 0.9884 - val_loss: 8.4412e-04 - val_acc: 0.9888\n",
      "Epoch 430/3000\n",
      " - 1s - loss: 8.9513e-04 - acc: 0.9884 - val_loss: 8.9798e-04 - val_acc: 0.9884\n",
      "Epoch 431/3000\n",
      " - 1s - loss: 8.8138e-04 - acc: 0.9886 - val_loss: 8.7039e-04 - val_acc: 0.9885\n",
      "Epoch 432/3000\n",
      " - 1s - loss: 8.7675e-04 - acc: 0.9885 - val_loss: 8.3639e-04 - val_acc: 0.9887\n",
      "Epoch 433/3000\n",
      " - 2s - loss: 8.8001e-04 - acc: 0.9885 - val_loss: 8.6850e-04 - val_acc: 0.9885\n",
      "Epoch 434/3000\n",
      " - 1s - loss: 8.8920e-04 - acc: 0.9884 - val_loss: 8.9608e-04 - val_acc: 0.9885\n",
      "Epoch 435/3000\n",
      " - 2s - loss: 8.8222e-04 - acc: 0.9886 - val_loss: 8.7910e-04 - val_acc: 0.9880\n",
      "Epoch 436/3000\n",
      " - 1s - loss: 8.8637e-04 - acc: 0.9884 - val_loss: 8.7239e-04 - val_acc: 0.9888\n",
      "Epoch 437/3000\n",
      " - 1s - loss: 8.7798e-04 - acc: 0.9885 - val_loss: 8.5402e-04 - val_acc: 0.9885\n",
      "Epoch 438/3000\n",
      " - 2s - loss: 8.6096e-04 - acc: 0.9886 - val_loss: 8.5771e-04 - val_acc: 0.9891\n",
      "Epoch 439/3000\n",
      " - 1s - loss: 8.8056e-04 - acc: 0.9886 - val_loss: 8.5675e-04 - val_acc: 0.9880\n",
      "Epoch 440/3000\n",
      "\n",
      "Epoch 00440: val_loss improved from 0.00087 to 0.00083, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 8.6107e-04 - acc: 0.9886 - val_loss: 8.2926e-04 - val_acc: 0.9889\n",
      "Epoch 441/3000\n",
      " - 1s - loss: 8.6001e-04 - acc: 0.9886 - val_loss: 8.6087e-04 - val_acc: 0.9889\n",
      "Epoch 442/3000\n",
      " - 2s - loss: 8.7394e-04 - acc: 0.9886 - val_loss: 8.4318e-04 - val_acc: 0.9886\n",
      "Epoch 443/3000\n",
      " - 2s - loss: 8.7863e-04 - acc: 0.9885 - val_loss: 8.7575e-04 - val_acc: 0.9886\n",
      "Epoch 444/3000\n",
      " - 2s - loss: 8.5832e-04 - acc: 0.9887 - val_loss: 8.4514e-04 - val_acc: 0.9890\n",
      "Epoch 445/3000\n",
      " - 1s - loss: 8.6260e-04 - acc: 0.9886 - val_loss: 8.3076e-04 - val_acc: 0.9888\n",
      "Epoch 446/3000\n",
      " - 1s - loss: 8.5379e-04 - acc: 0.9887 - val_loss: 8.3249e-04 - val_acc: 0.9890\n",
      "Epoch 447/3000\n",
      " - 1s - loss: 8.4948e-04 - acc: 0.9887 - val_loss: 8.1586e-04 - val_acc: 0.9890\n",
      "Epoch 448/3000\n",
      " - 1s - loss: 8.5033e-04 - acc: 0.9887 - val_loss: 8.3687e-04 - val_acc: 0.9888\n",
      "Epoch 449/3000\n",
      " - 1s - loss: 8.7475e-04 - acc: 0.9885 - val_loss: 8.2311e-04 - val_acc: 0.9889\n",
      "Epoch 450/3000\n",
      " - 1s - loss: 8.6356e-04 - acc: 0.9886 - val_loss: 8.6520e-04 - val_acc: 0.9881\n",
      "Epoch 451/3000\n",
      " - 1s - loss: 8.7089e-04 - acc: 0.9884 - val_loss: 9.7878e-04 - val_acc: 0.9877\n",
      "Epoch 452/3000\n",
      " - 1s - loss: 8.7694e-04 - acc: 0.9885 - val_loss: 8.4614e-04 - val_acc: 0.9881\n",
      "Epoch 453/3000\n",
      " - 1s - loss: 8.7493e-04 - acc: 0.9883 - val_loss: 8.6388e-04 - val_acc: 0.9886\n",
      "Epoch 454/3000\n",
      " - 1s - loss: 8.4240e-04 - acc: 0.9887 - val_loss: 8.8176e-04 - val_acc: 0.9890\n",
      "Epoch 455/3000\n",
      " - 1s - loss: 8.5309e-04 - acc: 0.9887 - val_loss: 8.5039e-04 - val_acc: 0.9888\n",
      "Epoch 456/3000\n",
      " - 1s - loss: 8.5744e-04 - acc: 0.9886 - val_loss: 8.1868e-04 - val_acc: 0.9888\n",
      "Epoch 457/3000\n",
      " - 1s - loss: 8.5981e-04 - acc: 0.9886 - val_loss: 8.1892e-04 - val_acc: 0.9885\n",
      "Epoch 458/3000\n",
      " - 1s - loss: 8.4444e-04 - acc: 0.9887 - val_loss: 8.2527e-04 - val_acc: 0.9889\n",
      "Epoch 459/3000\n",
      " - 1s - loss: 8.3140e-04 - acc: 0.9889 - val_loss: 8.1760e-04 - val_acc: 0.9890\n",
      "Epoch 460/3000\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.00083\n",
      " - 1s - loss: 8.4939e-04 - acc: 0.9887 - val_loss: 8.5957e-04 - val_acc: 0.9893\n",
      "Epoch 461/3000\n",
      " - 1s - loss: 8.6374e-04 - acc: 0.9885 - val_loss: 8.4393e-04 - val_acc: 0.9883\n",
      "Epoch 462/3000\n",
      " - 1s - loss: 8.5006e-04 - acc: 0.9888 - val_loss: 8.1230e-04 - val_acc: 0.9887\n",
      "Epoch 463/3000\n",
      " - 1s - loss: 8.3843e-04 - acc: 0.9887 - val_loss: 8.3405e-04 - val_acc: 0.9887\n",
      "Epoch 464/3000\n",
      " - 1s - loss: 8.5417e-04 - acc: 0.9887 - val_loss: 8.5442e-04 - val_acc: 0.9882\n",
      "Epoch 465/3000\n",
      " - 1s - loss: 8.3752e-04 - acc: 0.9887 - val_loss: 8.3479e-04 - val_acc: 0.9888\n",
      "Epoch 466/3000\n",
      " - 1s - loss: 8.2265e-04 - acc: 0.9888 - val_loss: 9.0377e-04 - val_acc: 0.9884\n",
      "Epoch 467/3000\n",
      " - 1s - loss: 8.3797e-04 - acc: 0.9888 - val_loss: 8.6436e-04 - val_acc: 0.9884\n",
      "Epoch 468/3000\n",
      " - 1s - loss: 8.3153e-04 - acc: 0.9888 - val_loss: 8.0537e-04 - val_acc: 0.9887\n",
      "Epoch 469/3000\n",
      " - 1s - loss: 8.2914e-04 - acc: 0.9887 - val_loss: 8.0528e-04 - val_acc: 0.9890\n",
      "Epoch 470/3000\n",
      " - 1s - loss: 8.3904e-04 - acc: 0.9888 - val_loss: 9.3589e-04 - val_acc: 0.9880\n",
      "Epoch 471/3000\n",
      " - 2s - loss: 8.5308e-04 - acc: 0.9885 - val_loss: 8.0554e-04 - val_acc: 0.9891\n",
      "Epoch 472/3000\n",
      " - 1s - loss: 8.5162e-04 - acc: 0.9886 - val_loss: 8.1733e-04 - val_acc: 0.9889\n",
      "Epoch 473/3000\n",
      " - 1s - loss: 8.2817e-04 - acc: 0.9888 - val_loss: 8.1786e-04 - val_acc: 0.9888\n",
      "Epoch 474/3000\n",
      " - 1s - loss: 8.6352e-04 - acc: 0.9886 - val_loss: 8.2769e-04 - val_acc: 0.9891\n",
      "Epoch 475/3000\n",
      " - 2s - loss: 8.2508e-04 - acc: 0.9887 - val_loss: 8.0377e-04 - val_acc: 0.9889\n",
      "Epoch 476/3000\n",
      " - 1s - loss: 8.3372e-04 - acc: 0.9888 - val_loss: 9.1349e-04 - val_acc: 0.9881\n",
      "Epoch 477/3000\n",
      " - 1s - loss: 8.2569e-04 - acc: 0.9887 - val_loss: 8.1374e-04 - val_acc: 0.9891\n",
      "Epoch 478/3000\n",
      " - 1s - loss: 8.5528e-04 - acc: 0.9886 - val_loss: 8.6959e-04 - val_acc: 0.9880\n",
      "Epoch 479/3000\n",
      " - 2s - loss: 8.2558e-04 - acc: 0.9888 - val_loss: 8.1762e-04 - val_acc: 0.9888\n",
      "Epoch 480/3000\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.00083\n",
      " - 2s - loss: 8.2398e-04 - acc: 0.9888 - val_loss: 8.5954e-04 - val_acc: 0.9891\n",
      "Epoch 481/3000\n",
      " - 1s - loss: 8.3026e-04 - acc: 0.9889 - val_loss: 8.1548e-04 - val_acc: 0.9886\n",
      "Epoch 482/3000\n",
      " - 2s - loss: 8.2393e-04 - acc: 0.9888 - val_loss: 8.3419e-04 - val_acc: 0.9889\n",
      "Epoch 483/3000\n",
      " - 1s - loss: 8.2328e-04 - acc: 0.9888 - val_loss: 7.8091e-04 - val_acc: 0.9888\n",
      "Epoch 484/3000\n",
      " - 2s - loss: 8.2070e-04 - acc: 0.9888 - val_loss: 7.8350e-04 - val_acc: 0.9892\n",
      "Epoch 485/3000\n",
      " - 2s - loss: 8.2548e-04 - acc: 0.9889 - val_loss: 8.4629e-04 - val_acc: 0.9886\n",
      "Epoch 486/3000\n",
      " - 2s - loss: 8.5335e-04 - acc: 0.9886 - val_loss: 8.4957e-04 - val_acc: 0.9884\n",
      "Epoch 487/3000\n",
      " - 2s - loss: 8.4183e-04 - acc: 0.9884 - val_loss: 8.5777e-04 - val_acc: 0.9887\n",
      "Epoch 488/3000\n",
      " - 1s - loss: 8.2807e-04 - acc: 0.9887 - val_loss: 7.9177e-04 - val_acc: 0.9886\n",
      "Epoch 489/3000\n",
      " - 1s - loss: 7.9437e-04 - acc: 0.9890 - val_loss: 7.8305e-04 - val_acc: 0.9892\n",
      "Epoch 490/3000\n",
      " - 2s - loss: 8.2224e-04 - acc: 0.9889 - val_loss: 8.4513e-04 - val_acc: 0.9886\n",
      "Epoch 491/3000\n",
      " - 1s - loss: 8.1475e-04 - acc: 0.9889 - val_loss: 7.9363e-04 - val_acc: 0.9889\n",
      "Epoch 492/3000\n",
      " - 1s - loss: 7.9813e-04 - acc: 0.9889 - val_loss: 7.8026e-04 - val_acc: 0.9892\n",
      "Epoch 493/3000\n",
      " - 2s - loss: 8.1109e-04 - acc: 0.9889 - val_loss: 8.1731e-04 - val_acc: 0.9889\n",
      "Epoch 494/3000\n",
      " - 2s - loss: 8.1236e-04 - acc: 0.9889 - val_loss: 8.0012e-04 - val_acc: 0.9885\n",
      "Epoch 495/3000\n",
      " - 1s - loss: 8.1839e-04 - acc: 0.9887 - val_loss: 8.6283e-04 - val_acc: 0.9890\n",
      "Epoch 496/3000\n",
      " - 1s - loss: 8.2534e-04 - acc: 0.9887 - val_loss: 7.7820e-04 - val_acc: 0.9889\n",
      "Epoch 497/3000\n",
      " - 1s - loss: 7.9952e-04 - acc: 0.9890 - val_loss: 8.2378e-04 - val_acc: 0.9890\n",
      "Epoch 498/3000\n",
      " - 1s - loss: 8.1272e-04 - acc: 0.9889 - val_loss: 8.0281e-04 - val_acc: 0.9890\n",
      "Epoch 499/3000\n",
      " - 1s - loss: 8.4097e-04 - acc: 0.9887 - val_loss: 7.9963e-04 - val_acc: 0.9891\n",
      "Epoch 500/3000\n",
      "\n",
      "Epoch 00500: val_loss improved from 0.00083 to 0.00078, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 7.9618e-04 - acc: 0.9891 - val_loss: 7.8336e-04 - val_acc: 0.9892\n",
      "Epoch 501/3000\n",
      " - 1s - loss: 8.1902e-04 - acc: 0.9887 - val_loss: 7.8160e-04 - val_acc: 0.9889\n",
      "Epoch 502/3000\n",
      " - 1s - loss: 8.0500e-04 - acc: 0.9889 - val_loss: 7.9796e-04 - val_acc: 0.9890\n",
      "Epoch 503/3000\n",
      " - 1s - loss: 8.1012e-04 - acc: 0.9888 - val_loss: 7.8625e-04 - val_acc: 0.9891\n",
      "Epoch 504/3000\n",
      " - 1s - loss: 7.9641e-04 - acc: 0.9890 - val_loss: 7.8414e-04 - val_acc: 0.9887\n",
      "Epoch 505/3000\n",
      " - 1s - loss: 7.9698e-04 - acc: 0.9889 - val_loss: 7.8069e-04 - val_acc: 0.9891\n",
      "Epoch 506/3000\n",
      " - 2s - loss: 8.0417e-04 - acc: 0.9889 - val_loss: 8.1720e-04 - val_acc: 0.9891\n",
      "Epoch 507/3000\n",
      " - 2s - loss: 8.0723e-04 - acc: 0.9888 - val_loss: 7.8852e-04 - val_acc: 0.9888\n",
      "Epoch 508/3000\n",
      " - 1s - loss: 7.9840e-04 - acc: 0.9889 - val_loss: 7.8342e-04 - val_acc: 0.9893\n",
      "Epoch 509/3000\n",
      " - 1s - loss: 7.9695e-04 - acc: 0.9889 - val_loss: 8.3568e-04 - val_acc: 0.9881\n",
      "Epoch 510/3000\n",
      " - 2s - loss: 7.8608e-04 - acc: 0.9890 - val_loss: 7.7203e-04 - val_acc: 0.9891\n",
      "Epoch 511/3000\n",
      " - 2s - loss: 7.9083e-04 - acc: 0.9890 - val_loss: 7.7395e-04 - val_acc: 0.9883\n",
      "Epoch 512/3000\n",
      " - 1s - loss: 8.2703e-04 - acc: 0.9885 - val_loss: 7.7481e-04 - val_acc: 0.9890\n",
      "Epoch 513/3000\n",
      " - 2s - loss: 7.9313e-04 - acc: 0.9890 - val_loss: 7.8839e-04 - val_acc: 0.9890\n",
      "Epoch 514/3000\n",
      " - 1s - loss: 7.8911e-04 - acc: 0.9891 - val_loss: 8.1633e-04 - val_acc: 0.9887\n",
      "Epoch 515/3000\n",
      " - 1s - loss: 8.1867e-04 - acc: 0.9888 - val_loss: 7.7886e-04 - val_acc: 0.9889\n",
      "Epoch 516/3000\n",
      " - 1s - loss: 7.9198e-04 - acc: 0.9890 - val_loss: 7.6447e-04 - val_acc: 0.9889\n",
      "Epoch 517/3000\n",
      " - 2s - loss: 7.7901e-04 - acc: 0.9891 - val_loss: 7.6590e-04 - val_acc: 0.9891\n",
      "Epoch 518/3000\n",
      " - 1s - loss: 7.8129e-04 - acc: 0.9891 - val_loss: 8.0610e-04 - val_acc: 0.9889\n",
      "Epoch 519/3000\n",
      " - 1s - loss: 7.7432e-04 - acc: 0.9891 - val_loss: 7.5821e-04 - val_acc: 0.9892\n",
      "Epoch 520/3000\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.00078\n",
      " - 2s - loss: 7.8754e-04 - acc: 0.9890 - val_loss: 8.2847e-04 - val_acc: 0.9891\n",
      "Epoch 521/3000\n",
      " - 1s - loss: 7.9977e-04 - acc: 0.9890 - val_loss: 8.0399e-04 - val_acc: 0.9880\n",
      "Epoch 522/3000\n",
      " - 1s - loss: 8.2334e-04 - acc: 0.9888 - val_loss: 7.7906e-04 - val_acc: 0.9890\n",
      "Epoch 523/3000\n",
      " - 1s - loss: 7.7759e-04 - acc: 0.9891 - val_loss: 7.9074e-04 - val_acc: 0.9890\n",
      "Epoch 524/3000\n",
      " - 2s - loss: 7.7149e-04 - acc: 0.9892 - val_loss: 7.6311e-04 - val_acc: 0.9895\n",
      "Epoch 525/3000\n",
      " - 1s - loss: 7.7643e-04 - acc: 0.9892 - val_loss: 7.9534e-04 - val_acc: 0.9891\n",
      "Epoch 526/3000\n",
      " - 1s - loss: 7.8100e-04 - acc: 0.9892 - val_loss: 8.6789e-04 - val_acc: 0.9889\n",
      "Epoch 527/3000\n",
      " - 1s - loss: 7.9292e-04 - acc: 0.9890 - val_loss: 7.6083e-04 - val_acc: 0.9891\n",
      "Epoch 528/3000\n",
      " - 2s - loss: 7.7464e-04 - acc: 0.9892 - val_loss: 7.8061e-04 - val_acc: 0.9888\n",
      "Epoch 529/3000\n",
      " - 2s - loss: 8.0569e-04 - acc: 0.9888 - val_loss: 8.2632e-04 - val_acc: 0.9891\n",
      "Epoch 530/3000\n",
      " - 2s - loss: 8.0393e-04 - acc: 0.9888 - val_loss: 7.3824e-04 - val_acc: 0.9892\n",
      "Epoch 531/3000\n",
      " - 1s - loss: 7.6229e-04 - acc: 0.9892 - val_loss: 7.5636e-04 - val_acc: 0.9892\n",
      "Epoch 532/3000\n",
      " - 2s - loss: 7.8561e-04 - acc: 0.9890 - val_loss: 7.6633e-04 - val_acc: 0.9890\n",
      "Epoch 533/3000\n",
      " - 1s - loss: 7.7606e-04 - acc: 0.9890 - val_loss: 7.8182e-04 - val_acc: 0.9890\n",
      "Epoch 534/3000\n",
      " - 1s - loss: 7.6724e-04 - acc: 0.9891 - val_loss: 7.4055e-04 - val_acc: 0.9894\n",
      "Epoch 535/3000\n",
      " - 1s - loss: 7.6793e-04 - acc: 0.9892 - val_loss: 7.6114e-04 - val_acc: 0.9893\n",
      "Epoch 536/3000\n",
      " - 1s - loss: 7.7532e-04 - acc: 0.9891 - val_loss: 7.8578e-04 - val_acc: 0.9892\n",
      "Epoch 537/3000\n",
      " - 2s - loss: 7.8568e-04 - acc: 0.9890 - val_loss: 7.5260e-04 - val_acc: 0.9891\n",
      "Epoch 538/3000\n",
      " - 2s - loss: 7.7333e-04 - acc: 0.9891 - val_loss: 7.9995e-04 - val_acc: 0.9892\n",
      "Epoch 539/3000\n",
      " - 1s - loss: 7.7883e-04 - acc: 0.9891 - val_loss: 7.3920e-04 - val_acc: 0.9892\n",
      "Epoch 540/3000\n",
      "\n",
      "Epoch 00540: val_loss improved from 0.00078 to 0.00076, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 7.6451e-04 - acc: 0.9892 - val_loss: 7.5754e-04 - val_acc: 0.9893\n",
      "Epoch 541/3000\n",
      " - 1s - loss: 7.6305e-04 - acc: 0.9892 - val_loss: 7.3997e-04 - val_acc: 0.9892\n",
      "Epoch 542/3000\n",
      " - 1s - loss: 7.5667e-04 - acc: 0.9892 - val_loss: 8.2784e-04 - val_acc: 0.9890\n",
      "Epoch 543/3000\n",
      " - 2s - loss: 7.7774e-04 - acc: 0.9891 - val_loss: 7.3422e-04 - val_acc: 0.9894\n",
      "Epoch 544/3000\n",
      " - 1s - loss: 7.6925e-04 - acc: 0.9890 - val_loss: 7.3141e-04 - val_acc: 0.9892\n",
      "Epoch 545/3000\n",
      " - 1s - loss: 7.6111e-04 - acc: 0.9892 - val_loss: 7.4009e-04 - val_acc: 0.9893\n",
      "Epoch 546/3000\n",
      " - 1s - loss: 7.6634e-04 - acc: 0.9892 - val_loss: 8.0715e-04 - val_acc: 0.9889\n",
      "Epoch 547/3000\n",
      " - 1s - loss: 7.6225e-04 - acc: 0.9891 - val_loss: 7.5943e-04 - val_acc: 0.9892\n",
      "Epoch 548/3000\n",
      " - 1s - loss: 7.6434e-04 - acc: 0.9892 - val_loss: 7.7492e-04 - val_acc: 0.9893\n",
      "Epoch 549/3000\n",
      " - 1s - loss: 7.7502e-04 - acc: 0.9891 - val_loss: 7.6341e-04 - val_acc: 0.9889\n",
      "Epoch 550/3000\n",
      " - 1s - loss: 7.7813e-04 - acc: 0.9890 - val_loss: 7.6920e-04 - val_acc: 0.9889\n",
      "Epoch 551/3000\n",
      " - 2s - loss: 7.8467e-04 - acc: 0.9890 - val_loss: 7.6275e-04 - val_acc: 0.9891\n",
      "Epoch 552/3000\n",
      " - 1s - loss: 7.6841e-04 - acc: 0.9891 - val_loss: 7.5374e-04 - val_acc: 0.9895\n",
      "Epoch 553/3000\n",
      " - 2s - loss: 7.5467e-04 - acc: 0.9892 - val_loss: 7.2872e-04 - val_acc: 0.9894\n",
      "Epoch 554/3000\n",
      " - 2s - loss: 7.5169e-04 - acc: 0.9893 - val_loss: 7.3539e-04 - val_acc: 0.9893\n",
      "Epoch 555/3000\n",
      " - 1s - loss: 7.4499e-04 - acc: 0.9893 - val_loss: 7.2686e-04 - val_acc: 0.9894\n",
      "Epoch 556/3000\n",
      " - 1s - loss: 7.5125e-04 - acc: 0.9893 - val_loss: 7.2906e-04 - val_acc: 0.9890\n",
      "Epoch 557/3000\n",
      " - 1s - loss: 7.5731e-04 - acc: 0.9892 - val_loss: 7.6084e-04 - val_acc: 0.9892\n",
      "Epoch 558/3000\n",
      " - 2s - loss: 7.4956e-04 - acc: 0.9892 - val_loss: 7.4194e-04 - val_acc: 0.9895\n",
      "Epoch 559/3000\n",
      " - 1s - loss: 7.4920e-04 - acc: 0.9892 - val_loss: 7.5432e-04 - val_acc: 0.9894\n",
      "Epoch 560/3000\n",
      "\n",
      "Epoch 00560: val_loss improved from 0.00076 to 0.00073, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 7.5530e-04 - acc: 0.9892 - val_loss: 7.2954e-04 - val_acc: 0.9893\n",
      "Epoch 561/3000\n",
      " - 2s - loss: 7.6801e-04 - acc: 0.9890 - val_loss: 7.5634e-04 - val_acc: 0.9890\n",
      "Epoch 562/3000\n",
      " - 2s - loss: 7.5460e-04 - acc: 0.9891 - val_loss: 7.5647e-04 - val_acc: 0.9893\n",
      "Epoch 563/3000\n",
      " - 2s - loss: 7.6462e-04 - acc: 0.9893 - val_loss: 7.4221e-04 - val_acc: 0.9894\n",
      "Epoch 564/3000\n",
      " - 2s - loss: 7.5134e-04 - acc: 0.9893 - val_loss: 8.3844e-04 - val_acc: 0.9892\n",
      "Epoch 565/3000\n",
      " - 2s - loss: 7.6494e-04 - acc: 0.9891 - val_loss: 7.6812e-04 - val_acc: 0.9888\n",
      "Epoch 566/3000\n",
      " - 1s - loss: 7.3949e-04 - acc: 0.9892 - val_loss: 7.3353e-04 - val_acc: 0.9895\n",
      "Epoch 567/3000\n",
      " - 1s - loss: 7.4654e-04 - acc: 0.9893 - val_loss: 7.2231e-04 - val_acc: 0.9894\n",
      "Epoch 568/3000\n",
      " - 1s - loss: 7.3921e-04 - acc: 0.9893 - val_loss: 7.2395e-04 - val_acc: 0.9896\n",
      "Epoch 569/3000\n",
      " - 1s - loss: 7.6242e-04 - acc: 0.9891 - val_loss: 7.7923e-04 - val_acc: 0.9892\n",
      "Epoch 570/3000\n",
      " - 1s - loss: 7.3386e-04 - acc: 0.9894 - val_loss: 7.0647e-04 - val_acc: 0.9897\n",
      "Epoch 571/3000\n",
      " - 1s - loss: 7.3124e-04 - acc: 0.9894 - val_loss: 7.3407e-04 - val_acc: 0.9889\n",
      "Epoch 572/3000\n",
      " - 1s - loss: 7.4339e-04 - acc: 0.9893 - val_loss: 7.4187e-04 - val_acc: 0.9894\n",
      "Epoch 573/3000\n",
      " - 1s - loss: 7.3368e-04 - acc: 0.9894 - val_loss: 7.3352e-04 - val_acc: 0.9895\n",
      "Epoch 574/3000\n",
      " - 1s - loss: 7.7260e-04 - acc: 0.9890 - val_loss: 7.8992e-04 - val_acc: 0.9894\n",
      "Epoch 575/3000\n",
      " - 2s - loss: 7.4396e-04 - acc: 0.9893 - val_loss: 7.5610e-04 - val_acc: 0.9893\n",
      "Epoch 576/3000\n",
      " - 1s - loss: 7.4227e-04 - acc: 0.9894 - val_loss: 7.5578e-04 - val_acc: 0.9887\n",
      "Epoch 577/3000\n",
      " - 2s - loss: 7.4092e-04 - acc: 0.9894 - val_loss: 7.3444e-04 - val_acc: 0.9892\n",
      "Epoch 578/3000\n",
      " - 1s - loss: 7.3063e-04 - acc: 0.9894 - val_loss: 7.2348e-04 - val_acc: 0.9885\n",
      "Epoch 579/3000\n",
      " - 1s - loss: 7.3867e-04 - acc: 0.9894 - val_loss: 7.9420e-04 - val_acc: 0.9892\n",
      "Epoch 580/3000\n",
      "\n",
      "Epoch 00580: val_loss improved from 0.00073 to 0.00072, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 7.4226e-04 - acc: 0.9893 - val_loss: 7.2046e-04 - val_acc: 0.9891\n",
      "Epoch 581/3000\n",
      " - 1s - loss: 7.4051e-04 - acc: 0.9892 - val_loss: 7.1724e-04 - val_acc: 0.9897\n",
      "Epoch 582/3000\n",
      " - 2s - loss: 7.5334e-04 - acc: 0.9893 - val_loss: 7.1282e-04 - val_acc: 0.9894\n",
      "Epoch 583/3000\n",
      " - 2s - loss: 7.4726e-04 - acc: 0.9892 - val_loss: 7.3990e-04 - val_acc: 0.9893\n",
      "Epoch 584/3000\n",
      " - 1s - loss: 7.2964e-04 - acc: 0.9894 - val_loss: 7.3822e-04 - val_acc: 0.9894\n",
      "Epoch 585/3000\n",
      " - 1s - loss: 7.3484e-04 - acc: 0.9894 - val_loss: 7.2996e-04 - val_acc: 0.9895\n",
      "Epoch 586/3000\n",
      " - 1s - loss: 7.3437e-04 - acc: 0.9893 - val_loss: 7.5697e-04 - val_acc: 0.9890\n",
      "Epoch 587/3000\n",
      " - 1s - loss: 7.4636e-04 - acc: 0.9892 - val_loss: 7.1538e-04 - val_acc: 0.9892\n",
      "Epoch 588/3000\n",
      " - 1s - loss: 7.2102e-04 - acc: 0.9894 - val_loss: 6.9832e-04 - val_acc: 0.9898\n",
      "Epoch 589/3000\n",
      " - 1s - loss: 7.3809e-04 - acc: 0.9893 - val_loss: 7.2459e-04 - val_acc: 0.9893\n",
      "Epoch 590/3000\n",
      " - 1s - loss: 7.3872e-04 - acc: 0.9894 - val_loss: 7.3658e-04 - val_acc: 0.9889\n",
      "Epoch 591/3000\n",
      " - 1s - loss: 7.2776e-04 - acc: 0.9893 - val_loss: 7.0890e-04 - val_acc: 0.9895\n",
      "Epoch 592/3000\n",
      " - 1s - loss: 7.2173e-04 - acc: 0.9895 - val_loss: 7.1410e-04 - val_acc: 0.9894\n",
      "Epoch 593/3000\n",
      " - 1s - loss: 7.1810e-04 - acc: 0.9895 - val_loss: 7.1507e-04 - val_acc: 0.9891\n",
      "Epoch 594/3000\n",
      " - 2s - loss: 7.2225e-04 - acc: 0.9895 - val_loss: 7.2086e-04 - val_acc: 0.9889\n",
      "Epoch 595/3000\n",
      " - 2s - loss: 7.5448e-04 - acc: 0.9891 - val_loss: 7.3507e-04 - val_acc: 0.9895\n",
      "Epoch 596/3000\n",
      " - 1s - loss: 7.2882e-04 - acc: 0.9894 - val_loss: 7.4288e-04 - val_acc: 0.9894\n",
      "Epoch 597/3000\n",
      " - 1s - loss: 7.1744e-04 - acc: 0.9895 - val_loss: 7.1391e-04 - val_acc: 0.9888\n",
      "Epoch 598/3000\n",
      " - 1s - loss: 7.2088e-04 - acc: 0.9894 - val_loss: 7.1494e-04 - val_acc: 0.9894\n",
      "Epoch 599/3000\n",
      " - 1s - loss: 7.2677e-04 - acc: 0.9894 - val_loss: 7.8524e-04 - val_acc: 0.9890\n",
      "Epoch 600/3000\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.00072\n",
      " - 1s - loss: 7.3670e-04 - acc: 0.9892 - val_loss: 7.3180e-04 - val_acc: 0.9891\n",
      "Epoch 601/3000\n",
      " - 1s - loss: 7.4990e-04 - acc: 0.9891 - val_loss: 7.8180e-04 - val_acc: 0.9891\n",
      "Epoch 602/3000\n",
      " - 1s - loss: 7.3353e-04 - acc: 0.9893 - val_loss: 7.3351e-04 - val_acc: 0.9890\n",
      "Epoch 603/3000\n",
      " - 2s - loss: 7.3212e-04 - acc: 0.9894 - val_loss: 6.9448e-04 - val_acc: 0.9897\n",
      "Epoch 604/3000\n",
      " - 1s - loss: 7.2730e-04 - acc: 0.9894 - val_loss: 7.2806e-04 - val_acc: 0.9893\n",
      "Epoch 605/3000\n",
      " - 1s - loss: 7.2114e-04 - acc: 0.9894 - val_loss: 6.8863e-04 - val_acc: 0.9895\n",
      "Epoch 606/3000\n",
      " - 2s - loss: 7.1402e-04 - acc: 0.9895 - val_loss: 6.9656e-04 - val_acc: 0.9891\n",
      "Epoch 607/3000\n",
      " - 1s - loss: 7.1660e-04 - acc: 0.9895 - val_loss: 7.2298e-04 - val_acc: 0.9894\n",
      "Epoch 608/3000\n",
      " - 1s - loss: 7.2962e-04 - acc: 0.9894 - val_loss: 7.1400e-04 - val_acc: 0.9892\n",
      "Epoch 609/3000\n",
      " - 1s - loss: 7.1204e-04 - acc: 0.9895 - val_loss: 7.1248e-04 - val_acc: 0.9897\n",
      "Epoch 610/3000\n",
      " - 1s - loss: 7.3165e-04 - acc: 0.9894 - val_loss: 7.2041e-04 - val_acc: 0.9890\n",
      "Epoch 611/3000\n",
      " - 1s - loss: 7.1159e-04 - acc: 0.9896 - val_loss: 7.2124e-04 - val_acc: 0.9892\n",
      "Epoch 612/3000\n",
      " - 1s - loss: 7.3439e-04 - acc: 0.9892 - val_loss: 7.0374e-04 - val_acc: 0.9890\n",
      "Epoch 613/3000\n",
      " - 1s - loss: 7.3126e-04 - acc: 0.9894 - val_loss: 7.2963e-04 - val_acc: 0.9890\n",
      "Epoch 614/3000\n",
      " - 2s - loss: 7.1514e-04 - acc: 0.9895 - val_loss: 7.0224e-04 - val_acc: 0.9892\n",
      "Epoch 615/3000\n",
      " - 1s - loss: 7.1570e-04 - acc: 0.9895 - val_loss: 7.3205e-04 - val_acc: 0.9891\n",
      "Epoch 616/3000\n",
      " - 1s - loss: 7.2452e-04 - acc: 0.9894 - val_loss: 7.8842e-04 - val_acc: 0.9889\n",
      "Epoch 617/3000\n",
      " - 2s - loss: 7.3199e-04 - acc: 0.9893 - val_loss: 7.7862e-04 - val_acc: 0.9887\n",
      "Epoch 618/3000\n",
      " - 1s - loss: 7.3675e-04 - acc: 0.9893 - val_loss: 7.2418e-04 - val_acc: 0.9896\n",
      "Epoch 619/3000\n",
      " - 1s - loss: 7.1382e-04 - acc: 0.9895 - val_loss: 7.1208e-04 - val_acc: 0.9896\n",
      "Epoch 620/3000\n",
      "\n",
      "Epoch 00620: val_loss improved from 0.00072 to 0.00071, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 7.0799e-04 - acc: 0.9896 - val_loss: 7.0578e-04 - val_acc: 0.9896\n",
      "Epoch 621/3000\n",
      " - 2s - loss: 7.0361e-04 - acc: 0.9896 - val_loss: 7.4129e-04 - val_acc: 0.9891\n",
      "Epoch 622/3000\n",
      " - 1s - loss: 7.0951e-04 - acc: 0.9895 - val_loss: 6.9185e-04 - val_acc: 0.9897\n",
      "Epoch 623/3000\n",
      " - 1s - loss: 7.0118e-04 - acc: 0.9897 - val_loss: 7.1121e-04 - val_acc: 0.9893\n",
      "Epoch 624/3000\n",
      " - 1s - loss: 7.0871e-04 - acc: 0.9895 - val_loss: 6.8819e-04 - val_acc: 0.9899\n",
      "Epoch 625/3000\n",
      " - 1s - loss: 7.0046e-04 - acc: 0.9896 - val_loss: 7.3839e-04 - val_acc: 0.9894\n",
      "Epoch 626/3000\n",
      " - 1s - loss: 7.2053e-04 - acc: 0.9893 - val_loss: 7.2211e-04 - val_acc: 0.9892\n",
      "Epoch 627/3000\n",
      " - 1s - loss: 7.1902e-04 - acc: 0.9894 - val_loss: 6.9946e-04 - val_acc: 0.9898\n",
      "Epoch 628/3000\n",
      " - 1s - loss: 7.1998e-04 - acc: 0.9894 - val_loss: 7.8417e-04 - val_acc: 0.9894\n",
      "Epoch 629/3000\n",
      " - 1s - loss: 7.2052e-04 - acc: 0.9894 - val_loss: 7.6329e-04 - val_acc: 0.9885\n",
      "Epoch 630/3000\n",
      " - 2s - loss: 7.0903e-04 - acc: 0.9894 - val_loss: 6.7783e-04 - val_acc: 0.9898\n",
      "Epoch 631/3000\n",
      " - 1s - loss: 7.0380e-04 - acc: 0.9896 - val_loss: 7.3966e-04 - val_acc: 0.9899\n",
      "Epoch 632/3000\n",
      " - 2s - loss: 6.9652e-04 - acc: 0.9896 - val_loss: 6.9027e-04 - val_acc: 0.9893\n",
      "Epoch 633/3000\n",
      " - 1s - loss: 7.0506e-04 - acc: 0.9896 - val_loss: 7.5803e-04 - val_acc: 0.9890\n",
      "Epoch 634/3000\n",
      " - 2s - loss: 7.1450e-04 - acc: 0.9894 - val_loss: 7.0304e-04 - val_acc: 0.9896\n",
      "Epoch 635/3000\n",
      " - 2s - loss: 6.9612e-04 - acc: 0.9896 - val_loss: 6.9647e-04 - val_acc: 0.9898\n",
      "Epoch 636/3000\n",
      " - 1s - loss: 7.1131e-04 - acc: 0.9894 - val_loss: 7.0248e-04 - val_acc: 0.9892\n",
      "Epoch 637/3000\n",
      " - 2s - loss: 7.0903e-04 - acc: 0.9895 - val_loss: 6.9124e-04 - val_acc: 0.9893\n",
      "Epoch 638/3000\n",
      " - 2s - loss: 6.9669e-04 - acc: 0.9896 - val_loss: 7.0056e-04 - val_acc: 0.9894\n",
      "Epoch 639/3000\n",
      " - 2s - loss: 6.9337e-04 - acc: 0.9898 - val_loss: 6.7392e-04 - val_acc: 0.9896\n",
      "Epoch 640/3000\n",
      "\n",
      "Epoch 00640: val_loss improved from 0.00071 to 0.00070, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 7.0478e-04 - acc: 0.9896 - val_loss: 6.9629e-04 - val_acc: 0.9893\n",
      "Epoch 641/3000\n",
      " - 2s - loss: 7.0159e-04 - acc: 0.9897 - val_loss: 6.8986e-04 - val_acc: 0.9897\n",
      "Epoch 642/3000\n",
      " - 2s - loss: 7.0390e-04 - acc: 0.9895 - val_loss: 7.9316e-04 - val_acc: 0.9889\n",
      "Epoch 643/3000\n",
      " - 1s - loss: 7.2018e-04 - acc: 0.9893 - val_loss: 7.1207e-04 - val_acc: 0.9891\n",
      "Epoch 644/3000\n",
      " - 1s - loss: 7.0336e-04 - acc: 0.9895 - val_loss: 7.1456e-04 - val_acc: 0.9898\n",
      "Epoch 645/3000\n",
      " - 1s - loss: 7.0994e-04 - acc: 0.9896 - val_loss: 7.1414e-04 - val_acc: 0.9894\n",
      "Epoch 646/3000\n",
      " - 1s - loss: 6.9637e-04 - acc: 0.9895 - val_loss: 6.7840e-04 - val_acc: 0.9895\n",
      "Epoch 647/3000\n",
      " - 1s - loss: 7.0443e-04 - acc: 0.9896 - val_loss: 6.6392e-04 - val_acc: 0.9898\n",
      "Epoch 648/3000\n",
      " - 1s - loss: 6.8776e-04 - acc: 0.9897 - val_loss: 6.7234e-04 - val_acc: 0.9897\n",
      "Epoch 649/3000\n",
      " - 2s - loss: 6.9607e-04 - acc: 0.9896 - val_loss: 6.8546e-04 - val_acc: 0.9898\n",
      "Epoch 650/3000\n",
      " - 2s - loss: 6.9008e-04 - acc: 0.9897 - val_loss: 6.7529e-04 - val_acc: 0.9899\n",
      "Epoch 651/3000\n",
      " - 1s - loss: 7.0841e-04 - acc: 0.9895 - val_loss: 7.0228e-04 - val_acc: 0.9897\n",
      "Epoch 652/3000\n",
      " - 1s - loss: 6.8024e-04 - acc: 0.9896 - val_loss: 6.8845e-04 - val_acc: 0.9896\n",
      "Epoch 653/3000\n",
      " - 2s - loss: 6.9831e-04 - acc: 0.9896 - val_loss: 6.8365e-04 - val_acc: 0.9895\n",
      "Epoch 654/3000\n",
      " - 1s - loss: 6.9212e-04 - acc: 0.9897 - val_loss: 6.9381e-04 - val_acc: 0.9894\n",
      "Epoch 655/3000\n",
      " - 1s - loss: 6.9570e-04 - acc: 0.9895 - val_loss: 7.0018e-04 - val_acc: 0.9897\n",
      "Epoch 656/3000\n",
      " - 1s - loss: 6.8259e-04 - acc: 0.9897 - val_loss: 6.8591e-04 - val_acc: 0.9898\n",
      "Epoch 657/3000\n",
      " - 1s - loss: 7.0094e-04 - acc: 0.9896 - val_loss: 6.7834e-04 - val_acc: 0.9898\n",
      "Epoch 658/3000\n",
      " - 2s - loss: 6.8538e-04 - acc: 0.9898 - val_loss: 6.9400e-04 - val_acc: 0.9894\n",
      "Epoch 659/3000\n",
      " - 1s - loss: 6.8153e-04 - acc: 0.9897 - val_loss: 6.6621e-04 - val_acc: 0.9899\n",
      "Epoch 660/3000\n",
      "\n",
      "Epoch 00660: val_loss improved from 0.00070 to 0.00067, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 6.9171e-04 - acc: 0.9897 - val_loss: 6.6606e-04 - val_acc: 0.9895\n",
      "Epoch 661/3000\n",
      " - 1s - loss: 6.8569e-04 - acc: 0.9897 - val_loss: 6.7163e-04 - val_acc: 0.9899\n",
      "Epoch 662/3000\n",
      " - 1s - loss: 6.8788e-04 - acc: 0.9897 - val_loss: 6.8923e-04 - val_acc: 0.9897\n",
      "Epoch 663/3000\n",
      " - 2s - loss: 6.7885e-04 - acc: 0.9898 - val_loss: 6.7118e-04 - val_acc: 0.9897\n",
      "Epoch 664/3000\n",
      " - 2s - loss: 6.8909e-04 - acc: 0.9896 - val_loss: 6.6377e-04 - val_acc: 0.9896\n",
      "Epoch 665/3000\n",
      " - 2s - loss: 6.7880e-04 - acc: 0.9898 - val_loss: 6.5916e-04 - val_acc: 0.9897\n",
      "Epoch 666/3000\n",
      " - 2s - loss: 6.8933e-04 - acc: 0.9896 - val_loss: 6.7783e-04 - val_acc: 0.9898\n",
      "Epoch 667/3000\n",
      " - 1s - loss: 6.8807e-04 - acc: 0.9896 - val_loss: 6.7217e-04 - val_acc: 0.9899\n",
      "Epoch 668/3000\n",
      " - 2s - loss: 6.8246e-04 - acc: 0.9898 - val_loss: 6.9397e-04 - val_acc: 0.9892\n",
      "Epoch 669/3000\n",
      " - 1s - loss: 6.7492e-04 - acc: 0.9897 - val_loss: 6.5421e-04 - val_acc: 0.9898\n",
      "Epoch 670/3000\n",
      " - 1s - loss: 6.8195e-04 - acc: 0.9897 - val_loss: 6.5352e-04 - val_acc: 0.9897\n",
      "Epoch 671/3000\n",
      " - 2s - loss: 6.7629e-04 - acc: 0.9898 - val_loss: 7.1248e-04 - val_acc: 0.9898\n",
      "Epoch 672/3000\n",
      " - 2s - loss: 6.8581e-04 - acc: 0.9897 - val_loss: 7.1520e-04 - val_acc: 0.9897\n",
      "Epoch 673/3000\n",
      " - 2s - loss: 6.8336e-04 - acc: 0.9897 - val_loss: 6.5936e-04 - val_acc: 0.9896\n",
      "Epoch 674/3000\n",
      " - 2s - loss: 6.7111e-04 - acc: 0.9899 - val_loss: 6.5199e-04 - val_acc: 0.9894\n",
      "Epoch 675/3000\n",
      " - 1s - loss: 6.8144e-04 - acc: 0.9898 - val_loss: 6.7248e-04 - val_acc: 0.9898\n",
      "Epoch 676/3000\n",
      " - 1s - loss: 6.7477e-04 - acc: 0.9898 - val_loss: 6.8717e-04 - val_acc: 0.9894\n",
      "Epoch 677/3000\n",
      " - 2s - loss: 6.7256e-04 - acc: 0.9897 - val_loss: 6.6613e-04 - val_acc: 0.9896\n",
      "Epoch 678/3000\n",
      " - 2s - loss: 6.7321e-04 - acc: 0.9898 - val_loss: 6.9315e-04 - val_acc: 0.9896\n",
      "Epoch 679/3000\n",
      " - 1s - loss: 6.7585e-04 - acc: 0.9898 - val_loss: 7.0444e-04 - val_acc: 0.9895\n",
      "Epoch 680/3000\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 0.00067\n",
      " - 2s - loss: 6.6575e-04 - acc: 0.9899 - val_loss: 6.6984e-04 - val_acc: 0.9898\n",
      "Epoch 681/3000\n",
      " - 2s - loss: 6.9104e-04 - acc: 0.9896 - val_loss: 6.9729e-04 - val_acc: 0.9897\n",
      "Epoch 682/3000\n",
      " - 2s - loss: 6.8797e-04 - acc: 0.9896 - val_loss: 6.7937e-04 - val_acc: 0.9895\n",
      "Epoch 683/3000\n",
      " - 1s - loss: 6.7306e-04 - acc: 0.9898 - val_loss: 6.9430e-04 - val_acc: 0.9892\n",
      "Epoch 684/3000\n",
      " - 1s - loss: 6.9662e-04 - acc: 0.9895 - val_loss: 6.5144e-04 - val_acc: 0.9898\n",
      "Epoch 685/3000\n",
      " - 2s - loss: 6.6636e-04 - acc: 0.9898 - val_loss: 7.0258e-04 - val_acc: 0.9895\n",
      "Epoch 686/3000\n",
      " - 1s - loss: 6.8332e-04 - acc: 0.9897 - val_loss: 6.7320e-04 - val_acc: 0.9897\n",
      "Epoch 687/3000\n",
      " - 2s - loss: 6.6932e-04 - acc: 0.9898 - val_loss: 6.6436e-04 - val_acc: 0.9893\n",
      "Epoch 688/3000\n",
      " - 1s - loss: 6.6545e-04 - acc: 0.9898 - val_loss: 6.5327e-04 - val_acc: 0.9898\n",
      "Epoch 689/3000\n",
      " - 1s - loss: 6.6487e-04 - acc: 0.9899 - val_loss: 6.7117e-04 - val_acc: 0.9895\n",
      "Epoch 690/3000\n",
      " - 1s - loss: 6.7657e-04 - acc: 0.9897 - val_loss: 6.7632e-04 - val_acc: 0.9897\n",
      "Epoch 691/3000\n",
      " - 1s - loss: 6.7321e-04 - acc: 0.9898 - val_loss: 6.7088e-04 - val_acc: 0.9895\n",
      "Epoch 692/3000\n",
      " - 1s - loss: 6.6233e-04 - acc: 0.9898 - val_loss: 6.6109e-04 - val_acc: 0.9897\n",
      "Epoch 693/3000\n",
      " - 1s - loss: 6.6657e-04 - acc: 0.9899 - val_loss: 6.5409e-04 - val_acc: 0.9897\n",
      "Epoch 694/3000\n",
      " - 1s - loss: 6.8750e-04 - acc: 0.9896 - val_loss: 7.0144e-04 - val_acc: 0.9896\n",
      "Epoch 695/3000\n",
      " - 2s - loss: 6.7357e-04 - acc: 0.9897 - val_loss: 6.8174e-04 - val_acc: 0.9896\n",
      "Epoch 696/3000\n",
      " - 2s - loss: 6.6515e-04 - acc: 0.9898 - val_loss: 6.4508e-04 - val_acc: 0.9896\n",
      "Epoch 697/3000\n",
      " - 2s - loss: 6.6659e-04 - acc: 0.9898 - val_loss: 6.5659e-04 - val_acc: 0.9898\n",
      "Epoch 698/3000\n",
      " - 1s - loss: 6.5362e-04 - acc: 0.9900 - val_loss: 6.4377e-04 - val_acc: 0.9898\n",
      "Epoch 699/3000\n",
      " - 1s - loss: 6.5998e-04 - acc: 0.9898 - val_loss: 6.5984e-04 - val_acc: 0.9898\n",
      "Epoch 700/3000\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 0.00067\n",
      " - 2s - loss: 6.7900e-04 - acc: 0.9897 - val_loss: 6.6931e-04 - val_acc: 0.9890\n",
      "Epoch 701/3000\n",
      " - 1s - loss: 6.7355e-04 - acc: 0.9897 - val_loss: 6.7121e-04 - val_acc: 0.9891\n",
      "Epoch 702/3000\n",
      " - 1s - loss: 6.6855e-04 - acc: 0.9897 - val_loss: 6.4914e-04 - val_acc: 0.9899\n",
      "Epoch 703/3000\n",
      " - 1s - loss: 6.6341e-04 - acc: 0.9898 - val_loss: 6.7601e-04 - val_acc: 0.9897\n",
      "Epoch 704/3000\n",
      " - 1s - loss: 6.8961e-04 - acc: 0.9895 - val_loss: 7.2787e-04 - val_acc: 0.9893\n",
      "Epoch 705/3000\n",
      " - 1s - loss: 6.5465e-04 - acc: 0.9898 - val_loss: 6.3759e-04 - val_acc: 0.9899\n",
      "Epoch 706/3000\n",
      " - 1s - loss: 6.5794e-04 - acc: 0.9899 - val_loss: 6.6923e-04 - val_acc: 0.9894\n",
      "Epoch 707/3000\n",
      " - 2s - loss: 6.5260e-04 - acc: 0.9899 - val_loss: 6.6305e-04 - val_acc: 0.9894\n",
      "Epoch 708/3000\n",
      " - 1s - loss: 6.5853e-04 - acc: 0.9899 - val_loss: 6.5362e-04 - val_acc: 0.9899\n",
      "Epoch 709/3000\n",
      " - 1s - loss: 6.6598e-04 - acc: 0.9897 - val_loss: 7.2853e-04 - val_acc: 0.9895\n",
      "Epoch 710/3000\n",
      " - 1s - loss: 6.8736e-04 - acc: 0.9894 - val_loss: 6.2607e-04 - val_acc: 0.9898\n",
      "Epoch 711/3000\n",
      " - 1s - loss: 6.6047e-04 - acc: 0.9899 - val_loss: 6.5583e-04 - val_acc: 0.9896\n",
      "Epoch 712/3000\n",
      " - 1s - loss: 6.5378e-04 - acc: 0.9899 - val_loss: 6.4308e-04 - val_acc: 0.9900\n",
      "Epoch 713/3000\n",
      " - 2s - loss: 6.5343e-04 - acc: 0.9899 - val_loss: 6.4270e-04 - val_acc: 0.9900\n",
      "Epoch 714/3000\n",
      " - 1s - loss: 6.6279e-04 - acc: 0.9898 - val_loss: 6.9119e-04 - val_acc: 0.9895\n",
      "Epoch 715/3000\n",
      " - 1s - loss: 6.5995e-04 - acc: 0.9898 - val_loss: 6.5074e-04 - val_acc: 0.9902\n",
      "Epoch 716/3000\n",
      " - 2s - loss: 6.6232e-04 - acc: 0.9897 - val_loss: 6.3599e-04 - val_acc: 0.9896\n",
      "Epoch 717/3000\n",
      " - 2s - loss: 6.4510e-04 - acc: 0.9900 - val_loss: 6.3820e-04 - val_acc: 0.9900\n",
      "Epoch 718/3000\n",
      " - 1s - loss: 6.4698e-04 - acc: 0.9899 - val_loss: 6.8311e-04 - val_acc: 0.9898\n",
      "Epoch 719/3000\n",
      " - 1s - loss: 6.6865e-04 - acc: 0.9898 - val_loss: 6.5970e-04 - val_acc: 0.9895\n",
      "Epoch 720/3000\n",
      "\n",
      "Epoch 00720: val_loss improved from 0.00067 to 0.00065, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 6.5201e-04 - acc: 0.9899 - val_loss: 6.5212e-04 - val_acc: 0.9894\n",
      "Epoch 721/3000\n",
      " - 2s - loss: 6.6843e-04 - acc: 0.9896 - val_loss: 6.3435e-04 - val_acc: 0.9900\n",
      "Epoch 722/3000\n",
      " - 1s - loss: 6.5193e-04 - acc: 0.9899 - val_loss: 6.4248e-04 - val_acc: 0.9893\n",
      "Epoch 723/3000\n",
      " - 2s - loss: 6.5068e-04 - acc: 0.9898 - val_loss: 6.3717e-04 - val_acc: 0.9899\n",
      "Epoch 724/3000\n",
      " - 1s - loss: 6.4115e-04 - acc: 0.9900 - val_loss: 6.3219e-04 - val_acc: 0.9899\n",
      "Epoch 725/3000\n",
      " - 1s - loss: 6.5937e-04 - acc: 0.9898 - val_loss: 6.9109e-04 - val_acc: 0.9895\n",
      "Epoch 726/3000\n",
      " - 1s - loss: 6.5305e-04 - acc: 0.9898 - val_loss: 6.4026e-04 - val_acc: 0.9898\n",
      "Epoch 727/3000\n",
      " - 1s - loss: 6.5344e-04 - acc: 0.9898 - val_loss: 6.4100e-04 - val_acc: 0.9898\n",
      "Epoch 728/3000\n",
      " - 1s - loss: 6.6569e-04 - acc: 0.9898 - val_loss: 6.9709e-04 - val_acc: 0.9894\n",
      "Epoch 729/3000\n",
      " - 1s - loss: 6.5483e-04 - acc: 0.9899 - val_loss: 6.4427e-04 - val_acc: 0.9897\n",
      "Epoch 730/3000\n",
      " - 1s - loss: 6.4488e-04 - acc: 0.9900 - val_loss: 6.2132e-04 - val_acc: 0.9900\n",
      "Epoch 731/3000\n",
      " - 2s - loss: 6.4626e-04 - acc: 0.9899 - val_loss: 6.7935e-04 - val_acc: 0.9899\n",
      "Epoch 732/3000\n",
      " - 1s - loss: 6.5250e-04 - acc: 0.9899 - val_loss: 6.6890e-04 - val_acc: 0.9897\n",
      "Epoch 733/3000\n",
      " - 2s - loss: 6.4507e-04 - acc: 0.9899 - val_loss: 6.2630e-04 - val_acc: 0.9895\n",
      "Epoch 734/3000\n",
      " - 1s - loss: 6.4534e-04 - acc: 0.9899 - val_loss: 6.2253e-04 - val_acc: 0.9899\n",
      "Epoch 735/3000\n",
      " - 1s - loss: 6.4219e-04 - acc: 0.9899 - val_loss: 6.3937e-04 - val_acc: 0.9895\n",
      "Epoch 736/3000\n",
      " - 1s - loss: 6.4391e-04 - acc: 0.9900 - val_loss: 6.2858e-04 - val_acc: 0.9896\n",
      "Epoch 737/3000\n",
      " - 1s - loss: 6.4617e-04 - acc: 0.9899 - val_loss: 6.3536e-04 - val_acc: 0.9900\n",
      "Epoch 738/3000\n",
      " - 2s - loss: 6.3410e-04 - acc: 0.9900 - val_loss: 6.2975e-04 - val_acc: 0.9899\n",
      "Epoch 739/3000\n",
      " - 1s - loss: 6.3822e-04 - acc: 0.9900 - val_loss: 6.1922e-04 - val_acc: 0.9899\n",
      "Epoch 740/3000\n",
      "\n",
      "Epoch 00740: val_loss improved from 0.00065 to 0.00062, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 6.3906e-04 - acc: 0.9899 - val_loss: 6.2450e-04 - val_acc: 0.9899\n",
      "Epoch 741/3000\n",
      " - 1s - loss: 6.5282e-04 - acc: 0.9898 - val_loss: 6.2343e-04 - val_acc: 0.9898\n",
      "Epoch 742/3000\n",
      " - 2s - loss: 6.8615e-04 - acc: 0.9894 - val_loss: 6.3620e-04 - val_acc: 0.9902\n",
      "Epoch 743/3000\n",
      " - 2s - loss: 6.4414e-04 - acc: 0.9899 - val_loss: 6.6277e-04 - val_acc: 0.9901\n",
      "Epoch 744/3000\n",
      " - 1s - loss: 6.6588e-04 - acc: 0.9897 - val_loss: 6.2415e-04 - val_acc: 0.9900\n",
      "Epoch 745/3000\n",
      " - 1s - loss: 6.4359e-04 - acc: 0.9898 - val_loss: 6.4470e-04 - val_acc: 0.9897\n",
      "Epoch 746/3000\n",
      " - 2s - loss: 6.4898e-04 - acc: 0.9898 - val_loss: 6.3299e-04 - val_acc: 0.9897\n",
      "Epoch 747/3000\n",
      " - 2s - loss: 6.4387e-04 - acc: 0.9899 - val_loss: 6.7182e-04 - val_acc: 0.9896\n",
      "Epoch 748/3000\n",
      " - 2s - loss: 6.6600e-04 - acc: 0.9898 - val_loss: 6.2996e-04 - val_acc: 0.9898\n",
      "Epoch 749/3000\n",
      " - 1s - loss: 6.3558e-04 - acc: 0.9899 - val_loss: 6.4504e-04 - val_acc: 0.9898\n",
      "Epoch 750/3000\n",
      " - 1s - loss: 6.3778e-04 - acc: 0.9899 - val_loss: 6.3856e-04 - val_acc: 0.9897\n",
      "Epoch 751/3000\n",
      " - 2s - loss: 6.4507e-04 - acc: 0.9899 - val_loss: 6.5738e-04 - val_acc: 0.9897\n",
      "Epoch 752/3000\n",
      " - 1s - loss: 6.4894e-04 - acc: 0.9899 - val_loss: 6.3496e-04 - val_acc: 0.9900\n",
      "Epoch 753/3000\n",
      " - 2s - loss: 6.4221e-04 - acc: 0.9900 - val_loss: 6.9364e-04 - val_acc: 0.9896\n",
      "Epoch 754/3000\n",
      " - 1s - loss: 6.4139e-04 - acc: 0.9897 - val_loss: 6.4285e-04 - val_acc: 0.9900\n",
      "Epoch 755/3000\n",
      " - 1s - loss: 6.4228e-04 - acc: 0.9899 - val_loss: 6.7858e-04 - val_acc: 0.9897\n",
      "Epoch 756/3000\n",
      " - 1s - loss: 6.5627e-04 - acc: 0.9897 - val_loss: 6.2654e-04 - val_acc: 0.9900\n",
      "Epoch 757/3000\n",
      " - 1s - loss: 6.3195e-04 - acc: 0.9900 - val_loss: 6.1617e-04 - val_acc: 0.9902\n",
      "Epoch 758/3000\n",
      " - 1s - loss: 6.2960e-04 - acc: 0.9900 - val_loss: 6.2782e-04 - val_acc: 0.9899\n",
      "Epoch 759/3000\n",
      " - 1s - loss: 6.4477e-04 - acc: 0.9899 - val_loss: 6.4630e-04 - val_acc: 0.9898\n",
      "Epoch 760/3000\n",
      "\n",
      "Epoch 00760: val_loss improved from 0.00062 to 0.00062, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 6.2592e-04 - acc: 0.9900 - val_loss: 6.1642e-04 - val_acc: 0.9900\n",
      "Epoch 761/3000\n",
      " - 1s - loss: 6.4240e-04 - acc: 0.9898 - val_loss: 6.5014e-04 - val_acc: 0.9900\n",
      "Epoch 762/3000\n",
      " - 1s - loss: 6.4041e-04 - acc: 0.9899 - val_loss: 6.4235e-04 - val_acc: 0.9892\n",
      "Epoch 763/3000\n",
      " - 1s - loss: 6.4207e-04 - acc: 0.9899 - val_loss: 6.5732e-04 - val_acc: 0.9898\n",
      "Epoch 764/3000\n",
      " - 2s - loss: 6.2589e-04 - acc: 0.9900 - val_loss: 6.0146e-04 - val_acc: 0.9900\n",
      "Epoch 765/3000\n",
      " - 1s - loss: 6.2279e-04 - acc: 0.9901 - val_loss: 6.0907e-04 - val_acc: 0.9900\n",
      "Epoch 766/3000\n",
      " - 1s - loss: 6.2682e-04 - acc: 0.9900 - val_loss: 6.4281e-04 - val_acc: 0.9898\n",
      "Epoch 767/3000\n",
      " - 1s - loss: 6.4951e-04 - acc: 0.9898 - val_loss: 6.2569e-04 - val_acc: 0.9899\n",
      "Epoch 768/3000\n",
      " - 1s - loss: 6.3931e-04 - acc: 0.9901 - val_loss: 6.3911e-04 - val_acc: 0.9900\n",
      "Epoch 769/3000\n",
      " - 1s - loss: 6.2947e-04 - acc: 0.9901 - val_loss: 6.1172e-04 - val_acc: 0.9899\n",
      "Epoch 770/3000\n",
      " - 1s - loss: 6.3915e-04 - acc: 0.9899 - val_loss: 6.4424e-04 - val_acc: 0.9900\n",
      "Epoch 771/3000\n",
      " - 2s - loss: 6.3003e-04 - acc: 0.9900 - val_loss: 6.0411e-04 - val_acc: 0.9899\n",
      "Epoch 772/3000\n",
      " - 1s - loss: 6.4279e-04 - acc: 0.9900 - val_loss: 6.5758e-04 - val_acc: 0.9898\n",
      "Epoch 773/3000\n",
      " - 1s - loss: 6.3270e-04 - acc: 0.9900 - val_loss: 6.1945e-04 - val_acc: 0.9898\n",
      "Epoch 774/3000\n",
      " - 1s - loss: 6.2322e-04 - acc: 0.9900 - val_loss: 6.6466e-04 - val_acc: 0.9899\n",
      "Epoch 775/3000\n",
      " - 1s - loss: 6.3765e-04 - acc: 0.9899 - val_loss: 6.1897e-04 - val_acc: 0.9898\n",
      "Epoch 776/3000\n",
      " - 1s - loss: 6.4172e-04 - acc: 0.9899 - val_loss: 6.2263e-04 - val_acc: 0.9904\n",
      "Epoch 777/3000\n",
      " - 1s - loss: 6.3213e-04 - acc: 0.9899 - val_loss: 6.4592e-04 - val_acc: 0.9900\n",
      "Epoch 778/3000\n",
      " - 1s - loss: 6.3494e-04 - acc: 0.9899 - val_loss: 6.3150e-04 - val_acc: 0.9896\n",
      "Epoch 779/3000\n",
      " - 1s - loss: 6.3834e-04 - acc: 0.9899 - val_loss: 6.1075e-04 - val_acc: 0.9899\n",
      "Epoch 780/3000\n",
      "\n",
      "Epoch 00780: val_loss did not improve from 0.00062\n",
      " - 1s - loss: 6.4474e-04 - acc: 0.9899 - val_loss: 7.4373e-04 - val_acc: 0.9879\n",
      "Epoch 781/3000\n",
      " - 1s - loss: 6.5076e-04 - acc: 0.9897 - val_loss: 6.2566e-04 - val_acc: 0.9901\n",
      "Epoch 782/3000\n",
      " - 1s - loss: 6.3279e-04 - acc: 0.9900 - val_loss: 6.3995e-04 - val_acc: 0.9898\n",
      "Epoch 783/3000\n",
      " - 2s - loss: 6.1536e-04 - acc: 0.9901 - val_loss: 6.6486e-04 - val_acc: 0.9903\n",
      "Epoch 784/3000\n",
      " - 1s - loss: 6.1578e-04 - acc: 0.9901 - val_loss: 6.2360e-04 - val_acc: 0.9900\n",
      "Epoch 785/3000\n",
      " - 1s - loss: 6.2261e-04 - acc: 0.9901 - val_loss: 6.1691e-04 - val_acc: 0.9902\n",
      "Epoch 786/3000\n",
      " - 1s - loss: 6.2516e-04 - acc: 0.9901 - val_loss: 6.1575e-04 - val_acc: 0.9897\n",
      "Epoch 787/3000\n",
      " - 2s - loss: 6.1147e-04 - acc: 0.9902 - val_loss: 6.1526e-04 - val_acc: 0.9901\n",
      "Epoch 788/3000\n",
      " - 1s - loss: 6.1518e-04 - acc: 0.9901 - val_loss: 6.1833e-04 - val_acc: 0.9896\n",
      "Epoch 789/3000\n",
      " - 1s - loss: 6.1666e-04 - acc: 0.9901 - val_loss: 6.0471e-04 - val_acc: 0.9901\n",
      "Epoch 790/3000\n",
      " - 2s - loss: 6.2459e-04 - acc: 0.9901 - val_loss: 6.0198e-04 - val_acc: 0.9899\n",
      "Epoch 791/3000\n",
      " - 2s - loss: 6.0540e-04 - acc: 0.9902 - val_loss: 6.0230e-04 - val_acc: 0.9899\n",
      "Epoch 792/3000\n",
      " - 2s - loss: 6.2163e-04 - acc: 0.9900 - val_loss: 6.0918e-04 - val_acc: 0.9898\n",
      "Epoch 793/3000\n",
      " - 1s - loss: 6.1864e-04 - acc: 0.9902 - val_loss: 6.9972e-04 - val_acc: 0.9889\n",
      "Epoch 794/3000\n",
      " - 1s - loss: 6.2719e-04 - acc: 0.9900 - val_loss: 6.0448e-04 - val_acc: 0.9900\n",
      "Epoch 795/3000\n",
      " - 1s - loss: 6.1426e-04 - acc: 0.9901 - val_loss: 6.5083e-04 - val_acc: 0.9901\n",
      "Epoch 796/3000\n",
      " - 2s - loss: 6.2298e-04 - acc: 0.9900 - val_loss: 6.0373e-04 - val_acc: 0.9900\n",
      "Epoch 797/3000\n",
      " - 1s - loss: 6.2480e-04 - acc: 0.9900 - val_loss: 5.9061e-04 - val_acc: 0.9901\n",
      "Epoch 798/3000\n",
      " - 1s - loss: 6.1632e-04 - acc: 0.9901 - val_loss: 5.9932e-04 - val_acc: 0.9902\n",
      "Epoch 799/3000\n",
      " - 1s - loss: 6.1824e-04 - acc: 0.9901 - val_loss: 6.1040e-04 - val_acc: 0.9899\n",
      "Epoch 800/3000\n",
      "\n",
      "Epoch 00800: val_loss improved from 0.00062 to 0.00061, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 6.2314e-04 - acc: 0.9900 - val_loss: 6.0926e-04 - val_acc: 0.9900\n",
      "Epoch 801/3000\n",
      " - 2s - loss: 6.2046e-04 - acc: 0.9901 - val_loss: 6.0216e-04 - val_acc: 0.9900\n",
      "Epoch 802/3000\n",
      " - 2s - loss: 6.2478e-04 - acc: 0.9899 - val_loss: 6.0003e-04 - val_acc: 0.9903\n",
      "Epoch 803/3000\n",
      " - 1s - loss: 6.2270e-04 - acc: 0.9900 - val_loss: 5.9665e-04 - val_acc: 0.9900\n",
      "Epoch 804/3000\n",
      " - 1s - loss: 6.0941e-04 - acc: 0.9902 - val_loss: 6.2422e-04 - val_acc: 0.9899\n",
      "Epoch 805/3000\n",
      " - 1s - loss: 6.2782e-04 - acc: 0.9900 - val_loss: 6.5115e-04 - val_acc: 0.9897\n",
      "Epoch 806/3000\n",
      " - 2s - loss: 6.2421e-04 - acc: 0.9899 - val_loss: 5.9925e-04 - val_acc: 0.9901\n",
      "Epoch 807/3000\n",
      " - 1s - loss: 6.3230e-04 - acc: 0.9899 - val_loss: 6.8248e-04 - val_acc: 0.9901\n",
      "Epoch 808/3000\n",
      " - 1s - loss: 6.2955e-04 - acc: 0.9900 - val_loss: 6.0604e-04 - val_acc: 0.9901\n",
      "Epoch 809/3000\n",
      " - 2s - loss: 6.0928e-04 - acc: 0.9901 - val_loss: 6.0096e-04 - val_acc: 0.9899\n",
      "Epoch 810/3000\n",
      " - 2s - loss: 6.1293e-04 - acc: 0.9901 - val_loss: 6.2096e-04 - val_acc: 0.9900\n",
      "Epoch 811/3000\n",
      " - 1s - loss: 6.1025e-04 - acc: 0.9901 - val_loss: 6.2884e-04 - val_acc: 0.9894\n",
      "Epoch 812/3000\n",
      " - 1s - loss: 6.2077e-04 - acc: 0.9901 - val_loss: 6.0425e-04 - val_acc: 0.9900\n",
      "Epoch 813/3000\n",
      " - 1s - loss: 6.1360e-04 - acc: 0.9900 - val_loss: 5.9320e-04 - val_acc: 0.9901\n",
      "Epoch 814/3000\n",
      " - 1s - loss: 6.2383e-04 - acc: 0.9901 - val_loss: 6.1509e-04 - val_acc: 0.9897\n",
      "Epoch 815/3000\n",
      " - 1s - loss: 6.0848e-04 - acc: 0.9902 - val_loss: 6.1010e-04 - val_acc: 0.9902\n",
      "Epoch 816/3000\n",
      " - 1s - loss: 6.1105e-04 - acc: 0.9901 - val_loss: 6.1010e-04 - val_acc: 0.9900\n",
      "Epoch 817/3000\n",
      " - 1s - loss: 6.2621e-04 - acc: 0.9899 - val_loss: 6.0416e-04 - val_acc: 0.9899\n",
      "Epoch 818/3000\n",
      " - 1s - loss: 6.1484e-04 - acc: 0.9901 - val_loss: 6.1765e-04 - val_acc: 0.9897\n",
      "Epoch 819/3000\n",
      " - 1s - loss: 6.0981e-04 - acc: 0.9901 - val_loss: 6.0113e-04 - val_acc: 0.9899\n",
      "Epoch 820/3000\n",
      "\n",
      "Epoch 00820: val_loss improved from 0.00061 to 0.00060, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 6.0034e-04 - acc: 0.9902 - val_loss: 6.0141e-04 - val_acc: 0.9901\n",
      "Epoch 821/3000\n",
      " - 2s - loss: 6.0860e-04 - acc: 0.9901 - val_loss: 5.9573e-04 - val_acc: 0.9900\n",
      "Epoch 822/3000\n",
      " - 1s - loss: 6.0548e-04 - acc: 0.9901 - val_loss: 6.1998e-04 - val_acc: 0.9890\n",
      "Epoch 823/3000\n",
      " - 1s - loss: 6.0752e-04 - acc: 0.9901 - val_loss: 6.0144e-04 - val_acc: 0.9900\n",
      "Epoch 824/3000\n",
      " - 1s - loss: 6.0757e-04 - acc: 0.9902 - val_loss: 5.9595e-04 - val_acc: 0.9903\n",
      "Epoch 825/3000\n",
      " - 2s - loss: 6.1768e-04 - acc: 0.9900 - val_loss: 6.1171e-04 - val_acc: 0.9896\n",
      "Epoch 826/3000\n",
      " - 1s - loss: 6.1588e-04 - acc: 0.9901 - val_loss: 6.1301e-04 - val_acc: 0.9896\n",
      "Epoch 827/3000\n",
      " - 1s - loss: 6.1043e-04 - acc: 0.9901 - val_loss: 5.9536e-04 - val_acc: 0.9904\n",
      "Epoch 828/3000\n",
      " - 2s - loss: 6.2627e-04 - acc: 0.9899 - val_loss: 6.4513e-04 - val_acc: 0.9898\n",
      "Epoch 829/3000\n",
      " - 1s - loss: 6.2256e-04 - acc: 0.9900 - val_loss: 6.0867e-04 - val_acc: 0.9899\n",
      "Epoch 830/3000\n",
      " - 1s - loss: 6.1615e-04 - acc: 0.9900 - val_loss: 5.9520e-04 - val_acc: 0.9901\n",
      "Epoch 831/3000\n",
      " - 2s - loss: 6.0928e-04 - acc: 0.9902 - val_loss: 6.0933e-04 - val_acc: 0.9902\n",
      "Epoch 832/3000\n",
      " - 1s - loss: 6.0971e-04 - acc: 0.9901 - val_loss: 6.2325e-04 - val_acc: 0.9900\n",
      "Epoch 833/3000\n",
      " - 2s - loss: 6.1400e-04 - acc: 0.9901 - val_loss: 5.9677e-04 - val_acc: 0.9900\n",
      "Epoch 834/3000\n",
      " - 1s - loss: 6.0665e-04 - acc: 0.9902 - val_loss: 5.9663e-04 - val_acc: 0.9902\n",
      "Epoch 835/3000\n",
      " - 1s - loss: 6.2411e-04 - acc: 0.9900 - val_loss: 6.1625e-04 - val_acc: 0.9893\n",
      "Epoch 836/3000\n",
      " - 1s - loss: 6.1825e-04 - acc: 0.9900 - val_loss: 6.1192e-04 - val_acc: 0.9896\n",
      "Epoch 837/3000\n",
      " - 2s - loss: 6.0898e-04 - acc: 0.9900 - val_loss: 5.8375e-04 - val_acc: 0.9902\n",
      "Epoch 838/3000\n",
      " - 1s - loss: 5.9670e-04 - acc: 0.9902 - val_loss: 6.0994e-04 - val_acc: 0.9903\n",
      "Epoch 839/3000\n",
      " - 1s - loss: 6.1334e-04 - acc: 0.9901 - val_loss: 5.9813e-04 - val_acc: 0.9903\n",
      "Epoch 840/3000\n",
      "\n",
      "Epoch 00840: val_loss improved from 0.00060 to 0.00060, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 6.0873e-04 - acc: 0.9901 - val_loss: 5.9977e-04 - val_acc: 0.9903\n",
      "Epoch 841/3000\n",
      " - 1s - loss: 6.0397e-04 - acc: 0.9903 - val_loss: 6.2833e-04 - val_acc: 0.9900\n",
      "Epoch 842/3000\n",
      " - 1s - loss: 6.0404e-04 - acc: 0.9901 - val_loss: 6.1870e-04 - val_acc: 0.9899\n",
      "Epoch 843/3000\n",
      " - 2s - loss: 6.0504e-04 - acc: 0.9901 - val_loss: 5.8443e-04 - val_acc: 0.9902\n",
      "Epoch 844/3000\n",
      " - 2s - loss: 5.9121e-04 - acc: 0.9903 - val_loss: 6.2425e-04 - val_acc: 0.9898\n",
      "Epoch 845/3000\n",
      " - 1s - loss: 6.0995e-04 - acc: 0.9901 - val_loss: 5.8262e-04 - val_acc: 0.9900\n",
      "Epoch 846/3000\n",
      " - 2s - loss: 5.9829e-04 - acc: 0.9901 - val_loss: 5.8891e-04 - val_acc: 0.9900\n",
      "Epoch 847/3000\n",
      " - 1s - loss: 5.9261e-04 - acc: 0.9903 - val_loss: 5.7465e-04 - val_acc: 0.9901\n",
      "Epoch 848/3000\n",
      " - 1s - loss: 5.9168e-04 - acc: 0.9903 - val_loss: 5.9870e-04 - val_acc: 0.9900\n",
      "Epoch 849/3000\n",
      " - 1s - loss: 5.9751e-04 - acc: 0.9902 - val_loss: 5.8779e-04 - val_acc: 0.9900\n",
      "Epoch 850/3000\n",
      " - 2s - loss: 5.9751e-04 - acc: 0.9902 - val_loss: 5.8709e-04 - val_acc: 0.9902\n",
      "Epoch 851/3000\n",
      " - 2s - loss: 6.0109e-04 - acc: 0.9902 - val_loss: 5.9804e-04 - val_acc: 0.9903\n",
      "Epoch 852/3000\n",
      " - 1s - loss: 5.8824e-04 - acc: 0.9904 - val_loss: 5.9582e-04 - val_acc: 0.9898\n",
      "Epoch 853/3000\n",
      " - 1s - loss: 6.0083e-04 - acc: 0.9902 - val_loss: 5.9332e-04 - val_acc: 0.9902\n",
      "Epoch 854/3000\n",
      " - 2s - loss: 5.9371e-04 - acc: 0.9902 - val_loss: 5.8265e-04 - val_acc: 0.9899\n",
      "Epoch 855/3000\n",
      " - 1s - loss: 5.9694e-04 - acc: 0.9903 - val_loss: 5.9333e-04 - val_acc: 0.9904\n",
      "Epoch 856/3000\n",
      " - 1s - loss: 5.9838e-04 - acc: 0.9902 - val_loss: 5.9827e-04 - val_acc: 0.9899\n",
      "Epoch 857/3000\n",
      " - 1s - loss: 5.9933e-04 - acc: 0.9902 - val_loss: 5.8635e-04 - val_acc: 0.9902\n",
      "Epoch 858/3000\n",
      " - 1s - loss: 6.0344e-04 - acc: 0.9901 - val_loss: 5.9092e-04 - val_acc: 0.9902\n",
      "Epoch 859/3000\n",
      " - 1s - loss: 6.2238e-04 - acc: 0.9900 - val_loss: 6.0577e-04 - val_acc: 0.9900\n",
      "Epoch 860/3000\n",
      "\n",
      "Epoch 00860: val_loss improved from 0.00060 to 0.00059, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 5.9920e-04 - acc: 0.9902 - val_loss: 5.8722e-04 - val_acc: 0.9900\n",
      "Epoch 861/3000\n",
      " - 2s - loss: 6.0019e-04 - acc: 0.9902 - val_loss: 5.7287e-04 - val_acc: 0.9901\n",
      "Epoch 862/3000\n",
      " - 1s - loss: 5.9113e-04 - acc: 0.9903 - val_loss: 5.9703e-04 - val_acc: 0.9898\n",
      "Epoch 863/3000\n",
      " - 1s - loss: 6.0433e-04 - acc: 0.9901 - val_loss: 6.3588e-04 - val_acc: 0.9898\n",
      "Epoch 864/3000\n",
      " - 1s - loss: 6.0225e-04 - acc: 0.9901 - val_loss: 5.7336e-04 - val_acc: 0.9903\n",
      "Epoch 865/3000\n",
      " - 2s - loss: 5.9727e-04 - acc: 0.9902 - val_loss: 5.9543e-04 - val_acc: 0.9902\n",
      "Epoch 866/3000\n",
      " - 1s - loss: 6.0889e-04 - acc: 0.9901 - val_loss: 5.9077e-04 - val_acc: 0.9902\n",
      "Epoch 867/3000\n",
      " - 1s - loss: 5.9915e-04 - acc: 0.9902 - val_loss: 6.0121e-04 - val_acc: 0.9900\n",
      "Epoch 868/3000\n",
      " - 1s - loss: 5.9894e-04 - acc: 0.9902 - val_loss: 5.7356e-04 - val_acc: 0.9904\n",
      "Epoch 869/3000\n",
      " - 2s - loss: 6.1738e-04 - acc: 0.9900 - val_loss: 5.8408e-04 - val_acc: 0.9902\n",
      "Epoch 870/3000\n",
      " - 1s - loss: 5.8296e-04 - acc: 0.9904 - val_loss: 5.8549e-04 - val_acc: 0.9897\n",
      "Epoch 871/3000\n",
      " - 1s - loss: 5.9291e-04 - acc: 0.9903 - val_loss: 5.7869e-04 - val_acc: 0.9900\n",
      "Epoch 872/3000\n",
      " - 1s - loss: 5.9212e-04 - acc: 0.9903 - val_loss: 5.8770e-04 - val_acc: 0.9901\n",
      "Epoch 873/3000\n",
      " - 1s - loss: 5.9538e-04 - acc: 0.9902 - val_loss: 5.9756e-04 - val_acc: 0.9903\n",
      "Epoch 874/3000\n",
      " - 1s - loss: 5.8819e-04 - acc: 0.9903 - val_loss: 5.7286e-04 - val_acc: 0.9902\n",
      "Epoch 875/3000\n",
      " - 1s - loss: 5.9000e-04 - acc: 0.9902 - val_loss: 5.6573e-04 - val_acc: 0.9900\n",
      "Epoch 876/3000\n",
      " - 1s - loss: 5.9454e-04 - acc: 0.9902 - val_loss: 6.1479e-04 - val_acc: 0.9903\n",
      "Epoch 877/3000\n",
      " - 1s - loss: 5.9480e-04 - acc: 0.9902 - val_loss: 6.1710e-04 - val_acc: 0.9900\n",
      "Epoch 878/3000\n",
      " - 2s - loss: 6.0863e-04 - acc: 0.9901 - val_loss: 7.1918e-04 - val_acc: 0.9902\n",
      "Epoch 879/3000\n",
      " - 1s - loss: 6.0991e-04 - acc: 0.9901 - val_loss: 5.8631e-04 - val_acc: 0.9903\n",
      "Epoch 880/3000\n",
      "\n",
      "Epoch 00880: val_loss did not improve from 0.00059\n",
      " - 1s - loss: 5.9238e-04 - acc: 0.9903 - val_loss: 6.0725e-04 - val_acc: 0.9900\n",
      "Epoch 881/3000\n",
      " - 1s - loss: 5.9018e-04 - acc: 0.9903 - val_loss: 5.7071e-04 - val_acc: 0.9899\n",
      "Epoch 882/3000\n",
      " - 2s - loss: 5.8817e-04 - acc: 0.9903 - val_loss: 5.6150e-04 - val_acc: 0.9905\n",
      "Epoch 883/3000\n",
      " - 1s - loss: 5.8249e-04 - acc: 0.9904 - val_loss: 5.9232e-04 - val_acc: 0.9900\n",
      "Epoch 884/3000\n",
      " - 1s - loss: 5.9213e-04 - acc: 0.9903 - val_loss: 5.7849e-04 - val_acc: 0.9903\n",
      "Epoch 885/3000\n",
      " - 1s - loss: 5.8916e-04 - acc: 0.9903 - val_loss: 5.8288e-04 - val_acc: 0.9899\n",
      "Epoch 886/3000\n",
      " - 1s - loss: 6.0407e-04 - acc: 0.9901 - val_loss: 6.1527e-04 - val_acc: 0.9897\n",
      "Epoch 887/3000\n",
      " - 1s - loss: 5.9530e-04 - acc: 0.9902 - val_loss: 6.1508e-04 - val_acc: 0.9902\n",
      "Epoch 888/3000\n",
      " - 1s - loss: 5.8335e-04 - acc: 0.9903 - val_loss: 5.6569e-04 - val_acc: 0.9903\n",
      "Epoch 889/3000\n",
      " - 2s - loss: 5.8680e-04 - acc: 0.9903 - val_loss: 5.6692e-04 - val_acc: 0.9903\n",
      "Epoch 890/3000\n",
      " - 1s - loss: 5.7581e-04 - acc: 0.9904 - val_loss: 5.8754e-04 - val_acc: 0.9900\n",
      "Epoch 891/3000\n",
      " - 1s - loss: 5.9866e-04 - acc: 0.9903 - val_loss: 5.9988e-04 - val_acc: 0.9900\n",
      "Epoch 892/3000\n",
      " - 2s - loss: 5.9599e-04 - acc: 0.9902 - val_loss: 5.8743e-04 - val_acc: 0.9900\n",
      "Epoch 893/3000\n",
      " - 1s - loss: 5.8575e-04 - acc: 0.9903 - val_loss: 5.7294e-04 - val_acc: 0.9902\n",
      "Epoch 894/3000\n",
      " - 1s - loss: 5.8913e-04 - acc: 0.9903 - val_loss: 5.9852e-04 - val_acc: 0.9898\n",
      "Epoch 895/3000\n",
      " - 1s - loss: 6.1216e-04 - acc: 0.9900 - val_loss: 5.5906e-04 - val_acc: 0.9903\n",
      "Epoch 896/3000\n",
      " - 1s - loss: 5.8915e-04 - acc: 0.9903 - val_loss: 6.4124e-04 - val_acc: 0.9895\n",
      "Epoch 897/3000\n",
      " - 2s - loss: 6.0221e-04 - acc: 0.9901 - val_loss: 5.8945e-04 - val_acc: 0.9901\n",
      "Epoch 898/3000\n",
      " - 1s - loss: 5.9212e-04 - acc: 0.9901 - val_loss: 5.7256e-04 - val_acc: 0.9902\n",
      "Epoch 899/3000\n",
      " - 1s - loss: 5.8623e-04 - acc: 0.9904 - val_loss: 6.2453e-04 - val_acc: 0.9903\n",
      "Epoch 900/3000\n",
      "\n",
      "Epoch 00900: val_loss improved from 0.00059 to 0.00058, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 5.9252e-04 - acc: 0.9903 - val_loss: 5.7730e-04 - val_acc: 0.9906\n",
      "Epoch 901/3000\n",
      " - 2s - loss: 5.7789e-04 - acc: 0.9904 - val_loss: 5.7777e-04 - val_acc: 0.9903\n",
      "Epoch 902/3000\n",
      " - 2s - loss: 5.8201e-04 - acc: 0.9904 - val_loss: 5.6751e-04 - val_acc: 0.9903\n",
      "Epoch 903/3000\n",
      " - 2s - loss: 5.6888e-04 - acc: 0.9904 - val_loss: 5.8372e-04 - val_acc: 0.9902\n",
      "Epoch 904/3000\n",
      " - 1s - loss: 5.9133e-04 - acc: 0.9902 - val_loss: 5.8100e-04 - val_acc: 0.9904\n",
      "Epoch 905/3000\n",
      " - 1s - loss: 6.0030e-04 - acc: 0.9902 - val_loss: 5.7370e-04 - val_acc: 0.9904\n",
      "Epoch 906/3000\n",
      " - 1s - loss: 5.8700e-04 - acc: 0.9904 - val_loss: 6.0720e-04 - val_acc: 0.9900\n",
      "Epoch 907/3000\n",
      " - 1s - loss: 5.8442e-04 - acc: 0.9902 - val_loss: 5.8469e-04 - val_acc: 0.9901\n",
      "Epoch 908/3000\n",
      " - 2s - loss: 6.1977e-04 - acc: 0.9899 - val_loss: 5.8089e-04 - val_acc: 0.9900\n",
      "Epoch 909/3000\n",
      " - 2s - loss: 5.7752e-04 - acc: 0.9904 - val_loss: 5.6754e-04 - val_acc: 0.9903\n",
      "Epoch 910/3000\n",
      " - 2s - loss: 5.8113e-04 - acc: 0.9903 - val_loss: 5.7073e-04 - val_acc: 0.9904\n",
      "Epoch 911/3000\n",
      " - 1s - loss: 5.8016e-04 - acc: 0.9904 - val_loss: 5.7819e-04 - val_acc: 0.9903\n",
      "Epoch 912/3000\n",
      " - 1s - loss: 5.9129e-04 - acc: 0.9903 - val_loss: 5.6183e-04 - val_acc: 0.9904\n",
      "Epoch 913/3000\n",
      " - 1s - loss: 5.7853e-04 - acc: 0.9903 - val_loss: 5.9731e-04 - val_acc: 0.9900\n",
      "Epoch 914/3000\n",
      " - 1s - loss: 5.8041e-04 - acc: 0.9904 - val_loss: 5.5536e-04 - val_acc: 0.9904\n",
      "Epoch 915/3000\n",
      " - 1s - loss: 5.7549e-04 - acc: 0.9904 - val_loss: 5.6649e-04 - val_acc: 0.9902\n",
      "Epoch 916/3000\n",
      " - 2s - loss: 5.7201e-04 - acc: 0.9904 - val_loss: 5.8131e-04 - val_acc: 0.9904\n",
      "Epoch 917/3000\n",
      " - 1s - loss: 5.9275e-04 - acc: 0.9903 - val_loss: 5.8235e-04 - val_acc: 0.9901\n",
      "Epoch 918/3000\n",
      " - 2s - loss: 5.7434e-04 - acc: 0.9904 - val_loss: 5.6501e-04 - val_acc: 0.9901\n",
      "Epoch 919/3000\n",
      " - 2s - loss: 5.8398e-04 - acc: 0.9904 - val_loss: 6.0276e-04 - val_acc: 0.9898\n",
      "Epoch 920/3000\n",
      "\n",
      "Epoch 00920: val_loss improved from 0.00058 to 0.00056, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 5.8023e-04 - acc: 0.9904 - val_loss: 5.5514e-04 - val_acc: 0.9902\n",
      "Epoch 921/3000\n",
      " - 2s - loss: 5.7201e-04 - acc: 0.9905 - val_loss: 5.6709e-04 - val_acc: 0.9900\n",
      "Epoch 922/3000\n",
      " - 2s - loss: 5.7526e-04 - acc: 0.9905 - val_loss: 5.8718e-04 - val_acc: 0.9902\n",
      "Epoch 923/3000\n",
      " - 1s - loss: 5.8858e-04 - acc: 0.9903 - val_loss: 5.9902e-04 - val_acc: 0.9903\n",
      "Epoch 924/3000\n",
      " - 1s - loss: 5.9072e-04 - acc: 0.9902 - val_loss: 5.7157e-04 - val_acc: 0.9903\n",
      "Epoch 925/3000\n",
      " - 1s - loss: 5.7420e-04 - acc: 0.9903 - val_loss: 5.7921e-04 - val_acc: 0.9902\n",
      "Epoch 926/3000\n",
      " - 1s - loss: 5.7352e-04 - acc: 0.9905 - val_loss: 5.8135e-04 - val_acc: 0.9903\n",
      "Epoch 927/3000\n",
      " - 1s - loss: 5.7309e-04 - acc: 0.9904 - val_loss: 5.6397e-04 - val_acc: 0.9903\n",
      "Epoch 928/3000\n",
      " - 2s - loss: 5.7183e-04 - acc: 0.9904 - val_loss: 5.5554e-04 - val_acc: 0.9902\n",
      "Epoch 929/3000\n",
      " - 1s - loss: 5.6529e-04 - acc: 0.9905 - val_loss: 5.6154e-04 - val_acc: 0.9905\n",
      "Epoch 930/3000\n",
      " - 1s - loss: 5.7404e-04 - acc: 0.9905 - val_loss: 5.6933e-04 - val_acc: 0.9900\n",
      "Epoch 931/3000\n",
      " - 1s - loss: 5.6566e-04 - acc: 0.9905 - val_loss: 5.6767e-04 - val_acc: 0.9901\n",
      "Epoch 932/3000\n",
      " - 1s - loss: 5.7183e-04 - acc: 0.9905 - val_loss: 5.5045e-04 - val_acc: 0.9905\n",
      "Epoch 933/3000\n",
      " - 2s - loss: 5.6398e-04 - acc: 0.9905 - val_loss: 5.5236e-04 - val_acc: 0.9905\n",
      "Epoch 934/3000\n",
      " - 1s - loss: 5.6805e-04 - acc: 0.9905 - val_loss: 5.5827e-04 - val_acc: 0.9904\n",
      "Epoch 935/3000\n",
      " - 1s - loss: 5.8849e-04 - acc: 0.9902 - val_loss: 5.6159e-04 - val_acc: 0.9905\n",
      "Epoch 936/3000\n",
      " - 1s - loss: 5.7002e-04 - acc: 0.9904 - val_loss: 5.5396e-04 - val_acc: 0.9904\n",
      "Epoch 937/3000\n",
      " - 1s - loss: 5.7207e-04 - acc: 0.9906 - val_loss: 5.7399e-04 - val_acc: 0.9904\n",
      "Epoch 938/3000\n",
      " - 1s - loss: 5.6829e-04 - acc: 0.9905 - val_loss: 6.8543e-04 - val_acc: 0.9900\n",
      "Epoch 939/3000\n",
      " - 1s - loss: 5.8435e-04 - acc: 0.9903 - val_loss: 5.6544e-04 - val_acc: 0.9904\n",
      "Epoch 940/3000\n",
      "\n",
      "Epoch 00940: val_loss did not improve from 0.00056\n",
      " - 1s - loss: 5.7792e-04 - acc: 0.9905 - val_loss: 5.5841e-04 - val_acc: 0.9904\n",
      "Epoch 941/3000\n",
      " - 2s - loss: 5.7554e-04 - acc: 0.9904 - val_loss: 5.7133e-04 - val_acc: 0.9904\n",
      "Epoch 942/3000\n",
      " - 2s - loss: 5.7440e-04 - acc: 0.9903 - val_loss: 5.5620e-04 - val_acc: 0.9904\n",
      "Epoch 943/3000\n",
      " - 1s - loss: 5.6847e-04 - acc: 0.9905 - val_loss: 5.5729e-04 - val_acc: 0.9905\n",
      "Epoch 944/3000\n",
      " - 1s - loss: 5.7428e-04 - acc: 0.9904 - val_loss: 6.1066e-04 - val_acc: 0.9900\n",
      "Epoch 945/3000\n",
      " - 1s - loss: 5.7341e-04 - acc: 0.9905 - val_loss: 5.5878e-04 - val_acc: 0.9903\n",
      "Epoch 946/3000\n",
      " - 1s - loss: 5.6875e-04 - acc: 0.9905 - val_loss: 5.5648e-04 - val_acc: 0.9903\n",
      "Epoch 947/3000\n",
      " - 1s - loss: 5.6854e-04 - acc: 0.9905 - val_loss: 5.8563e-04 - val_acc: 0.9902\n",
      "Epoch 948/3000\n",
      " - 2s - loss: 5.7304e-04 - acc: 0.9905 - val_loss: 6.0615e-04 - val_acc: 0.9903\n",
      "Epoch 949/3000\n",
      " - 2s - loss: 5.7806e-04 - acc: 0.9904 - val_loss: 5.7712e-04 - val_acc: 0.9901\n",
      "Epoch 950/3000\n",
      " - 1s - loss: 5.7529e-04 - acc: 0.9904 - val_loss: 5.6747e-04 - val_acc: 0.9899\n",
      "Epoch 951/3000\n",
      " - 1s - loss: 5.8688e-04 - acc: 0.9903 - val_loss: 5.6396e-04 - val_acc: 0.9904\n",
      "Epoch 952/3000\n",
      " - 1s - loss: 5.8795e-04 - acc: 0.9902 - val_loss: 5.6983e-04 - val_acc: 0.9903\n",
      "Epoch 953/3000\n",
      " - 1s - loss: 5.6345e-04 - acc: 0.9906 - val_loss: 5.5497e-04 - val_acc: 0.9903\n",
      "Epoch 954/3000\n",
      " - 1s - loss: 5.5684e-04 - acc: 0.9906 - val_loss: 5.7223e-04 - val_acc: 0.9906\n",
      "Epoch 955/3000\n",
      " - 2s - loss: 5.7693e-04 - acc: 0.9904 - val_loss: 5.5155e-04 - val_acc: 0.9905\n",
      "Epoch 956/3000\n",
      " - 1s - loss: 5.8432e-04 - acc: 0.9903 - val_loss: 5.9417e-04 - val_acc: 0.9894\n",
      "Epoch 957/3000\n",
      " - 1s - loss: 5.8029e-04 - acc: 0.9902 - val_loss: 5.6553e-04 - val_acc: 0.9904\n",
      "Epoch 958/3000\n",
      " - 2s - loss: 5.7373e-04 - acc: 0.9904 - val_loss: 5.5320e-04 - val_acc: 0.9900\n",
      "Epoch 959/3000\n",
      " - 1s - loss: 5.5653e-04 - acc: 0.9906 - val_loss: 5.4334e-04 - val_acc: 0.9906\n",
      "Epoch 960/3000\n",
      "\n",
      "Epoch 00960: val_loss did not improve from 0.00056\n",
      " - 1s - loss: 5.6439e-04 - acc: 0.9905 - val_loss: 5.9311e-04 - val_acc: 0.9905\n",
      "Epoch 961/3000\n",
      " - 1s - loss: 5.7560e-04 - acc: 0.9904 - val_loss: 6.3218e-04 - val_acc: 0.9892\n",
      "Epoch 962/3000\n",
      " - 1s - loss: 5.7580e-04 - acc: 0.9904 - val_loss: 5.5350e-04 - val_acc: 0.9903\n",
      "Epoch 963/3000\n",
      " - 1s - loss: 5.7749e-04 - acc: 0.9902 - val_loss: 5.6912e-04 - val_acc: 0.9904\n",
      "Epoch 964/3000\n",
      " - 1s - loss: 5.5767e-04 - acc: 0.9906 - val_loss: 5.5025e-04 - val_acc: 0.9904\n",
      "Epoch 965/3000\n",
      " - 1s - loss: 5.6159e-04 - acc: 0.9906 - val_loss: 5.8044e-04 - val_acc: 0.9901\n",
      "Epoch 966/3000\n",
      " - 2s - loss: 5.5680e-04 - acc: 0.9906 - val_loss: 5.5496e-04 - val_acc: 0.9905\n",
      "Epoch 967/3000\n",
      " - 1s - loss: 5.6446e-04 - acc: 0.9905 - val_loss: 5.4080e-04 - val_acc: 0.9906\n",
      "Epoch 968/3000\n",
      " - 2s - loss: 5.7057e-04 - acc: 0.9905 - val_loss: 5.5709e-04 - val_acc: 0.9904\n",
      "Epoch 969/3000\n",
      " - 1s - loss: 5.6783e-04 - acc: 0.9904 - val_loss: 6.2796e-04 - val_acc: 0.9898\n",
      "Epoch 970/3000\n",
      " - 1s - loss: 5.6831e-04 - acc: 0.9904 - val_loss: 6.0399e-04 - val_acc: 0.9905\n",
      "Epoch 971/3000\n",
      " - 1s - loss: 5.6148e-04 - acc: 0.9905 - val_loss: 5.4800e-04 - val_acc: 0.9901\n",
      "Epoch 972/3000\n",
      " - 1s - loss: 5.6282e-04 - acc: 0.9905 - val_loss: 5.9137e-04 - val_acc: 0.9900\n",
      "Epoch 973/3000\n",
      " - 2s - loss: 5.6460e-04 - acc: 0.9905 - val_loss: 5.5622e-04 - val_acc: 0.9905\n",
      "Epoch 974/3000\n",
      " - 1s - loss: 5.8018e-04 - acc: 0.9904 - val_loss: 5.9507e-04 - val_acc: 0.9897\n",
      "Epoch 975/3000\n",
      " - 1s - loss: 5.6727e-04 - acc: 0.9904 - val_loss: 5.7359e-04 - val_acc: 0.9902\n",
      "Epoch 976/3000\n",
      " - 1s - loss: 5.7845e-04 - acc: 0.9903 - val_loss: 5.5834e-04 - val_acc: 0.9902\n",
      "Epoch 977/3000\n",
      " - 1s - loss: 5.6626e-04 - acc: 0.9905 - val_loss: 5.5649e-04 - val_acc: 0.9905\n",
      "Epoch 978/3000\n",
      " - 2s - loss: 5.7402e-04 - acc: 0.9905 - val_loss: 6.3065e-04 - val_acc: 0.9898\n",
      "Epoch 979/3000\n",
      " - 1s - loss: 5.6820e-04 - acc: 0.9904 - val_loss: 5.7249e-04 - val_acc: 0.9903\n",
      "Epoch 980/3000\n",
      "\n",
      "Epoch 00980: val_loss did not improve from 0.00056\n",
      " - 1s - loss: 5.6688e-04 - acc: 0.9905 - val_loss: 5.5778e-04 - val_acc: 0.9905\n",
      "Epoch 981/3000\n",
      " - 1s - loss: 5.5966e-04 - acc: 0.9906 - val_loss: 5.6179e-04 - val_acc: 0.9905\n",
      "Epoch 982/3000\n",
      " - 1s - loss: 5.5773e-04 - acc: 0.9907 - val_loss: 5.6459e-04 - val_acc: 0.9901\n",
      "Epoch 983/3000\n",
      " - 1s - loss: 5.7946e-04 - acc: 0.9902 - val_loss: 5.4810e-04 - val_acc: 0.9902\n",
      "Epoch 984/3000\n",
      " - 1s - loss: 5.7461e-04 - acc: 0.9904 - val_loss: 5.8353e-04 - val_acc: 0.9900\n",
      "Epoch 985/3000\n",
      " - 1s - loss: 5.6556e-04 - acc: 0.9906 - val_loss: 5.8447e-04 - val_acc: 0.9902\n",
      "Epoch 986/3000\n",
      " - 2s - loss: 5.7134e-04 - acc: 0.9904 - val_loss: 5.5734e-04 - val_acc: 0.9904\n",
      "Epoch 987/3000\n",
      " - 1s - loss: 5.5531e-04 - acc: 0.9906 - val_loss: 5.3824e-04 - val_acc: 0.9905\n",
      "Epoch 988/3000\n",
      " - 2s - loss: 5.5468e-04 - acc: 0.9906 - val_loss: 5.5071e-04 - val_acc: 0.9906\n",
      "Epoch 989/3000\n",
      " - 1s - loss: 5.6052e-04 - acc: 0.9906 - val_loss: 5.4957e-04 - val_acc: 0.9903\n",
      "Epoch 990/3000\n",
      " - 1s - loss: 5.6427e-04 - acc: 0.9905 - val_loss: 5.7107e-04 - val_acc: 0.9902\n",
      "Epoch 991/3000\n",
      " - 2s - loss: 5.5513e-04 - acc: 0.9906 - val_loss: 5.6031e-04 - val_acc: 0.9906\n",
      "Epoch 992/3000\n",
      " - 1s - loss: 5.6412e-04 - acc: 0.9905 - val_loss: 5.5170e-04 - val_acc: 0.9904\n",
      "Epoch 993/3000\n",
      " - 2s - loss: 5.6734e-04 - acc: 0.9905 - val_loss: 5.6735e-04 - val_acc: 0.9904\n",
      "Epoch 994/3000\n",
      " - 1s - loss: 5.5142e-04 - acc: 0.9906 - val_loss: 5.5830e-04 - val_acc: 0.9903\n",
      "Epoch 995/3000\n",
      " - 1s - loss: 5.6589e-04 - acc: 0.9905 - val_loss: 5.5321e-04 - val_acc: 0.9903\n",
      "Epoch 996/3000\n",
      " - 1s - loss: 5.5790e-04 - acc: 0.9905 - val_loss: 5.4429e-04 - val_acc: 0.9905\n",
      "Epoch 997/3000\n",
      " - 1s - loss: 5.4646e-04 - acc: 0.9907 - val_loss: 5.5997e-04 - val_acc: 0.9906\n",
      "Epoch 998/3000\n",
      " - 2s - loss: 5.5549e-04 - acc: 0.9906 - val_loss: 5.4137e-04 - val_acc: 0.9904\n",
      "Epoch 999/3000\n",
      " - 2s - loss: 5.6437e-04 - acc: 0.9905 - val_loss: 5.6554e-04 - val_acc: 0.9902\n",
      "Epoch 1000/3000\n",
      "\n",
      "Epoch 01000: val_loss improved from 0.00056 to 0.00054, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 5.5922e-04 - acc: 0.9906 - val_loss: 5.3776e-04 - val_acc: 0.9907\n",
      "Epoch 1001/3000\n",
      " - 2s - loss: 5.5251e-04 - acc: 0.9907 - val_loss: 5.3563e-04 - val_acc: 0.9906\n",
      "Epoch 1002/3000\n",
      " - 2s - loss: 5.5756e-04 - acc: 0.9906 - val_loss: 5.7589e-04 - val_acc: 0.9904\n",
      "Epoch 1003/3000\n",
      " - 1s - loss: 5.6692e-04 - acc: 0.9905 - val_loss: 5.8803e-04 - val_acc: 0.9899\n",
      "Epoch 1004/3000\n",
      " - 2s - loss: 5.5767e-04 - acc: 0.9906 - val_loss: 5.3600e-04 - val_acc: 0.9905\n",
      "Epoch 1005/3000\n",
      " - 2s - loss: 5.5148e-04 - acc: 0.9907 - val_loss: 5.3148e-04 - val_acc: 0.9908\n",
      "Epoch 1006/3000\n",
      " - 2s - loss: 5.5858e-04 - acc: 0.9906 - val_loss: 5.6810e-04 - val_acc: 0.9905\n",
      "Epoch 1007/3000\n",
      " - 2s - loss: 5.5079e-04 - acc: 0.9907 - val_loss: 5.4066e-04 - val_acc: 0.9904\n",
      "Epoch 1008/3000\n",
      " - 2s - loss: 5.7053e-04 - acc: 0.9904 - val_loss: 5.5213e-04 - val_acc: 0.9904\n",
      "Epoch 1009/3000\n",
      " - 1s - loss: 5.4429e-04 - acc: 0.9907 - val_loss: 5.6555e-04 - val_acc: 0.9906\n",
      "Epoch 1010/3000\n",
      " - 1s - loss: 5.6272e-04 - acc: 0.9905 - val_loss: 5.7476e-04 - val_acc: 0.9901\n",
      "Epoch 1011/3000\n",
      " - 2s - loss: 5.5297e-04 - acc: 0.9906 - val_loss: 5.4593e-04 - val_acc: 0.9901\n",
      "Epoch 1012/3000\n",
      " - 1s - loss: 5.5332e-04 - acc: 0.9906 - val_loss: 5.3661e-04 - val_acc: 0.9905\n",
      "Epoch 1013/3000\n",
      " - 1s - loss: 5.6633e-04 - acc: 0.9906 - val_loss: 5.8998e-04 - val_acc: 0.9903\n",
      "Epoch 1014/3000\n",
      " - 1s - loss: 5.5782e-04 - acc: 0.9906 - val_loss: 5.5167e-04 - val_acc: 0.9902\n",
      "Epoch 1015/3000\n",
      " - 1s - loss: 5.4540e-04 - acc: 0.9907 - val_loss: 5.6731e-04 - val_acc: 0.9905\n",
      "Epoch 1016/3000\n",
      " - 1s - loss: 5.6023e-04 - acc: 0.9904 - val_loss: 5.6330e-04 - val_acc: 0.9907\n",
      "Epoch 1017/3000\n",
      " - 1s - loss: 5.5516e-04 - acc: 0.9907 - val_loss: 5.7942e-04 - val_acc: 0.9903\n",
      "Epoch 1018/3000\n",
      " - 2s - loss: 5.5579e-04 - acc: 0.9906 - val_loss: 5.6476e-04 - val_acc: 0.9905\n",
      "Epoch 1019/3000\n",
      " - 2s - loss: 5.5502e-04 - acc: 0.9906 - val_loss: 5.3898e-04 - val_acc: 0.9903\n",
      "Epoch 1020/3000\n",
      "\n",
      "Epoch 01020: val_loss did not improve from 0.00054\n",
      " - 1s - loss: 5.4768e-04 - acc: 0.9907 - val_loss: 5.4723e-04 - val_acc: 0.9904\n",
      "Epoch 1021/3000\n",
      " - 2s - loss: 5.4682e-04 - acc: 0.9908 - val_loss: 5.4865e-04 - val_acc: 0.9905\n",
      "Epoch 1022/3000\n",
      " - 1s - loss: 5.4928e-04 - acc: 0.9907 - val_loss: 5.3136e-04 - val_acc: 0.9906\n",
      "Epoch 1023/3000\n",
      " - 2s - loss: 5.5861e-04 - acc: 0.9905 - val_loss: 5.4913e-04 - val_acc: 0.9901\n",
      "Epoch 1024/3000\n",
      " - 2s - loss: 5.6535e-04 - acc: 0.9905 - val_loss: 5.7414e-04 - val_acc: 0.9902\n",
      "Epoch 1025/3000\n",
      " - 2s - loss: 5.5094e-04 - acc: 0.9906 - val_loss: 5.3589e-04 - val_acc: 0.9905\n",
      "Epoch 1026/3000\n",
      " - 2s - loss: 5.4430e-04 - acc: 0.9907 - val_loss: 5.4440e-04 - val_acc: 0.9907\n",
      "Epoch 1027/3000\n",
      " - 2s - loss: 5.7302e-04 - acc: 0.9905 - val_loss: 5.5912e-04 - val_acc: 0.9903\n",
      "Epoch 1028/3000\n",
      " - 2s - loss: 5.6032e-04 - acc: 0.9906 - val_loss: 5.4097e-04 - val_acc: 0.9905\n",
      "Epoch 1029/3000\n",
      " - 2s - loss: 5.4545e-04 - acc: 0.9907 - val_loss: 5.3203e-04 - val_acc: 0.9907\n",
      "Epoch 1030/3000\n",
      " - 1s - loss: 5.4996e-04 - acc: 0.9907 - val_loss: 5.6419e-04 - val_acc: 0.9906\n",
      "Epoch 1031/3000\n",
      " - 2s - loss: 5.4497e-04 - acc: 0.9907 - val_loss: 5.3649e-04 - val_acc: 0.9908\n",
      "Epoch 1032/3000\n",
      " - 1s - loss: 5.4590e-04 - acc: 0.9907 - val_loss: 5.3908e-04 - val_acc: 0.9905\n",
      "Epoch 1033/3000\n",
      " - 2s - loss: 5.5145e-04 - acc: 0.9906 - val_loss: 5.3675e-04 - val_acc: 0.9903\n",
      "Epoch 1034/3000\n",
      " - 2s - loss: 5.5075e-04 - acc: 0.9906 - val_loss: 5.4581e-04 - val_acc: 0.9903\n",
      "Epoch 1035/3000\n",
      " - 2s - loss: 5.4205e-04 - acc: 0.9908 - val_loss: 5.3757e-04 - val_acc: 0.9908\n",
      "Epoch 1036/3000\n",
      " - 2s - loss: 5.5168e-04 - acc: 0.9906 - val_loss: 5.4082e-04 - val_acc: 0.9904\n",
      "Epoch 1037/3000\n",
      " - 2s - loss: 5.4632e-04 - acc: 0.9907 - val_loss: 5.8463e-04 - val_acc: 0.9899\n",
      "Epoch 1038/3000\n",
      " - 1s - loss: 5.4513e-04 - acc: 0.9907 - val_loss: 5.3091e-04 - val_acc: 0.9908\n",
      "Epoch 1039/3000\n",
      " - 2s - loss: 5.5473e-04 - acc: 0.9906 - val_loss: 5.5165e-04 - val_acc: 0.9905\n",
      "Epoch 1040/3000\n",
      "\n",
      "Epoch 01040: val_loss did not improve from 0.00054\n",
      " - 1s - loss: 5.5986e-04 - acc: 0.9905 - val_loss: 5.7948e-04 - val_acc: 0.9902\n",
      "Epoch 1041/3000\n",
      " - 1s - loss: 5.8074e-04 - acc: 0.9902 - val_loss: 5.3859e-04 - val_acc: 0.9906\n",
      "Epoch 1042/3000\n",
      " - 2s - loss: 5.5791e-04 - acc: 0.9906 - val_loss: 5.4313e-04 - val_acc: 0.9901\n",
      "Epoch 1043/3000\n",
      " - 2s - loss: 5.4864e-04 - acc: 0.9906 - val_loss: 5.5486e-04 - val_acc: 0.9903\n",
      "Epoch 1044/3000\n",
      " - 2s - loss: 5.4491e-04 - acc: 0.9907 - val_loss: 5.4785e-04 - val_acc: 0.9906\n",
      "Epoch 1045/3000\n",
      " - 2s - loss: 5.4574e-04 - acc: 0.9907 - val_loss: 5.5016e-04 - val_acc: 0.9905\n",
      "Epoch 1046/3000\n",
      " - 2s - loss: 5.4695e-04 - acc: 0.9907 - val_loss: 5.3746e-04 - val_acc: 0.9907\n",
      "Epoch 1047/3000\n",
      " - 2s - loss: 5.4130e-04 - acc: 0.9908 - val_loss: 5.3494e-04 - val_acc: 0.9908\n",
      "Epoch 1048/3000\n",
      " - 2s - loss: 5.5488e-04 - acc: 0.9906 - val_loss: 5.2887e-04 - val_acc: 0.9908\n",
      "Epoch 1049/3000\n",
      " - 2s - loss: 5.4755e-04 - acc: 0.9908 - val_loss: 5.7345e-04 - val_acc: 0.9903\n",
      "Epoch 1050/3000\n",
      " - 2s - loss: 5.5236e-04 - acc: 0.9907 - val_loss: 5.4145e-04 - val_acc: 0.9908\n",
      "Epoch 1051/3000\n",
      " - 2s - loss: 5.4073e-04 - acc: 0.9908 - val_loss: 5.6052e-04 - val_acc: 0.9907\n",
      "Epoch 1052/3000\n",
      " - 1s - loss: 5.4001e-04 - acc: 0.9908 - val_loss: 5.4869e-04 - val_acc: 0.9904\n",
      "Epoch 1053/3000\n",
      " - 2s - loss: 5.3999e-04 - acc: 0.9908 - val_loss: 5.4396e-04 - val_acc: 0.9903\n",
      "Epoch 1054/3000\n",
      " - 2s - loss: 5.4895e-04 - acc: 0.9906 - val_loss: 5.4516e-04 - val_acc: 0.9904\n",
      "Epoch 1055/3000\n",
      " - 2s - loss: 5.4740e-04 - acc: 0.9907 - val_loss: 5.2554e-04 - val_acc: 0.9907\n",
      "Epoch 1056/3000\n",
      " - 2s - loss: 5.4709e-04 - acc: 0.9907 - val_loss: 5.3741e-04 - val_acc: 0.9901\n",
      "Epoch 1057/3000\n",
      " - 1s - loss: 5.5194e-04 - acc: 0.9906 - val_loss: 5.5421e-04 - val_acc: 0.9906\n",
      "Epoch 1058/3000\n",
      " - 2s - loss: 5.6171e-04 - acc: 0.9906 - val_loss: 5.3995e-04 - val_acc: 0.9906\n",
      "Epoch 1059/3000\n",
      " - 1s - loss: 5.3925e-04 - acc: 0.9907 - val_loss: 5.2366e-04 - val_acc: 0.9905\n",
      "Epoch 1060/3000\n",
      "\n",
      "Epoch 01060: val_loss did not improve from 0.00054\n",
      " - 2s - loss: 5.4816e-04 - acc: 0.9907 - val_loss: 5.4845e-04 - val_acc: 0.9904\n",
      "Epoch 1061/3000\n",
      " - 2s - loss: 5.5282e-04 - acc: 0.9906 - val_loss: 5.4469e-04 - val_acc: 0.9906\n",
      "Epoch 1062/3000\n",
      " - 2s - loss: 5.5428e-04 - acc: 0.9907 - val_loss: 5.5298e-04 - val_acc: 0.9902\n",
      "Epoch 1063/3000\n",
      " - 2s - loss: 5.4455e-04 - acc: 0.9907 - val_loss: 5.4100e-04 - val_acc: 0.9907\n",
      "Epoch 1064/3000\n",
      " - 1s - loss: 5.3498e-04 - acc: 0.9909 - val_loss: 5.2928e-04 - val_acc: 0.9906\n",
      "Epoch 1065/3000\n",
      " - 2s - loss: 5.4892e-04 - acc: 0.9907 - val_loss: 5.7165e-04 - val_acc: 0.9897\n",
      "Epoch 1066/3000\n",
      " - 2s - loss: 5.6208e-04 - acc: 0.9905 - val_loss: 5.2868e-04 - val_acc: 0.9904\n",
      "Epoch 1067/3000\n",
      " - 2s - loss: 5.5126e-04 - acc: 0.9906 - val_loss: 5.5769e-04 - val_acc: 0.9908\n",
      "Epoch 1068/3000\n",
      " - 2s - loss: 5.4363e-04 - acc: 0.9907 - val_loss: 5.3337e-04 - val_acc: 0.9907\n",
      "Epoch 1069/3000\n",
      " - 2s - loss: 5.4809e-04 - acc: 0.9906 - val_loss: 5.5486e-04 - val_acc: 0.9904\n",
      "Epoch 1070/3000\n",
      " - 2s - loss: 5.5027e-04 - acc: 0.9906 - val_loss: 5.4277e-04 - val_acc: 0.9905\n",
      "Epoch 1071/3000\n",
      " - 2s - loss: 5.4499e-04 - acc: 0.9906 - val_loss: 5.6324e-04 - val_acc: 0.9907\n",
      "Epoch 1072/3000\n",
      " - 2s - loss: 5.4259e-04 - acc: 0.9908 - val_loss: 5.5366e-04 - val_acc: 0.9908\n",
      "Epoch 1073/3000\n",
      " - 2s - loss: 5.5050e-04 - acc: 0.9907 - val_loss: 5.3538e-04 - val_acc: 0.9905\n",
      "Epoch 1074/3000\n",
      " - 2s - loss: 5.4985e-04 - acc: 0.9907 - val_loss: 5.5441e-04 - val_acc: 0.9905\n",
      "Epoch 1075/3000\n",
      " - 2s - loss: 5.3578e-04 - acc: 0.9908 - val_loss: 5.2925e-04 - val_acc: 0.9909\n",
      "Epoch 1076/3000\n",
      " - 1s - loss: 5.4311e-04 - acc: 0.9908 - val_loss: 5.4086e-04 - val_acc: 0.9907\n",
      "Epoch 1077/3000\n",
      " - 2s - loss: 5.4913e-04 - acc: 0.9907 - val_loss: 5.3875e-04 - val_acc: 0.9906\n",
      "Epoch 1078/3000\n",
      " - 2s - loss: 5.4001e-04 - acc: 0.9908 - val_loss: 5.3897e-04 - val_acc: 0.9906\n",
      "Epoch 1079/3000\n",
      " - 1s - loss: 5.6418e-04 - acc: 0.9906 - val_loss: 5.5684e-04 - val_acc: 0.9903\n",
      "Epoch 1080/3000\n",
      "\n",
      "Epoch 01080: val_loss improved from 0.00054 to 0.00053, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 5.4404e-04 - acc: 0.9906 - val_loss: 5.2512e-04 - val_acc: 0.9906\n",
      "Epoch 1081/3000\n",
      " - 2s - loss: 5.4338e-04 - acc: 0.9908 - val_loss: 5.6895e-04 - val_acc: 0.9905\n",
      "Epoch 1082/3000\n",
      " - 1s - loss: 5.4307e-04 - acc: 0.9907 - val_loss: 5.5754e-04 - val_acc: 0.9908\n",
      "Epoch 1083/3000\n",
      " - 1s - loss: 5.4979e-04 - acc: 0.9905 - val_loss: 5.3711e-04 - val_acc: 0.9904\n",
      "Epoch 1084/3000\n",
      " - 2s - loss: 5.5139e-04 - acc: 0.9906 - val_loss: 5.2412e-04 - val_acc: 0.9907\n",
      "Epoch 1085/3000\n",
      " - 2s - loss: 5.5119e-04 - acc: 0.9907 - val_loss: 5.5521e-04 - val_acc: 0.9903\n",
      "Epoch 1086/3000\n",
      " - 2s - loss: 5.3883e-04 - acc: 0.9907 - val_loss: 5.8487e-04 - val_acc: 0.9904\n",
      "Epoch 1087/3000\n",
      " - 2s - loss: 5.4773e-04 - acc: 0.9907 - val_loss: 5.2307e-04 - val_acc: 0.9908\n",
      "Epoch 1088/3000\n",
      " - 2s - loss: 5.3290e-04 - acc: 0.9908 - val_loss: 5.1683e-04 - val_acc: 0.9910\n",
      "Epoch 1089/3000\n",
      " - 1s - loss: 5.3135e-04 - acc: 0.9908 - val_loss: 5.5332e-04 - val_acc: 0.9909\n",
      "Epoch 1090/3000\n",
      " - 2s - loss: 5.3944e-04 - acc: 0.9908 - val_loss: 5.2948e-04 - val_acc: 0.9906\n",
      "Epoch 1091/3000\n",
      " - 1s - loss: 5.3469e-04 - acc: 0.9908 - val_loss: 5.5173e-04 - val_acc: 0.9905\n",
      "Epoch 1092/3000\n",
      " - 2s - loss: 5.4209e-04 - acc: 0.9906 - val_loss: 5.2626e-04 - val_acc: 0.9908\n",
      "Epoch 1093/3000\n",
      " - 1s - loss: 5.3833e-04 - acc: 0.9908 - val_loss: 5.4475e-04 - val_acc: 0.9908\n",
      "Epoch 1094/3000\n",
      " - 2s - loss: 5.2944e-04 - acc: 0.9908 - val_loss: 5.2219e-04 - val_acc: 0.9910\n",
      "Epoch 1095/3000\n",
      " - 2s - loss: 5.3250e-04 - acc: 0.9908 - val_loss: 5.3511e-04 - val_acc: 0.9906\n",
      "Epoch 1096/3000\n",
      " - 2s - loss: 5.3169e-04 - acc: 0.9909 - val_loss: 5.4172e-04 - val_acc: 0.9908\n",
      "Epoch 1097/3000\n",
      " - 1s - loss: 5.3989e-04 - acc: 0.9908 - val_loss: 5.5276e-04 - val_acc: 0.9906\n",
      "Epoch 1098/3000\n",
      " - 2s - loss: 5.3811e-04 - acc: 0.9908 - val_loss: 5.4132e-04 - val_acc: 0.9901\n",
      "Epoch 1099/3000\n",
      " - 2s - loss: 5.4050e-04 - acc: 0.9907 - val_loss: 5.3907e-04 - val_acc: 0.9910\n",
      "Epoch 1100/3000\n",
      "\n",
      "Epoch 01100: val_loss did not improve from 0.00053\n",
      " - 2s - loss: 5.5098e-04 - acc: 0.9907 - val_loss: 5.5588e-04 - val_acc: 0.9908\n",
      "Epoch 1101/3000\n",
      " - 2s - loss: 5.4864e-04 - acc: 0.9907 - val_loss: 5.3132e-04 - val_acc: 0.9909\n",
      "Epoch 1102/3000\n",
      " - 2s - loss: 5.4162e-04 - acc: 0.9907 - val_loss: 5.5818e-04 - val_acc: 0.9908\n",
      "Epoch 1103/3000\n",
      " - 2s - loss: 5.4920e-04 - acc: 0.9907 - val_loss: 5.4279e-04 - val_acc: 0.9909\n",
      "Epoch 1104/3000\n",
      " - 2s - loss: 5.4776e-04 - acc: 0.9906 - val_loss: 5.3513e-04 - val_acc: 0.9904\n",
      "Epoch 1105/3000\n",
      " - 2s - loss: 5.3092e-04 - acc: 0.9908 - val_loss: 5.2509e-04 - val_acc: 0.9907\n",
      "Epoch 1106/3000\n",
      " - 2s - loss: 5.3837e-04 - acc: 0.9908 - val_loss: 5.3430e-04 - val_acc: 0.9909\n",
      "Epoch 1107/3000\n",
      " - 2s - loss: 5.2249e-04 - acc: 0.9910 - val_loss: 5.2750e-04 - val_acc: 0.9907\n",
      "Epoch 1108/3000\n",
      " - 2s - loss: 5.3076e-04 - acc: 0.9909 - val_loss: 5.4433e-04 - val_acc: 0.9903\n",
      "Epoch 1109/3000\n",
      " - 1s - loss: 5.3072e-04 - acc: 0.9908 - val_loss: 5.4360e-04 - val_acc: 0.9905\n",
      "Epoch 1110/3000\n",
      " - 2s - loss: 5.2847e-04 - acc: 0.9909 - val_loss: 5.2608e-04 - val_acc: 0.9909\n",
      "Epoch 1111/3000\n",
      " - 2s - loss: 5.5355e-04 - acc: 0.9907 - val_loss: 5.3803e-04 - val_acc: 0.9899\n",
      "Epoch 1112/3000\n",
      " - 2s - loss: 5.3035e-04 - acc: 0.9909 - val_loss: 5.5145e-04 - val_acc: 0.9908\n",
      "Epoch 1113/3000\n",
      " - 2s - loss: 5.4085e-04 - acc: 0.9907 - val_loss: 5.2005e-04 - val_acc: 0.9909\n",
      "Epoch 1114/3000\n",
      " - 1s - loss: 5.3000e-04 - acc: 0.9909 - val_loss: 5.4805e-04 - val_acc: 0.9900\n",
      "Epoch 1115/3000\n",
      " - 1s - loss: 5.3015e-04 - acc: 0.9908 - val_loss: 5.1720e-04 - val_acc: 0.9908\n",
      "Epoch 1116/3000\n",
      " - 2s - loss: 5.4049e-04 - acc: 0.9909 - val_loss: 5.7125e-04 - val_acc: 0.9905\n",
      "Epoch 1117/3000\n",
      " - 1s - loss: 5.3626e-04 - acc: 0.9909 - val_loss: 5.1607e-04 - val_acc: 0.9908\n",
      "Epoch 1118/3000\n",
      " - 2s - loss: 5.2509e-04 - acc: 0.9910 - val_loss: 5.2766e-04 - val_acc: 0.9908\n",
      "Epoch 1119/3000\n",
      " - 2s - loss: 5.2392e-04 - acc: 0.9910 - val_loss: 5.3315e-04 - val_acc: 0.9907\n",
      "Epoch 1120/3000\n",
      "\n",
      "Epoch 01120: val_loss did not improve from 0.00053\n",
      " - 1s - loss: 5.2855e-04 - acc: 0.9909 - val_loss: 5.6257e-04 - val_acc: 0.9907\n",
      "Epoch 1121/3000\n",
      " - 2s - loss: 5.2183e-04 - acc: 0.9910 - val_loss: 5.1987e-04 - val_acc: 0.9910\n",
      "Epoch 1122/3000\n",
      " - 2s - loss: 5.3645e-04 - acc: 0.9908 - val_loss: 5.5055e-04 - val_acc: 0.9904\n",
      "Epoch 1123/3000\n",
      " - 2s - loss: 5.3001e-04 - acc: 0.9909 - val_loss: 5.0735e-04 - val_acc: 0.9909\n",
      "Epoch 1124/3000\n",
      " - 1s - loss: 5.2659e-04 - acc: 0.9909 - val_loss: 5.1380e-04 - val_acc: 0.9909\n",
      "Epoch 1125/3000\n",
      " - 1s - loss: 5.1806e-04 - acc: 0.9910 - val_loss: 5.0951e-04 - val_acc: 0.9909\n",
      "Epoch 1126/3000\n",
      " - 2s - loss: 5.3063e-04 - acc: 0.9908 - val_loss: 5.3765e-04 - val_acc: 0.9904\n",
      "Epoch 1127/3000\n",
      " - 2s - loss: 5.3774e-04 - acc: 0.9907 - val_loss: 5.2269e-04 - val_acc: 0.9910\n",
      "Epoch 1128/3000\n",
      " - 2s - loss: 5.4791e-04 - acc: 0.9907 - val_loss: 5.2808e-04 - val_acc: 0.9906\n",
      "Epoch 1129/3000\n",
      " - 2s - loss: 5.3157e-04 - acc: 0.9909 - val_loss: 5.1560e-04 - val_acc: 0.9908\n",
      "Epoch 1130/3000\n",
      " - 2s - loss: 5.2961e-04 - acc: 0.9909 - val_loss: 5.2549e-04 - val_acc: 0.9910\n",
      "Epoch 1131/3000\n",
      " - 2s - loss: 5.3526e-04 - acc: 0.9909 - val_loss: 5.2506e-04 - val_acc: 0.9910\n",
      "Epoch 1132/3000\n",
      " - 2s - loss: 5.3392e-04 - acc: 0.9909 - val_loss: 5.1727e-04 - val_acc: 0.9909\n",
      "Epoch 1133/3000\n",
      " - 1s - loss: 5.3170e-04 - acc: 0.9909 - val_loss: 5.4354e-04 - val_acc: 0.9907\n",
      "Epoch 1134/3000\n",
      " - 2s - loss: 5.3802e-04 - acc: 0.9908 - val_loss: 5.4943e-04 - val_acc: 0.9905\n",
      "Epoch 1135/3000\n",
      " - 2s - loss: 5.2977e-04 - acc: 0.9909 - val_loss: 5.4658e-04 - val_acc: 0.9906\n",
      "Epoch 1136/3000\n",
      " - 1s - loss: 5.2333e-04 - acc: 0.9910 - val_loss: 5.1664e-04 - val_acc: 0.9905\n",
      "Epoch 1137/3000\n",
      " - 2s - loss: 5.3064e-04 - acc: 0.9908 - val_loss: 5.1417e-04 - val_acc: 0.9910\n",
      "Epoch 1138/3000\n",
      " - 2s - loss: 5.2669e-04 - acc: 0.9908 - val_loss: 5.1670e-04 - val_acc: 0.9907\n",
      "Epoch 1139/3000\n",
      " - 1s - loss: 5.2577e-04 - acc: 0.9910 - val_loss: 5.1805e-04 - val_acc: 0.9910\n",
      "Epoch 1140/3000\n",
      "\n",
      "Epoch 01140: val_loss improved from 0.00053 to 0.00051, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 5.2640e-04 - acc: 0.9909 - val_loss: 5.1357e-04 - val_acc: 0.9909\n",
      "Epoch 1141/3000\n",
      " - 2s - loss: 5.2554e-04 - acc: 0.9909 - val_loss: 5.3861e-04 - val_acc: 0.9908\n",
      "Epoch 1142/3000\n",
      " - 1s - loss: 5.2701e-04 - acc: 0.9909 - val_loss: 5.1757e-04 - val_acc: 0.9910\n",
      "Epoch 1143/3000\n",
      " - 1s - loss: 5.2720e-04 - acc: 0.9909 - val_loss: 5.2889e-04 - val_acc: 0.9908\n",
      "Epoch 1144/3000\n",
      " - 2s - loss: 5.5603e-04 - acc: 0.9906 - val_loss: 5.5832e-04 - val_acc: 0.9890\n",
      "Epoch 1145/3000\n",
      " - 2s - loss: 5.2638e-04 - acc: 0.9908 - val_loss: 5.1628e-04 - val_acc: 0.9907\n",
      "Epoch 1146/3000\n",
      " - 2s - loss: 5.2224e-04 - acc: 0.9909 - val_loss: 5.4244e-04 - val_acc: 0.9907\n",
      "Epoch 1147/3000\n",
      " - 2s - loss: 5.2186e-04 - acc: 0.9910 - val_loss: 5.2447e-04 - val_acc: 0.9906\n",
      "Epoch 1148/3000\n",
      " - 2s - loss: 5.3167e-04 - acc: 0.9909 - val_loss: 5.9384e-04 - val_acc: 0.9903\n",
      "Epoch 1149/3000\n",
      " - 2s - loss: 5.3500e-04 - acc: 0.9908 - val_loss: 5.0323e-04 - val_acc: 0.9909\n",
      "Epoch 1150/3000\n",
      " - 2s - loss: 5.1580e-04 - acc: 0.9911 - val_loss: 5.2270e-04 - val_acc: 0.9908\n",
      "Epoch 1151/3000\n",
      " - 2s - loss: 5.1861e-04 - acc: 0.9910 - val_loss: 5.2173e-04 - val_acc: 0.9906\n",
      "Epoch 1152/3000\n",
      " - 2s - loss: 5.2814e-04 - acc: 0.9908 - val_loss: 5.3250e-04 - val_acc: 0.9902\n",
      "Epoch 1153/3000\n",
      " - 2s - loss: 5.1888e-04 - acc: 0.9910 - val_loss: 5.0929e-04 - val_acc: 0.9909\n",
      "Epoch 1154/3000\n",
      " - 1s - loss: 5.2416e-04 - acc: 0.9909 - val_loss: 5.3060e-04 - val_acc: 0.9909\n",
      "Epoch 1155/3000\n",
      " - 2s - loss: 5.4516e-04 - acc: 0.9906 - val_loss: 5.1292e-04 - val_acc: 0.9911\n",
      "Epoch 1156/3000\n",
      " - 2s - loss: 5.1132e-04 - acc: 0.9910 - val_loss: 5.0494e-04 - val_acc: 0.9910\n",
      "Epoch 1157/3000\n",
      " - 2s - loss: 5.1823e-04 - acc: 0.9910 - val_loss: 5.2103e-04 - val_acc: 0.9910\n",
      "Epoch 1158/3000\n",
      " - 1s - loss: 5.2522e-04 - acc: 0.9910 - val_loss: 5.2308e-04 - val_acc: 0.9911\n",
      "Epoch 1159/3000\n",
      " - 1s - loss: 5.1866e-04 - acc: 0.9910 - val_loss: 5.1826e-04 - val_acc: 0.9909\n",
      "Epoch 1160/3000\n",
      "\n",
      "Epoch 01160: val_loss improved from 0.00051 to 0.00050, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 5.1949e-04 - acc: 0.9909 - val_loss: 4.9960e-04 - val_acc: 0.9911\n",
      "Epoch 1161/3000\n",
      " - 1s - loss: 5.1354e-04 - acc: 0.9910 - val_loss: 5.0238e-04 - val_acc: 0.9909\n",
      "Epoch 1162/3000\n",
      " - 2s - loss: 5.1145e-04 - acc: 0.9911 - val_loss: 5.2012e-04 - val_acc: 0.9909\n",
      "Epoch 1163/3000\n",
      " - 2s - loss: 5.2988e-04 - acc: 0.9909 - val_loss: 5.1872e-04 - val_acc: 0.9908\n",
      "Epoch 1164/3000\n",
      " - 2s - loss: 5.1142e-04 - acc: 0.9911 - val_loss: 5.1321e-04 - val_acc: 0.9909\n",
      "Epoch 1165/3000\n",
      " - 2s - loss: 5.1895e-04 - acc: 0.9910 - val_loss: 5.3397e-04 - val_acc: 0.9907\n",
      "Epoch 1166/3000\n",
      " - 1s - loss: 5.1779e-04 - acc: 0.9910 - val_loss: 5.2477e-04 - val_acc: 0.9909\n",
      "Epoch 1167/3000\n",
      " - 2s - loss: 5.2302e-04 - acc: 0.9909 - val_loss: 5.1295e-04 - val_acc: 0.9906\n",
      "Epoch 1168/3000\n",
      " - 2s - loss: 5.2002e-04 - acc: 0.9909 - val_loss: 5.3577e-04 - val_acc: 0.9910\n",
      "Epoch 1169/3000\n",
      " - 2s - loss: 5.1775e-04 - acc: 0.9910 - val_loss: 5.1846e-04 - val_acc: 0.9908\n",
      "Epoch 1170/3000\n",
      " - 2s - loss: 5.1607e-04 - acc: 0.9911 - val_loss: 5.3450e-04 - val_acc: 0.9909\n",
      "Epoch 1171/3000\n",
      " - 2s - loss: 5.2939e-04 - acc: 0.9908 - val_loss: 5.0318e-04 - val_acc: 0.9910\n",
      "Epoch 1172/3000\n",
      " - 1s - loss: 5.1621e-04 - acc: 0.9910 - val_loss: 5.1555e-04 - val_acc: 0.9910\n",
      "Epoch 1173/3000\n",
      " - 2s - loss: 5.1540e-04 - acc: 0.9910 - val_loss: 5.3993e-04 - val_acc: 0.9909\n",
      "Epoch 1174/3000\n",
      " - 2s - loss: 5.3411e-04 - acc: 0.9908 - val_loss: 5.1848e-04 - val_acc: 0.9909\n",
      "Epoch 1175/3000\n",
      " - 2s - loss: 5.2617e-04 - acc: 0.9908 - val_loss: 5.1283e-04 - val_acc: 0.9907\n",
      "Epoch 1176/3000\n",
      " - 2s - loss: 5.1929e-04 - acc: 0.9910 - val_loss: 5.2677e-04 - val_acc: 0.9910\n",
      "Epoch 1177/3000\n",
      " - 2s - loss: 5.1295e-04 - acc: 0.9911 - val_loss: 5.1398e-04 - val_acc: 0.9909\n",
      "Epoch 1178/3000\n",
      " - 2s - loss: 5.1033e-04 - acc: 0.9911 - val_loss: 4.9607e-04 - val_acc: 0.9911\n",
      "Epoch 1179/3000\n",
      " - 1s - loss: 5.2123e-04 - acc: 0.9910 - val_loss: 5.4226e-04 - val_acc: 0.9904\n",
      "Epoch 1180/3000\n",
      "\n",
      "Epoch 01180: val_loss did not improve from 0.00050\n",
      " - 2s - loss: 5.1221e-04 - acc: 0.9910 - val_loss: 5.2356e-04 - val_acc: 0.9911\n",
      "Epoch 1181/3000\n",
      " - 2s - loss: 5.1317e-04 - acc: 0.9910 - val_loss: 5.0393e-04 - val_acc: 0.9908\n",
      "Epoch 1182/3000\n",
      " - 2s - loss: 5.1634e-04 - acc: 0.9910 - val_loss: 5.0129e-04 - val_acc: 0.9907\n",
      "Epoch 1183/3000\n",
      " - 2s - loss: 5.1472e-04 - acc: 0.9910 - val_loss: 5.0928e-04 - val_acc: 0.9908\n",
      "Epoch 1184/3000\n",
      " - 2s - loss: 5.1406e-04 - acc: 0.9911 - val_loss: 5.2038e-04 - val_acc: 0.9909\n",
      "Epoch 1185/3000\n",
      " - 1s - loss: 5.1793e-04 - acc: 0.9910 - val_loss: 4.9782e-04 - val_acc: 0.9909\n",
      "Epoch 1186/3000\n",
      " - 2s - loss: 5.1779e-04 - acc: 0.9910 - val_loss: 5.1133e-04 - val_acc: 0.9907\n",
      "Epoch 1187/3000\n",
      " - 2s - loss: 5.2665e-04 - acc: 0.9908 - val_loss: 5.1749e-04 - val_acc: 0.9908\n",
      "Epoch 1188/3000\n",
      " - 2s - loss: 5.1482e-04 - acc: 0.9910 - val_loss: 5.0085e-04 - val_acc: 0.9910\n",
      "Epoch 1189/3000\n",
      " - 2s - loss: 5.1247e-04 - acc: 0.9910 - val_loss: 5.5579e-04 - val_acc: 0.9909\n",
      "Epoch 1190/3000\n",
      " - 2s - loss: 5.2710e-04 - acc: 0.9908 - val_loss: 5.3091e-04 - val_acc: 0.9910\n",
      "Epoch 1191/3000\n",
      " - 1s - loss: 5.2019e-04 - acc: 0.9909 - val_loss: 5.5596e-04 - val_acc: 0.9907\n",
      "Epoch 1192/3000\n",
      " - 1s - loss: 5.3397e-04 - acc: 0.9909 - val_loss: 5.3089e-04 - val_acc: 0.9903\n",
      "Epoch 1193/3000\n",
      " - 1s - loss: 5.2520e-04 - acc: 0.9909 - val_loss: 5.2520e-04 - val_acc: 0.9910\n",
      "Epoch 1194/3000\n",
      " - 2s - loss: 5.2934e-04 - acc: 0.9907 - val_loss: 5.0760e-04 - val_acc: 0.9911\n",
      "Epoch 1195/3000\n",
      " - 2s - loss: 5.1010e-04 - acc: 0.9911 - val_loss: 5.1723e-04 - val_acc: 0.9911\n",
      "Epoch 1196/3000\n",
      " - 2s - loss: 5.3193e-04 - acc: 0.9908 - val_loss: 5.3617e-04 - val_acc: 0.9906\n",
      "Epoch 1197/3000\n",
      " - 2s - loss: 5.1640e-04 - acc: 0.9910 - val_loss: 5.2649e-04 - val_acc: 0.9908\n",
      "Epoch 1198/3000\n",
      " - 2s - loss: 5.1840e-04 - acc: 0.9909 - val_loss: 5.0713e-04 - val_acc: 0.9911\n",
      "Epoch 1199/3000\n",
      " - 1s - loss: 5.2221e-04 - acc: 0.9910 - val_loss: 5.0236e-04 - val_acc: 0.9908\n",
      "Epoch 1200/3000\n",
      "\n",
      "Epoch 01200: val_loss did not improve from 0.00050\n",
      " - 1s - loss: 5.1202e-04 - acc: 0.9911 - val_loss: 5.0679e-04 - val_acc: 0.9909\n",
      "Epoch 1201/3000\n",
      " - 2s - loss: 5.1275e-04 - acc: 0.9911 - val_loss: 5.0400e-04 - val_acc: 0.9910\n",
      "Epoch 1202/3000\n",
      " - 2s - loss: 5.1631e-04 - acc: 0.9910 - val_loss: 4.9177e-04 - val_acc: 0.9911\n",
      "Epoch 1203/3000\n",
      " - 2s - loss: 5.1561e-04 - acc: 0.9909 - val_loss: 4.9212e-04 - val_acc: 0.9911\n",
      "Epoch 1204/3000\n",
      " - 2s - loss: 5.1302e-04 - acc: 0.9910 - val_loss: 5.2821e-04 - val_acc: 0.9910\n",
      "Epoch 1205/3000\n",
      " - 1s - loss: 5.1851e-04 - acc: 0.9910 - val_loss: 5.1137e-04 - val_acc: 0.9910\n",
      "Epoch 1206/3000\n",
      " - 2s - loss: 5.2287e-04 - acc: 0.9909 - val_loss: 5.3530e-04 - val_acc: 0.9902\n",
      "Epoch 1207/3000\n",
      " - 2s - loss: 5.2395e-04 - acc: 0.9909 - val_loss: 5.0920e-04 - val_acc: 0.9909\n",
      "Epoch 1208/3000\n",
      " - 2s - loss: 5.0941e-04 - acc: 0.9911 - val_loss: 5.0852e-04 - val_acc: 0.9911\n",
      "Epoch 1209/3000\n",
      " - 1s - loss: 5.0914e-04 - acc: 0.9911 - val_loss: 5.2535e-04 - val_acc: 0.9911\n",
      "Epoch 1210/3000\n",
      " - 2s - loss: 5.1875e-04 - acc: 0.9910 - val_loss: 5.0263e-04 - val_acc: 0.9909\n",
      "Epoch 1211/3000\n",
      " - 2s - loss: 5.2781e-04 - acc: 0.9908 - val_loss: 5.0056e-04 - val_acc: 0.9909\n",
      "Epoch 1212/3000\n",
      " - 2s - loss: 5.0252e-04 - acc: 0.9911 - val_loss: 4.9271e-04 - val_acc: 0.9911\n",
      "Epoch 1213/3000\n",
      " - 2s - loss: 5.1095e-04 - acc: 0.9911 - val_loss: 5.2277e-04 - val_acc: 0.9908\n",
      "Epoch 1214/3000\n",
      " - 2s - loss: 5.4242e-04 - acc: 0.9906 - val_loss: 4.9177e-04 - val_acc: 0.9911\n",
      "Epoch 1215/3000\n",
      " - 1s - loss: 5.1546e-04 - acc: 0.9911 - val_loss: 5.1716e-04 - val_acc: 0.9911\n",
      "Epoch 1216/3000\n",
      " - 2s - loss: 5.0753e-04 - acc: 0.9912 - val_loss: 5.0714e-04 - val_acc: 0.9908\n",
      "Epoch 1217/3000\n",
      " - 1s - loss: 5.1062e-04 - acc: 0.9910 - val_loss: 4.9097e-04 - val_acc: 0.9910\n",
      "Epoch 1218/3000\n",
      " - 2s - loss: 5.0385e-04 - acc: 0.9912 - val_loss: 5.0339e-04 - val_acc: 0.9909\n",
      "Epoch 1219/3000\n",
      " - 2s - loss: 5.1036e-04 - acc: 0.9911 - val_loss: 5.2642e-04 - val_acc: 0.9907\n",
      "Epoch 1220/3000\n",
      "\n",
      "Epoch 01220: val_loss did not improve from 0.00050\n",
      " - 2s - loss: 5.0931e-04 - acc: 0.9910 - val_loss: 5.0644e-04 - val_acc: 0.9909\n",
      "Epoch 1221/3000\n",
      " - 2s - loss: 5.1314e-04 - acc: 0.9910 - val_loss: 5.1869e-04 - val_acc: 0.9910\n",
      "Epoch 1222/3000\n",
      " - 2s - loss: 5.0593e-04 - acc: 0.9911 - val_loss: 4.9279e-04 - val_acc: 0.9910\n",
      "Epoch 1223/3000\n",
      " - 2s - loss: 5.1382e-04 - acc: 0.9911 - val_loss: 5.0236e-04 - val_acc: 0.9906\n",
      "Epoch 1224/3000\n",
      " - 2s - loss: 5.1886e-04 - acc: 0.9910 - val_loss: 5.1360e-04 - val_acc: 0.9910\n",
      "Epoch 1225/3000\n",
      " - 1s - loss: 5.1741e-04 - acc: 0.9910 - val_loss: 4.9600e-04 - val_acc: 0.9909\n",
      "Epoch 1226/3000\n",
      " - 1s - loss: 5.0569e-04 - acc: 0.9911 - val_loss: 5.0401e-04 - val_acc: 0.9908\n",
      "Epoch 1227/3000\n",
      " - 2s - loss: 5.3307e-04 - acc: 0.9907 - val_loss: 5.0528e-04 - val_acc: 0.9909\n",
      "Epoch 1228/3000\n",
      " - 2s - loss: 5.0475e-04 - acc: 0.9911 - val_loss: 4.9465e-04 - val_acc: 0.9911\n",
      "Epoch 1229/3000\n",
      " - 2s - loss: 5.0826e-04 - acc: 0.9911 - val_loss: 5.6919e-04 - val_acc: 0.9903\n",
      "Epoch 1230/3000\n",
      " - 2s - loss: 5.1751e-04 - acc: 0.9909 - val_loss: 5.0439e-04 - val_acc: 0.9910\n",
      "Epoch 1231/3000\n",
      " - 2s - loss: 5.0662e-04 - acc: 0.9911 - val_loss: 5.2386e-04 - val_acc: 0.9904\n",
      "Epoch 1232/3000\n",
      " - 2s - loss: 5.1180e-04 - acc: 0.9911 - val_loss: 5.1141e-04 - val_acc: 0.9909\n",
      "Epoch 1233/3000\n",
      " - 2s - loss: 5.1359e-04 - acc: 0.9911 - val_loss: 5.0937e-04 - val_acc: 0.9910\n",
      "Epoch 1234/3000\n",
      " - 2s - loss: 5.0683e-04 - acc: 0.9911 - val_loss: 5.1471e-04 - val_acc: 0.9910\n",
      "Epoch 1235/3000\n",
      " - 2s - loss: 5.0844e-04 - acc: 0.9912 - val_loss: 5.2177e-04 - val_acc: 0.9908\n",
      "Epoch 1236/3000\n",
      " - 1s - loss: 5.1975e-04 - acc: 0.9908 - val_loss: 4.9545e-04 - val_acc: 0.9910\n",
      "Epoch 1237/3000\n",
      " - 2s - loss: 5.0059e-04 - acc: 0.9912 - val_loss: 5.1697e-04 - val_acc: 0.9910\n",
      "Epoch 1238/3000\n",
      " - 2s - loss: 5.2855e-04 - acc: 0.9909 - val_loss: 5.0412e-04 - val_acc: 0.9907\n",
      "Epoch 1239/3000\n",
      " - 2s - loss: 5.0228e-04 - acc: 0.9911 - val_loss: 5.1839e-04 - val_acc: 0.9911\n",
      "Epoch 1240/3000\n",
      "\n",
      "Epoch 01240: val_loss improved from 0.00050 to 0.00049, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 5.0965e-04 - acc: 0.9910 - val_loss: 4.9402e-04 - val_acc: 0.9911\n",
      "Epoch 1241/3000\n",
      " - 2s - loss: 4.9751e-04 - acc: 0.9912 - val_loss: 4.8697e-04 - val_acc: 0.9912\n",
      "Epoch 1242/3000\n",
      " - 2s - loss: 5.1973e-04 - acc: 0.9911 - val_loss: 5.2454e-04 - val_acc: 0.9905\n",
      "Epoch 1243/3000\n",
      " - 1s - loss: 5.0451e-04 - acc: 0.9911 - val_loss: 5.1050e-04 - val_acc: 0.9910\n",
      "Epoch 1244/3000\n",
      " - 2s - loss: 5.1204e-04 - acc: 0.9910 - val_loss: 4.9771e-04 - val_acc: 0.9911\n",
      "Epoch 1245/3000\n",
      " - 2s - loss: 5.1182e-04 - acc: 0.9910 - val_loss: 4.8410e-04 - val_acc: 0.9911\n",
      "Epoch 1246/3000\n",
      " - 1s - loss: 5.1657e-04 - acc: 0.9910 - val_loss: 5.1726e-04 - val_acc: 0.9910\n",
      "Epoch 1247/3000\n",
      " - 2s - loss: 5.0535e-04 - acc: 0.9911 - val_loss: 4.9278e-04 - val_acc: 0.9910\n",
      "Epoch 1248/3000\n",
      " - 1s - loss: 5.0271e-04 - acc: 0.9912 - val_loss: 4.8985e-04 - val_acc: 0.9910\n",
      "Epoch 1249/3000\n",
      " - 1s - loss: 4.9956e-04 - acc: 0.9912 - val_loss: 4.8342e-04 - val_acc: 0.9911\n",
      "Epoch 1250/3000\n",
      " - 2s - loss: 5.0708e-04 - acc: 0.9911 - val_loss: 5.1144e-04 - val_acc: 0.9909\n",
      "Epoch 1251/3000\n",
      " - 2s - loss: 5.1086e-04 - acc: 0.9911 - val_loss: 4.9281e-04 - val_acc: 0.9910\n",
      "Epoch 1252/3000\n",
      " - 1s - loss: 4.9799e-04 - acc: 0.9913 - val_loss: 5.0789e-04 - val_acc: 0.9911\n",
      "Epoch 1253/3000\n",
      " - 2s - loss: 5.1199e-04 - acc: 0.9911 - val_loss: 5.5170e-04 - val_acc: 0.9907\n",
      "Epoch 1254/3000\n",
      " - 2s - loss: 5.0279e-04 - acc: 0.9911 - val_loss: 4.8934e-04 - val_acc: 0.9913\n",
      "Epoch 1255/3000\n",
      " - 2s - loss: 4.9611e-04 - acc: 0.9912 - val_loss: 5.0708e-04 - val_acc: 0.9910\n",
      "Epoch 1256/3000\n",
      " - 2s - loss: 5.1222e-04 - acc: 0.9910 - val_loss: 5.9949e-04 - val_acc: 0.9908\n",
      "Epoch 1257/3000\n",
      " - 1s - loss: 5.1680e-04 - acc: 0.9909 - val_loss: 4.9486e-04 - val_acc: 0.9911\n",
      "Epoch 1258/3000\n",
      " - 2s - loss: 4.9677e-04 - acc: 0.9912 - val_loss: 5.0571e-04 - val_acc: 0.9910\n",
      "Epoch 1259/3000\n",
      " - 2s - loss: 4.9654e-04 - acc: 0.9912 - val_loss: 4.9812e-04 - val_acc: 0.9908\n",
      "Epoch 1260/3000\n",
      "\n",
      "Epoch 01260: val_loss improved from 0.00049 to 0.00049, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 5.0262e-04 - acc: 0.9912 - val_loss: 4.8503e-04 - val_acc: 0.9911\n",
      "Epoch 1261/3000\n",
      " - 2s - loss: 5.1067e-04 - acc: 0.9911 - val_loss: 5.7796e-04 - val_acc: 0.9900\n",
      "Epoch 1262/3000\n",
      " - 1s - loss: 5.0461e-04 - acc: 0.9910 - val_loss: 5.0479e-04 - val_acc: 0.9909\n",
      "Epoch 1263/3000\n",
      " - 2s - loss: 5.1399e-04 - acc: 0.9909 - val_loss: 4.8905e-04 - val_acc: 0.9911\n",
      "Epoch 1264/3000\n",
      " - 2s - loss: 5.0577e-04 - acc: 0.9911 - val_loss: 4.8196e-04 - val_acc: 0.9912\n",
      "Epoch 1265/3000\n",
      " - 2s - loss: 4.9982e-04 - acc: 0.9912 - val_loss: 4.9176e-04 - val_acc: 0.9912\n",
      "Epoch 1266/3000\n",
      " - 2s - loss: 5.0173e-04 - acc: 0.9911 - val_loss: 5.1252e-04 - val_acc: 0.9909\n",
      "Epoch 1267/3000\n",
      " - 2s - loss: 5.1448e-04 - acc: 0.9910 - val_loss: 5.3599e-04 - val_acc: 0.9909\n",
      "Epoch 1268/3000\n",
      " - 2s - loss: 5.0337e-04 - acc: 0.9912 - val_loss: 4.8560e-04 - val_acc: 0.9910\n",
      "Epoch 1269/3000\n",
      " - 2s - loss: 4.9711e-04 - acc: 0.9912 - val_loss: 4.9854e-04 - val_acc: 0.9911\n",
      "Epoch 1270/3000\n",
      " - 2s - loss: 4.9914e-04 - acc: 0.9912 - val_loss: 5.1277e-04 - val_acc: 0.9910\n",
      "Epoch 1271/3000\n",
      " - 2s - loss: 4.9758e-04 - acc: 0.9912 - val_loss: 4.9096e-04 - val_acc: 0.9910\n",
      "Epoch 1272/3000\n",
      " - 2s - loss: 4.9712e-04 - acc: 0.9912 - val_loss: 4.8928e-04 - val_acc: 0.9911\n",
      "Epoch 1273/3000\n",
      " - 2s - loss: 5.0659e-04 - acc: 0.9911 - val_loss: 5.1104e-04 - val_acc: 0.9911\n",
      "Epoch 1274/3000\n",
      " - 2s - loss: 4.9752e-04 - acc: 0.9912 - val_loss: 5.1136e-04 - val_acc: 0.9907\n",
      "Epoch 1275/3000\n",
      " - 2s - loss: 5.0692e-04 - acc: 0.9911 - val_loss: 4.7831e-04 - val_acc: 0.9912\n",
      "Epoch 1276/3000\n",
      " - 2s - loss: 5.0711e-04 - acc: 0.9912 - val_loss: 5.3870e-04 - val_acc: 0.9906\n",
      "Epoch 1277/3000\n",
      " - 2s - loss: 5.0767e-04 - acc: 0.9911 - val_loss: 4.8860e-04 - val_acc: 0.9910\n",
      "Epoch 1278/3000\n",
      " - 2s - loss: 4.9141e-04 - acc: 0.9913 - val_loss: 5.1353e-04 - val_acc: 0.9910\n",
      "Epoch 1279/3000\n",
      " - 1s - loss: 4.9625e-04 - acc: 0.9912 - val_loss: 4.8359e-04 - val_acc: 0.9910\n",
      "Epoch 1280/3000\n",
      "\n",
      "Epoch 01280: val_loss did not improve from 0.00049\n",
      " - 2s - loss: 5.0700e-04 - acc: 0.9910 - val_loss: 4.9096e-04 - val_acc: 0.9909\n",
      "Epoch 1281/3000\n",
      " - 2s - loss: 4.9698e-04 - acc: 0.9913 - val_loss: 4.9916e-04 - val_acc: 0.9910\n",
      "Epoch 1282/3000\n",
      " - 1s - loss: 4.9430e-04 - acc: 0.9912 - val_loss: 4.9114e-04 - val_acc: 0.9910\n",
      "Epoch 1283/3000\n",
      " - 2s - loss: 4.9966e-04 - acc: 0.9912 - val_loss: 5.0349e-04 - val_acc: 0.9911\n",
      "Epoch 1284/3000\n",
      " - 2s - loss: 4.9065e-04 - acc: 0.9913 - val_loss: 5.0070e-04 - val_acc: 0.9911\n",
      "Epoch 1285/3000\n",
      " - 2s - loss: 4.9653e-04 - acc: 0.9912 - val_loss: 5.1176e-04 - val_acc: 0.9910\n",
      "Epoch 1286/3000\n",
      " - 2s - loss: 5.0119e-04 - acc: 0.9912 - val_loss: 4.8545e-04 - val_acc: 0.9911\n",
      "Epoch 1287/3000\n",
      " - 2s - loss: 5.0804e-04 - acc: 0.9911 - val_loss: 5.0205e-04 - val_acc: 0.9910\n",
      "Epoch 1288/3000\n",
      " - 2s - loss: 4.9669e-04 - acc: 0.9912 - val_loss: 4.7974e-04 - val_acc: 0.9913\n",
      "Epoch 1289/3000\n",
      " - 2s - loss: 4.9630e-04 - acc: 0.9913 - val_loss: 5.0875e-04 - val_acc: 0.9910\n",
      "Epoch 1290/3000\n",
      " - 2s - loss: 4.9810e-04 - acc: 0.9911 - val_loss: 4.9651e-04 - val_acc: 0.9912\n",
      "Epoch 1291/3000\n",
      " - 2s - loss: 5.0070e-04 - acc: 0.9912 - val_loss: 4.8470e-04 - val_acc: 0.9912\n",
      "Epoch 1292/3000\n",
      " - 2s - loss: 5.0412e-04 - acc: 0.9911 - val_loss: 4.7553e-04 - val_acc: 0.9912\n",
      "Epoch 1293/3000\n",
      " - 2s - loss: 4.9505e-04 - acc: 0.9913 - val_loss: 5.0166e-04 - val_acc: 0.9909\n",
      "Epoch 1294/3000\n",
      " - 1s - loss: 5.0070e-04 - acc: 0.9912 - val_loss: 4.8441e-04 - val_acc: 0.9913\n",
      "Epoch 1295/3000\n",
      " - 2s - loss: 4.9475e-04 - acc: 0.9912 - val_loss: 4.7700e-04 - val_acc: 0.9912\n",
      "Epoch 1296/3000\n",
      " - 2s - loss: 4.8719e-04 - acc: 0.9913 - val_loss: 4.7976e-04 - val_acc: 0.9913\n",
      "Epoch 1297/3000\n",
      " - 1s - loss: 4.8668e-04 - acc: 0.9913 - val_loss: 4.8956e-04 - val_acc: 0.9908\n",
      "Epoch 1298/3000\n",
      " - 2s - loss: 5.0471e-04 - acc: 0.9911 - val_loss: 4.9209e-04 - val_acc: 0.9910\n",
      "Epoch 1299/3000\n",
      " - 1s - loss: 4.9183e-04 - acc: 0.9913 - val_loss: 4.8973e-04 - val_acc: 0.9911\n",
      "Epoch 1300/3000\n",
      "\n",
      "Epoch 01300: val_loss improved from 0.00049 to 0.00048, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 4.9323e-04 - acc: 0.9912 - val_loss: 4.7944e-04 - val_acc: 0.9912\n",
      "Epoch 1301/3000\n",
      " - 2s - loss: 4.9338e-04 - acc: 0.9913 - val_loss: 5.0741e-04 - val_acc: 0.9911\n",
      "Epoch 1302/3000\n",
      " - 2s - loss: 4.9989e-04 - acc: 0.9912 - val_loss: 4.9165e-04 - val_acc: 0.9910\n",
      "Epoch 1303/3000\n",
      " - 2s - loss: 5.0153e-04 - acc: 0.9911 - val_loss: 4.9481e-04 - val_acc: 0.9911\n",
      "Epoch 1304/3000\n",
      " - 1s - loss: 4.8831e-04 - acc: 0.9913 - val_loss: 5.0201e-04 - val_acc: 0.9912\n",
      "Epoch 1305/3000\n",
      " - 2s - loss: 4.9832e-04 - acc: 0.9911 - val_loss: 4.9082e-04 - val_acc: 0.9913\n",
      "Epoch 1306/3000\n",
      " - 1s - loss: 4.8588e-04 - acc: 0.9914 - val_loss: 4.9327e-04 - val_acc: 0.9909\n",
      "Epoch 1307/3000\n",
      " - 2s - loss: 4.9772e-04 - acc: 0.9912 - val_loss: 4.8822e-04 - val_acc: 0.9911\n",
      "Epoch 1308/3000\n",
      " - 1s - loss: 4.9038e-04 - acc: 0.9913 - val_loss: 4.9622e-04 - val_acc: 0.9907\n",
      "Epoch 1309/3000\n",
      " - 2s - loss: 4.9455e-04 - acc: 0.9912 - val_loss: 5.0781e-04 - val_acc: 0.9908\n",
      "Epoch 1310/3000\n",
      " - 1s - loss: 4.9282e-04 - acc: 0.9912 - val_loss: 4.8958e-04 - val_acc: 0.9912\n",
      "Epoch 1311/3000\n",
      " - 1s - loss: 4.8939e-04 - acc: 0.9913 - val_loss: 4.7456e-04 - val_acc: 0.9912\n",
      "Epoch 1312/3000\n",
      " - 2s - loss: 4.8920e-04 - acc: 0.9913 - val_loss: 4.7719e-04 - val_acc: 0.9912\n",
      "Epoch 1313/3000\n",
      " - 2s - loss: 5.0314e-04 - acc: 0.9911 - val_loss: 5.0535e-04 - val_acc: 0.9909\n",
      "Epoch 1314/3000\n",
      " - 2s - loss: 4.9757e-04 - acc: 0.9912 - val_loss: 4.7994e-04 - val_acc: 0.9913\n",
      "Epoch 1315/3000\n",
      " - 2s - loss: 4.8556e-04 - acc: 0.9913 - val_loss: 4.9202e-04 - val_acc: 0.9911\n",
      "Epoch 1316/3000\n",
      " - 2s - loss: 5.0111e-04 - acc: 0.9912 - val_loss: 4.8466e-04 - val_acc: 0.9909\n",
      "Epoch 1317/3000\n",
      " - 1s - loss: 4.9729e-04 - acc: 0.9912 - val_loss: 5.7703e-04 - val_acc: 0.9905\n",
      "Epoch 1318/3000\n",
      " - 2s - loss: 5.0162e-04 - acc: 0.9911 - val_loss: 4.8917e-04 - val_acc: 0.9910\n",
      "Epoch 1319/3000\n",
      " - 2s - loss: 4.9573e-04 - acc: 0.9912 - val_loss: 4.7938e-04 - val_acc: 0.9910\n",
      "Epoch 1320/3000\n",
      "\n",
      "Epoch 01320: val_loss did not improve from 0.00048\n",
      " - 2s - loss: 4.8754e-04 - acc: 0.9913 - val_loss: 4.7973e-04 - val_acc: 0.9910\n",
      "Epoch 1321/3000\n",
      " - 2s - loss: 4.9278e-04 - acc: 0.9912 - val_loss: 4.9860e-04 - val_acc: 0.9911\n",
      "Epoch 1322/3000\n",
      " - 2s - loss: 4.9264e-04 - acc: 0.9913 - val_loss: 4.7872e-04 - val_acc: 0.9913\n",
      "Epoch 1323/3000\n",
      " - 2s - loss: 4.8715e-04 - acc: 0.9913 - val_loss: 5.0866e-04 - val_acc: 0.9912\n",
      "Epoch 1324/3000\n",
      " - 1s - loss: 4.9411e-04 - acc: 0.9912 - val_loss: 4.9527e-04 - val_acc: 0.9912\n",
      "Epoch 1325/3000\n",
      " - 2s - loss: 4.9120e-04 - acc: 0.9913 - val_loss: 5.6349e-04 - val_acc: 0.9899\n",
      "Epoch 1326/3000\n",
      " - 2s - loss: 5.0966e-04 - acc: 0.9910 - val_loss: 4.9098e-04 - val_acc: 0.9911\n",
      "Epoch 1327/3000\n",
      " - 2s - loss: 5.1690e-04 - acc: 0.9910 - val_loss: 4.7530e-04 - val_acc: 0.9913\n",
      "Epoch 1328/3000\n",
      " - 2s - loss: 4.9679e-04 - acc: 0.9912 - val_loss: 4.8833e-04 - val_acc: 0.9910\n",
      "Epoch 1329/3000\n",
      " - 2s - loss: 4.9230e-04 - acc: 0.9913 - val_loss: 4.9559e-04 - val_acc: 0.9910\n",
      "Epoch 1330/3000\n",
      " - 2s - loss: 5.0873e-04 - acc: 0.9911 - val_loss: 5.2187e-04 - val_acc: 0.9909\n",
      "Epoch 1331/3000\n",
      " - 2s - loss: 5.0254e-04 - acc: 0.9911 - val_loss: 4.8587e-04 - val_acc: 0.9912\n",
      "Epoch 1332/3000\n",
      " - 2s - loss: 4.9086e-04 - acc: 0.9913 - val_loss: 4.9211e-04 - val_acc: 0.9911\n",
      "Epoch 1333/3000\n",
      " - 2s - loss: 5.0293e-04 - acc: 0.9912 - val_loss: 4.8480e-04 - val_acc: 0.9910\n",
      "Epoch 1334/3000\n",
      " - 2s - loss: 4.8683e-04 - acc: 0.9913 - val_loss: 5.0453e-04 - val_acc: 0.9906\n",
      "Epoch 1335/3000\n",
      " - 2s - loss: 4.8722e-04 - acc: 0.9912 - val_loss: 4.9239e-04 - val_acc: 0.9909\n",
      "Epoch 1336/3000\n",
      " - 2s - loss: 4.8237e-04 - acc: 0.9914 - val_loss: 4.7901e-04 - val_acc: 0.9912\n",
      "Epoch 1337/3000\n",
      " - 2s - loss: 4.8685e-04 - acc: 0.9913 - val_loss: 4.7888e-04 - val_acc: 0.9910\n",
      "Epoch 1338/3000\n",
      " - 1s - loss: 4.8808e-04 - acc: 0.9912 - val_loss: 4.7922e-04 - val_acc: 0.9909\n",
      "Epoch 1339/3000\n",
      " - 2s - loss: 4.8222e-04 - acc: 0.9913 - val_loss: 4.9569e-04 - val_acc: 0.9911\n",
      "Epoch 1340/3000\n",
      "\n",
      "Epoch 01340: val_loss did not improve from 0.00048\n",
      " - 1s - loss: 4.9078e-04 - acc: 0.9912 - val_loss: 4.8090e-04 - val_acc: 0.9913\n",
      "Epoch 1341/3000\n",
      " - 2s - loss: 4.9535e-04 - acc: 0.9912 - val_loss: 4.9260e-04 - val_acc: 0.9912\n",
      "Epoch 1342/3000\n",
      " - 1s - loss: 4.8760e-04 - acc: 0.9913 - val_loss: 4.7072e-04 - val_acc: 0.9912\n",
      "Epoch 1343/3000\n",
      " - 2s - loss: 4.8563e-04 - acc: 0.9913 - val_loss: 4.9427e-04 - val_acc: 0.9908\n",
      "Epoch 1344/3000\n",
      " - 2s - loss: 5.1252e-04 - acc: 0.9909 - val_loss: 4.7961e-04 - val_acc: 0.9907\n",
      "Epoch 1345/3000\n",
      " - 2s - loss: 4.8622e-04 - acc: 0.9913 - val_loss: 4.7929e-04 - val_acc: 0.9910\n",
      "Epoch 1346/3000\n",
      " - 2s - loss: 4.8502e-04 - acc: 0.9913 - val_loss: 4.8447e-04 - val_acc: 0.9912\n",
      "Epoch 1347/3000\n",
      " - 2s - loss: 4.8654e-04 - acc: 0.9913 - val_loss: 4.8147e-04 - val_acc: 0.9910\n",
      "Epoch 1348/3000\n",
      " - 1s - loss: 4.8991e-04 - acc: 0.9913 - val_loss: 4.9786e-04 - val_acc: 0.9911\n",
      "Epoch 1349/3000\n",
      " - 2s - loss: 5.1778e-04 - acc: 0.9908 - val_loss: 4.9633e-04 - val_acc: 0.9907\n",
      "Epoch 1350/3000\n",
      " - 2s - loss: 4.9179e-04 - acc: 0.9913 - val_loss: 4.7211e-04 - val_acc: 0.9912\n",
      "Epoch 1351/3000\n",
      " - 2s - loss: 5.0826e-04 - acc: 0.9910 - val_loss: 4.9809e-04 - val_acc: 0.9907\n",
      "Epoch 1352/3000\n",
      " - 2s - loss: 4.8785e-04 - acc: 0.9912 - val_loss: 4.7393e-04 - val_acc: 0.9912\n",
      "Epoch 1353/3000\n",
      " - 2s - loss: 4.9687e-04 - acc: 0.9911 - val_loss: 4.7743e-04 - val_acc: 0.9913\n",
      "Epoch 1354/3000\n",
      " - 2s - loss: 4.8389e-04 - acc: 0.9913 - val_loss: 4.8638e-04 - val_acc: 0.9909\n",
      "Epoch 1355/3000\n",
      " - 2s - loss: 4.8711e-04 - acc: 0.9913 - val_loss: 4.7056e-04 - val_acc: 0.9913\n",
      "Epoch 1356/3000\n",
      " - 2s - loss: 4.8082e-04 - acc: 0.9914 - val_loss: 4.7236e-04 - val_acc: 0.9914\n",
      "Epoch 1357/3000\n",
      " - 2s - loss: 4.8131e-04 - acc: 0.9914 - val_loss: 4.8827e-04 - val_acc: 0.9912\n",
      "Epoch 1358/3000\n",
      " - 2s - loss: 5.0627e-04 - acc: 0.9910 - val_loss: 4.8168e-04 - val_acc: 0.9910\n",
      "Epoch 1359/3000\n",
      " - 1s - loss: 4.8866e-04 - acc: 0.9913 - val_loss: 4.7797e-04 - val_acc: 0.9913\n",
      "Epoch 1360/3000\n",
      "\n",
      "Epoch 01360: val_loss did not improve from 0.00048\n",
      " - 2s - loss: 4.8125e-04 - acc: 0.9913 - val_loss: 4.8219e-04 - val_acc: 0.9914\n",
      "Epoch 1361/3000\n",
      " - 2s - loss: 4.8766e-04 - acc: 0.9913 - val_loss: 4.9288e-04 - val_acc: 0.9911\n",
      "Epoch 1362/3000\n",
      " - 2s - loss: 4.9971e-04 - acc: 0.9911 - val_loss: 4.7755e-04 - val_acc: 0.9912\n",
      "Epoch 1363/3000\n",
      " - 2s - loss: 4.8601e-04 - acc: 0.9913 - val_loss: 4.8513e-04 - val_acc: 0.9913\n",
      "Epoch 1364/3000\n",
      " - 2s - loss: 4.8259e-04 - acc: 0.9913 - val_loss: 4.7515e-04 - val_acc: 0.9910\n",
      "Epoch 1365/3000\n",
      " - 2s - loss: 4.9366e-04 - acc: 0.9912 - val_loss: 4.9091e-04 - val_acc: 0.9908\n",
      "Epoch 1366/3000\n",
      " - 2s - loss: 4.8510e-04 - acc: 0.9913 - val_loss: 4.7378e-04 - val_acc: 0.9914\n",
      "Epoch 1367/3000\n",
      " - 2s - loss: 4.8193e-04 - acc: 0.9914 - val_loss: 4.9316e-04 - val_acc: 0.9912\n",
      "Epoch 1368/3000\n",
      " - 2s - loss: 4.9664e-04 - acc: 0.9912 - val_loss: 5.3067e-04 - val_acc: 0.9907\n",
      "Epoch 1369/3000\n",
      " - 2s - loss: 4.8829e-04 - acc: 0.9913 - val_loss: 4.9045e-04 - val_acc: 0.9913\n",
      "Epoch 1370/3000\n",
      " - 2s - loss: 4.9657e-04 - acc: 0.9912 - val_loss: 4.8388e-04 - val_acc: 0.9914\n",
      "Epoch 1371/3000\n",
      " - 2s - loss: 4.8148e-04 - acc: 0.9913 - val_loss: 4.9614e-04 - val_acc: 0.9913\n",
      "Epoch 1372/3000\n",
      " - 2s - loss: 4.8608e-04 - acc: 0.9914 - val_loss: 4.7961e-04 - val_acc: 0.9912\n",
      "Epoch 1373/3000\n",
      " - 2s - loss: 4.9805e-04 - acc: 0.9912 - val_loss: 5.5804e-04 - val_acc: 0.9896\n",
      "Epoch 1374/3000\n",
      " - 2s - loss: 4.9543e-04 - acc: 0.9911 - val_loss: 4.7812e-04 - val_acc: 0.9912\n",
      "Epoch 1375/3000\n",
      " - 1s - loss: 5.2239e-04 - acc: 0.9908 - val_loss: 5.1277e-04 - val_acc: 0.9908\n",
      "Epoch 1376/3000\n",
      " - 2s - loss: 4.9384e-04 - acc: 0.9913 - val_loss: 4.8549e-04 - val_acc: 0.9913\n",
      "Epoch 1377/3000\n",
      " - 2s - loss: 4.8862e-04 - acc: 0.9913 - val_loss: 5.2556e-04 - val_acc: 0.9911\n",
      "Epoch 1378/3000\n",
      " - 2s - loss: 4.9121e-04 - acc: 0.9911 - val_loss: 4.6771e-04 - val_acc: 0.9912\n",
      "Epoch 1379/3000\n",
      " - 1s - loss: 4.8449e-04 - acc: 0.9913 - val_loss: 4.9078e-04 - val_acc: 0.9912\n",
      "Epoch 1380/3000\n",
      "\n",
      "Epoch 01380: val_loss improved from 0.00048 to 0.00046, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 4.8306e-04 - acc: 0.9913 - val_loss: 4.6365e-04 - val_acc: 0.9913\n",
      "Epoch 1381/3000\n",
      " - 2s - loss: 4.8876e-04 - acc: 0.9912 - val_loss: 5.1315e-04 - val_acc: 0.9909\n",
      "Epoch 1382/3000\n",
      " - 2s - loss: 4.8327e-04 - acc: 0.9913 - val_loss: 4.8264e-04 - val_acc: 0.9913\n",
      "Epoch 1383/3000\n",
      " - 2s - loss: 4.7950e-04 - acc: 0.9913 - val_loss: 4.9212e-04 - val_acc: 0.9909\n",
      "Epoch 1384/3000\n",
      " - 2s - loss: 4.9374e-04 - acc: 0.9912 - val_loss: 4.8349e-04 - val_acc: 0.9910\n",
      "Epoch 1385/3000\n",
      " - 2s - loss: 5.0159e-04 - acc: 0.9910 - val_loss: 5.1230e-04 - val_acc: 0.9908\n",
      "Epoch 1386/3000\n",
      " - 2s - loss: 4.8629e-04 - acc: 0.9913 - val_loss: 4.7578e-04 - val_acc: 0.9913\n",
      "Epoch 1387/3000\n",
      " - 1s - loss: 4.8721e-04 - acc: 0.9913 - val_loss: 4.7846e-04 - val_acc: 0.9913\n",
      "Epoch 1388/3000\n",
      " - 2s - loss: 4.7485e-04 - acc: 0.9914 - val_loss: 4.8539e-04 - val_acc: 0.9911\n",
      "Epoch 1389/3000\n",
      " - 2s - loss: 4.7611e-04 - acc: 0.9914 - val_loss: 5.0593e-04 - val_acc: 0.9911\n",
      "Epoch 1390/3000\n",
      " - 2s - loss: 4.9406e-04 - acc: 0.9912 - val_loss: 4.6711e-04 - val_acc: 0.9913\n",
      "Epoch 1391/3000\n",
      " - 2s - loss: 4.8506e-04 - acc: 0.9913 - val_loss: 4.9055e-04 - val_acc: 0.9913\n",
      "Epoch 1392/3000\n",
      " - 2s - loss: 4.8788e-04 - acc: 0.9913 - val_loss: 4.7660e-04 - val_acc: 0.9912\n",
      "Epoch 1393/3000\n",
      " - 2s - loss: 4.8855e-04 - acc: 0.9912 - val_loss: 4.8930e-04 - val_acc: 0.9912\n",
      "Epoch 1394/3000\n",
      " - 2s - loss: 4.7611e-04 - acc: 0.9913 - val_loss: 4.8343e-04 - val_acc: 0.9911\n",
      "Epoch 1395/3000\n",
      " - 1s - loss: 4.7263e-04 - acc: 0.9914 - val_loss: 4.6496e-04 - val_acc: 0.9913\n",
      "Epoch 1396/3000\n",
      " - 2s - loss: 4.7701e-04 - acc: 0.9914 - val_loss: 4.8134e-04 - val_acc: 0.9907\n",
      "Epoch 1397/3000\n",
      " - 2s - loss: 4.7731e-04 - acc: 0.9913 - val_loss: 4.8163e-04 - val_acc: 0.9912\n",
      "Epoch 1398/3000\n",
      " - 2s - loss: 5.0037e-04 - acc: 0.9911 - val_loss: 5.4470e-04 - val_acc: 0.9912\n",
      "Epoch 1399/3000\n",
      " - 1s - loss: 4.9145e-04 - acc: 0.9911 - val_loss: 4.7466e-04 - val_acc: 0.9912\n",
      "Epoch 1400/3000\n",
      "\n",
      "Epoch 01400: val_loss did not improve from 0.00046\n",
      " - 2s - loss: 4.7528e-04 - acc: 0.9914 - val_loss: 4.7268e-04 - val_acc: 0.9914\n",
      "Epoch 1401/3000\n",
      " - 2s - loss: 4.8679e-04 - acc: 0.9913 - val_loss: 4.8310e-04 - val_acc: 0.9911\n",
      "Epoch 1402/3000\n",
      " - 2s - loss: 4.9553e-04 - acc: 0.9911 - val_loss: 4.6430e-04 - val_acc: 0.9913\n",
      "Epoch 1403/3000\n",
      " - 2s - loss: 4.7589e-04 - acc: 0.9914 - val_loss: 4.6187e-04 - val_acc: 0.9914\n",
      "Epoch 1404/3000\n",
      " - 2s - loss: 4.7351e-04 - acc: 0.9914 - val_loss: 4.6634e-04 - val_acc: 0.9913\n",
      "Epoch 1405/3000\n",
      " - 2s - loss: 4.7353e-04 - acc: 0.9914 - val_loss: 5.3451e-04 - val_acc: 0.9912\n",
      "Epoch 1406/3000\n",
      " - 2s - loss: 4.8209e-04 - acc: 0.9914 - val_loss: 4.6727e-04 - val_acc: 0.9912\n",
      "Epoch 1407/3000\n",
      " - 2s - loss: 4.8041e-04 - acc: 0.9913 - val_loss: 4.7934e-04 - val_acc: 0.9912\n",
      "Epoch 1408/3000\n",
      " - 2s - loss: 4.8173e-04 - acc: 0.9914 - val_loss: 4.6312e-04 - val_acc: 0.9914\n",
      "Epoch 1409/3000\n",
      " - 1s - loss: 4.7528e-04 - acc: 0.9914 - val_loss: 4.7169e-04 - val_acc: 0.9910\n",
      "Epoch 1410/3000\n",
      " - 1s - loss: 4.7892e-04 - acc: 0.9913 - val_loss: 4.7356e-04 - val_acc: 0.9914\n",
      "Epoch 1411/3000\n",
      " - 1s - loss: 4.9361e-04 - acc: 0.9911 - val_loss: 4.9257e-04 - val_acc: 0.9911\n",
      "Epoch 1412/3000\n",
      " - 2s - loss: 4.8201e-04 - acc: 0.9913 - val_loss: 4.9731e-04 - val_acc: 0.9910\n",
      "Epoch 1413/3000\n",
      " - 2s - loss: 4.8792e-04 - acc: 0.9912 - val_loss: 4.8334e-04 - val_acc: 0.9914\n",
      "Epoch 1414/3000\n",
      " - 2s - loss: 4.9227e-04 - acc: 0.9912 - val_loss: 4.8389e-04 - val_acc: 0.9913\n",
      "Epoch 1415/3000\n",
      " - 1s - loss: 4.8769e-04 - acc: 0.9913 - val_loss: 4.6676e-04 - val_acc: 0.9912\n",
      "Epoch 1416/3000\n",
      " - 2s - loss: 4.6999e-04 - acc: 0.9914 - val_loss: 4.6111e-04 - val_acc: 0.9914\n",
      "Epoch 1417/3000\n",
      " - 2s - loss: 4.7127e-04 - acc: 0.9914 - val_loss: 4.5708e-04 - val_acc: 0.9914\n",
      "Epoch 1418/3000\n",
      " - 2s - loss: 4.7801e-04 - acc: 0.9914 - val_loss: 4.7009e-04 - val_acc: 0.9911\n",
      "Epoch 1419/3000\n",
      " - 1s - loss: 4.7446e-04 - acc: 0.9914 - val_loss: 4.6918e-04 - val_acc: 0.9913\n",
      "Epoch 1420/3000\n",
      "\n",
      "Epoch 01420: val_loss did not improve from 0.00046\n",
      " - 1s - loss: 4.9028e-04 - acc: 0.9912 - val_loss: 4.6659e-04 - val_acc: 0.9914\n",
      "Epoch 1421/3000\n",
      " - 2s - loss: 4.8692e-04 - acc: 0.9911 - val_loss: 4.8827e-04 - val_acc: 0.9908\n",
      "Epoch 1422/3000\n",
      " - 2s - loss: 4.7468e-04 - acc: 0.9914 - val_loss: 5.1096e-04 - val_acc: 0.9911\n",
      "Epoch 1423/3000\n",
      " - 2s - loss: 4.8115e-04 - acc: 0.9914 - val_loss: 4.9722e-04 - val_acc: 0.9914\n",
      "Epoch 1424/3000\n",
      " - 1s - loss: 4.7834e-04 - acc: 0.9914 - val_loss: 4.5900e-04 - val_acc: 0.9913\n",
      "Epoch 1425/3000\n",
      " - 2s - loss: 4.6991e-04 - acc: 0.9915 - val_loss: 4.6988e-04 - val_acc: 0.9911\n",
      "Epoch 1426/3000\n",
      " - 2s - loss: 4.7886e-04 - acc: 0.9914 - val_loss: 4.9400e-04 - val_acc: 0.9910\n",
      "Epoch 1427/3000\n",
      " - 1s - loss: 4.7755e-04 - acc: 0.9914 - val_loss: 4.6330e-04 - val_acc: 0.9912\n",
      "Epoch 1428/3000\n",
      " - 1s - loss: 4.7509e-04 - acc: 0.9914 - val_loss: 4.8801e-04 - val_acc: 0.9912\n",
      "Epoch 1429/3000\n",
      " - 2s - loss: 4.7681e-04 - acc: 0.9913 - val_loss: 4.7778e-04 - val_acc: 0.9913\n",
      "Epoch 1430/3000\n",
      " - 2s - loss: 4.6962e-04 - acc: 0.9914 - val_loss: 4.8230e-04 - val_acc: 0.9913\n",
      "Epoch 1431/3000\n",
      " - 2s - loss: 4.8096e-04 - acc: 0.9913 - val_loss: 4.6070e-04 - val_acc: 0.9914\n",
      "Epoch 1432/3000\n",
      " - 1s - loss: 4.8609e-04 - acc: 0.9913 - val_loss: 4.6672e-04 - val_acc: 0.9913\n",
      "Epoch 1433/3000\n",
      " - 1s - loss: 4.7988e-04 - acc: 0.9914 - val_loss: 4.6371e-04 - val_acc: 0.9912\n",
      "Epoch 1434/3000\n",
      " - 2s - loss: 4.7816e-04 - acc: 0.9913 - val_loss: 4.6426e-04 - val_acc: 0.9912\n",
      "Epoch 1435/3000\n",
      " - 2s - loss: 4.7569e-04 - acc: 0.9914 - val_loss: 4.7902e-04 - val_acc: 0.9911\n",
      "Epoch 1436/3000\n",
      " - 2s - loss: 4.9619e-04 - acc: 0.9910 - val_loss: 5.2662e-04 - val_acc: 0.9899\n",
      "Epoch 1437/3000\n",
      " - 2s - loss: 4.7281e-04 - acc: 0.9913 - val_loss: 4.5988e-04 - val_acc: 0.9913\n",
      "Epoch 1438/3000\n",
      " - 2s - loss: 4.7447e-04 - acc: 0.9915 - val_loss: 4.5658e-04 - val_acc: 0.9914\n",
      "Epoch 1439/3000\n",
      " - 2s - loss: 4.7132e-04 - acc: 0.9914 - val_loss: 4.7111e-04 - val_acc: 0.9914\n",
      "Epoch 1440/3000\n",
      "\n",
      "Epoch 01440: val_loss did not improve from 0.00046\n",
      " - 2s - loss: 4.8106e-04 - acc: 0.9914 - val_loss: 4.9448e-04 - val_acc: 0.9913\n",
      "Epoch 1441/3000\n",
      " - 1s - loss: 4.7898e-04 - acc: 0.9913 - val_loss: 4.8453e-04 - val_acc: 0.9914\n",
      "Epoch 1442/3000\n",
      " - 2s - loss: 4.8949e-04 - acc: 0.9913 - val_loss: 4.9968e-04 - val_acc: 0.9911\n",
      "Epoch 1443/3000\n",
      " - 2s - loss: 4.7939e-04 - acc: 0.9912 - val_loss: 4.8129e-04 - val_acc: 0.9913\n",
      "Epoch 1444/3000\n",
      " - 2s - loss: 4.9540e-04 - acc: 0.9911 - val_loss: 4.7803e-04 - val_acc: 0.9912\n",
      "Epoch 1445/3000\n",
      " - 1s - loss: 4.7617e-04 - acc: 0.9913 - val_loss: 4.5582e-04 - val_acc: 0.9914\n",
      "Epoch 1446/3000\n",
      " - 2s - loss: 4.7080e-04 - acc: 0.9915 - val_loss: 4.6744e-04 - val_acc: 0.9914\n",
      "Epoch 1447/3000\n",
      " - 1s - loss: 4.7651e-04 - acc: 0.9914 - val_loss: 5.0720e-04 - val_acc: 0.9912\n",
      "Epoch 1448/3000\n",
      " - 2s - loss: 4.7235e-04 - acc: 0.9915 - val_loss: 4.9492e-04 - val_acc: 0.9913\n",
      "Epoch 1449/3000\n",
      " - 1s - loss: 4.8161e-04 - acc: 0.9913 - val_loss: 4.6727e-04 - val_acc: 0.9913\n",
      "Epoch 1450/3000\n",
      " - 1s - loss: 4.6877e-04 - acc: 0.9914 - val_loss: 5.0705e-04 - val_acc: 0.9914\n",
      "Epoch 1451/3000\n",
      " - 2s - loss: 4.7401e-04 - acc: 0.9914 - val_loss: 4.6093e-04 - val_acc: 0.9912\n",
      "Epoch 1452/3000\n",
      " - 1s - loss: 4.8058e-04 - acc: 0.9914 - val_loss: 4.5813e-04 - val_acc: 0.9914\n",
      "Epoch 1453/3000\n",
      " - 2s - loss: 4.9067e-04 - acc: 0.9912 - val_loss: 5.0805e-04 - val_acc: 0.9905\n",
      "Epoch 1454/3000\n",
      " - 2s - loss: 4.8136e-04 - acc: 0.9912 - val_loss: 4.5418e-04 - val_acc: 0.9914\n",
      "Epoch 1455/3000\n",
      " - 1s - loss: 4.6965e-04 - acc: 0.9914 - val_loss: 4.6568e-04 - val_acc: 0.9914\n",
      "Epoch 1456/3000\n",
      " - 2s - loss: 4.6944e-04 - acc: 0.9915 - val_loss: 4.5863e-04 - val_acc: 0.9914\n",
      "Epoch 1457/3000\n",
      " - 2s - loss: 4.7384e-04 - acc: 0.9914 - val_loss: 4.9696e-04 - val_acc: 0.9913\n",
      "Epoch 1458/3000\n",
      " - 2s - loss: 4.9283e-04 - acc: 0.9911 - val_loss: 4.6335e-04 - val_acc: 0.9912\n",
      "Epoch 1459/3000\n",
      " - 2s - loss: 4.6876e-04 - acc: 0.9915 - val_loss: 4.6146e-04 - val_acc: 0.9914\n",
      "Epoch 1460/3000\n",
      "\n",
      "Epoch 01460: val_loss did not improve from 0.00046\n",
      " - 2s - loss: 4.6632e-04 - acc: 0.9915 - val_loss: 4.7384e-04 - val_acc: 0.9914\n",
      "Epoch 1461/3000\n",
      " - 2s - loss: 4.7029e-04 - acc: 0.9914 - val_loss: 4.9103e-04 - val_acc: 0.9911\n",
      "Epoch 1462/3000\n",
      " - 2s - loss: 4.7056e-04 - acc: 0.9915 - val_loss: 4.6083e-04 - val_acc: 0.9913\n",
      "Epoch 1463/3000\n",
      " - 2s - loss: 4.7179e-04 - acc: 0.9914 - val_loss: 4.9063e-04 - val_acc: 0.9915\n",
      "Epoch 1464/3000\n",
      " - 2s - loss: 4.7060e-04 - acc: 0.9914 - val_loss: 4.6746e-04 - val_acc: 0.9913\n",
      "Epoch 1465/3000\n",
      " - 2s - loss: 4.6710e-04 - acc: 0.9914 - val_loss: 4.5620e-04 - val_acc: 0.9914\n",
      "Epoch 1466/3000\n",
      " - 2s - loss: 4.6998e-04 - acc: 0.9915 - val_loss: 4.6660e-04 - val_acc: 0.9914\n",
      "Epoch 1467/3000\n",
      " - 1s - loss: 4.6913e-04 - acc: 0.9914 - val_loss: 4.5851e-04 - val_acc: 0.9911\n",
      "Epoch 1468/3000\n",
      " - 2s - loss: 4.6313e-04 - acc: 0.9915 - val_loss: 4.6872e-04 - val_acc: 0.9911\n",
      "Epoch 1469/3000\n",
      " - 2s - loss: 4.7762e-04 - acc: 0.9914 - val_loss: 4.7304e-04 - val_acc: 0.9911\n",
      "Epoch 1470/3000\n",
      " - 1s - loss: 4.6773e-04 - acc: 0.9915 - val_loss: 4.6377e-04 - val_acc: 0.9912\n",
      "Epoch 1471/3000\n",
      " - 2s - loss: 4.6743e-04 - acc: 0.9915 - val_loss: 4.7519e-04 - val_acc: 0.9910\n",
      "Epoch 1472/3000\n",
      " - 2s - loss: 4.8014e-04 - acc: 0.9913 - val_loss: 4.7430e-04 - val_acc: 0.9909\n",
      "Epoch 1473/3000\n",
      " - 2s - loss: 4.7095e-04 - acc: 0.9914 - val_loss: 4.5480e-04 - val_acc: 0.9915\n",
      "Epoch 1474/3000\n",
      " - 1s - loss: 4.6831e-04 - acc: 0.9915 - val_loss: 4.6596e-04 - val_acc: 0.9914\n",
      "Epoch 1475/3000\n",
      " - 2s - loss: 4.7526e-04 - acc: 0.9914 - val_loss: 4.7160e-04 - val_acc: 0.9914\n",
      "Epoch 1476/3000\n",
      " - 2s - loss: 4.7301e-04 - acc: 0.9914 - val_loss: 4.7539e-04 - val_acc: 0.9908\n",
      "Epoch 1477/3000\n",
      " - 2s - loss: 4.6701e-04 - acc: 0.9915 - val_loss: 4.8263e-04 - val_acc: 0.9914\n",
      "Epoch 1478/3000\n",
      " - 1s - loss: 4.6518e-04 - acc: 0.9915 - val_loss: 4.8047e-04 - val_acc: 0.9912\n",
      "Epoch 1479/3000\n",
      " - 2s - loss: 4.7408e-04 - acc: 0.9914 - val_loss: 4.6542e-04 - val_acc: 0.9913\n",
      "Epoch 1480/3000\n",
      "\n",
      "Epoch 01480: val_loss did not improve from 0.00046\n",
      " - 2s - loss: 4.6151e-04 - acc: 0.9915 - val_loss: 4.7269e-04 - val_acc: 0.9914\n",
      "Epoch 1481/3000\n",
      " - 2s - loss: 4.9642e-04 - acc: 0.9911 - val_loss: 4.6745e-04 - val_acc: 0.9913\n",
      "Epoch 1482/3000\n",
      " - 1s - loss: 4.7307e-04 - acc: 0.9913 - val_loss: 4.5820e-04 - val_acc: 0.9914\n",
      "Epoch 1483/3000\n",
      " - 2s - loss: 4.7048e-04 - acc: 0.9914 - val_loss: 4.5942e-04 - val_acc: 0.9911\n",
      "Epoch 1484/3000\n",
      " - 2s - loss: 4.6311e-04 - acc: 0.9915 - val_loss: 4.5373e-04 - val_acc: 0.9914\n",
      "Epoch 1485/3000\n",
      " - 2s - loss: 4.6942e-04 - acc: 0.9914 - val_loss: 4.6894e-04 - val_acc: 0.9913\n",
      "Epoch 1486/3000\n",
      " - 1s - loss: 4.7340e-04 - acc: 0.9915 - val_loss: 4.9873e-04 - val_acc: 0.9913\n",
      "Epoch 1487/3000\n",
      " - 2s - loss: 4.8234e-04 - acc: 0.9914 - val_loss: 4.6927e-04 - val_acc: 0.9914\n",
      "Epoch 1488/3000\n",
      " - 2s - loss: 4.6970e-04 - acc: 0.9914 - val_loss: 4.7436e-04 - val_acc: 0.9913\n",
      "Epoch 1489/3000\n",
      " - 2s - loss: 4.7388e-04 - acc: 0.9913 - val_loss: 5.2502e-04 - val_acc: 0.9907\n",
      "Epoch 1490/3000\n",
      " - 2s - loss: 4.7499e-04 - acc: 0.9913 - val_loss: 4.6299e-04 - val_acc: 0.9913\n",
      "Epoch 1491/3000\n",
      " - 2s - loss: 4.7017e-04 - acc: 0.9913 - val_loss: 4.5627e-04 - val_acc: 0.9913\n",
      "Epoch 1492/3000\n",
      " - 2s - loss: 4.6372e-04 - acc: 0.9914 - val_loss: 4.6617e-04 - val_acc: 0.9914\n",
      "Epoch 1493/3000\n",
      " - 2s - loss: 4.6404e-04 - acc: 0.9914 - val_loss: 4.9013e-04 - val_acc: 0.9911\n",
      "Epoch 1494/3000\n",
      " - 1s - loss: 4.7811e-04 - acc: 0.9913 - val_loss: 4.6038e-04 - val_acc: 0.9914\n",
      "Epoch 1495/3000\n",
      " - 2s - loss: 4.6721e-04 - acc: 0.9914 - val_loss: 4.5614e-04 - val_acc: 0.9913\n",
      "Epoch 1496/3000\n",
      " - 2s - loss: 4.6418e-04 - acc: 0.9914 - val_loss: 4.5223e-04 - val_acc: 0.9915\n",
      "Epoch 1497/3000\n",
      " - 2s - loss: 4.7116e-04 - acc: 0.9914 - val_loss: 4.6568e-04 - val_acc: 0.9915\n",
      "Epoch 1498/3000\n",
      " - 2s - loss: 4.7297e-04 - acc: 0.9913 - val_loss: 4.6262e-04 - val_acc: 0.9912\n",
      "Epoch 1499/3000\n",
      " - 1s - loss: 4.6493e-04 - acc: 0.9915 - val_loss: 4.7406e-04 - val_acc: 0.9910\n",
      "Epoch 1500/3000\n",
      "\n",
      "Epoch 01500: val_loss improved from 0.00046 to 0.00045, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 4.6992e-04 - acc: 0.9913 - val_loss: 4.4807e-04 - val_acc: 0.9915\n",
      "Epoch 1501/3000\n",
      " - 2s - loss: 4.6680e-04 - acc: 0.9915 - val_loss: 4.5283e-04 - val_acc: 0.9914\n",
      "Epoch 1502/3000\n",
      " - 2s - loss: 4.5957e-04 - acc: 0.9916 - val_loss: 4.9300e-04 - val_acc: 0.9913\n",
      "Epoch 1503/3000\n",
      " - 2s - loss: 4.7695e-04 - acc: 0.9913 - val_loss: 4.5810e-04 - val_acc: 0.9911\n",
      "Epoch 1504/3000\n",
      " - 1s - loss: 4.6760e-04 - acc: 0.9915 - val_loss: 4.7227e-04 - val_acc: 0.9913\n",
      "Epoch 1505/3000\n",
      " - 2s - loss: 4.6976e-04 - acc: 0.9914 - val_loss: 4.6222e-04 - val_acc: 0.9913\n",
      "Epoch 1506/3000\n",
      " - 1s - loss: 4.8390e-04 - acc: 0.9912 - val_loss: 4.7215e-04 - val_acc: 0.9910\n",
      "Epoch 1507/3000\n",
      " - 1s - loss: 4.9091e-04 - acc: 0.9911 - val_loss: 4.8934e-04 - val_acc: 0.9910\n",
      "Epoch 1508/3000\n",
      " - 2s - loss: 4.7346e-04 - acc: 0.9913 - val_loss: 4.5261e-04 - val_acc: 0.9915\n",
      "Epoch 1509/3000\n",
      " - 2s - loss: 4.5928e-04 - acc: 0.9916 - val_loss: 4.8227e-04 - val_acc: 0.9914\n",
      "Epoch 1510/3000\n",
      " - 2s - loss: 4.8119e-04 - acc: 0.9913 - val_loss: 4.7727e-04 - val_acc: 0.9912\n",
      "Epoch 1511/3000\n",
      " - 1s - loss: 4.8036e-04 - acc: 0.9913 - val_loss: 5.3418e-04 - val_acc: 0.9907\n",
      "Epoch 1512/3000\n",
      " - 2s - loss: 4.8789e-04 - acc: 0.9911 - val_loss: 4.5799e-04 - val_acc: 0.9914\n",
      "Epoch 1513/3000\n",
      " - 2s - loss: 4.7082e-04 - acc: 0.9913 - val_loss: 4.4903e-04 - val_acc: 0.9912\n",
      "Epoch 1514/3000\n",
      " - 2s - loss: 4.6024e-04 - acc: 0.9915 - val_loss: 4.6235e-04 - val_acc: 0.9913\n",
      "Epoch 1515/3000\n",
      " - 2s - loss: 4.5592e-04 - acc: 0.9916 - val_loss: 4.5182e-04 - val_acc: 0.9914\n",
      "Epoch 1516/3000\n",
      " - 2s - loss: 4.6385e-04 - acc: 0.9914 - val_loss: 4.4639e-04 - val_acc: 0.9917\n",
      "Epoch 1517/3000\n",
      " - 1s - loss: 4.6958e-04 - acc: 0.9914 - val_loss: 4.8495e-04 - val_acc: 0.9913\n",
      "Epoch 1518/3000\n",
      " - 2s - loss: 4.6644e-04 - acc: 0.9916 - val_loss: 4.4997e-04 - val_acc: 0.9916\n",
      "Epoch 1519/3000\n",
      " - 2s - loss: 4.5746e-04 - acc: 0.9916 - val_loss: 4.4398e-04 - val_acc: 0.9916\n",
      "Epoch 1520/3000\n",
      "\n",
      "Epoch 01520: val_loss did not improve from 0.00045\n",
      " - 2s - loss: 4.5928e-04 - acc: 0.9916 - val_loss: 4.6223e-04 - val_acc: 0.9914\n",
      "Epoch 1521/3000\n",
      " - 2s - loss: 4.6085e-04 - acc: 0.9915 - val_loss: 4.5431e-04 - val_acc: 0.9916\n",
      "Epoch 1522/3000\n",
      " - 1s - loss: 4.6883e-04 - acc: 0.9914 - val_loss: 4.5739e-04 - val_acc: 0.9913\n",
      "Epoch 1523/3000\n",
      " - 1s - loss: 4.6794e-04 - acc: 0.9914 - val_loss: 4.5650e-04 - val_acc: 0.9912\n",
      "Epoch 1524/3000\n",
      " - 1s - loss: 4.5988e-04 - acc: 0.9915 - val_loss: 4.5610e-04 - val_acc: 0.9915\n",
      "Epoch 1525/3000\n",
      " - 2s - loss: 4.5767e-04 - acc: 0.9916 - val_loss: 4.6074e-04 - val_acc: 0.9911\n",
      "Epoch 1526/3000\n",
      " - 2s - loss: 4.5967e-04 - acc: 0.9915 - val_loss: 4.6119e-04 - val_acc: 0.9912\n",
      "Epoch 1527/3000\n",
      " - 2s - loss: 4.7123e-04 - acc: 0.9913 - val_loss: 4.5496e-04 - val_acc: 0.9910\n",
      "Epoch 1528/3000\n",
      " - 1s - loss: 4.5926e-04 - acc: 0.9915 - val_loss: 4.6537e-04 - val_acc: 0.9915\n",
      "Epoch 1529/3000\n",
      " - 2s - loss: 4.6277e-04 - acc: 0.9915 - val_loss: 4.4641e-04 - val_acc: 0.9914\n",
      "Epoch 1530/3000\n",
      " - 2s - loss: 4.5746e-04 - acc: 0.9916 - val_loss: 4.7012e-04 - val_acc: 0.9915\n",
      "Epoch 1531/3000\n",
      " - 2s - loss: 4.7158e-04 - acc: 0.9913 - val_loss: 4.6895e-04 - val_acc: 0.9915\n",
      "Epoch 1532/3000\n",
      " - 2s - loss: 4.6579e-04 - acc: 0.9915 - val_loss: 4.5303e-04 - val_acc: 0.9912\n",
      "Epoch 1533/3000\n",
      " - 2s - loss: 4.5900e-04 - acc: 0.9915 - val_loss: 4.5807e-04 - val_acc: 0.9914\n",
      "Epoch 1534/3000\n",
      " - 2s - loss: 4.5754e-04 - acc: 0.9916 - val_loss: 4.6658e-04 - val_acc: 0.9915\n",
      "Epoch 1535/3000\n",
      " - 1s - loss: 4.6348e-04 - acc: 0.9916 - val_loss: 4.6694e-04 - val_acc: 0.9914\n",
      "Epoch 1536/3000\n",
      " - 2s - loss: 4.6649e-04 - acc: 0.9914 - val_loss: 4.5850e-04 - val_acc: 0.9914\n",
      "Epoch 1537/3000\n",
      " - 2s - loss: 4.7701e-04 - acc: 0.9914 - val_loss: 4.6855e-04 - val_acc: 0.9914\n",
      "Epoch 1538/3000\n",
      " - 2s - loss: 4.7033e-04 - acc: 0.9914 - val_loss: 4.5129e-04 - val_acc: 0.9915\n",
      "Epoch 1539/3000\n",
      " - 2s - loss: 4.5542e-04 - acc: 0.9916 - val_loss: 4.6108e-04 - val_acc: 0.9915\n",
      "Epoch 1540/3000\n",
      "\n",
      "Epoch 01540: val_loss did not improve from 0.00045\n",
      " - 2s - loss: 4.5582e-04 - acc: 0.9916 - val_loss: 4.5272e-04 - val_acc: 0.9916\n",
      "Epoch 1541/3000\n",
      " - 1s - loss: 4.7448e-04 - acc: 0.9913 - val_loss: 4.5086e-04 - val_acc: 0.9914\n",
      "Epoch 1542/3000\n",
      " - 1s - loss: 4.6643e-04 - acc: 0.9913 - val_loss: 4.5009e-04 - val_acc: 0.9915\n",
      "Epoch 1543/3000\n",
      " - 1s - loss: 4.6318e-04 - acc: 0.9915 - val_loss: 4.6138e-04 - val_acc: 0.9914\n",
      "Epoch 1544/3000\n",
      " - 2s - loss: 4.7111e-04 - acc: 0.9914 - val_loss: 4.6574e-04 - val_acc: 0.9912\n",
      "Epoch 1545/3000\n",
      " - 2s - loss: 4.5930e-04 - acc: 0.9916 - val_loss: 4.5564e-04 - val_acc: 0.9917\n",
      "Epoch 1546/3000\n",
      " - 2s - loss: 4.5928e-04 - acc: 0.9915 - val_loss: 4.5262e-04 - val_acc: 0.9913\n",
      "Epoch 1547/3000\n",
      " - 2s - loss: 4.6249e-04 - acc: 0.9915 - val_loss: 4.6245e-04 - val_acc: 0.9913\n",
      "Epoch 1548/3000\n",
      " - 2s - loss: 4.8169e-04 - acc: 0.9912 - val_loss: 4.5427e-04 - val_acc: 0.9913\n",
      "Epoch 1549/3000\n",
      " - 2s - loss: 4.8573e-04 - acc: 0.9911 - val_loss: 4.7989e-04 - val_acc: 0.9907\n",
      "Epoch 1550/3000\n",
      " - 1s - loss: 4.5715e-04 - acc: 0.9915 - val_loss: 4.5595e-04 - val_acc: 0.9913\n",
      "Epoch 1551/3000\n",
      " - 1s - loss: 4.5664e-04 - acc: 0.9917 - val_loss: 4.6629e-04 - val_acc: 0.9912\n",
      "Epoch 1552/3000\n",
      " - 2s - loss: 4.5253e-04 - acc: 0.9916 - val_loss: 4.4672e-04 - val_acc: 0.9915\n",
      "Epoch 1553/3000\n",
      " - 1s - loss: 4.6931e-04 - acc: 0.9915 - val_loss: 4.6255e-04 - val_acc: 0.9910\n",
      "Epoch 1554/3000\n",
      " - 1s - loss: 4.6336e-04 - acc: 0.9914 - val_loss: 4.7388e-04 - val_acc: 0.9915\n",
      "Epoch 1555/3000\n",
      " - 2s - loss: 4.6817e-04 - acc: 0.9914 - val_loss: 4.6038e-04 - val_acc: 0.9912\n",
      "Epoch 1556/3000\n",
      " - 1s - loss: 4.5801e-04 - acc: 0.9915 - val_loss: 4.7164e-04 - val_acc: 0.9916\n",
      "Epoch 1557/3000\n",
      " - 2s - loss: 4.6017e-04 - acc: 0.9915 - val_loss: 4.5455e-04 - val_acc: 0.9916\n",
      "Epoch 1558/3000\n",
      " - 2s - loss: 4.5958e-04 - acc: 0.9916 - val_loss: 4.6581e-04 - val_acc: 0.9912\n",
      "Epoch 1559/3000\n",
      " - 1s - loss: 4.8360e-04 - acc: 0.9912 - val_loss: 4.5903e-04 - val_acc: 0.9914\n",
      "Epoch 1560/3000\n",
      "\n",
      "Epoch 01560: val_loss did not improve from 0.00045\n",
      " - 1s - loss: 4.5867e-04 - acc: 0.9915 - val_loss: 4.7022e-04 - val_acc: 0.9913\n",
      "Epoch 1561/3000\n",
      " - 2s - loss: 4.6369e-04 - acc: 0.9915 - val_loss: 4.6857e-04 - val_acc: 0.9915\n",
      "Epoch 1562/3000\n",
      " - 2s - loss: 4.5921e-04 - acc: 0.9915 - val_loss: 4.4768e-04 - val_acc: 0.9916\n",
      "Epoch 1563/3000\n",
      " - 2s - loss: 4.5724e-04 - acc: 0.9916 - val_loss: 4.5267e-04 - val_acc: 0.9913\n",
      "Epoch 1564/3000\n",
      " - 2s - loss: 4.5449e-04 - acc: 0.9916 - val_loss: 4.5238e-04 - val_acc: 0.9916\n",
      "Epoch 1565/3000\n",
      " - 1s - loss: 4.5930e-04 - acc: 0.9915 - val_loss: 4.7682e-04 - val_acc: 0.9904\n",
      "Epoch 1566/3000\n",
      " - 2s - loss: 4.5950e-04 - acc: 0.9915 - val_loss: 4.5810e-04 - val_acc: 0.9913\n",
      "Epoch 1567/3000\n",
      " - 1s - loss: 4.5953e-04 - acc: 0.9914 - val_loss: 4.5200e-04 - val_acc: 0.9913\n",
      "Epoch 1568/3000\n",
      " - 2s - loss: 4.6018e-04 - acc: 0.9915 - val_loss: 4.5441e-04 - val_acc: 0.9913\n",
      "Epoch 1569/3000\n",
      " - 2s - loss: 4.5539e-04 - acc: 0.9916 - val_loss: 4.5687e-04 - val_acc: 0.9914\n",
      "Epoch 1570/3000\n",
      " - 2s - loss: 4.5406e-04 - acc: 0.9916 - val_loss: 4.6505e-04 - val_acc: 0.9912\n",
      "Epoch 1571/3000\n",
      " - 2s - loss: 4.5795e-04 - acc: 0.9915 - val_loss: 4.5379e-04 - val_acc: 0.9914\n",
      "Epoch 1572/3000\n",
      " - 2s - loss: 4.5408e-04 - acc: 0.9915 - val_loss: 4.5125e-04 - val_acc: 0.9915\n",
      "Epoch 1573/3000\n",
      " - 1s - loss: 4.5557e-04 - acc: 0.9916 - val_loss: 4.5579e-04 - val_acc: 0.9915\n",
      "Epoch 1574/3000\n",
      " - 1s - loss: 4.5784e-04 - acc: 0.9916 - val_loss: 4.6934e-04 - val_acc: 0.9914\n",
      "Epoch 1575/3000\n",
      " - 2s - loss: 4.6028e-04 - acc: 0.9915 - val_loss: 4.5504e-04 - val_acc: 0.9915\n",
      "Epoch 1576/3000\n",
      " - 1s - loss: 4.6218e-04 - acc: 0.9915 - val_loss: 4.6128e-04 - val_acc: 0.9911\n",
      "Epoch 1577/3000\n",
      " - 2s - loss: 4.5043e-04 - acc: 0.9916 - val_loss: 4.5854e-04 - val_acc: 0.9915\n",
      "Epoch 1578/3000\n",
      " - 2s - loss: 4.7883e-04 - acc: 0.9912 - val_loss: 4.6802e-04 - val_acc: 0.9910\n",
      "Epoch 1579/3000\n",
      " - 2s - loss: 4.5909e-04 - acc: 0.9915 - val_loss: 4.6022e-04 - val_acc: 0.9910\n",
      "Epoch 1580/3000\n",
      "\n",
      "Epoch 01580: val_loss did not improve from 0.00045\n",
      " - 2s - loss: 4.5929e-04 - acc: 0.9916 - val_loss: 4.7737e-04 - val_acc: 0.9915\n",
      "Epoch 1581/3000\n",
      " - 2s - loss: 4.5821e-04 - acc: 0.9915 - val_loss: 4.4560e-04 - val_acc: 0.9914\n",
      "Epoch 1582/3000\n",
      " - 2s - loss: 4.6198e-04 - acc: 0.9914 - val_loss: 4.4408e-04 - val_acc: 0.9915\n",
      "Epoch 1583/3000\n",
      " - 2s - loss: 4.6208e-04 - acc: 0.9915 - val_loss: 4.7105e-04 - val_acc: 0.9910\n",
      "Epoch 1584/3000\n",
      " - 1s - loss: 4.8308e-04 - acc: 0.9911 - val_loss: 4.6039e-04 - val_acc: 0.9912\n",
      "Epoch 1585/3000\n",
      " - 2s - loss: 4.5418e-04 - acc: 0.9916 - val_loss: 4.3984e-04 - val_acc: 0.9916\n",
      "Epoch 1586/3000\n",
      " - 2s - loss: 4.5336e-04 - acc: 0.9916 - val_loss: 4.8223e-04 - val_acc: 0.9915\n",
      "Epoch 1587/3000\n",
      " - 2s - loss: 4.6122e-04 - acc: 0.9915 - val_loss: 4.6259e-04 - val_acc: 0.9914\n",
      "Epoch 1588/3000\n",
      " - 2s - loss: 4.6261e-04 - acc: 0.9915 - val_loss: 4.5815e-04 - val_acc: 0.9914\n",
      "Epoch 1589/3000\n",
      " - 1s - loss: 4.5520e-04 - acc: 0.9916 - val_loss: 4.5446e-04 - val_acc: 0.9915\n",
      "Epoch 1590/3000\n",
      " - 2s - loss: 4.6342e-04 - acc: 0.9915 - val_loss: 4.4569e-04 - val_acc: 0.9913\n",
      "Epoch 1591/3000\n",
      " - 2s - loss: 4.5458e-04 - acc: 0.9916 - val_loss: 4.4720e-04 - val_acc: 0.9915\n",
      "Epoch 1592/3000\n",
      " - 2s - loss: 4.5747e-04 - acc: 0.9916 - val_loss: 4.5573e-04 - val_acc: 0.9915\n",
      "Epoch 1593/3000\n",
      " - 1s - loss: 4.6569e-04 - acc: 0.9913 - val_loss: 4.4665e-04 - val_acc: 0.9916\n",
      "Epoch 1594/3000\n",
      " - 2s - loss: 4.5278e-04 - acc: 0.9916 - val_loss: 4.6232e-04 - val_acc: 0.9916\n",
      "Epoch 1595/3000\n",
      " - 2s - loss: 4.6512e-04 - acc: 0.9914 - val_loss: 4.4935e-04 - val_acc: 0.9917\n",
      "Epoch 1596/3000\n",
      " - 1s - loss: 4.5898e-04 - acc: 0.9916 - val_loss: 4.8307e-04 - val_acc: 0.9910\n",
      "Epoch 1597/3000\n",
      " - 2s - loss: 4.6423e-04 - acc: 0.9915 - val_loss: 4.5436e-04 - val_acc: 0.9914\n",
      "Epoch 1598/3000\n",
      " - 2s - loss: 4.5418e-04 - acc: 0.9916 - val_loss: 4.4435e-04 - val_acc: 0.9915\n",
      "Epoch 1599/3000\n",
      " - 2s - loss: 4.5083e-04 - acc: 0.9917 - val_loss: 4.4707e-04 - val_acc: 0.9914\n",
      "Epoch 1600/3000\n",
      "\n",
      "Epoch 01600: val_loss did not improve from 0.00045\n",
      " - 2s - loss: 4.5201e-04 - acc: 0.9917 - val_loss: 4.4862e-04 - val_acc: 0.9916\n",
      "Epoch 1601/3000\n",
      " - 2s - loss: 4.5204e-04 - acc: 0.9917 - val_loss: 4.4380e-04 - val_acc: 0.9916\n",
      "Epoch 1602/3000\n",
      " - 2s - loss: 4.5453e-04 - acc: 0.9916 - val_loss: 4.7303e-04 - val_acc: 0.9915\n",
      "Epoch 1603/3000\n",
      " - 2s - loss: 4.6119e-04 - acc: 0.9915 - val_loss: 4.9268e-04 - val_acc: 0.9910\n",
      "Epoch 1604/3000\n",
      " - 1s - loss: 4.5820e-04 - acc: 0.9916 - val_loss: 4.6661e-04 - val_acc: 0.9910\n",
      "Epoch 1605/3000\n",
      " - 2s - loss: 4.4887e-04 - acc: 0.9916 - val_loss: 4.4485e-04 - val_acc: 0.9916\n",
      "Epoch 1606/3000\n",
      " - 2s - loss: 4.5985e-04 - acc: 0.9915 - val_loss: 4.7013e-04 - val_acc: 0.9916\n",
      "Epoch 1607/3000\n",
      " - 2s - loss: 4.5649e-04 - acc: 0.9916 - val_loss: 4.8444e-04 - val_acc: 0.9915\n",
      "Epoch 1608/3000\n",
      " - 2s - loss: 4.5761e-04 - acc: 0.9915 - val_loss: 4.5772e-04 - val_acc: 0.9915\n",
      "Epoch 1609/3000\n",
      " - 1s - loss: 4.7857e-04 - acc: 0.9913 - val_loss: 5.5179e-04 - val_acc: 0.9912\n",
      "Epoch 1610/3000\n",
      " - 2s - loss: 4.6124e-04 - acc: 0.9915 - val_loss: 4.7976e-04 - val_acc: 0.9910\n",
      "Epoch 1611/3000\n",
      " - 2s - loss: 4.5081e-04 - acc: 0.9916 - val_loss: 4.3464e-04 - val_acc: 0.9916\n",
      "Epoch 1612/3000\n",
      " - 2s - loss: 4.5760e-04 - acc: 0.9916 - val_loss: 4.9238e-04 - val_acc: 0.9910\n",
      "Epoch 1613/3000\n",
      " - 1s - loss: 4.6805e-04 - acc: 0.9914 - val_loss: 4.8883e-04 - val_acc: 0.9908\n",
      "Epoch 1614/3000\n",
      " - 2s - loss: 4.5555e-04 - acc: 0.9917 - val_loss: 4.5992e-04 - val_acc: 0.9914\n",
      "Epoch 1615/3000\n",
      " - 2s - loss: 4.4996e-04 - acc: 0.9916 - val_loss: 4.3224e-04 - val_acc: 0.9916\n",
      "Epoch 1616/3000\n",
      " - 2s - loss: 4.4497e-04 - acc: 0.9916 - val_loss: 4.3422e-04 - val_acc: 0.9917\n",
      "Epoch 1617/3000\n",
      " - 2s - loss: 4.5343e-04 - acc: 0.9916 - val_loss: 4.3723e-04 - val_acc: 0.9916\n",
      "Epoch 1618/3000\n",
      " - 2s - loss: 4.5588e-04 - acc: 0.9916 - val_loss: 4.7320e-04 - val_acc: 0.9910\n",
      "Epoch 1619/3000\n",
      " - 2s - loss: 4.5428e-04 - acc: 0.9916 - val_loss: 4.8736e-04 - val_acc: 0.9912\n",
      "Epoch 1620/3000\n",
      "\n",
      "Epoch 01620: val_loss improved from 0.00045 to 0.00044, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 4.5481e-04 - acc: 0.9916 - val_loss: 4.3715e-04 - val_acc: 0.9916\n",
      "Epoch 1621/3000\n",
      " - 2s - loss: 4.6172e-04 - acc: 0.9914 - val_loss: 4.4691e-04 - val_acc: 0.9917\n",
      "Epoch 1622/3000\n",
      " - 1s - loss: 4.4976e-04 - acc: 0.9917 - val_loss: 4.7917e-04 - val_acc: 0.9911\n",
      "Epoch 1623/3000\n",
      " - 2s - loss: 4.5550e-04 - acc: 0.9916 - val_loss: 4.3933e-04 - val_acc: 0.9916\n",
      "Epoch 1624/3000\n",
      " - 2s - loss: 4.5248e-04 - acc: 0.9916 - val_loss: 4.5698e-04 - val_acc: 0.9912\n",
      "Epoch 1625/3000\n",
      " - 2s - loss: 4.6107e-04 - acc: 0.9914 - val_loss: 4.4275e-04 - val_acc: 0.9915\n",
      "Epoch 1626/3000\n",
      " - 1s - loss: 4.4746e-04 - acc: 0.9917 - val_loss: 4.5785e-04 - val_acc: 0.9915\n",
      "Epoch 1627/3000\n",
      " - 2s - loss: 4.5649e-04 - acc: 0.9916 - val_loss: 4.5583e-04 - val_acc: 0.9910\n",
      "Epoch 1628/3000\n",
      " - 2s - loss: 4.6487e-04 - acc: 0.9914 - val_loss: 4.3876e-04 - val_acc: 0.9917\n",
      "Epoch 1629/3000\n",
      " - 2s - loss: 4.5066e-04 - acc: 0.9917 - val_loss: 4.4743e-04 - val_acc: 0.9917\n",
      "Epoch 1630/3000\n",
      " - 2s - loss: 4.4109e-04 - acc: 0.9918 - val_loss: 4.5522e-04 - val_acc: 0.9914\n",
      "Epoch 1631/3000\n",
      " - 2s - loss: 4.4899e-04 - acc: 0.9917 - val_loss: 4.4897e-04 - val_acc: 0.9914\n",
      "Epoch 1632/3000\n",
      " - 1s - loss: 4.4732e-04 - acc: 0.9917 - val_loss: 4.4619e-04 - val_acc: 0.9916\n",
      "Epoch 1633/3000\n",
      " - 2s - loss: 4.4218e-04 - acc: 0.9918 - val_loss: 4.7841e-04 - val_acc: 0.9915\n",
      "Epoch 1634/3000\n",
      " - 2s - loss: 4.5225e-04 - acc: 0.9917 - val_loss: 4.4350e-04 - val_acc: 0.9916\n",
      "Epoch 1635/3000\n",
      " - 2s - loss: 4.4795e-04 - acc: 0.9916 - val_loss: 4.4112e-04 - val_acc: 0.9917\n",
      "Epoch 1636/3000\n",
      " - 2s - loss: 4.5171e-04 - acc: 0.9916 - val_loss: 4.5870e-04 - val_acc: 0.9913\n",
      "Epoch 1637/3000\n",
      " - 2s - loss: 4.5123e-04 - acc: 0.9917 - val_loss: 4.9079e-04 - val_acc: 0.9909\n",
      "Epoch 1638/3000\n",
      " - 1s - loss: 4.5820e-04 - acc: 0.9916 - val_loss: 4.4540e-04 - val_acc: 0.9915\n",
      "Epoch 1639/3000\n",
      " - 2s - loss: 4.5018e-04 - acc: 0.9916 - val_loss: 4.3167e-04 - val_acc: 0.9917\n",
      "Epoch 1640/3000\n",
      "\n",
      "Epoch 01640: val_loss did not improve from 0.00044\n",
      " - 1s - loss: 4.4328e-04 - acc: 0.9917 - val_loss: 4.5352e-04 - val_acc: 0.9916\n",
      "Epoch 1641/3000\n",
      " - 2s - loss: 4.5972e-04 - acc: 0.9916 - val_loss: 4.4538e-04 - val_acc: 0.9915\n",
      "Epoch 1642/3000\n",
      " - 1s - loss: 4.5467e-04 - acc: 0.9916 - val_loss: 4.5220e-04 - val_acc: 0.9915\n",
      "Epoch 1643/3000\n",
      " - 2s - loss: 4.5552e-04 - acc: 0.9916 - val_loss: 4.8153e-04 - val_acc: 0.9911\n",
      "Epoch 1644/3000\n",
      " - 1s - loss: 4.5595e-04 - acc: 0.9916 - val_loss: 4.5757e-04 - val_acc: 0.9915\n",
      "Epoch 1645/3000\n",
      " - 1s - loss: 4.5008e-04 - acc: 0.9917 - val_loss: 4.6030e-04 - val_acc: 0.9916\n",
      "Epoch 1646/3000\n",
      " - 2s - loss: 4.4879e-04 - acc: 0.9917 - val_loss: 4.4951e-04 - val_acc: 0.9914\n",
      "Epoch 1647/3000\n",
      " - 2s - loss: 4.6527e-04 - acc: 0.9915 - val_loss: 4.3412e-04 - val_acc: 0.9917\n",
      "Epoch 1648/3000\n",
      " - 2s - loss: 4.5330e-04 - acc: 0.9916 - val_loss: 4.4366e-04 - val_acc: 0.9916\n",
      "Epoch 1649/3000\n",
      " - 2s - loss: 4.5636e-04 - acc: 0.9915 - val_loss: 4.3644e-04 - val_acc: 0.9914\n",
      "Epoch 1650/3000\n",
      " - 2s - loss: 4.5644e-04 - acc: 0.9915 - val_loss: 4.3498e-04 - val_acc: 0.9914\n",
      "Epoch 1651/3000\n",
      " - 2s - loss: 4.4498e-04 - acc: 0.9917 - val_loss: 4.3572e-04 - val_acc: 0.9917\n",
      "Epoch 1652/3000\n",
      " - 2s - loss: 4.4696e-04 - acc: 0.9917 - val_loss: 4.3520e-04 - val_acc: 0.9916\n",
      "Epoch 1653/3000\n",
      " - 1s - loss: 4.4206e-04 - acc: 0.9917 - val_loss: 4.4926e-04 - val_acc: 0.9915\n",
      "Epoch 1654/3000\n",
      " - 1s - loss: 4.4642e-04 - acc: 0.9917 - val_loss: 4.3976e-04 - val_acc: 0.9917\n",
      "Epoch 1655/3000\n",
      " - 2s - loss: 4.5183e-04 - acc: 0.9917 - val_loss: 4.4899e-04 - val_acc: 0.9915\n",
      "Epoch 1656/3000\n",
      " - 2s - loss: 4.6708e-04 - acc: 0.9914 - val_loss: 4.4675e-04 - val_acc: 0.9915\n",
      "Epoch 1657/3000\n",
      " - 1s - loss: 4.5348e-04 - acc: 0.9916 - val_loss: 4.4268e-04 - val_acc: 0.9915\n",
      "Epoch 1658/3000\n",
      " - 2s - loss: 4.4662e-04 - acc: 0.9918 - val_loss: 4.4214e-04 - val_acc: 0.9916\n",
      "Epoch 1659/3000\n",
      " - 2s - loss: 4.4606e-04 - acc: 0.9917 - val_loss: 4.5651e-04 - val_acc: 0.9916\n",
      "Epoch 1660/3000\n",
      "\n",
      "Epoch 01660: val_loss did not improve from 0.00044\n",
      " - 2s - loss: 4.4809e-04 - acc: 0.9917 - val_loss: 4.4426e-04 - val_acc: 0.9915\n",
      "Epoch 1661/3000\n",
      " - 2s - loss: 4.5595e-04 - acc: 0.9915 - val_loss: 4.4026e-04 - val_acc: 0.9916\n",
      "Epoch 1662/3000\n",
      " - 1s - loss: 4.4322e-04 - acc: 0.9917 - val_loss: 4.4241e-04 - val_acc: 0.9915\n",
      "Epoch 1663/3000\n",
      " - 1s - loss: 4.4758e-04 - acc: 0.9916 - val_loss: 4.3528e-04 - val_acc: 0.9916\n",
      "Epoch 1664/3000\n",
      " - 2s - loss: 4.4557e-04 - acc: 0.9917 - val_loss: 4.7062e-04 - val_acc: 0.9914\n",
      "Epoch 1665/3000\n",
      " - 2s - loss: 4.4869e-04 - acc: 0.9916 - val_loss: 4.3833e-04 - val_acc: 0.9914\n",
      "Epoch 1666/3000\n",
      " - 2s - loss: 4.4389e-04 - acc: 0.9917 - val_loss: 4.5457e-04 - val_acc: 0.9916\n",
      "Epoch 1667/3000\n",
      " - 2s - loss: 4.4975e-04 - acc: 0.9916 - val_loss: 4.3207e-04 - val_acc: 0.9917\n",
      "Epoch 1668/3000\n",
      " - 1s - loss: 4.4539e-04 - acc: 0.9917 - val_loss: 4.4798e-04 - val_acc: 0.9914\n",
      "Epoch 1669/3000\n",
      " - 2s - loss: 4.5257e-04 - acc: 0.9916 - val_loss: 4.4637e-04 - val_acc: 0.9916\n",
      "Epoch 1670/3000\n",
      " - 2s - loss: 4.5174e-04 - acc: 0.9917 - val_loss: 4.4463e-04 - val_acc: 0.9915\n",
      "Epoch 1671/3000\n",
      " - 2s - loss: 4.4002e-04 - acc: 0.9918 - val_loss: 4.5340e-04 - val_acc: 0.9916\n",
      "Epoch 1672/3000\n",
      " - 2s - loss: 4.5427e-04 - acc: 0.9916 - val_loss: 4.3204e-04 - val_acc: 0.9915\n",
      "Epoch 1673/3000\n",
      " - 2s - loss: 4.4796e-04 - acc: 0.9917 - val_loss: 4.3932e-04 - val_acc: 0.9914\n",
      "Epoch 1674/3000\n",
      " - 2s - loss: 4.3801e-04 - acc: 0.9918 - val_loss: 4.4402e-04 - val_acc: 0.9916\n",
      "Epoch 1675/3000\n",
      " - 1s - loss: 4.5856e-04 - acc: 0.9915 - val_loss: 4.4291e-04 - val_acc: 0.9913\n",
      "Epoch 1676/3000\n",
      " - 2s - loss: 4.4148e-04 - acc: 0.9917 - val_loss: 4.3858e-04 - val_acc: 0.9916\n",
      "Epoch 1677/3000\n",
      " - 2s - loss: 4.3920e-04 - acc: 0.9918 - val_loss: 4.5472e-04 - val_acc: 0.9914\n",
      "Epoch 1678/3000\n",
      " - 2s - loss: 4.4430e-04 - acc: 0.9917 - val_loss: 4.6082e-04 - val_acc: 0.9913\n",
      "Epoch 1679/3000\n",
      " - 1s - loss: 4.5597e-04 - acc: 0.9915 - val_loss: 4.3624e-04 - val_acc: 0.9915\n",
      "Epoch 1680/3000\n",
      "\n",
      "Epoch 01680: val_loss did not improve from 0.00044\n",
      " - 2s - loss: 4.4731e-04 - acc: 0.9917 - val_loss: 4.9884e-04 - val_acc: 0.9906\n",
      "Epoch 1681/3000\n",
      " - 2s - loss: 4.4951e-04 - acc: 0.9916 - val_loss: 4.4956e-04 - val_acc: 0.9911\n",
      "Epoch 1682/3000\n",
      " - 2s - loss: 4.4582e-04 - acc: 0.9917 - val_loss: 4.5704e-04 - val_acc: 0.9914\n",
      "Epoch 1683/3000\n",
      " - 2s - loss: 4.3994e-04 - acc: 0.9918 - val_loss: 4.3006e-04 - val_acc: 0.9917\n",
      "Epoch 1684/3000\n",
      " - 1s - loss: 4.4006e-04 - acc: 0.9918 - val_loss: 4.5138e-04 - val_acc: 0.9917\n",
      "Epoch 1685/3000\n",
      " - 2s - loss: 4.4778e-04 - acc: 0.9917 - val_loss: 4.4737e-04 - val_acc: 0.9914\n",
      "Epoch 1686/3000\n",
      " - 1s - loss: 4.5810e-04 - acc: 0.9915 - val_loss: 4.6769e-04 - val_acc: 0.9913\n",
      "Epoch 1687/3000\n",
      " - 1s - loss: 4.4138e-04 - acc: 0.9918 - val_loss: 4.3545e-04 - val_acc: 0.9916\n",
      "Epoch 1688/3000\n",
      " - 2s - loss: 4.4414e-04 - acc: 0.9917 - val_loss: 4.3790e-04 - val_acc: 0.9915\n",
      "Epoch 1689/3000\n",
      " - 2s - loss: 4.4862e-04 - acc: 0.9917 - val_loss: 4.4401e-04 - val_acc: 0.9913\n",
      "Epoch 1690/3000\n",
      " - 1s - loss: 4.5695e-04 - acc: 0.9915 - val_loss: 4.5140e-04 - val_acc: 0.9912\n",
      "Epoch 1691/3000\n",
      " - 1s - loss: 4.5480e-04 - acc: 0.9916 - val_loss: 4.4518e-04 - val_acc: 0.9915\n",
      "Epoch 1692/3000\n",
      " - 2s - loss: 4.3885e-04 - acc: 0.9918 - val_loss: 4.3403e-04 - val_acc: 0.9918\n",
      "Epoch 1693/3000\n",
      " - 2s - loss: 4.4503e-04 - acc: 0.9917 - val_loss: 4.3849e-04 - val_acc: 0.9916\n",
      "Epoch 1694/3000\n",
      " - 1s - loss: 4.4058e-04 - acc: 0.9918 - val_loss: 4.5658e-04 - val_acc: 0.9914\n",
      "Epoch 1695/3000\n",
      " - 2s - loss: 4.3856e-04 - acc: 0.9918 - val_loss: 4.3870e-04 - val_acc: 0.9916\n",
      "Epoch 1696/3000\n",
      " - 2s - loss: 4.4189e-04 - acc: 0.9918 - val_loss: 4.4949e-04 - val_acc: 0.9916\n",
      "Epoch 1697/3000\n",
      " - 2s - loss: 4.4270e-04 - acc: 0.9918 - val_loss: 4.2484e-04 - val_acc: 0.9917\n",
      "Epoch 1698/3000\n",
      " - 2s - loss: 4.4125e-04 - acc: 0.9918 - val_loss: 4.7167e-04 - val_acc: 0.9915\n",
      "Epoch 1699/3000\n",
      " - 2s - loss: 4.5256e-04 - acc: 0.9915 - val_loss: 4.3208e-04 - val_acc: 0.9917\n",
      "Epoch 1700/3000\n",
      "\n",
      "Epoch 01700: val_loss improved from 0.00044 to 0.00043, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 4.4427e-04 - acc: 0.9916 - val_loss: 4.3493e-04 - val_acc: 0.9916\n",
      "Epoch 1701/3000\n",
      " - 2s - loss: 4.3637e-04 - acc: 0.9918 - val_loss: 4.2948e-04 - val_acc: 0.9917\n",
      "Epoch 1702/3000\n",
      " - 2s - loss: 4.5054e-04 - acc: 0.9916 - val_loss: 4.5426e-04 - val_acc: 0.9910\n",
      "Epoch 1703/3000\n",
      " - 2s - loss: 4.4213e-04 - acc: 0.9917 - val_loss: 4.3336e-04 - val_acc: 0.9916\n",
      "Epoch 1704/3000\n",
      " - 1s - loss: 4.4742e-04 - acc: 0.9917 - val_loss: 4.3117e-04 - val_acc: 0.9916\n",
      "Epoch 1705/3000\n",
      " - 2s - loss: 4.3890e-04 - acc: 0.9917 - val_loss: 4.5482e-04 - val_acc: 0.9914\n",
      "Epoch 1706/3000\n",
      " - 1s - loss: 4.5488e-04 - acc: 0.9915 - val_loss: 4.5379e-04 - val_acc: 0.9914\n",
      "Epoch 1707/3000\n",
      " - 2s - loss: 4.4395e-04 - acc: 0.9916 - val_loss: 4.2749e-04 - val_acc: 0.9916\n",
      "Epoch 1708/3000\n",
      " - 2s - loss: 4.4306e-04 - acc: 0.9918 - val_loss: 4.7265e-04 - val_acc: 0.9911\n",
      "Epoch 1709/3000\n",
      " - 2s - loss: 4.5330e-04 - acc: 0.9916 - val_loss: 4.4414e-04 - val_acc: 0.9917\n",
      "Epoch 1710/3000\n",
      " - 1s - loss: 4.3491e-04 - acc: 0.9919 - val_loss: 4.3435e-04 - val_acc: 0.9916\n",
      "Epoch 1711/3000\n",
      " - 1s - loss: 4.4089e-04 - acc: 0.9918 - val_loss: 5.8501e-04 - val_acc: 0.9905\n",
      "Epoch 1712/3000\n",
      " - 2s - loss: 4.5399e-04 - acc: 0.9915 - val_loss: 4.2587e-04 - val_acc: 0.9917\n",
      "Epoch 1713/3000\n",
      " - 2s - loss: 4.3730e-04 - acc: 0.9919 - val_loss: 4.3319e-04 - val_acc: 0.9917\n",
      "Epoch 1714/3000\n",
      " - 1s - loss: 4.4744e-04 - acc: 0.9916 - val_loss: 4.2792e-04 - val_acc: 0.9918\n",
      "Epoch 1715/3000\n",
      " - 2s - loss: 4.4133e-04 - acc: 0.9918 - val_loss: 4.3797e-04 - val_acc: 0.9917\n",
      "Epoch 1716/3000\n",
      " - 2s - loss: 4.4191e-04 - acc: 0.9918 - val_loss: 4.2374e-04 - val_acc: 0.9918\n",
      "Epoch 1717/3000\n",
      " - 2s - loss: 4.4038e-04 - acc: 0.9918 - val_loss: 4.5767e-04 - val_acc: 0.9915\n",
      "Epoch 1718/3000\n",
      " - 2s - loss: 4.4145e-04 - acc: 0.9917 - val_loss: 4.4330e-04 - val_acc: 0.9916\n",
      "Epoch 1719/3000\n",
      " - 2s - loss: 4.4842e-04 - acc: 0.9916 - val_loss: 4.4660e-04 - val_acc: 0.9916\n",
      "Epoch 1720/3000\n",
      "\n",
      "Epoch 01720: val_loss did not improve from 0.00043\n",
      " - 1s - loss: 4.4268e-04 - acc: 0.9917 - val_loss: 4.4214e-04 - val_acc: 0.9914\n",
      "Epoch 1721/3000\n",
      " - 1s - loss: 4.4825e-04 - acc: 0.9917 - val_loss: 4.3036e-04 - val_acc: 0.9916\n",
      "Epoch 1722/3000\n",
      " - 1s - loss: 4.4307e-04 - acc: 0.9917 - val_loss: 4.2201e-04 - val_acc: 0.9917\n",
      "Epoch 1723/3000\n",
      " - 2s - loss: 4.4244e-04 - acc: 0.9916 - val_loss: 4.3501e-04 - val_acc: 0.9916\n",
      "Epoch 1724/3000\n",
      " - 2s - loss: 4.3613e-04 - acc: 0.9918 - val_loss: 4.2203e-04 - val_acc: 0.9918\n",
      "Epoch 1725/3000\n",
      " - 2s - loss: 4.3650e-04 - acc: 0.9918 - val_loss: 4.4189e-04 - val_acc: 0.9916\n",
      "Epoch 1726/3000\n",
      " - 1s - loss: 4.3445e-04 - acc: 0.9918 - val_loss: 4.5739e-04 - val_acc: 0.9916\n",
      "Epoch 1727/3000\n",
      " - 2s - loss: 4.4672e-04 - acc: 0.9916 - val_loss: 4.6797e-04 - val_acc: 0.9914\n",
      "Epoch 1728/3000\n",
      " - 2s - loss: 4.4600e-04 - acc: 0.9916 - val_loss: 4.3674e-04 - val_acc: 0.9916\n",
      "Epoch 1729/3000\n",
      " - 2s - loss: 4.5289e-04 - acc: 0.9915 - val_loss: 4.2812e-04 - val_acc: 0.9918\n",
      "Epoch 1730/3000\n",
      " - 1s - loss: 4.3883e-04 - acc: 0.9917 - val_loss: 4.3734e-04 - val_acc: 0.9918\n",
      "Epoch 1731/3000\n",
      " - 2s - loss: 4.3428e-04 - acc: 0.9918 - val_loss: 4.2701e-04 - val_acc: 0.9917\n",
      "Epoch 1732/3000\n",
      " - 1s - loss: 4.3655e-04 - acc: 0.9918 - val_loss: 4.3774e-04 - val_acc: 0.9916\n",
      "Epoch 1733/3000\n",
      " - 2s - loss: 4.4759e-04 - acc: 0.9917 - val_loss: 4.3646e-04 - val_acc: 0.9916\n",
      "Epoch 1734/3000\n",
      " - 1s - loss: 4.4293e-04 - acc: 0.9918 - val_loss: 4.7248e-04 - val_acc: 0.9915\n",
      "Epoch 1735/3000\n",
      " - 2s - loss: 4.4423e-04 - acc: 0.9918 - val_loss: 4.3098e-04 - val_acc: 0.9918\n",
      "Epoch 1736/3000\n",
      " - 2s - loss: 4.3475e-04 - acc: 0.9918 - val_loss: 4.3172e-04 - val_acc: 0.9914\n",
      "Epoch 1737/3000\n",
      " - 1s - loss: 4.5947e-04 - acc: 0.9914 - val_loss: 4.8827e-04 - val_acc: 0.9917\n",
      "Epoch 1738/3000\n",
      " - 2s - loss: 4.4936e-04 - acc: 0.9916 - val_loss: 4.4845e-04 - val_acc: 0.9915\n",
      "Epoch 1739/3000\n",
      " - 2s - loss: 4.4144e-04 - acc: 0.9917 - val_loss: 4.3769e-04 - val_acc: 0.9915\n",
      "Epoch 1740/3000\n",
      "\n",
      "Epoch 01740: val_loss did not improve from 0.00043\n",
      " - 1s - loss: 4.4117e-04 - acc: 0.9917 - val_loss: 4.6488e-04 - val_acc: 0.9917\n",
      "Epoch 1741/3000\n",
      " - 2s - loss: 4.3655e-04 - acc: 0.9918 - val_loss: 4.5318e-04 - val_acc: 0.9918\n",
      "Epoch 1742/3000\n",
      " - 1s - loss: 4.3799e-04 - acc: 0.9918 - val_loss: 4.4034e-04 - val_acc: 0.9915\n",
      "Epoch 1743/3000\n",
      " - 2s - loss: 4.3576e-04 - acc: 0.9918 - val_loss: 4.3191e-04 - val_acc: 0.9918\n",
      "Epoch 1744/3000\n",
      " - 2s - loss: 4.3606e-04 - acc: 0.9919 - val_loss: 4.3017e-04 - val_acc: 0.9917\n",
      "Epoch 1745/3000\n",
      " - 2s - loss: 4.4177e-04 - acc: 0.9918 - val_loss: 4.2809e-04 - val_acc: 0.9915\n",
      "Epoch 1746/3000\n",
      " - 2s - loss: 4.4037e-04 - acc: 0.9917 - val_loss: 4.4332e-04 - val_acc: 0.9917\n",
      "Epoch 1747/3000\n",
      " - 2s - loss: 4.3683e-04 - acc: 0.9918 - val_loss: 4.2484e-04 - val_acc: 0.9919\n",
      "Epoch 1748/3000\n",
      " - 2s - loss: 4.3354e-04 - acc: 0.9919 - val_loss: 4.1991e-04 - val_acc: 0.9918\n",
      "Epoch 1749/3000\n",
      " - 2s - loss: 4.3049e-04 - acc: 0.9919 - val_loss: 4.2974e-04 - val_acc: 0.9918\n",
      "Epoch 1750/3000\n",
      " - 2s - loss: 4.3364e-04 - acc: 0.9918 - val_loss: 4.2551e-04 - val_acc: 0.9916\n",
      "Epoch 1751/3000\n",
      " - 2s - loss: 4.3483e-04 - acc: 0.9918 - val_loss: 4.3779e-04 - val_acc: 0.9915\n",
      "Epoch 1752/3000\n",
      " - 2s - loss: 4.3618e-04 - acc: 0.9918 - val_loss: 4.2874e-04 - val_acc: 0.9916\n",
      "Epoch 1753/3000\n",
      " - 2s - loss: 4.3944e-04 - acc: 0.9918 - val_loss: 4.5859e-04 - val_acc: 0.9914\n",
      "Epoch 1754/3000\n",
      " - 2s - loss: 4.4597e-04 - acc: 0.9917 - val_loss: 4.6002e-04 - val_acc: 0.9916\n",
      "Epoch 1755/3000\n",
      " - 2s - loss: 4.6030e-04 - acc: 0.9915 - val_loss: 4.5694e-04 - val_acc: 0.9912\n",
      "Epoch 1756/3000\n",
      " - 2s - loss: 4.3344e-04 - acc: 0.9918 - val_loss: 4.4628e-04 - val_acc: 0.9917\n",
      "Epoch 1757/3000\n",
      " - 1s - loss: 4.3878e-04 - acc: 0.9918 - val_loss: 4.3855e-04 - val_acc: 0.9915\n",
      "Epoch 1758/3000\n",
      " - 1s - loss: 4.3920e-04 - acc: 0.9918 - val_loss: 5.0947e-04 - val_acc: 0.9912\n",
      "Epoch 1759/3000\n",
      " - 2s - loss: 4.5042e-04 - acc: 0.9915 - val_loss: 4.2958e-04 - val_acc: 0.9915\n",
      "Epoch 1760/3000\n",
      "\n",
      "Epoch 01760: val_loss did not improve from 0.00043\n",
      " - 2s - loss: 4.3408e-04 - acc: 0.9918 - val_loss: 4.3559e-04 - val_acc: 0.9919\n",
      "Epoch 1761/3000\n",
      " - 2s - loss: 4.3614e-04 - acc: 0.9918 - val_loss: 4.3134e-04 - val_acc: 0.9918\n",
      "Epoch 1762/3000\n",
      " - 2s - loss: 4.4468e-04 - acc: 0.9916 - val_loss: 4.4907e-04 - val_acc: 0.9916\n",
      "Epoch 1763/3000\n",
      " - 2s - loss: 4.3649e-04 - acc: 0.9919 - val_loss: 4.2964e-04 - val_acc: 0.9916\n",
      "Epoch 1764/3000\n",
      " - 2s - loss: 4.4441e-04 - acc: 0.9917 - val_loss: 4.3145e-04 - val_acc: 0.9915\n",
      "Epoch 1765/3000\n",
      " - 2s - loss: 4.3957e-04 - acc: 0.9917 - val_loss: 4.4678e-04 - val_acc: 0.9917\n",
      "Epoch 1766/3000\n",
      " - 2s - loss: 4.5127e-04 - acc: 0.9916 - val_loss: 4.6092e-04 - val_acc: 0.9912\n",
      "Epoch 1767/3000\n",
      " - 2s - loss: 4.4377e-04 - acc: 0.9917 - val_loss: 4.2937e-04 - val_acc: 0.9917\n",
      "Epoch 1768/3000\n",
      " - 2s - loss: 4.4686e-04 - acc: 0.9917 - val_loss: 4.5861e-04 - val_acc: 0.9915\n",
      "Epoch 1769/3000\n",
      " - 2s - loss: 4.5107e-04 - acc: 0.9916 - val_loss: 4.3936e-04 - val_acc: 0.9916\n",
      "Epoch 1770/3000\n",
      " - 2s - loss: 4.4527e-04 - acc: 0.9916 - val_loss: 4.3118e-04 - val_acc: 0.9916\n",
      "Epoch 1771/3000\n",
      " - 1s - loss: 4.3748e-04 - acc: 0.9918 - val_loss: 4.6985e-04 - val_acc: 0.9915\n",
      "Epoch 1772/3000\n",
      " - 1s - loss: 4.4117e-04 - acc: 0.9917 - val_loss: 4.1891e-04 - val_acc: 0.9918\n",
      "Epoch 1773/3000\n",
      " - 2s - loss: 4.3143e-04 - acc: 0.9919 - val_loss: 4.4011e-04 - val_acc: 0.9919\n",
      "Epoch 1774/3000\n",
      " - 2s - loss: 4.4156e-04 - acc: 0.9917 - val_loss: 4.3222e-04 - val_acc: 0.9916\n",
      "Epoch 1775/3000\n",
      " - 2s - loss: 4.4283e-04 - acc: 0.9918 - val_loss: 4.4178e-04 - val_acc: 0.9917\n",
      "Epoch 1776/3000\n",
      " - 1s - loss: 4.3962e-04 - acc: 0.9918 - val_loss: 4.3150e-04 - val_acc: 0.9918\n",
      "Epoch 1777/3000\n",
      " - 2s - loss: 4.3284e-04 - acc: 0.9918 - val_loss: 4.4020e-04 - val_acc: 0.9917\n",
      "Epoch 1778/3000\n",
      " - 2s - loss: 4.4251e-04 - acc: 0.9917 - val_loss: 4.8653e-04 - val_acc: 0.9912\n",
      "Epoch 1779/3000\n",
      " - 2s - loss: 4.5349e-04 - acc: 0.9915 - val_loss: 4.3595e-04 - val_acc: 0.9918\n",
      "Epoch 1780/3000\n",
      "\n",
      "Epoch 01780: val_loss improved from 0.00043 to 0.00043, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 4.3090e-04 - acc: 0.9918 - val_loss: 4.2622e-04 - val_acc: 0.9918\n",
      "Epoch 1781/3000\n",
      " - 2s - loss: 4.4112e-04 - acc: 0.9917 - val_loss: 4.2139e-04 - val_acc: 0.9918\n",
      "Epoch 1782/3000\n",
      " - 2s - loss: 4.4306e-04 - acc: 0.9917 - val_loss: 4.3805e-04 - val_acc: 0.9919\n",
      "Epoch 1783/3000\n",
      " - 2s - loss: 4.3563e-04 - acc: 0.9918 - val_loss: 4.3904e-04 - val_acc: 0.9916\n",
      "Epoch 1784/3000\n",
      " - 2s - loss: 4.5146e-04 - acc: 0.9916 - val_loss: 4.5278e-04 - val_acc: 0.9913\n",
      "Epoch 1785/3000\n",
      " - 2s - loss: 4.3652e-04 - acc: 0.9919 - val_loss: 4.1806e-04 - val_acc: 0.9916\n",
      "Epoch 1786/3000\n",
      " - 2s - loss: 4.3786e-04 - acc: 0.9918 - val_loss: 4.3398e-04 - val_acc: 0.9915\n",
      "Epoch 1787/3000\n",
      " - 2s - loss: 4.3640e-04 - acc: 0.9918 - val_loss: 4.2965e-04 - val_acc: 0.9919\n",
      "Epoch 1788/3000\n",
      " - 2s - loss: 4.3768e-04 - acc: 0.9918 - val_loss: 4.5930e-04 - val_acc: 0.9913\n",
      "Epoch 1789/3000\n",
      " - 2s - loss: 4.3828e-04 - acc: 0.9918 - val_loss: 4.4903e-04 - val_acc: 0.9913\n",
      "Epoch 1790/3000\n",
      " - 1s - loss: 4.4003e-04 - acc: 0.9917 - val_loss: 4.2697e-04 - val_acc: 0.9918\n",
      "Epoch 1791/3000\n",
      " - 2s - loss: 4.3948e-04 - acc: 0.9917 - val_loss: 4.4243e-04 - val_acc: 0.9919\n",
      "Epoch 1792/3000\n",
      " - 2s - loss: 4.4425e-04 - acc: 0.9917 - val_loss: 4.4915e-04 - val_acc: 0.9916\n",
      "Epoch 1793/3000\n",
      " - 1s - loss: 4.4163e-04 - acc: 0.9917 - val_loss: 4.3163e-04 - val_acc: 0.9917\n",
      "Epoch 1794/3000\n",
      " - 2s - loss: 4.2698e-04 - acc: 0.9919 - val_loss: 4.2001e-04 - val_acc: 0.9919\n",
      "Epoch 1795/3000\n",
      " - 2s - loss: 4.4871e-04 - acc: 0.9917 - val_loss: 4.5554e-04 - val_acc: 0.9918\n",
      "Epoch 1796/3000\n",
      " - 2s - loss: 4.2922e-04 - acc: 0.9919 - val_loss: 4.4438e-04 - val_acc: 0.9918\n",
      "Epoch 1797/3000\n",
      " - 2s - loss: 4.3422e-04 - acc: 0.9918 - val_loss: 4.2598e-04 - val_acc: 0.9916\n",
      "Epoch 1798/3000\n",
      " - 2s - loss: 4.3395e-04 - acc: 0.9918 - val_loss: 4.3785e-04 - val_acc: 0.9916\n",
      "Epoch 1799/3000\n",
      " - 2s - loss: 4.5399e-04 - acc: 0.9916 - val_loss: 5.1327e-04 - val_acc: 0.9904\n",
      "Epoch 1800/3000\n",
      "\n",
      "Epoch 01800: val_loss did not improve from 0.00043\n",
      " - 2s - loss: 4.3872e-04 - acc: 0.9916 - val_loss: 4.3473e-04 - val_acc: 0.9916\n",
      "Epoch 1801/3000\n",
      " - 2s - loss: 4.3358e-04 - acc: 0.9918 - val_loss: 4.9368e-04 - val_acc: 0.9912\n",
      "Epoch 1802/3000\n",
      " - 2s - loss: 4.4670e-04 - acc: 0.9916 - val_loss: 4.4058e-04 - val_acc: 0.9915\n",
      "Epoch 1803/3000\n",
      " - 2s - loss: 4.4152e-04 - acc: 0.9917 - val_loss: 4.4587e-04 - val_acc: 0.9917\n",
      "Epoch 1804/3000\n",
      " - 2s - loss: 4.3541e-04 - acc: 0.9918 - val_loss: 4.2652e-04 - val_acc: 0.9920\n",
      "Epoch 1805/3000\n",
      " - 1s - loss: 4.3911e-04 - acc: 0.9918 - val_loss: 4.3951e-04 - val_acc: 0.9918\n",
      "Epoch 1806/3000\n",
      " - 2s - loss: 4.3832e-04 - acc: 0.9917 - val_loss: 4.2578e-04 - val_acc: 0.9917\n",
      "Epoch 1807/3000\n",
      " - 2s - loss: 4.3157e-04 - acc: 0.9918 - val_loss: 4.5118e-04 - val_acc: 0.9916\n",
      "Epoch 1808/3000\n",
      " - 1s - loss: 4.3876e-04 - acc: 0.9917 - val_loss: 4.2608e-04 - val_acc: 0.9918\n",
      "Epoch 1809/3000\n",
      " - 2s - loss: 4.2440e-04 - acc: 0.9920 - val_loss: 4.2947e-04 - val_acc: 0.9916\n",
      "Epoch 1810/3000\n",
      " - 2s - loss: 4.2483e-04 - acc: 0.9919 - val_loss: 4.1878e-04 - val_acc: 0.9919\n",
      "Epoch 1811/3000\n",
      " - 2s - loss: 4.3482e-04 - acc: 0.9919 - val_loss: 4.2617e-04 - val_acc: 0.9919\n",
      "Epoch 1812/3000\n",
      " - 1s - loss: 4.2492e-04 - acc: 0.9920 - val_loss: 4.1136e-04 - val_acc: 0.9919\n",
      "Epoch 1813/3000\n",
      " - 1s - loss: 4.3184e-04 - acc: 0.9919 - val_loss: 4.4497e-04 - val_acc: 0.9917\n",
      "Epoch 1814/3000\n",
      " - 2s - loss: 4.4100e-04 - acc: 0.9918 - val_loss: 4.2962e-04 - val_acc: 0.9916\n",
      "Epoch 1815/3000\n",
      " - 2s - loss: 4.2960e-04 - acc: 0.9919 - val_loss: 4.1989e-04 - val_acc: 0.9918\n",
      "Epoch 1816/3000\n",
      " - 2s - loss: 4.3878e-04 - acc: 0.9918 - val_loss: 4.3463e-04 - val_acc: 0.9918\n",
      "Epoch 1817/3000\n",
      " - 1s - loss: 4.3235e-04 - acc: 0.9918 - val_loss: 4.1904e-04 - val_acc: 0.9918\n",
      "Epoch 1818/3000\n",
      " - 2s - loss: 4.3035e-04 - acc: 0.9919 - val_loss: 4.3679e-04 - val_acc: 0.9918\n",
      "Epoch 1819/3000\n",
      " - 2s - loss: 4.2739e-04 - acc: 0.9919 - val_loss: 4.2324e-04 - val_acc: 0.9919\n",
      "Epoch 1820/3000\n",
      "\n",
      "Epoch 01820: val_loss did not improve from 0.00043\n",
      " - 2s - loss: 4.3665e-04 - acc: 0.9918 - val_loss: 4.2782e-04 - val_acc: 0.9917\n",
      "Epoch 1821/3000\n",
      " - 2s - loss: 4.3371e-04 - acc: 0.9918 - val_loss: 4.1837e-04 - val_acc: 0.9918\n",
      "Epoch 1822/3000\n",
      " - 2s - loss: 4.2558e-04 - acc: 0.9920 - val_loss: 4.4842e-04 - val_acc: 0.9916\n",
      "Epoch 1823/3000\n",
      " - 2s - loss: 4.2566e-04 - acc: 0.9920 - val_loss: 4.2131e-04 - val_acc: 0.9919\n",
      "Epoch 1824/3000\n",
      " - 2s - loss: 4.2312e-04 - acc: 0.9919 - val_loss: 4.1228e-04 - val_acc: 0.9919\n",
      "Epoch 1825/3000\n",
      " - 2s - loss: 4.2082e-04 - acc: 0.9920 - val_loss: 4.3936e-04 - val_acc: 0.9919\n",
      "Epoch 1826/3000\n",
      " - 2s - loss: 4.3591e-04 - acc: 0.9917 - val_loss: 4.2505e-04 - val_acc: 0.9914\n",
      "Epoch 1827/3000\n",
      " - 1s - loss: 4.2974e-04 - acc: 0.9919 - val_loss: 4.1752e-04 - val_acc: 0.9915\n",
      "Epoch 1828/3000\n",
      " - 2s - loss: 4.2427e-04 - acc: 0.9919 - val_loss: 4.3492e-04 - val_acc: 0.9916\n",
      "Epoch 1829/3000\n",
      " - 2s - loss: 4.3353e-04 - acc: 0.9919 - val_loss: 4.5257e-04 - val_acc: 0.9919\n",
      "Epoch 1830/3000\n",
      " - 2s - loss: 4.4801e-04 - acc: 0.9916 - val_loss: 4.4223e-04 - val_acc: 0.9914\n",
      "Epoch 1831/3000\n",
      " - 2s - loss: 4.2920e-04 - acc: 0.9919 - val_loss: 4.3758e-04 - val_acc: 0.9919\n",
      "Epoch 1832/3000\n",
      " - 2s - loss: 4.3083e-04 - acc: 0.9919 - val_loss: 4.2750e-04 - val_acc: 0.9918\n",
      "Epoch 1833/3000\n",
      " - 2s - loss: 4.2673e-04 - acc: 0.9919 - val_loss: 4.3388e-04 - val_acc: 0.9914\n",
      "Epoch 1834/3000\n",
      " - 2s - loss: 4.2673e-04 - acc: 0.9919 - val_loss: 4.1942e-04 - val_acc: 0.9918\n",
      "Epoch 1835/3000\n",
      " - 2s - loss: 4.3054e-04 - acc: 0.9918 - val_loss: 4.2390e-04 - val_acc: 0.9917\n",
      "Epoch 1836/3000\n",
      " - 2s - loss: 4.4032e-04 - acc: 0.9917 - val_loss: 4.3050e-04 - val_acc: 0.9918\n",
      "Epoch 1837/3000\n",
      " - 1s - loss: 4.3240e-04 - acc: 0.9918 - val_loss: 4.4651e-04 - val_acc: 0.9917\n",
      "Epoch 1838/3000\n",
      " - 1s - loss: 4.3140e-04 - acc: 0.9919 - val_loss: 4.5368e-04 - val_acc: 0.9912\n",
      "Epoch 1839/3000\n",
      " - 2s - loss: 4.2861e-04 - acc: 0.9919 - val_loss: 4.2241e-04 - val_acc: 0.9919\n",
      "Epoch 1840/3000\n",
      "\n",
      "Epoch 01840: val_loss did not improve from 0.00043\n",
      " - 1s - loss: 4.3666e-04 - acc: 0.9918 - val_loss: 4.3436e-04 - val_acc: 0.9917\n",
      "Epoch 1841/3000\n",
      " - 2s - loss: 4.2737e-04 - acc: 0.9920 - val_loss: 4.5353e-04 - val_acc: 0.9913\n",
      "Epoch 1842/3000\n",
      " - 1s - loss: 4.3412e-04 - acc: 0.9918 - val_loss: 4.1754e-04 - val_acc: 0.9920\n",
      "Epoch 1843/3000\n",
      " - 1s - loss: 4.2632e-04 - acc: 0.9919 - val_loss: 4.1674e-04 - val_acc: 0.9917\n",
      "Epoch 1844/3000\n",
      " - 1s - loss: 4.2694e-04 - acc: 0.9919 - val_loss: 4.4991e-04 - val_acc: 0.9918\n",
      "Epoch 1845/3000\n",
      " - 1s - loss: 4.3715e-04 - acc: 0.9917 - val_loss: 4.1501e-04 - val_acc: 0.9920\n",
      "Epoch 1846/3000\n",
      " - 1s - loss: 4.2781e-04 - acc: 0.9919 - val_loss: 4.2358e-04 - val_acc: 0.9916\n",
      "Epoch 1847/3000\n",
      " - 2s - loss: 4.3614e-04 - acc: 0.9917 - val_loss: 4.3086e-04 - val_acc: 0.9917\n",
      "Epoch 1848/3000\n",
      " - 2s - loss: 4.2902e-04 - acc: 0.9919 - val_loss: 4.2913e-04 - val_acc: 0.9917\n",
      "Epoch 1849/3000\n",
      " - 2s - loss: 4.3077e-04 - acc: 0.9919 - val_loss: 4.4152e-04 - val_acc: 0.9916\n",
      "Epoch 1850/3000\n",
      " - 2s - loss: 4.3528e-04 - acc: 0.9918 - val_loss: 4.9088e-04 - val_acc: 0.9916\n",
      "Epoch 1851/3000\n",
      " - 2s - loss: 4.3361e-04 - acc: 0.9919 - val_loss: 4.1125e-04 - val_acc: 0.9920\n",
      "Epoch 1852/3000\n",
      " - 2s - loss: 4.3003e-04 - acc: 0.9919 - val_loss: 4.4397e-04 - val_acc: 0.9918\n",
      "Epoch 1853/3000\n",
      " - 2s - loss: 4.2930e-04 - acc: 0.9919 - val_loss: 4.1589e-04 - val_acc: 0.9919\n",
      "Epoch 1854/3000\n",
      " - 1s - loss: 4.2542e-04 - acc: 0.9919 - val_loss: 4.2422e-04 - val_acc: 0.9919\n",
      "Epoch 1855/3000\n",
      " - 1s - loss: 4.1859e-04 - acc: 0.9920 - val_loss: 4.2046e-04 - val_acc: 0.9918\n",
      "Epoch 1856/3000\n",
      " - 2s - loss: 4.5656e-04 - acc: 0.9914 - val_loss: 4.2069e-04 - val_acc: 0.9917\n",
      "Epoch 1857/3000\n",
      " - 2s - loss: 4.2960e-04 - acc: 0.9919 - val_loss: 4.1734e-04 - val_acc: 0.9918\n",
      "Epoch 1858/3000\n",
      " - 1s - loss: 4.3808e-04 - acc: 0.9918 - val_loss: 4.3755e-04 - val_acc: 0.9915\n",
      "Epoch 1859/3000\n",
      " - 2s - loss: 4.3291e-04 - acc: 0.9918 - val_loss: 4.2230e-04 - val_acc: 0.9918\n",
      "Epoch 1860/3000\n",
      "\n",
      "Epoch 01860: val_loss did not improve from 0.00043\n",
      " - 2s - loss: 4.3288e-04 - acc: 0.9919 - val_loss: 4.3311e-04 - val_acc: 0.9917\n",
      "Epoch 1861/3000\n",
      " - 2s - loss: 4.3066e-04 - acc: 0.9919 - val_loss: 4.1469e-04 - val_acc: 0.9918\n",
      "Epoch 1862/3000\n",
      " - 2s - loss: 4.4056e-04 - acc: 0.9917 - val_loss: 4.3280e-04 - val_acc: 0.9917\n",
      "Epoch 1863/3000\n",
      " - 2s - loss: 4.2682e-04 - acc: 0.9919 - val_loss: 4.2472e-04 - val_acc: 0.9917\n",
      "Epoch 1864/3000\n",
      " - 1s - loss: 4.2711e-04 - acc: 0.9919 - val_loss: 4.3752e-04 - val_acc: 0.9916\n",
      "Epoch 1865/3000\n",
      " - 2s - loss: 4.2540e-04 - acc: 0.9919 - val_loss: 4.2176e-04 - val_acc: 0.9918\n",
      "Epoch 1866/3000\n",
      " - 2s - loss: 4.3770e-04 - acc: 0.9917 - val_loss: 4.3593e-04 - val_acc: 0.9911\n",
      "Epoch 1867/3000\n",
      " - 2s - loss: 4.3023e-04 - acc: 0.9918 - val_loss: 4.1673e-04 - val_acc: 0.9921\n",
      "Epoch 1868/3000\n",
      " - 1s - loss: 4.2298e-04 - acc: 0.9919 - val_loss: 4.3285e-04 - val_acc: 0.9916\n",
      "Epoch 1869/3000\n",
      " - 1s - loss: 4.2283e-04 - acc: 0.9920 - val_loss: 4.1832e-04 - val_acc: 0.9919\n",
      "Epoch 1870/3000\n",
      " - 1s - loss: 4.2706e-04 - acc: 0.9919 - val_loss: 4.2533e-04 - val_acc: 0.9917\n",
      "Epoch 1871/3000\n",
      " - 2s - loss: 4.3092e-04 - acc: 0.9918 - val_loss: 4.3487e-04 - val_acc: 0.9918\n",
      "Epoch 1872/3000\n",
      " - 2s - loss: 4.2406e-04 - acc: 0.9919 - val_loss: 4.2856e-04 - val_acc: 0.9919\n",
      "Epoch 1873/3000\n",
      " - 1s - loss: 4.2758e-04 - acc: 0.9918 - val_loss: 4.3142e-04 - val_acc: 0.9918\n",
      "Epoch 1874/3000\n",
      " - 2s - loss: 4.2011e-04 - acc: 0.9920 - val_loss: 4.3702e-04 - val_acc: 0.9917\n",
      "Epoch 1875/3000\n",
      " - 2s - loss: 4.2713e-04 - acc: 0.9919 - val_loss: 4.3310e-04 - val_acc: 0.9917\n",
      "Epoch 1876/3000\n",
      " - 2s - loss: 4.3214e-04 - acc: 0.9919 - val_loss: 4.2434e-04 - val_acc: 0.9914\n",
      "Epoch 1877/3000\n",
      " - 2s - loss: 4.3665e-04 - acc: 0.9916 - val_loss: 4.2184e-04 - val_acc: 0.9920\n",
      "Epoch 1878/3000\n",
      " - 1s - loss: 4.2742e-04 - acc: 0.9919 - val_loss: 4.2655e-04 - val_acc: 0.9920\n",
      "Epoch 1879/3000\n",
      " - 2s - loss: 4.1864e-04 - acc: 0.9920 - val_loss: 4.1639e-04 - val_acc: 0.9919\n",
      "Epoch 1880/3000\n",
      "\n",
      "Epoch 01880: val_loss improved from 0.00043 to 0.00043, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 4.1855e-04 - acc: 0.9920 - val_loss: 4.2527e-04 - val_acc: 0.9920\n",
      "Epoch 1881/3000\n",
      " - 1s - loss: 4.2933e-04 - acc: 0.9919 - val_loss: 4.4934e-04 - val_acc: 0.9915\n",
      "Epoch 1882/3000\n",
      " - 1s - loss: 4.3050e-04 - acc: 0.9918 - val_loss: 4.2830e-04 - val_acc: 0.9920\n",
      "Epoch 1883/3000\n",
      " - 1s - loss: 4.2256e-04 - acc: 0.9920 - val_loss: 4.1217e-04 - val_acc: 0.9919\n",
      "Epoch 1884/3000\n",
      " - 2s - loss: 4.2719e-04 - acc: 0.9919 - val_loss: 4.3290e-04 - val_acc: 0.9919\n",
      "Epoch 1885/3000\n",
      " - 2s - loss: 4.2533e-04 - acc: 0.9919 - val_loss: 4.2533e-04 - val_acc: 0.9919\n",
      "Epoch 1886/3000\n",
      " - 2s - loss: 4.2549e-04 - acc: 0.9919 - val_loss: 4.2878e-04 - val_acc: 0.9915\n",
      "Epoch 1887/3000\n",
      " - 1s - loss: 4.3765e-04 - acc: 0.9917 - val_loss: 4.2906e-04 - val_acc: 0.9915\n",
      "Epoch 1888/3000\n",
      " - 1s - loss: 4.2250e-04 - acc: 0.9919 - val_loss: 4.4281e-04 - val_acc: 0.9917\n",
      "Epoch 1889/3000\n",
      " - 2s - loss: 4.3279e-04 - acc: 0.9918 - val_loss: 4.1670e-04 - val_acc: 0.9918\n",
      "Epoch 1890/3000\n",
      " - 2s - loss: 4.2825e-04 - acc: 0.9919 - val_loss: 4.3357e-04 - val_acc: 0.9921\n",
      "Epoch 1891/3000\n",
      " - 2s - loss: 4.2502e-04 - acc: 0.9920 - val_loss: 4.1454e-04 - val_acc: 0.9918\n",
      "Epoch 1892/3000\n",
      " - 2s - loss: 4.2065e-04 - acc: 0.9920 - val_loss: 4.2392e-04 - val_acc: 0.9918\n",
      "Epoch 1893/3000\n",
      " - 2s - loss: 4.3535e-04 - acc: 0.9918 - val_loss: 4.2029e-04 - val_acc: 0.9920\n",
      "Epoch 1894/3000\n",
      " - 2s - loss: 4.1893e-04 - acc: 0.9921 - val_loss: 4.1784e-04 - val_acc: 0.9919\n",
      "Epoch 1895/3000\n",
      " - 2s - loss: 4.2910e-04 - acc: 0.9919 - val_loss: 4.0961e-04 - val_acc: 0.9920\n",
      "Epoch 1896/3000\n",
      " - 2s - loss: 4.2575e-04 - acc: 0.9919 - val_loss: 4.4719e-04 - val_acc: 0.9915\n",
      "Epoch 1897/3000\n",
      " - 2s - loss: 4.2448e-04 - acc: 0.9920 - val_loss: 4.3294e-04 - val_acc: 0.9920\n",
      "Epoch 1898/3000\n",
      " - 2s - loss: 4.2768e-04 - acc: 0.9919 - val_loss: 4.1344e-04 - val_acc: 0.9919\n",
      "Epoch 1899/3000\n",
      " - 2s - loss: 4.1840e-04 - acc: 0.9921 - val_loss: 4.0962e-04 - val_acc: 0.9921\n",
      "Epoch 1900/3000\n",
      "\n",
      "Epoch 01900: val_loss improved from 0.00043 to 0.00042, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 4.2587e-04 - acc: 0.9919 - val_loss: 4.1604e-04 - val_acc: 0.9918\n",
      "Epoch 1901/3000\n",
      " - 2s - loss: 4.1919e-04 - acc: 0.9920 - val_loss: 4.1439e-04 - val_acc: 0.9920\n",
      "Epoch 1902/3000\n",
      " - 2s - loss: 4.2312e-04 - acc: 0.9919 - val_loss: 4.2216e-04 - val_acc: 0.9919\n",
      "Epoch 1903/3000\n",
      " - 2s - loss: 4.3817e-04 - acc: 0.9917 - val_loss: 4.0960e-04 - val_acc: 0.9917\n",
      "Epoch 1904/3000\n",
      " - 2s - loss: 4.2645e-04 - acc: 0.9919 - val_loss: 4.2226e-04 - val_acc: 0.9919\n",
      "Epoch 1905/3000\n",
      " - 2s - loss: 4.3400e-04 - acc: 0.9919 - val_loss: 4.3698e-04 - val_acc: 0.9916\n",
      "Epoch 1906/3000\n",
      " - 1s - loss: 4.4037e-04 - acc: 0.9917 - val_loss: 4.1086e-04 - val_acc: 0.9920\n",
      "Epoch 1907/3000\n",
      " - 2s - loss: 4.1785e-04 - acc: 0.9920 - val_loss: 4.0427e-04 - val_acc: 0.9919\n",
      "Epoch 1908/3000\n",
      " - 2s - loss: 4.2451e-04 - acc: 0.9918 - val_loss: 4.2027e-04 - val_acc: 0.9917\n",
      "Epoch 1909/3000\n",
      " - 2s - loss: 4.1980e-04 - acc: 0.9920 - val_loss: 4.4984e-04 - val_acc: 0.9919\n",
      "Epoch 1910/3000\n",
      " - 2s - loss: 4.3329e-04 - acc: 0.9918 - val_loss: 4.1328e-04 - val_acc: 0.9919\n",
      "Epoch 1911/3000\n",
      " - 1s - loss: 4.3239e-04 - acc: 0.9918 - val_loss: 4.2990e-04 - val_acc: 0.9918\n",
      "Epoch 1912/3000\n",
      " - 2s - loss: 4.2544e-04 - acc: 0.9919 - val_loss: 4.6737e-04 - val_acc: 0.9913\n",
      "Epoch 1913/3000\n",
      " - 2s - loss: 4.2941e-04 - acc: 0.9919 - val_loss: 4.2917e-04 - val_acc: 0.9919\n",
      "Epoch 1914/3000\n",
      " - 2s - loss: 4.4215e-04 - acc: 0.9917 - val_loss: 4.1495e-04 - val_acc: 0.9917\n",
      "Epoch 1915/3000\n",
      " - 2s - loss: 4.2483e-04 - acc: 0.9919 - val_loss: 4.2477e-04 - val_acc: 0.9917\n",
      "Epoch 1916/3000\n",
      " - 2s - loss: 4.2022e-04 - acc: 0.9920 - val_loss: 4.2778e-04 - val_acc: 0.9919\n",
      "Epoch 1917/3000\n",
      " - 2s - loss: 4.3067e-04 - acc: 0.9918 - val_loss: 4.2157e-04 - val_acc: 0.9919\n",
      "Epoch 1918/3000\n",
      " - 1s - loss: 4.2573e-04 - acc: 0.9919 - val_loss: 4.2910e-04 - val_acc: 0.9916\n",
      "Epoch 1919/3000\n",
      " - 1s - loss: 4.2758e-04 - acc: 0.9918 - val_loss: 4.1335e-04 - val_acc: 0.9919\n",
      "Epoch 1920/3000\n",
      "\n",
      "Epoch 01920: val_loss did not improve from 0.00042\n",
      " - 2s - loss: 4.2245e-04 - acc: 0.9920 - val_loss: 4.2562e-04 - val_acc: 0.9918\n",
      "Epoch 1921/3000\n",
      " - 2s - loss: 4.2050e-04 - acc: 0.9920 - val_loss: 4.3851e-04 - val_acc: 0.9917\n",
      "Epoch 1922/3000\n",
      " - 2s - loss: 4.2802e-04 - acc: 0.9920 - val_loss: 4.2052e-04 - val_acc: 0.9917\n",
      "Epoch 1923/3000\n",
      " - 2s - loss: 4.1856e-04 - acc: 0.9920 - val_loss: 4.1499e-04 - val_acc: 0.9919\n",
      "Epoch 1924/3000\n",
      " - 1s - loss: 4.1883e-04 - acc: 0.9920 - val_loss: 4.1623e-04 - val_acc: 0.9917\n",
      "Epoch 1925/3000\n",
      " - 2s - loss: 4.1959e-04 - acc: 0.9920 - val_loss: 4.1855e-04 - val_acc: 0.9920\n",
      "Epoch 1926/3000\n",
      " - 2s - loss: 4.2599e-04 - acc: 0.9919 - val_loss: 4.1517e-04 - val_acc: 0.9918\n",
      "Epoch 1927/3000\n",
      " - 2s - loss: 4.3013e-04 - acc: 0.9918 - val_loss: 4.4841e-04 - val_acc: 0.9912\n",
      "Epoch 1928/3000\n",
      " - 2s - loss: 4.1965e-04 - acc: 0.9919 - val_loss: 4.1559e-04 - val_acc: 0.9920\n",
      "Epoch 1929/3000\n",
      " - 1s - loss: 4.2016e-04 - acc: 0.9920 - val_loss: 4.1518e-04 - val_acc: 0.9920\n",
      "Epoch 1930/3000\n",
      " - 2s - loss: 4.2059e-04 - acc: 0.9920 - val_loss: 4.1881e-04 - val_acc: 0.9920\n",
      "Epoch 1931/3000\n",
      " - 2s - loss: 4.2308e-04 - acc: 0.9920 - val_loss: 4.4838e-04 - val_acc: 0.9917\n",
      "Epoch 1932/3000\n",
      " - 2s - loss: 4.2970e-04 - acc: 0.9917 - val_loss: 4.2061e-04 - val_acc: 0.9917\n",
      "Epoch 1933/3000\n",
      " - 2s - loss: 4.2839e-04 - acc: 0.9919 - val_loss: 4.3587e-04 - val_acc: 0.9918\n",
      "Epoch 1934/3000\n",
      " - 2s - loss: 4.1901e-04 - acc: 0.9920 - val_loss: 4.1910e-04 - val_acc: 0.9919\n",
      "Epoch 1935/3000\n",
      " - 2s - loss: 4.2955e-04 - acc: 0.9918 - val_loss: 4.2325e-04 - val_acc: 0.9916\n",
      "Epoch 1936/3000\n",
      " - 1s - loss: 4.3055e-04 - acc: 0.9919 - val_loss: 4.2592e-04 - val_acc: 0.9919\n",
      "Epoch 1937/3000\n",
      " - 2s - loss: 4.2182e-04 - acc: 0.9920 - val_loss: 4.2681e-04 - val_acc: 0.9918\n",
      "Epoch 1938/3000\n",
      " - 2s - loss: 4.1571e-04 - acc: 0.9921 - val_loss: 4.1144e-04 - val_acc: 0.9918\n",
      "Epoch 1939/3000\n",
      " - 2s - loss: 4.1615e-04 - acc: 0.9921 - val_loss: 4.2237e-04 - val_acc: 0.9919\n",
      "Epoch 1940/3000\n",
      "\n",
      "Epoch 01940: val_loss did not improve from 0.00042\n",
      " - 1s - loss: 4.2517e-04 - acc: 0.9920 - val_loss: 4.3575e-04 - val_acc: 0.9918\n",
      "Epoch 1941/3000\n",
      " - 1s - loss: 4.2248e-04 - acc: 0.9919 - val_loss: 4.0977e-04 - val_acc: 0.9920\n",
      "Epoch 1942/3000\n",
      " - 2s - loss: 4.2672e-04 - acc: 0.9919 - val_loss: 4.3028e-04 - val_acc: 0.9918\n",
      "Epoch 1943/3000\n",
      " - 2s - loss: 4.3120e-04 - acc: 0.9919 - val_loss: 4.0780e-04 - val_acc: 0.9920\n",
      "Epoch 1944/3000\n",
      " - 2s - loss: 4.2113e-04 - acc: 0.9919 - val_loss: 4.4586e-04 - val_acc: 0.9918\n",
      "Epoch 1945/3000\n",
      " - 2s - loss: 4.2269e-04 - acc: 0.9920 - val_loss: 4.2361e-04 - val_acc: 0.9919\n",
      "Epoch 1946/3000\n",
      " - 2s - loss: 4.2530e-04 - acc: 0.9919 - val_loss: 4.1869e-04 - val_acc: 0.9920\n",
      "Epoch 1947/3000\n",
      " - 2s - loss: 4.2625e-04 - acc: 0.9919 - val_loss: 4.1959e-04 - val_acc: 0.9919\n",
      "Epoch 1948/3000\n",
      " - 2s - loss: 4.1470e-04 - acc: 0.9920 - val_loss: 4.1686e-04 - val_acc: 0.9917\n",
      "Epoch 1949/3000\n",
      " - 2s - loss: 4.2919e-04 - acc: 0.9919 - val_loss: 4.4965e-04 - val_acc: 0.9914\n",
      "Epoch 1950/3000\n",
      " - 2s - loss: 4.2507e-04 - acc: 0.9918 - val_loss: 4.2908e-04 - val_acc: 0.9915\n",
      "Epoch 1951/3000\n",
      " - 2s - loss: 4.1531e-04 - acc: 0.9920 - val_loss: 4.0866e-04 - val_acc: 0.9919\n",
      "Epoch 1952/3000\n",
      " - 2s - loss: 4.3306e-04 - acc: 0.9918 - val_loss: 4.4481e-04 - val_acc: 0.9919\n",
      "Epoch 1953/3000\n",
      " - 2s - loss: 4.5395e-04 - acc: 0.9914 - val_loss: 4.2198e-04 - val_acc: 0.9919\n",
      "Epoch 1954/3000\n",
      " - 2s - loss: 4.1753e-04 - acc: 0.9920 - val_loss: 4.2043e-04 - val_acc: 0.9919\n",
      "Epoch 1955/3000\n",
      " - 2s - loss: 4.1531e-04 - acc: 0.9921 - val_loss: 4.1378e-04 - val_acc: 0.9921\n",
      "Epoch 1956/3000\n",
      " - 2s - loss: 4.1532e-04 - acc: 0.9921 - val_loss: 4.2184e-04 - val_acc: 0.9918\n",
      "Epoch 1957/3000\n",
      " - 2s - loss: 4.2153e-04 - acc: 0.9920 - val_loss: 4.6404e-04 - val_acc: 0.9920\n",
      "Epoch 1958/3000\n",
      " - 1s - loss: 4.3878e-04 - acc: 0.9917 - val_loss: 4.2484e-04 - val_acc: 0.9919\n",
      "Epoch 1959/3000\n",
      " - 1s - loss: 4.3302e-04 - acc: 0.9919 - val_loss: 4.4150e-04 - val_acc: 0.9919\n",
      "Epoch 1960/3000\n",
      "\n",
      "Epoch 01960: val_loss did not improve from 0.00042\n",
      " - 2s - loss: 4.3536e-04 - acc: 0.9918 - val_loss: 4.5019e-04 - val_acc: 0.9916\n",
      "Epoch 1961/3000\n",
      " - 2s - loss: 4.3538e-04 - acc: 0.9918 - val_loss: 4.1495e-04 - val_acc: 0.9920\n",
      "Epoch 1962/3000\n",
      " - 2s - loss: 4.1657e-04 - acc: 0.9921 - val_loss: 4.1089e-04 - val_acc: 0.9919\n",
      "Epoch 1963/3000\n",
      " - 2s - loss: 4.1352e-04 - acc: 0.9921 - val_loss: 4.1477e-04 - val_acc: 0.9920\n",
      "Epoch 1964/3000\n",
      " - 1s - loss: 4.1178e-04 - acc: 0.9921 - val_loss: 4.0787e-04 - val_acc: 0.9920\n",
      "Epoch 1965/3000\n",
      " - 1s - loss: 4.1681e-04 - acc: 0.9921 - val_loss: 4.5342e-04 - val_acc: 0.9920\n",
      "Epoch 1966/3000\n",
      " - 2s - loss: 4.2926e-04 - acc: 0.9917 - val_loss: 4.0971e-04 - val_acc: 0.9920\n",
      "Epoch 1967/3000\n",
      " - 2s - loss: 4.1916e-04 - acc: 0.9920 - val_loss: 4.2044e-04 - val_acc: 0.9919\n",
      "Epoch 1968/3000\n",
      " - 2s - loss: 4.1504e-04 - acc: 0.9920 - val_loss: 4.1243e-04 - val_acc: 0.9918\n",
      "Epoch 1969/3000\n",
      " - 2s - loss: 4.1695e-04 - acc: 0.9920 - val_loss: 4.0912e-04 - val_acc: 0.9922\n",
      "Epoch 1970/3000\n",
      " - 2s - loss: 4.1808e-04 - acc: 0.9920 - val_loss: 4.0944e-04 - val_acc: 0.9920\n",
      "Epoch 1971/3000\n",
      " - 1s - loss: 4.2972e-04 - acc: 0.9918 - val_loss: 4.5018e-04 - val_acc: 0.9916\n",
      "Epoch 1972/3000\n",
      " - 1s - loss: 4.4960e-04 - acc: 0.9915 - val_loss: 4.1482e-04 - val_acc: 0.9919\n",
      "Epoch 1973/3000\n",
      " - 2s - loss: 4.2000e-04 - acc: 0.9919 - val_loss: 4.0806e-04 - val_acc: 0.9918\n",
      "Epoch 1974/3000\n",
      " - 2s - loss: 4.1586e-04 - acc: 0.9920 - val_loss: 4.0618e-04 - val_acc: 0.9918\n",
      "Epoch 1975/3000\n",
      " - 2s - loss: 4.1927e-04 - acc: 0.9921 - val_loss: 4.2541e-04 - val_acc: 0.9921\n",
      "Epoch 1976/3000\n",
      " - 2s - loss: 4.2269e-04 - acc: 0.9919 - val_loss: 4.2126e-04 - val_acc: 0.9919\n",
      "Epoch 1977/3000\n",
      " - 2s - loss: 4.1812e-04 - acc: 0.9920 - val_loss: 4.2787e-04 - val_acc: 0.9918\n",
      "Epoch 1978/3000\n",
      " - 1s - loss: 4.2562e-04 - acc: 0.9919 - val_loss: 4.1985e-04 - val_acc: 0.9917\n",
      "Epoch 1979/3000\n",
      " - 2s - loss: 4.2021e-04 - acc: 0.9920 - val_loss: 4.0829e-04 - val_acc: 0.9920\n",
      "Epoch 1980/3000\n",
      "\n",
      "Epoch 01980: val_loss improved from 0.00042 to 0.00041, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 4.1000e-04 - acc: 0.9921 - val_loss: 4.0633e-04 - val_acc: 0.9918\n",
      "Epoch 1981/3000\n",
      " - 2s - loss: 4.1391e-04 - acc: 0.9921 - val_loss: 4.5405e-04 - val_acc: 0.9915\n",
      "Epoch 1982/3000\n",
      " - 1s - loss: 4.2154e-04 - acc: 0.9919 - val_loss: 4.1993e-04 - val_acc: 0.9920\n",
      "Epoch 1983/3000\n",
      " - 2s - loss: 4.1799e-04 - acc: 0.9919 - val_loss: 4.1878e-04 - val_acc: 0.9918\n",
      "Epoch 1984/3000\n",
      " - 2s - loss: 4.2484e-04 - acc: 0.9920 - val_loss: 4.3215e-04 - val_acc: 0.9913\n",
      "Epoch 1985/3000\n",
      " - 1s - loss: 4.2723e-04 - acc: 0.9918 - val_loss: 4.6307e-04 - val_acc: 0.9918\n",
      "Epoch 1986/3000\n",
      " - 2s - loss: 4.2590e-04 - acc: 0.9919 - val_loss: 4.0947e-04 - val_acc: 0.9921\n",
      "Epoch 1987/3000\n",
      " - 2s - loss: 4.1462e-04 - acc: 0.9921 - val_loss: 4.1591e-04 - val_acc: 0.9920\n",
      "Epoch 1988/3000\n",
      " - 2s - loss: 4.1552e-04 - acc: 0.9920 - val_loss: 4.1816e-04 - val_acc: 0.9916\n",
      "Epoch 1989/3000\n",
      " - 1s - loss: 4.1942e-04 - acc: 0.9920 - val_loss: 4.0453e-04 - val_acc: 0.9922\n",
      "Epoch 1990/3000\n",
      " - 1s - loss: 4.1201e-04 - acc: 0.9921 - val_loss: 4.0048e-04 - val_acc: 0.9921\n",
      "Epoch 1991/3000\n",
      " - 2s - loss: 4.1465e-04 - acc: 0.9921 - val_loss: 4.2541e-04 - val_acc: 0.9918\n",
      "Epoch 1992/3000\n",
      " - 2s - loss: 4.2330e-04 - acc: 0.9919 - val_loss: 4.2891e-04 - val_acc: 0.9916\n",
      "Epoch 1993/3000\n",
      " - 2s - loss: 4.1774e-04 - acc: 0.9920 - val_loss: 4.1308e-04 - val_acc: 0.9919\n",
      "Epoch 1994/3000\n",
      " - 2s - loss: 4.1485e-04 - acc: 0.9920 - val_loss: 4.0294e-04 - val_acc: 0.9922\n",
      "Epoch 1995/3000\n",
      " - 2s - loss: 4.1736e-04 - acc: 0.9920 - val_loss: 4.3687e-04 - val_acc: 0.9915\n",
      "Epoch 1996/3000\n",
      " - 2s - loss: 4.1800e-04 - acc: 0.9919 - val_loss: 4.2268e-04 - val_acc: 0.9915\n",
      "Epoch 1997/3000\n",
      " - 2s - loss: 4.2448e-04 - acc: 0.9918 - val_loss: 4.1454e-04 - val_acc: 0.9916\n",
      "Epoch 1998/3000\n",
      " - 2s - loss: 4.2163e-04 - acc: 0.9920 - val_loss: 4.0196e-04 - val_acc: 0.9921\n",
      "Epoch 1999/3000\n",
      " - 1s - loss: 4.1286e-04 - acc: 0.9921 - val_loss: 4.3457e-04 - val_acc: 0.9918\n",
      "Epoch 2000/3000\n",
      "\n",
      "Epoch 02000: val_loss did not improve from 0.00041\n",
      " - 2s - loss: 4.3053e-04 - acc: 0.9917 - val_loss: 4.2223e-04 - val_acc: 0.9919\n",
      "Epoch 2001/3000\n",
      " - 2s - loss: 4.2001e-04 - acc: 0.9920 - val_loss: 4.1901e-04 - val_acc: 0.9918\n",
      "Epoch 2002/3000\n",
      " - 2s - loss: 4.1153e-04 - acc: 0.9921 - val_loss: 4.2240e-04 - val_acc: 0.9918\n",
      "Epoch 2003/3000\n",
      " - 2s - loss: 4.1421e-04 - acc: 0.9920 - val_loss: 4.1889e-04 - val_acc: 0.9919\n",
      "Epoch 2004/3000\n",
      " - 1s - loss: 4.1706e-04 - acc: 0.9921 - val_loss: 4.1095e-04 - val_acc: 0.9918\n",
      "Epoch 2005/3000\n",
      " - 2s - loss: 4.1798e-04 - acc: 0.9920 - val_loss: 4.2017e-04 - val_acc: 0.9918\n",
      "Epoch 2006/3000\n",
      " - 2s - loss: 4.1587e-04 - acc: 0.9920 - val_loss: 4.0110e-04 - val_acc: 0.9921\n",
      "Epoch 2007/3000\n",
      " - 1s - loss: 4.1406e-04 - acc: 0.9920 - val_loss: 3.9863e-04 - val_acc: 0.9920\n",
      "Epoch 2008/3000\n",
      " - 2s - loss: 4.2070e-04 - acc: 0.9919 - val_loss: 4.1539e-04 - val_acc: 0.9918\n",
      "Epoch 2009/3000\n",
      " - 2s - loss: 4.1763e-04 - acc: 0.9919 - val_loss: 4.1308e-04 - val_acc: 0.9922\n",
      "Epoch 2010/3000\n",
      " - 2s - loss: 4.1101e-04 - acc: 0.9921 - val_loss: 4.0416e-04 - val_acc: 0.9918\n",
      "Epoch 2011/3000\n",
      " - 2s - loss: 4.2424e-04 - acc: 0.9919 - val_loss: 4.8022e-04 - val_acc: 0.9904\n",
      "Epoch 2012/3000\n",
      " - 1s - loss: 4.2567e-04 - acc: 0.9918 - val_loss: 4.1587e-04 - val_acc: 0.9919\n",
      "Epoch 2013/3000\n",
      " - 1s - loss: 4.1719e-04 - acc: 0.9920 - val_loss: 4.0302e-04 - val_acc: 0.9922\n",
      "Epoch 2014/3000\n",
      " - 2s - loss: 4.1381e-04 - acc: 0.9920 - val_loss: 4.1575e-04 - val_acc: 0.9921\n",
      "Epoch 2015/3000\n",
      " - 2s - loss: 4.2078e-04 - acc: 0.9920 - val_loss: 4.1433e-04 - val_acc: 0.9920\n",
      "Epoch 2016/3000\n",
      " - 2s - loss: 4.2093e-04 - acc: 0.9920 - val_loss: 4.2430e-04 - val_acc: 0.9914\n",
      "Epoch 2017/3000\n",
      " - 2s - loss: 4.3460e-04 - acc: 0.9917 - val_loss: 4.1122e-04 - val_acc: 0.9920\n",
      "Epoch 2018/3000\n",
      " - 2s - loss: 4.1621e-04 - acc: 0.9920 - val_loss: 4.4172e-04 - val_acc: 0.9916\n",
      "Epoch 2019/3000\n",
      " - 2s - loss: 4.1191e-04 - acc: 0.9921 - val_loss: 3.9923e-04 - val_acc: 0.9922\n",
      "Epoch 2020/3000\n",
      "\n",
      "Epoch 02020: val_loss improved from 0.00041 to 0.00040, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 4.0562e-04 - acc: 0.9922 - val_loss: 3.9721e-04 - val_acc: 0.9922\n",
      "Epoch 2021/3000\n",
      " - 2s - loss: 4.1226e-04 - acc: 0.9921 - val_loss: 4.3376e-04 - val_acc: 0.9920\n",
      "Epoch 2022/3000\n",
      " - 2s - loss: 4.2155e-04 - acc: 0.9919 - val_loss: 4.6588e-04 - val_acc: 0.9911\n",
      "Epoch 2023/3000\n",
      " - 1s - loss: 4.1460e-04 - acc: 0.9920 - val_loss: 4.1548e-04 - val_acc: 0.9920\n",
      "Epoch 2024/3000\n",
      " - 2s - loss: 4.1191e-04 - acc: 0.9920 - val_loss: 4.0590e-04 - val_acc: 0.9919\n",
      "Epoch 2025/3000\n",
      " - 1s - loss: 4.0558e-04 - acc: 0.9922 - val_loss: 4.1340e-04 - val_acc: 0.9919\n",
      "Epoch 2026/3000\n",
      " - 1s - loss: 4.1789e-04 - acc: 0.9921 - val_loss: 4.0588e-04 - val_acc: 0.9920\n",
      "Epoch 2027/3000\n",
      " - 2s - loss: 4.2302e-04 - acc: 0.9919 - val_loss: 4.1543e-04 - val_acc: 0.9920\n",
      "Epoch 2028/3000\n",
      " - 1s - loss: 4.1715e-04 - acc: 0.9920 - val_loss: 3.9712e-04 - val_acc: 0.9920\n",
      "Epoch 2029/3000\n",
      " - 2s - loss: 4.1071e-04 - acc: 0.9920 - val_loss: 4.0971e-04 - val_acc: 0.9917\n",
      "Epoch 2030/3000\n",
      " - 2s - loss: 4.1375e-04 - acc: 0.9920 - val_loss: 4.1447e-04 - val_acc: 0.9919\n",
      "Epoch 2031/3000\n",
      " - 2s - loss: 4.1385e-04 - acc: 0.9920 - val_loss: 4.1683e-04 - val_acc: 0.9920\n",
      "Epoch 2032/3000\n",
      " - 2s - loss: 4.1959e-04 - acc: 0.9919 - val_loss: 4.4394e-04 - val_acc: 0.9920\n",
      "Epoch 2033/3000\n",
      " - 1s - loss: 4.2352e-04 - acc: 0.9918 - val_loss: 4.4779e-04 - val_acc: 0.9916\n",
      "Epoch 2034/3000\n",
      " - 2s - loss: 4.1779e-04 - acc: 0.9920 - val_loss: 4.2751e-04 - val_acc: 0.9920\n",
      "Epoch 2035/3000\n",
      " - 2s - loss: 4.1677e-04 - acc: 0.9920 - val_loss: 4.2573e-04 - val_acc: 0.9919\n",
      "Epoch 2036/3000\n",
      " - 2s - loss: 4.1876e-04 - acc: 0.9920 - val_loss: 4.2541e-04 - val_acc: 0.9915\n",
      "Epoch 2037/3000\n",
      " - 1s - loss: 4.2572e-04 - acc: 0.9918 - val_loss: 4.1154e-04 - val_acc: 0.9921\n",
      "Epoch 2038/3000\n",
      " - 1s - loss: 4.1357e-04 - acc: 0.9920 - val_loss: 4.3536e-04 - val_acc: 0.9919\n",
      "Epoch 2039/3000\n",
      " - 2s - loss: 4.2189e-04 - acc: 0.9919 - val_loss: 4.1694e-04 - val_acc: 0.9920\n",
      "Epoch 2040/3000\n",
      "\n",
      "Epoch 02040: val_loss did not improve from 0.00040\n",
      " - 1s - loss: 4.1100e-04 - acc: 0.9921 - val_loss: 4.0708e-04 - val_acc: 0.9919\n",
      "Epoch 2041/3000\n",
      " - 2s - loss: 4.1879e-04 - acc: 0.9919 - val_loss: 4.2239e-04 - val_acc: 0.9920\n",
      "Epoch 2042/3000\n",
      " - 1s - loss: 4.2298e-04 - acc: 0.9918 - val_loss: 4.0520e-04 - val_acc: 0.9919\n",
      "Epoch 2043/3000\n",
      " - 2s - loss: 4.1019e-04 - acc: 0.9921 - val_loss: 4.0013e-04 - val_acc: 0.9920\n",
      "Epoch 2044/3000\n",
      " - 2s - loss: 4.1162e-04 - acc: 0.9921 - val_loss: 4.3084e-04 - val_acc: 0.9920\n",
      "Epoch 2045/3000\n",
      " - 2s - loss: 4.2160e-04 - acc: 0.9918 - val_loss: 4.0700e-04 - val_acc: 0.9920\n",
      "Epoch 2046/3000\n",
      " - 1s - loss: 4.0749e-04 - acc: 0.9921 - val_loss: 4.0511e-04 - val_acc: 0.9920\n",
      "Epoch 2047/3000\n",
      " - 2s - loss: 4.1595e-04 - acc: 0.9920 - val_loss: 3.9778e-04 - val_acc: 0.9921\n",
      "Epoch 2048/3000\n",
      " - 2s - loss: 4.0825e-04 - acc: 0.9921 - val_loss: 4.1234e-04 - val_acc: 0.9920\n",
      "Epoch 2049/3000\n",
      " - 1s - loss: 4.2531e-04 - acc: 0.9919 - val_loss: 4.1374e-04 - val_acc: 0.9917\n",
      "Epoch 2050/3000\n",
      " - 1s - loss: 4.0723e-04 - acc: 0.9921 - val_loss: 4.2233e-04 - val_acc: 0.9917\n",
      "Epoch 2051/3000\n",
      " - 2s - loss: 4.2709e-04 - acc: 0.9917 - val_loss: 4.1296e-04 - val_acc: 0.9916\n",
      "Epoch 2052/3000\n",
      " - 2s - loss: 4.1173e-04 - acc: 0.9921 - val_loss: 4.1167e-04 - val_acc: 0.9920\n",
      "Epoch 2053/3000\n",
      " - 2s - loss: 4.1527e-04 - acc: 0.9920 - val_loss: 4.1478e-04 - val_acc: 0.9917\n",
      "Epoch 2054/3000\n",
      " - 2s - loss: 4.1743e-04 - acc: 0.9919 - val_loss: 4.0598e-04 - val_acc: 0.9920\n",
      "Epoch 2055/3000\n",
      " - 1s - loss: 4.0892e-04 - acc: 0.9921 - val_loss: 4.0866e-04 - val_acc: 0.9919\n",
      "Epoch 2056/3000\n",
      " - 2s - loss: 4.1575e-04 - acc: 0.9920 - val_loss: 4.0882e-04 - val_acc: 0.9917\n",
      "Epoch 2057/3000\n",
      " - 2s - loss: 4.0994e-04 - acc: 0.9920 - val_loss: 4.5196e-04 - val_acc: 0.9918\n",
      "Epoch 2058/3000\n",
      " - 2s - loss: 4.1363e-04 - acc: 0.9920 - val_loss: 4.0700e-04 - val_acc: 0.9921\n",
      "Epoch 2059/3000\n",
      " - 1s - loss: 4.0466e-04 - acc: 0.9922 - val_loss: 3.9452e-04 - val_acc: 0.9920\n",
      "Epoch 2060/3000\n",
      "\n",
      "Epoch 02060: val_loss did not improve from 0.00040\n",
      " - 2s - loss: 4.1739e-04 - acc: 0.9920 - val_loss: 4.1066e-04 - val_acc: 0.9918\n",
      "Epoch 2061/3000\n",
      " - 2s - loss: 4.0975e-04 - acc: 0.9922 - val_loss: 3.9791e-04 - val_acc: 0.9920\n",
      "Epoch 2062/3000\n",
      " - 2s - loss: 4.1347e-04 - acc: 0.9921 - val_loss: 4.0628e-04 - val_acc: 0.9921\n",
      "Epoch 2063/3000\n",
      " - 2s - loss: 4.1032e-04 - acc: 0.9921 - val_loss: 3.9573e-04 - val_acc: 0.9919\n",
      "Epoch 2064/3000\n",
      " - 1s - loss: 4.0530e-04 - acc: 0.9922 - val_loss: 4.0544e-04 - val_acc: 0.9920\n",
      "Epoch 2065/3000\n",
      " - 2s - loss: 4.2450e-04 - acc: 0.9918 - val_loss: 4.0972e-04 - val_acc: 0.9919\n",
      "Epoch 2066/3000\n",
      " - 2s - loss: 4.1703e-04 - acc: 0.9920 - val_loss: 4.1096e-04 - val_acc: 0.9918\n",
      "Epoch 2067/3000\n",
      " - 2s - loss: 4.1441e-04 - acc: 0.9920 - val_loss: 4.0700e-04 - val_acc: 0.9921\n",
      "Epoch 2068/3000\n",
      " - 2s - loss: 4.1178e-04 - acc: 0.9920 - val_loss: 3.9619e-04 - val_acc: 0.9920\n",
      "Epoch 2069/3000\n",
      " - 2s - loss: 4.2258e-04 - acc: 0.9918 - val_loss: 3.9724e-04 - val_acc: 0.9921\n",
      "Epoch 2070/3000\n",
      " - 2s - loss: 4.2884e-04 - acc: 0.9919 - val_loss: 4.1615e-04 - val_acc: 0.9919\n",
      "Epoch 2071/3000\n",
      " - 2s - loss: 4.1282e-04 - acc: 0.9920 - val_loss: 4.0320e-04 - val_acc: 0.9921\n",
      "Epoch 2072/3000\n",
      " - 2s - loss: 4.1006e-04 - acc: 0.9921 - val_loss: 4.1084e-04 - val_acc: 0.9918\n",
      "Epoch 2073/3000\n",
      " - 2s - loss: 4.2090e-04 - acc: 0.9919 - val_loss: 4.0583e-04 - val_acc: 0.9921\n",
      "Epoch 2074/3000\n",
      " - 2s - loss: 4.0627e-04 - acc: 0.9921 - val_loss: 3.9994e-04 - val_acc: 0.9922\n",
      "Epoch 2075/3000\n",
      " - 2s - loss: 4.1169e-04 - acc: 0.9920 - val_loss: 4.2303e-04 - val_acc: 0.9919\n",
      "Epoch 2076/3000\n",
      " - 2s - loss: 4.1646e-04 - acc: 0.9920 - val_loss: 4.3253e-04 - val_acc: 0.9919\n",
      "Epoch 2077/3000\n",
      " - 2s - loss: 4.1188e-04 - acc: 0.9921 - val_loss: 4.0396e-04 - val_acc: 0.9918\n",
      "Epoch 2078/3000\n",
      " - 2s - loss: 4.1130e-04 - acc: 0.9921 - val_loss: 3.9948e-04 - val_acc: 0.9923\n",
      "Epoch 2079/3000\n",
      " - 2s - loss: 4.0952e-04 - acc: 0.9921 - val_loss: 4.0375e-04 - val_acc: 0.9919\n",
      "Epoch 2080/3000\n",
      "\n",
      "Epoch 02080: val_loss did not improve from 0.00040\n",
      " - 2s - loss: 4.1571e-04 - acc: 0.9920 - val_loss: 4.1009e-04 - val_acc: 0.9919\n",
      "Epoch 2081/3000\n",
      " - 2s - loss: 4.1035e-04 - acc: 0.9921 - val_loss: 4.1855e-04 - val_acc: 0.9920\n",
      "Epoch 2082/3000\n",
      " - 1s - loss: 4.0955e-04 - acc: 0.9921 - val_loss: 4.1830e-04 - val_acc: 0.9918\n",
      "Epoch 2083/3000\n",
      " - 2s - loss: 4.1091e-04 - acc: 0.9920 - val_loss: 4.0400e-04 - val_acc: 0.9922\n",
      "Epoch 2084/3000\n",
      " - 2s - loss: 4.1599e-04 - acc: 0.9920 - val_loss: 4.2282e-04 - val_acc: 0.9918\n",
      "Epoch 2085/3000\n",
      " - 2s - loss: 4.1754e-04 - acc: 0.9919 - val_loss: 4.0070e-04 - val_acc: 0.9921\n",
      "Epoch 2086/3000\n",
      " - 2s - loss: 4.0710e-04 - acc: 0.9921 - val_loss: 3.9555e-04 - val_acc: 0.9922\n",
      "Epoch 2087/3000\n",
      " - 2s - loss: 4.1236e-04 - acc: 0.9921 - val_loss: 4.5349e-04 - val_acc: 0.9908\n",
      "Epoch 2088/3000\n",
      " - 2s - loss: 4.1027e-04 - acc: 0.9920 - val_loss: 4.2692e-04 - val_acc: 0.9918\n",
      "Epoch 2089/3000\n",
      " - 2s - loss: 4.1012e-04 - acc: 0.9921 - val_loss: 4.0489e-04 - val_acc: 0.9921\n",
      "Epoch 2090/3000\n",
      " - 1s - loss: 4.0761e-04 - acc: 0.9921 - val_loss: 4.1266e-04 - val_acc: 0.9917\n",
      "Epoch 2091/3000\n",
      " - 2s - loss: 4.1079e-04 - acc: 0.9921 - val_loss: 4.0422e-04 - val_acc: 0.9920\n",
      "Epoch 2092/3000\n",
      " - 2s - loss: 4.0803e-04 - acc: 0.9920 - val_loss: 3.9610e-04 - val_acc: 0.9921\n",
      "Epoch 2093/3000\n",
      " - 2s - loss: 4.1340e-04 - acc: 0.9920 - val_loss: 4.1328e-04 - val_acc: 0.9920\n",
      "Epoch 2094/3000\n",
      " - 2s - loss: 4.1491e-04 - acc: 0.9919 - val_loss: 3.9630e-04 - val_acc: 0.9922\n",
      "Epoch 2095/3000\n",
      " - 2s - loss: 4.0993e-04 - acc: 0.9921 - val_loss: 4.3694e-04 - val_acc: 0.9920\n",
      "Epoch 2096/3000\n",
      " - 2s - loss: 4.1316e-04 - acc: 0.9920 - val_loss: 4.1302e-04 - val_acc: 0.9919\n",
      "Epoch 2097/3000\n",
      " - 2s - loss: 4.1687e-04 - acc: 0.9921 - val_loss: 4.3983e-04 - val_acc: 0.9918\n",
      "Epoch 2098/3000\n",
      " - 2s - loss: 4.1775e-04 - acc: 0.9919 - val_loss: 4.1702e-04 - val_acc: 0.9921\n",
      "Epoch 2099/3000\n",
      " - 1s - loss: 4.1546e-04 - acc: 0.9920 - val_loss: 4.0304e-04 - val_acc: 0.9921\n",
      "Epoch 2100/3000\n",
      "\n",
      "Epoch 02100: val_loss did not improve from 0.00040\n",
      " - 2s - loss: 4.1486e-04 - acc: 0.9919 - val_loss: 4.0587e-04 - val_acc: 0.9922\n",
      "Epoch 2101/3000\n",
      " - 1s - loss: 4.1894e-04 - acc: 0.9918 - val_loss: 4.0184e-04 - val_acc: 0.9919\n",
      "Epoch 2102/3000\n",
      " - 2s - loss: 4.0514e-04 - acc: 0.9921 - val_loss: 4.2553e-04 - val_acc: 0.9921\n",
      "Epoch 2103/3000\n",
      " - 2s - loss: 4.1917e-04 - acc: 0.9919 - val_loss: 4.0862e-04 - val_acc: 0.9921\n",
      "Epoch 2104/3000\n",
      " - 1s - loss: 4.1133e-04 - acc: 0.9921 - val_loss: 4.1011e-04 - val_acc: 0.9917\n",
      "Epoch 2105/3000\n",
      " - 2s - loss: 4.1375e-04 - acc: 0.9920 - val_loss: 4.4694e-04 - val_acc: 0.9913\n",
      "Epoch 2106/3000\n",
      " - 2s - loss: 4.1302e-04 - acc: 0.9920 - val_loss: 3.9794e-04 - val_acc: 0.9920\n",
      "Epoch 2107/3000\n",
      " - 2s - loss: 4.0458e-04 - acc: 0.9921 - val_loss: 4.0091e-04 - val_acc: 0.9921\n",
      "Epoch 2108/3000\n",
      " - 2s - loss: 4.1082e-04 - acc: 0.9921 - val_loss: 3.9595e-04 - val_acc: 0.9919\n",
      "Epoch 2109/3000\n",
      " - 2s - loss: 4.0151e-04 - acc: 0.9922 - val_loss: 3.9229e-04 - val_acc: 0.9922\n",
      "Epoch 2110/3000\n",
      " - 2s - loss: 4.0039e-04 - acc: 0.9922 - val_loss: 3.9128e-04 - val_acc: 0.9922\n",
      "Epoch 2111/3000\n",
      " - 2s - loss: 4.0497e-04 - acc: 0.9921 - val_loss: 4.0338e-04 - val_acc: 0.9920\n",
      "Epoch 2112/3000\n",
      " - 2s - loss: 4.0511e-04 - acc: 0.9922 - val_loss: 4.0252e-04 - val_acc: 0.9920\n",
      "Epoch 2113/3000\n",
      " - 1s - loss: 4.1126e-04 - acc: 0.9920 - val_loss: 4.1036e-04 - val_acc: 0.9919\n",
      "Epoch 2114/3000\n",
      " - 2s - loss: 4.1480e-04 - acc: 0.9921 - val_loss: 4.3490e-04 - val_acc: 0.9919\n",
      "Epoch 2115/3000\n",
      " - 2s - loss: 4.1457e-04 - acc: 0.9920 - val_loss: 4.5627e-04 - val_acc: 0.9914\n",
      "Epoch 2116/3000\n",
      " - 2s - loss: 4.3411e-04 - acc: 0.9918 - val_loss: 4.0886e-04 - val_acc: 0.9919\n",
      "Epoch 2117/3000\n",
      " - 2s - loss: 4.0501e-04 - acc: 0.9922 - val_loss: 4.1310e-04 - val_acc: 0.9919\n",
      "Epoch 2118/3000\n",
      " - 2s - loss: 4.1162e-04 - acc: 0.9921 - val_loss: 4.0946e-04 - val_acc: 0.9920\n",
      "Epoch 2119/3000\n",
      " - 1s - loss: 4.0584e-04 - acc: 0.9922 - val_loss: 3.9702e-04 - val_acc: 0.9923\n",
      "Epoch 2120/3000\n",
      "\n",
      "Epoch 02120: val_loss did not improve from 0.00040\n",
      " - 1s - loss: 4.0372e-04 - acc: 0.9921 - val_loss: 4.0413e-04 - val_acc: 0.9921\n",
      "Epoch 2121/3000\n",
      " - 2s - loss: 4.0877e-04 - acc: 0.9921 - val_loss: 4.2035e-04 - val_acc: 0.9916\n",
      "Epoch 2122/3000\n",
      " - 2s - loss: 4.0629e-04 - acc: 0.9921 - val_loss: 3.9711e-04 - val_acc: 0.9920\n",
      "Epoch 2123/3000\n",
      " - 2s - loss: 4.2203e-04 - acc: 0.9918 - val_loss: 4.0740e-04 - val_acc: 0.9921\n",
      "Epoch 2124/3000\n",
      " - 2s - loss: 4.1125e-04 - acc: 0.9920 - val_loss: 4.3507e-04 - val_acc: 0.9918\n",
      "Epoch 2125/3000\n",
      " - 1s - loss: 4.0864e-04 - acc: 0.9920 - val_loss: 4.6631e-04 - val_acc: 0.9920\n",
      "Epoch 2126/3000\n",
      " - 2s - loss: 4.0571e-04 - acc: 0.9922 - val_loss: 4.2416e-04 - val_acc: 0.9920\n",
      "Epoch 2127/3000\n",
      " - 2s - loss: 4.0794e-04 - acc: 0.9920 - val_loss: 4.2308e-04 - val_acc: 0.9919\n",
      "Epoch 2128/3000\n",
      " - 2s - loss: 4.0544e-04 - acc: 0.9922 - val_loss: 4.0158e-04 - val_acc: 0.9921\n",
      "Epoch 2129/3000\n",
      " - 1s - loss: 4.0255e-04 - acc: 0.9922 - val_loss: 4.0116e-04 - val_acc: 0.9923\n",
      "Epoch 2130/3000\n",
      " - 2s - loss: 4.1499e-04 - acc: 0.9919 - val_loss: 4.0222e-04 - val_acc: 0.9920\n",
      "Epoch 2131/3000\n",
      " - 1s - loss: 4.1778e-04 - acc: 0.9920 - val_loss: 4.2000e-04 - val_acc: 0.9919\n",
      "Epoch 2132/3000\n",
      " - 1s - loss: 4.1279e-04 - acc: 0.9920 - val_loss: 4.1583e-04 - val_acc: 0.9918\n",
      "Epoch 2133/3000\n",
      " - 2s - loss: 4.1050e-04 - acc: 0.9920 - val_loss: 4.0701e-04 - val_acc: 0.9921\n",
      "Epoch 2134/3000\n",
      " - 2s - loss: 4.0800e-04 - acc: 0.9921 - val_loss: 4.0547e-04 - val_acc: 0.9921\n",
      "Epoch 2135/3000\n",
      " - 1s - loss: 4.0752e-04 - acc: 0.9920 - val_loss: 3.9769e-04 - val_acc: 0.9922\n",
      "Epoch 2136/3000\n",
      " - 2s - loss: 4.0255e-04 - acc: 0.9921 - val_loss: 3.9351e-04 - val_acc: 0.9920\n",
      "Epoch 2137/3000\n",
      " - 2s - loss: 4.0524e-04 - acc: 0.9921 - val_loss: 3.9672e-04 - val_acc: 0.9921\n",
      "Epoch 2138/3000\n",
      " - 2s - loss: 3.9866e-04 - acc: 0.9922 - val_loss: 4.0451e-04 - val_acc: 0.9919\n",
      "Epoch 2139/3000\n",
      " - 2s - loss: 4.0311e-04 - acc: 0.9922 - val_loss: 4.1178e-04 - val_acc: 0.9920\n",
      "Epoch 2140/3000\n",
      "\n",
      "Epoch 02140: val_loss did not improve from 0.00040\n",
      " - 2s - loss: 4.1222e-04 - acc: 0.9920 - val_loss: 4.1492e-04 - val_acc: 0.9916\n",
      "Epoch 2141/3000\n",
      " - 2s - loss: 4.0605e-04 - acc: 0.9921 - val_loss: 3.9933e-04 - val_acc: 0.9921\n",
      "Epoch 2142/3000\n",
      " - 2s - loss: 3.9864e-04 - acc: 0.9922 - val_loss: 3.9214e-04 - val_acc: 0.9922\n",
      "Epoch 2143/3000\n",
      " - 2s - loss: 3.9945e-04 - acc: 0.9922 - val_loss: 4.0651e-04 - val_acc: 0.9918\n",
      "Epoch 2144/3000\n",
      " - 2s - loss: 4.0323e-04 - acc: 0.9921 - val_loss: 4.6423e-04 - val_acc: 0.9919\n",
      "Epoch 2145/3000\n",
      " - 2s - loss: 4.1437e-04 - acc: 0.9920 - val_loss: 3.9230e-04 - val_acc: 0.9923\n",
      "Epoch 2146/3000\n",
      " - 1s - loss: 3.9677e-04 - acc: 0.9923 - val_loss: 3.8973e-04 - val_acc: 0.9923\n",
      "Epoch 2147/3000\n",
      " - 1s - loss: 3.9899e-04 - acc: 0.9922 - val_loss: 4.2363e-04 - val_acc: 0.9919\n",
      "Epoch 2148/3000\n",
      " - 1s - loss: 4.1333e-04 - acc: 0.9919 - val_loss: 4.1022e-04 - val_acc: 0.9918\n",
      "Epoch 2149/3000\n",
      " - 2s - loss: 4.1234e-04 - acc: 0.9921 - val_loss: 4.0278e-04 - val_acc: 0.9919\n",
      "Epoch 2150/3000\n",
      " - 2s - loss: 4.0244e-04 - acc: 0.9921 - val_loss: 3.9790e-04 - val_acc: 0.9921\n",
      "Epoch 2151/3000\n",
      " - 2s - loss: 4.0731e-04 - acc: 0.9921 - val_loss: 4.3304e-04 - val_acc: 0.9915\n",
      "Epoch 2152/3000\n",
      " - 2s - loss: 4.1828e-04 - acc: 0.9918 - val_loss: 4.0124e-04 - val_acc: 0.9920\n",
      "Epoch 2153/3000\n",
      " - 2s - loss: 4.0896e-04 - acc: 0.9922 - val_loss: 4.0249e-04 - val_acc: 0.9917\n",
      "Epoch 2154/3000\n",
      " - 2s - loss: 4.0935e-04 - acc: 0.9921 - val_loss: 4.0325e-04 - val_acc: 0.9922\n",
      "Epoch 2155/3000\n",
      " - 2s - loss: 4.0755e-04 - acc: 0.9921 - val_loss: 4.0453e-04 - val_acc: 0.9921\n",
      "Epoch 2156/3000\n",
      " - 2s - loss: 4.1517e-04 - acc: 0.9920 - val_loss: 4.2624e-04 - val_acc: 0.9917\n",
      "Epoch 2157/3000\n",
      " - 2s - loss: 4.0397e-04 - acc: 0.9921 - val_loss: 4.0563e-04 - val_acc: 0.9920\n",
      "Epoch 2158/3000\n",
      " - 2s - loss: 4.0709e-04 - acc: 0.9921 - val_loss: 3.9780e-04 - val_acc: 0.9922\n",
      "Epoch 2159/3000\n",
      " - 2s - loss: 4.0368e-04 - acc: 0.9922 - val_loss: 4.0693e-04 - val_acc: 0.9920\n",
      "Epoch 2160/3000\n",
      "\n",
      "Epoch 02160: val_loss did not improve from 0.00040\n",
      " - 2s - loss: 4.0286e-04 - acc: 0.9921 - val_loss: 3.9735e-04 - val_acc: 0.9922\n",
      "Epoch 2161/3000\n",
      " - 2s - loss: 4.1494e-04 - acc: 0.9919 - val_loss: 3.9561e-04 - val_acc: 0.9921\n",
      "Epoch 2162/3000\n",
      " - 1s - loss: 4.0272e-04 - acc: 0.9921 - val_loss: 4.3021e-04 - val_acc: 0.9919\n",
      "Epoch 2163/3000\n",
      " - 1s - loss: 4.1721e-04 - acc: 0.9920 - val_loss: 3.9759e-04 - val_acc: 0.9922\n",
      "Epoch 2164/3000\n",
      " - 2s - loss: 4.1165e-04 - acc: 0.9920 - val_loss: 4.0875e-04 - val_acc: 0.9913\n",
      "Epoch 2165/3000\n",
      " - 2s - loss: 4.0437e-04 - acc: 0.9920 - val_loss: 4.0926e-04 - val_acc: 0.9919\n",
      "Epoch 2166/3000\n",
      " - 1s - loss: 3.9732e-04 - acc: 0.9922 - val_loss: 4.0705e-04 - val_acc: 0.9922\n",
      "Epoch 2167/3000\n",
      " - 2s - loss: 4.1432e-04 - acc: 0.9920 - val_loss: 3.9684e-04 - val_acc: 0.9920\n",
      "Epoch 2168/3000\n",
      " - 2s - loss: 4.0887e-04 - acc: 0.9921 - val_loss: 3.9777e-04 - val_acc: 0.9919\n",
      "Epoch 2169/3000\n",
      " - 2s - loss: 3.9847e-04 - acc: 0.9921 - val_loss: 3.9716e-04 - val_acc: 0.9922\n",
      "Epoch 2170/3000\n",
      " - 2s - loss: 4.1051e-04 - acc: 0.9920 - val_loss: 3.9887e-04 - val_acc: 0.9922\n",
      "Epoch 2171/3000\n",
      " - 1s - loss: 4.0006e-04 - acc: 0.9922 - val_loss: 3.9854e-04 - val_acc: 0.9922\n",
      "Epoch 2172/3000\n",
      " - 2s - loss: 4.1367e-04 - acc: 0.9920 - val_loss: 4.1606e-04 - val_acc: 0.9918\n",
      "Epoch 2173/3000\n",
      " - 2s - loss: 4.0214e-04 - acc: 0.9921 - val_loss: 3.9862e-04 - val_acc: 0.9922\n",
      "Epoch 2174/3000\n",
      " - 2s - loss: 4.0036e-04 - acc: 0.9922 - val_loss: 4.0412e-04 - val_acc: 0.9918\n",
      "Epoch 2175/3000\n",
      " - 2s - loss: 4.0374e-04 - acc: 0.9921 - val_loss: 3.9845e-04 - val_acc: 0.9921\n",
      "Epoch 2176/3000\n",
      " - 1s - loss: 3.9618e-04 - acc: 0.9922 - val_loss: 4.0038e-04 - val_acc: 0.9920\n",
      "Epoch 2177/3000\n",
      " - 1s - loss: 4.0724e-04 - acc: 0.9921 - val_loss: 3.8731e-04 - val_acc: 0.9922\n",
      "Epoch 2178/3000\n",
      " - 2s - loss: 4.0066e-04 - acc: 0.9922 - val_loss: 3.9804e-04 - val_acc: 0.9922\n",
      "Epoch 2179/3000\n",
      " - 2s - loss: 4.1050e-04 - acc: 0.9920 - val_loss: 4.1211e-04 - val_acc: 0.9917\n",
      "Epoch 2180/3000\n",
      "\n",
      "Epoch 02180: val_loss improved from 0.00040 to 0.00039, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 3.9553e-04 - acc: 0.9923 - val_loss: 3.8811e-04 - val_acc: 0.9924\n",
      "Epoch 2181/3000\n",
      " - 1s - loss: 4.0366e-04 - acc: 0.9921 - val_loss: 4.0552e-04 - val_acc: 0.9921\n",
      "Epoch 2182/3000\n",
      " - 2s - loss: 4.0295e-04 - acc: 0.9922 - val_loss: 3.9073e-04 - val_acc: 0.9921\n",
      "Epoch 2183/3000\n",
      " - 2s - loss: 4.0658e-04 - acc: 0.9921 - val_loss: 4.0288e-04 - val_acc: 0.9920\n",
      "Epoch 2184/3000\n",
      " - 1s - loss: 4.0661e-04 - acc: 0.9921 - val_loss: 3.9588e-04 - val_acc: 0.9921\n",
      "Epoch 2185/3000\n",
      " - 2s - loss: 4.0019e-04 - acc: 0.9922 - val_loss: 3.8986e-04 - val_acc: 0.9921\n",
      "Epoch 2186/3000\n",
      " - 2s - loss: 4.0294e-04 - acc: 0.9922 - val_loss: 3.9774e-04 - val_acc: 0.9922\n",
      "Epoch 2187/3000\n",
      " - 2s - loss: 4.0965e-04 - acc: 0.9920 - val_loss: 3.9685e-04 - val_acc: 0.9921\n",
      "Epoch 2188/3000\n",
      " - 2s - loss: 4.0482e-04 - acc: 0.9921 - val_loss: 3.9740e-04 - val_acc: 0.9919\n",
      "Epoch 2189/3000\n",
      " - 1s - loss: 4.0583e-04 - acc: 0.9921 - val_loss: 4.3295e-04 - val_acc: 0.9917\n",
      "Epoch 2190/3000\n",
      " - 2s - loss: 4.0760e-04 - acc: 0.9920 - val_loss: 3.9454e-04 - val_acc: 0.9922\n",
      "Epoch 2191/3000\n",
      " - 2s - loss: 4.0637e-04 - acc: 0.9920 - val_loss: 3.9285e-04 - val_acc: 0.9919\n",
      "Epoch 2192/3000\n",
      " - 2s - loss: 3.9856e-04 - acc: 0.9922 - val_loss: 4.0328e-04 - val_acc: 0.9922\n",
      "Epoch 2193/3000\n",
      " - 2s - loss: 4.1485e-04 - acc: 0.9919 - val_loss: 4.0811e-04 - val_acc: 0.9922\n",
      "Epoch 2194/3000\n",
      " - 2s - loss: 4.0264e-04 - acc: 0.9922 - val_loss: 3.9528e-04 - val_acc: 0.9919\n",
      "Epoch 2195/3000\n",
      " - 2s - loss: 4.0626e-04 - acc: 0.9921 - val_loss: 3.8745e-04 - val_acc: 0.9923\n",
      "Epoch 2196/3000\n",
      " - 2s - loss: 4.0677e-04 - acc: 0.9921 - val_loss: 4.0524e-04 - val_acc: 0.9920\n",
      "Epoch 2197/3000\n",
      " - 2s - loss: 4.0191e-04 - acc: 0.9921 - val_loss: 4.0301e-04 - val_acc: 0.9922\n",
      "Epoch 2198/3000\n",
      " - 1s - loss: 4.0145e-04 - acc: 0.9922 - val_loss: 4.1121e-04 - val_acc: 0.9920\n",
      "Epoch 2199/3000\n",
      " - 2s - loss: 4.0167e-04 - acc: 0.9921 - val_loss: 3.9546e-04 - val_acc: 0.9921\n",
      "Epoch 2200/3000\n",
      "\n",
      "Epoch 02200: val_loss did not improve from 0.00039\n",
      " - 2s - loss: 4.0216e-04 - acc: 0.9921 - val_loss: 4.0621e-04 - val_acc: 0.9918\n",
      "Epoch 2201/3000\n",
      " - 2s - loss: 4.0162e-04 - acc: 0.9922 - val_loss: 4.0042e-04 - val_acc: 0.9923\n",
      "Epoch 2202/3000\n",
      " - 1s - loss: 4.0122e-04 - acc: 0.9921 - val_loss: 3.8613e-04 - val_acc: 0.9924\n",
      "Epoch 2203/3000\n",
      " - 2s - loss: 4.0381e-04 - acc: 0.9921 - val_loss: 4.5767e-04 - val_acc: 0.9916\n",
      "Epoch 2204/3000\n",
      " - 2s - loss: 4.1024e-04 - acc: 0.9920 - val_loss: 3.9296e-04 - val_acc: 0.9921\n",
      "Epoch 2205/3000\n",
      " - 2s - loss: 4.1257e-04 - acc: 0.9920 - val_loss: 4.4405e-04 - val_acc: 0.9913\n",
      "Epoch 2206/3000\n",
      " - 2s - loss: 4.1838e-04 - acc: 0.9919 - val_loss: 3.9584e-04 - val_acc: 0.9920\n",
      "Epoch 2207/3000\n",
      " - 2s - loss: 3.9992e-04 - acc: 0.9921 - val_loss: 3.9517e-04 - val_acc: 0.9921\n",
      "Epoch 2208/3000\n",
      " - 2s - loss: 4.0488e-04 - acc: 0.9921 - val_loss: 4.2631e-04 - val_acc: 0.9922\n",
      "Epoch 2209/3000\n",
      " - 2s - loss: 4.0986e-04 - acc: 0.9920 - val_loss: 3.9662e-04 - val_acc: 0.9922\n",
      "Epoch 2210/3000\n",
      " - 2s - loss: 4.0766e-04 - acc: 0.9920 - val_loss: 3.9868e-04 - val_acc: 0.9919\n",
      "Epoch 2211/3000\n",
      " - 1s - loss: 4.0548e-04 - acc: 0.9920 - val_loss: 3.9760e-04 - val_acc: 0.9923\n",
      "Epoch 2212/3000\n",
      " - 2s - loss: 4.0016e-04 - acc: 0.9922 - val_loss: 3.9577e-04 - val_acc: 0.9919\n",
      "Epoch 2213/3000\n",
      " - 2s - loss: 3.9691e-04 - acc: 0.9922 - val_loss: 3.8398e-04 - val_acc: 0.9922\n",
      "Epoch 2214/3000\n",
      " - 2s - loss: 4.0419e-04 - acc: 0.9921 - val_loss: 3.9584e-04 - val_acc: 0.9919\n",
      "Epoch 2215/3000\n",
      " - 2s - loss: 4.0629e-04 - acc: 0.9921 - val_loss: 3.9920e-04 - val_acc: 0.9917\n",
      "Epoch 2216/3000\n",
      " - 2s - loss: 4.0251e-04 - acc: 0.9921 - val_loss: 4.0044e-04 - val_acc: 0.9920\n",
      "Epoch 2217/3000\n",
      " - 2s - loss: 4.0566e-04 - acc: 0.9921 - val_loss: 3.9918e-04 - val_acc: 0.9922\n",
      "Epoch 2218/3000\n",
      " - 2s - loss: 3.9988e-04 - acc: 0.9922 - val_loss: 3.9134e-04 - val_acc: 0.9921\n",
      "Epoch 2219/3000\n",
      " - 1s - loss: 4.1513e-04 - acc: 0.9920 - val_loss: 3.8788e-04 - val_acc: 0.9922\n",
      "Epoch 2220/3000\n",
      "\n",
      "Epoch 02220: val_loss did not improve from 0.00039\n",
      " - 2s - loss: 4.0019e-04 - acc: 0.9922 - val_loss: 4.9260e-04 - val_acc: 0.9909\n",
      "Epoch 2221/3000\n",
      " - 1s - loss: 4.0792e-04 - acc: 0.9921 - val_loss: 3.9350e-04 - val_acc: 0.9922\n",
      "Epoch 2222/3000\n",
      " - 2s - loss: 4.1731e-04 - acc: 0.9919 - val_loss: 4.0782e-04 - val_acc: 0.9920\n",
      "Epoch 2223/3000\n",
      " - 2s - loss: 4.0190e-04 - acc: 0.9921 - val_loss: 4.0047e-04 - val_acc: 0.9918\n",
      "Epoch 2224/3000\n",
      " - 2s - loss: 4.0902e-04 - acc: 0.9920 - val_loss: 4.0404e-04 - val_acc: 0.9921\n",
      "Epoch 2225/3000\n",
      " - 2s - loss: 3.9922e-04 - acc: 0.9922 - val_loss: 3.9463e-04 - val_acc: 0.9920\n",
      "Epoch 2226/3000\n",
      " - 2s - loss: 4.0490e-04 - acc: 0.9921 - val_loss: 4.0015e-04 - val_acc: 0.9920\n",
      "Epoch 2227/3000\n",
      " - 1s - loss: 3.9637e-04 - acc: 0.9922 - val_loss: 3.8850e-04 - val_acc: 0.9923\n",
      "Epoch 2228/3000\n",
      " - 2s - loss: 3.9416e-04 - acc: 0.9923 - val_loss: 4.0219e-04 - val_acc: 0.9920\n",
      "Epoch 2229/3000\n",
      " - 2s - loss: 4.0145e-04 - acc: 0.9922 - val_loss: 3.8843e-04 - val_acc: 0.9922\n",
      "Epoch 2230/3000\n",
      " - 1s - loss: 3.9915e-04 - acc: 0.9922 - val_loss: 4.3181e-04 - val_acc: 0.9919\n",
      "Epoch 2231/3000\n",
      " - 1s - loss: 4.1025e-04 - acc: 0.9920 - val_loss: 3.9817e-04 - val_acc: 0.9920\n",
      "Epoch 2232/3000\n",
      " - 2s - loss: 4.0490e-04 - acc: 0.9921 - val_loss: 4.2185e-04 - val_acc: 0.9919\n",
      "Epoch 2233/3000\n",
      " - 1s - loss: 4.0731e-04 - acc: 0.9922 - val_loss: 3.9659e-04 - val_acc: 0.9920\n",
      "Epoch 2234/3000\n",
      " - 1s - loss: 4.0268e-04 - acc: 0.9921 - val_loss: 3.9639e-04 - val_acc: 0.9923\n",
      "Epoch 2235/3000\n",
      " - 2s - loss: 3.9678e-04 - acc: 0.9922 - val_loss: 4.1591e-04 - val_acc: 0.9921\n",
      "Epoch 2236/3000\n",
      " - 2s - loss: 4.1568e-04 - acc: 0.9919 - val_loss: 4.1076e-04 - val_acc: 0.9916\n",
      "Epoch 2237/3000\n",
      " - 2s - loss: 4.0169e-04 - acc: 0.9922 - val_loss: 4.2154e-04 - val_acc: 0.9922\n",
      "Epoch 2238/3000\n",
      " - 1s - loss: 4.0254e-04 - acc: 0.9922 - val_loss: 4.1515e-04 - val_acc: 0.9919\n",
      "Epoch 2239/3000\n",
      " - 1s - loss: 3.9955e-04 - acc: 0.9922 - val_loss: 3.9058e-04 - val_acc: 0.9922\n",
      "Epoch 2240/3000\n",
      "\n",
      "Epoch 02240: val_loss did not improve from 0.00039\n",
      " - 2s - loss: 4.0151e-04 - acc: 0.9921 - val_loss: 3.9395e-04 - val_acc: 0.9921\n",
      "Epoch 2241/3000\n",
      " - 2s - loss: 3.9815e-04 - acc: 0.9922 - val_loss: 3.8920e-04 - val_acc: 0.9921\n",
      "Epoch 2242/3000\n",
      " - 1s - loss: 3.9815e-04 - acc: 0.9923 - val_loss: 4.3036e-04 - val_acc: 0.9913\n",
      "Epoch 2243/3000\n",
      " - 2s - loss: 4.0541e-04 - acc: 0.9920 - val_loss: 3.8422e-04 - val_acc: 0.9923\n",
      "Epoch 2244/3000\n",
      " - 2s - loss: 3.9521e-04 - acc: 0.9922 - val_loss: 3.9826e-04 - val_acc: 0.9919\n",
      "Epoch 2245/3000\n",
      " - 2s - loss: 4.0939e-04 - acc: 0.9920 - val_loss: 3.8726e-04 - val_acc: 0.9921\n",
      "Epoch 2246/3000\n",
      " - 2s - loss: 3.9834e-04 - acc: 0.9922 - val_loss: 3.8087e-04 - val_acc: 0.9923\n",
      "Epoch 2247/3000\n",
      " - 2s - loss: 3.9920e-04 - acc: 0.9922 - val_loss: 3.8494e-04 - val_acc: 0.9922\n",
      "Epoch 2248/3000\n",
      " - 2s - loss: 4.0981e-04 - acc: 0.9921 - val_loss: 3.9996e-04 - val_acc: 0.9918\n",
      "Epoch 2249/3000\n",
      " - 1s - loss: 4.0087e-04 - acc: 0.9921 - val_loss: 3.9417e-04 - val_acc: 0.9920\n",
      "Epoch 2250/3000\n",
      " - 2s - loss: 4.0276e-04 - acc: 0.9921 - val_loss: 3.9569e-04 - val_acc: 0.9921\n",
      "Epoch 2251/3000\n",
      " - 1s - loss: 4.0057e-04 - acc: 0.9921 - val_loss: 4.0198e-04 - val_acc: 0.9921\n",
      "Epoch 2252/3000\n",
      " - 1s - loss: 4.0449e-04 - acc: 0.9921 - val_loss: 4.1754e-04 - val_acc: 0.9919\n",
      "Epoch 2253/3000\n",
      " - 1s - loss: 4.0056e-04 - acc: 0.9922 - val_loss: 3.9119e-04 - val_acc: 0.9921\n",
      "Epoch 2254/3000\n",
      " - 2s - loss: 4.0143e-04 - acc: 0.9921 - val_loss: 3.9558e-04 - val_acc: 0.9921\n",
      "Epoch 2255/3000\n",
      " - 2s - loss: 4.0019e-04 - acc: 0.9923 - val_loss: 3.9136e-04 - val_acc: 0.9921\n",
      "Epoch 2256/3000\n",
      " - 1s - loss: 3.9897e-04 - acc: 0.9922 - val_loss: 3.9189e-04 - val_acc: 0.9923\n",
      "Epoch 2257/3000\n",
      " - 2s - loss: 3.9248e-04 - acc: 0.9923 - val_loss: 3.9999e-04 - val_acc: 0.9922\n",
      "Epoch 2258/3000\n",
      " - 2s - loss: 4.0473e-04 - acc: 0.9920 - val_loss: 3.8971e-04 - val_acc: 0.9922\n",
      "Epoch 2259/3000\n",
      " - 1s - loss: 3.9668e-04 - acc: 0.9922 - val_loss: 3.8780e-04 - val_acc: 0.9922\n",
      "Epoch 2260/3000\n",
      "\n",
      "Epoch 02260: val_loss did not improve from 0.00039\n",
      " - 2s - loss: 3.9637e-04 - acc: 0.9922 - val_loss: 4.3538e-04 - val_acc: 0.9916\n",
      "Epoch 2261/3000\n",
      " - 2s - loss: 3.9891e-04 - acc: 0.9922 - val_loss: 3.8493e-04 - val_acc: 0.9922\n",
      "Epoch 2262/3000\n",
      " - 2s - loss: 4.1050e-04 - acc: 0.9920 - val_loss: 4.1198e-04 - val_acc: 0.9915\n",
      "Epoch 2263/3000\n",
      " - 1s - loss: 3.9396e-04 - acc: 0.9923 - val_loss: 4.2814e-04 - val_acc: 0.9921\n",
      "Epoch 2264/3000\n",
      " - 1s - loss: 3.9820e-04 - acc: 0.9922 - val_loss: 3.8489e-04 - val_acc: 0.9923\n",
      "Epoch 2265/3000\n",
      " - 1s - loss: 4.0942e-04 - acc: 0.9921 - val_loss: 3.7922e-04 - val_acc: 0.9924\n",
      "Epoch 2266/3000\n",
      " - 2s - loss: 3.9400e-04 - acc: 0.9923 - val_loss: 3.8396e-04 - val_acc: 0.9922\n",
      "Epoch 2267/3000\n",
      " - 1s - loss: 3.9773e-04 - acc: 0.9922 - val_loss: 4.0906e-04 - val_acc: 0.9920\n",
      "Epoch 2268/3000\n",
      " - 1s - loss: 3.9822e-04 - acc: 0.9922 - val_loss: 4.7214e-04 - val_acc: 0.9913\n",
      "Epoch 2269/3000\n",
      " - 1s - loss: 4.0363e-04 - acc: 0.9920 - val_loss: 3.9033e-04 - val_acc: 0.9921\n",
      "Epoch 2270/3000\n",
      " - 2s - loss: 3.9456e-04 - acc: 0.9922 - val_loss: 3.9418e-04 - val_acc: 0.9921\n",
      "Epoch 2271/3000\n",
      " - 1s - loss: 3.9936e-04 - acc: 0.9921 - val_loss: 3.8873e-04 - val_acc: 0.9922\n",
      "Epoch 2272/3000\n",
      " - 2s - loss: 4.0115e-04 - acc: 0.9921 - val_loss: 3.9524e-04 - val_acc: 0.9920\n",
      "Epoch 2273/3000\n",
      " - 1s - loss: 3.9555e-04 - acc: 0.9922 - val_loss: 3.8711e-04 - val_acc: 0.9924\n",
      "Epoch 2274/3000\n",
      " - 2s - loss: 3.9844e-04 - acc: 0.9921 - val_loss: 3.9103e-04 - val_acc: 0.9919\n",
      "Epoch 2275/3000\n",
      " - 1s - loss: 4.0706e-04 - acc: 0.9920 - val_loss: 4.0777e-04 - val_acc: 0.9918\n",
      "Epoch 2276/3000\n",
      " - 2s - loss: 4.0023e-04 - acc: 0.9922 - val_loss: 3.9774e-04 - val_acc: 0.9921\n",
      "Epoch 2277/3000\n",
      " - 1s - loss: 3.9722e-04 - acc: 0.9922 - val_loss: 4.1448e-04 - val_acc: 0.9920\n",
      "Epoch 2278/3000\n",
      " - 2s - loss: 4.1324e-04 - acc: 0.9919 - val_loss: 3.9932e-04 - val_acc: 0.9922\n",
      "Epoch 2279/3000\n",
      " - 2s - loss: 4.2782e-04 - acc: 0.9918 - val_loss: 4.8613e-04 - val_acc: 0.9912\n",
      "Epoch 2280/3000\n",
      "\n",
      "Epoch 02280: val_loss improved from 0.00039 to 0.00039, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 4.1156e-04 - acc: 0.9917 - val_loss: 3.8598e-04 - val_acc: 0.9922\n",
      "Epoch 2281/3000\n",
      " - 2s - loss: 3.9097e-04 - acc: 0.9923 - val_loss: 3.8711e-04 - val_acc: 0.9922\n",
      "Epoch 2282/3000\n",
      " - 2s - loss: 4.0444e-04 - acc: 0.9921 - val_loss: 3.9617e-04 - val_acc: 0.9920\n",
      "Epoch 2283/3000\n",
      " - 1s - loss: 3.9335e-04 - acc: 0.9923 - val_loss: 3.9889e-04 - val_acc: 0.9922\n",
      "Epoch 2284/3000\n",
      " - 1s - loss: 3.9276e-04 - acc: 0.9922 - val_loss: 3.8880e-04 - val_acc: 0.9923\n",
      "Epoch 2285/3000\n",
      " - 2s - loss: 4.0192e-04 - acc: 0.9921 - val_loss: 3.9342e-04 - val_acc: 0.9922\n",
      "Epoch 2286/3000\n",
      " - 2s - loss: 3.9653e-04 - acc: 0.9922 - val_loss: 4.0544e-04 - val_acc: 0.9921\n",
      "Epoch 2287/3000\n",
      " - 2s - loss: 3.9638e-04 - acc: 0.9922 - val_loss: 3.9266e-04 - val_acc: 0.9922\n",
      "Epoch 2288/3000\n",
      " - 2s - loss: 3.9054e-04 - acc: 0.9923 - val_loss: 4.0303e-04 - val_acc: 0.9922\n",
      "Epoch 2289/3000\n",
      " - 2s - loss: 4.0038e-04 - acc: 0.9921 - val_loss: 3.9171e-04 - val_acc: 0.9924\n",
      "Epoch 2290/3000\n",
      " - 2s - loss: 4.0193e-04 - acc: 0.9920 - val_loss: 3.9820e-04 - val_acc: 0.9921\n",
      "Epoch 2291/3000\n",
      " - 2s - loss: 3.9805e-04 - acc: 0.9921 - val_loss: 3.8026e-04 - val_acc: 0.9923\n",
      "Epoch 2292/3000\n",
      " - 2s - loss: 3.9729e-04 - acc: 0.9922 - val_loss: 3.9754e-04 - val_acc: 0.9923\n",
      "Epoch 2293/3000\n",
      " - 2s - loss: 4.0205e-04 - acc: 0.9922 - val_loss: 4.6322e-04 - val_acc: 0.9913\n",
      "Epoch 2294/3000\n",
      " - 1s - loss: 4.1151e-04 - acc: 0.9918 - val_loss: 4.0182e-04 - val_acc: 0.9920\n",
      "Epoch 2295/3000\n",
      " - 1s - loss: 3.9985e-04 - acc: 0.9922 - val_loss: 3.9353e-04 - val_acc: 0.9921\n",
      "Epoch 2296/3000\n",
      " - 1s - loss: 3.9566e-04 - acc: 0.9922 - val_loss: 3.9461e-04 - val_acc: 0.9922\n",
      "Epoch 2297/3000\n",
      " - 1s - loss: 3.9204e-04 - acc: 0.9923 - val_loss: 3.7933e-04 - val_acc: 0.9921\n",
      "Epoch 2298/3000\n",
      " - 1s - loss: 3.9364e-04 - acc: 0.9922 - val_loss: 3.8535e-04 - val_acc: 0.9922\n",
      "Epoch 2299/3000\n",
      " - 2s - loss: 3.9710e-04 - acc: 0.9921 - val_loss: 3.9622e-04 - val_acc: 0.9922\n",
      "Epoch 2300/3000\n",
      "\n",
      "Epoch 02300: val_loss improved from 0.00039 to 0.00039, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 4.0122e-04 - acc: 0.9921 - val_loss: 3.8517e-04 - val_acc: 0.9922\n",
      "Epoch 2301/3000\n",
      " - 1s - loss: 3.9839e-04 - acc: 0.9922 - val_loss: 3.9207e-04 - val_acc: 0.9921\n",
      "Epoch 2302/3000\n",
      " - 2s - loss: 3.9870e-04 - acc: 0.9921 - val_loss: 3.9371e-04 - val_acc: 0.9921\n",
      "Epoch 2303/3000\n",
      " - 2s - loss: 3.9121e-04 - acc: 0.9923 - val_loss: 3.9778e-04 - val_acc: 0.9923\n",
      "Epoch 2304/3000\n",
      " - 2s - loss: 3.9250e-04 - acc: 0.9922 - val_loss: 3.8089e-04 - val_acc: 0.9922\n",
      "Epoch 2305/3000\n",
      " - 2s - loss: 3.9833e-04 - acc: 0.9922 - val_loss: 3.8879e-04 - val_acc: 0.9922\n",
      "Epoch 2306/3000\n",
      " - 2s - loss: 3.9353e-04 - acc: 0.9922 - val_loss: 3.9054e-04 - val_acc: 0.9921\n",
      "Epoch 2307/3000\n",
      " - 2s - loss: 3.9860e-04 - acc: 0.9921 - val_loss: 3.8221e-04 - val_acc: 0.9921\n",
      "Epoch 2308/3000\n",
      " - 1s - loss: 4.0487e-04 - acc: 0.9920 - val_loss: 4.2191e-04 - val_acc: 0.9917\n",
      "Epoch 2309/3000\n",
      " - 2s - loss: 3.9609e-04 - acc: 0.9922 - val_loss: 3.9950e-04 - val_acc: 0.9923\n",
      "Epoch 2310/3000\n",
      " - 2s - loss: 4.0326e-04 - acc: 0.9921 - val_loss: 3.8663e-04 - val_acc: 0.9922\n",
      "Epoch 2311/3000\n",
      " - 1s - loss: 3.9908e-04 - acc: 0.9921 - val_loss: 4.0359e-04 - val_acc: 0.9919\n",
      "Epoch 2312/3000\n",
      " - 2s - loss: 4.0119e-04 - acc: 0.9922 - val_loss: 3.9000e-04 - val_acc: 0.9919\n",
      "Epoch 2313/3000\n",
      " - 2s - loss: 3.9170e-04 - acc: 0.9922 - val_loss: 3.9317e-04 - val_acc: 0.9923\n",
      "Epoch 2314/3000\n",
      " - 2s - loss: 3.8762e-04 - acc: 0.9923 - val_loss: 3.8805e-04 - val_acc: 0.9923\n",
      "Epoch 2315/3000\n",
      " - 1s - loss: 3.9117e-04 - acc: 0.9923 - val_loss: 4.0248e-04 - val_acc: 0.9921\n",
      "Epoch 2316/3000\n",
      " - 1s - loss: 3.9731e-04 - acc: 0.9922 - val_loss: 3.8524e-04 - val_acc: 0.9924\n",
      "Epoch 2317/3000\n",
      " - 2s - loss: 3.9244e-04 - acc: 0.9923 - val_loss: 3.8249e-04 - val_acc: 0.9921\n",
      "Epoch 2318/3000\n",
      " - 1s - loss: 3.9574e-04 - acc: 0.9922 - val_loss: 4.1381e-04 - val_acc: 0.9921\n",
      "Epoch 2319/3000\n",
      " - 1s - loss: 3.9774e-04 - acc: 0.9921 - val_loss: 3.8461e-04 - val_acc: 0.9923\n",
      "Epoch 2320/3000\n",
      "\n",
      "Epoch 02320: val_loss did not improve from 0.00039\n",
      " - 1s - loss: 3.9735e-04 - acc: 0.9922 - val_loss: 4.1899e-04 - val_acc: 0.9918\n",
      "Epoch 2321/3000\n",
      " - 2s - loss: 3.9277e-04 - acc: 0.9922 - val_loss: 3.9315e-04 - val_acc: 0.9921\n",
      "Epoch 2322/3000\n",
      " - 2s - loss: 3.8854e-04 - acc: 0.9923 - val_loss: 4.0975e-04 - val_acc: 0.9918\n",
      "Epoch 2323/3000\n",
      " - 1s - loss: 4.0118e-04 - acc: 0.9921 - val_loss: 3.9778e-04 - val_acc: 0.9920\n",
      "Epoch 2324/3000\n",
      " - 2s - loss: 3.9220e-04 - acc: 0.9923 - val_loss: 3.9002e-04 - val_acc: 0.9921\n",
      "Epoch 2325/3000\n",
      " - 2s - loss: 3.9397e-04 - acc: 0.9922 - val_loss: 3.9375e-04 - val_acc: 0.9923\n",
      "Epoch 2326/3000\n",
      " - 2s - loss: 4.0277e-04 - acc: 0.9922 - val_loss: 4.5505e-04 - val_acc: 0.9909\n",
      "Epoch 2327/3000\n",
      " - 2s - loss: 4.0279e-04 - acc: 0.9921 - val_loss: 3.8560e-04 - val_acc: 0.9923\n",
      "Epoch 2328/3000\n",
      " - 2s - loss: 3.8953e-04 - acc: 0.9923 - val_loss: 3.9528e-04 - val_acc: 0.9921\n",
      "Epoch 2329/3000\n",
      " - 2s - loss: 4.2696e-04 - acc: 0.9916 - val_loss: 3.9204e-04 - val_acc: 0.9920\n",
      "Epoch 2330/3000\n",
      " - 2s - loss: 3.9246e-04 - acc: 0.9922 - val_loss: 3.8295e-04 - val_acc: 0.9923\n",
      "Epoch 2331/3000\n",
      " - 2s - loss: 3.9485e-04 - acc: 0.9922 - val_loss: 4.0643e-04 - val_acc: 0.9921\n",
      "Epoch 2332/3000\n",
      " - 2s - loss: 3.9935e-04 - acc: 0.9921 - val_loss: 3.9216e-04 - val_acc: 0.9921\n",
      "Epoch 2333/3000\n",
      " - 1s - loss: 3.9287e-04 - acc: 0.9923 - val_loss: 3.8947e-04 - val_acc: 0.9924\n",
      "Epoch 2334/3000\n",
      " - 1s - loss: 3.8740e-04 - acc: 0.9923 - val_loss: 3.8148e-04 - val_acc: 0.9923\n",
      "Epoch 2335/3000\n",
      " - 1s - loss: 3.9270e-04 - acc: 0.9923 - val_loss: 3.9722e-04 - val_acc: 0.9920\n",
      "Epoch 2336/3000\n",
      " - 2s - loss: 3.9606e-04 - acc: 0.9921 - val_loss: 3.9387e-04 - val_acc: 0.9919\n",
      "Epoch 2337/3000\n",
      " - 1s - loss: 3.8639e-04 - acc: 0.9923 - val_loss: 3.8227e-04 - val_acc: 0.9922\n",
      "Epoch 2338/3000\n",
      " - 2s - loss: 4.0059e-04 - acc: 0.9921 - val_loss: 3.9576e-04 - val_acc: 0.9922\n",
      "Epoch 2339/3000\n",
      " - 2s - loss: 3.8641e-04 - acc: 0.9924 - val_loss: 3.8236e-04 - val_acc: 0.9922\n",
      "Epoch 2340/3000\n",
      "\n",
      "Epoch 02340: val_loss did not improve from 0.00039\n",
      " - 2s - loss: 3.8471e-04 - acc: 0.9923 - val_loss: 3.8878e-04 - val_acc: 0.9920\n",
      "Epoch 2341/3000\n",
      " - 2s - loss: 3.9286e-04 - acc: 0.9922 - val_loss: 3.7733e-04 - val_acc: 0.9923\n",
      "Epoch 2342/3000\n",
      " - 1s - loss: 3.8593e-04 - acc: 0.9924 - val_loss: 3.8366e-04 - val_acc: 0.9922\n",
      "Epoch 2343/3000\n",
      " - 2s - loss: 3.8901e-04 - acc: 0.9923 - val_loss: 3.9507e-04 - val_acc: 0.9922\n",
      "Epoch 2344/3000\n",
      " - 1s - loss: 3.9262e-04 - acc: 0.9922 - val_loss: 3.8354e-04 - val_acc: 0.9923\n",
      "Epoch 2345/3000\n",
      " - 1s - loss: 3.8891e-04 - acc: 0.9922 - val_loss: 3.7592e-04 - val_acc: 0.9922\n",
      "Epoch 2346/3000\n",
      " - 2s - loss: 3.8659e-04 - acc: 0.9923 - val_loss: 3.9091e-04 - val_acc: 0.9923\n",
      "Epoch 2347/3000\n",
      " - 2s - loss: 3.8751e-04 - acc: 0.9923 - val_loss: 3.9215e-04 - val_acc: 0.9920\n",
      "Epoch 2348/3000\n",
      " - 2s - loss: 3.9326e-04 - acc: 0.9922 - val_loss: 3.7862e-04 - val_acc: 0.9921\n",
      "Epoch 2349/3000\n",
      " - 2s - loss: 3.9681e-04 - acc: 0.9921 - val_loss: 3.7932e-04 - val_acc: 0.9924\n",
      "Epoch 2350/3000\n",
      " - 1s - loss: 3.9316e-04 - acc: 0.9922 - val_loss: 3.8118e-04 - val_acc: 0.9923\n",
      "Epoch 2351/3000\n",
      " - 1s - loss: 3.8573e-04 - acc: 0.9923 - val_loss: 3.9004e-04 - val_acc: 0.9922\n",
      "Epoch 2352/3000\n",
      " - 2s - loss: 3.8890e-04 - acc: 0.9923 - val_loss: 3.8422e-04 - val_acc: 0.9923\n",
      "Epoch 2353/3000\n",
      " - 1s - loss: 3.9019e-04 - acc: 0.9923 - val_loss: 3.8683e-04 - val_acc: 0.9922\n",
      "Epoch 2354/3000\n",
      " - 1s - loss: 3.9885e-04 - acc: 0.9921 - val_loss: 3.8547e-04 - val_acc: 0.9922\n",
      "Epoch 2355/3000\n",
      " - 1s - loss: 3.9560e-04 - acc: 0.9922 - val_loss: 3.9340e-04 - val_acc: 0.9918\n",
      "Epoch 2356/3000\n",
      " - 2s - loss: 3.9136e-04 - acc: 0.9922 - val_loss: 3.8215e-04 - val_acc: 0.9922\n",
      "Epoch 2357/3000\n",
      " - 2s - loss: 3.9472e-04 - acc: 0.9922 - val_loss: 3.8261e-04 - val_acc: 0.9919\n",
      "Epoch 2358/3000\n",
      " - 2s - loss: 3.8883e-04 - acc: 0.9922 - val_loss: 3.8371e-04 - val_acc: 0.9920\n",
      "Epoch 2359/3000\n",
      " - 2s - loss: 3.8755e-04 - acc: 0.9923 - val_loss: 4.0249e-04 - val_acc: 0.9920\n",
      "Epoch 2360/3000\n",
      "\n",
      "Epoch 02360: val_loss improved from 0.00039 to 0.00038, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 3.8715e-04 - acc: 0.9923 - val_loss: 3.8170e-04 - val_acc: 0.9923\n",
      "Epoch 2361/3000\n",
      " - 1s - loss: 3.9376e-04 - acc: 0.9922 - val_loss: 3.8281e-04 - val_acc: 0.9922\n",
      "Epoch 2362/3000\n",
      " - 1s - loss: 3.9390e-04 - acc: 0.9922 - val_loss: 4.0085e-04 - val_acc: 0.9921\n",
      "Epoch 2363/3000\n",
      " - 1s - loss: 3.9021e-04 - acc: 0.9923 - val_loss: 3.7739e-04 - val_acc: 0.9922\n",
      "Epoch 2364/3000\n",
      " - 2s - loss: 3.8370e-04 - acc: 0.9923 - val_loss: 4.0564e-04 - val_acc: 0.9919\n",
      "Epoch 2365/3000\n",
      " - 1s - loss: 3.8476e-04 - acc: 0.9924 - val_loss: 3.7785e-04 - val_acc: 0.9920\n",
      "Epoch 2366/3000\n",
      " - 2s - loss: 3.8818e-04 - acc: 0.9923 - val_loss: 3.7552e-04 - val_acc: 0.9923\n",
      "Epoch 2367/3000\n",
      " - 2s - loss: 3.8661e-04 - acc: 0.9923 - val_loss: 3.8259e-04 - val_acc: 0.9923\n",
      "Epoch 2368/3000\n",
      " - 2s - loss: 4.0912e-04 - acc: 0.9919 - val_loss: 3.9849e-04 - val_acc: 0.9922\n",
      "Epoch 2369/3000\n",
      " - 1s - loss: 3.9191e-04 - acc: 0.9922 - val_loss: 3.8100e-04 - val_acc: 0.9924\n",
      "Epoch 2370/3000\n",
      " - 2s - loss: 4.0522e-04 - acc: 0.9921 - val_loss: 4.0060e-04 - val_acc: 0.9919\n",
      "Epoch 2371/3000\n",
      " - 1s - loss: 3.9031e-04 - acc: 0.9922 - val_loss: 3.8477e-04 - val_acc: 0.9922\n",
      "Epoch 2372/3000\n",
      " - 1s - loss: 3.9074e-04 - acc: 0.9922 - val_loss: 3.8684e-04 - val_acc: 0.9918\n",
      "Epoch 2373/3000\n",
      " - 1s - loss: 3.8809e-04 - acc: 0.9922 - val_loss: 3.9276e-04 - val_acc: 0.9921\n",
      "Epoch 2374/3000\n",
      " - 2s - loss: 3.8482e-04 - acc: 0.9923 - val_loss: 3.8267e-04 - val_acc: 0.9923\n",
      "Epoch 2375/3000\n",
      " - 1s - loss: 3.8620e-04 - acc: 0.9923 - val_loss: 3.8492e-04 - val_acc: 0.9922\n",
      "Epoch 2376/3000\n",
      " - 2s - loss: 3.8788e-04 - acc: 0.9923 - val_loss: 3.8189e-04 - val_acc: 0.9922\n",
      "Epoch 2377/3000\n",
      " - 2s - loss: 3.8527e-04 - acc: 0.9923 - val_loss: 3.8510e-04 - val_acc: 0.9923\n",
      "Epoch 2378/3000\n",
      " - 2s - loss: 3.8907e-04 - acc: 0.9923 - val_loss: 3.9641e-04 - val_acc: 0.9922\n",
      "Epoch 2379/3000\n",
      " - 2s - loss: 3.8284e-04 - acc: 0.9923 - val_loss: 3.7853e-04 - val_acc: 0.9922\n",
      "Epoch 2380/3000\n",
      "\n",
      "Epoch 02380: val_loss did not improve from 0.00038\n",
      " - 2s - loss: 3.9561e-04 - acc: 0.9922 - val_loss: 3.8298e-04 - val_acc: 0.9921\n",
      "Epoch 2381/3000\n",
      " - 1s - loss: 3.9761e-04 - acc: 0.9921 - val_loss: 4.0293e-04 - val_acc: 0.9918\n",
      "Epoch 2382/3000\n",
      " - 1s - loss: 3.9427e-04 - acc: 0.9922 - val_loss: 4.2574e-04 - val_acc: 0.9913\n",
      "Epoch 2383/3000\n",
      " - 2s - loss: 3.8535e-04 - acc: 0.9923 - val_loss: 3.7889e-04 - val_acc: 0.9923\n",
      "Epoch 2384/3000\n",
      " - 2s - loss: 3.8380e-04 - acc: 0.9924 - val_loss: 4.0681e-04 - val_acc: 0.9923\n",
      "Epoch 2385/3000\n",
      " - 1s - loss: 3.8789e-04 - acc: 0.9922 - val_loss: 3.9999e-04 - val_acc: 0.9922\n",
      "Epoch 2386/3000\n",
      " - 2s - loss: 3.8889e-04 - acc: 0.9922 - val_loss: 3.7610e-04 - val_acc: 0.9924\n",
      "Epoch 2387/3000\n",
      " - 2s - loss: 3.8936e-04 - acc: 0.9922 - val_loss: 3.9842e-04 - val_acc: 0.9923\n",
      "Epoch 2388/3000\n",
      " - 2s - loss: 3.9209e-04 - acc: 0.9922 - val_loss: 3.8490e-04 - val_acc: 0.9921\n",
      "Epoch 2389/3000\n",
      " - 2s - loss: 3.8531e-04 - acc: 0.9923 - val_loss: 4.0458e-04 - val_acc: 0.9921\n",
      "Epoch 2390/3000\n",
      " - 1s - loss: 3.8376e-04 - acc: 0.9924 - val_loss: 3.7720e-04 - val_acc: 0.9924\n",
      "Epoch 2391/3000\n",
      " - 2s - loss: 3.8581e-04 - acc: 0.9924 - val_loss: 3.8062e-04 - val_acc: 0.9922\n",
      "Epoch 2392/3000\n",
      " - 2s - loss: 3.8893e-04 - acc: 0.9923 - val_loss: 3.9281e-04 - val_acc: 0.9919\n",
      "Epoch 2393/3000\n",
      " - 1s - loss: 4.0462e-04 - acc: 0.9920 - val_loss: 3.8122e-04 - val_acc: 0.9924\n",
      "Epoch 2394/3000\n",
      " - 2s - loss: 3.8516e-04 - acc: 0.9923 - val_loss: 3.7878e-04 - val_acc: 0.9922\n",
      "Epoch 2395/3000\n",
      " - 2s - loss: 3.9129e-04 - acc: 0.9923 - val_loss: 4.0170e-04 - val_acc: 0.9915\n",
      "Epoch 2396/3000\n",
      " - 2s - loss: 3.9052e-04 - acc: 0.9922 - val_loss: 4.1426e-04 - val_acc: 0.9921\n",
      "Epoch 2397/3000\n",
      " - 1s - loss: 3.9704e-04 - acc: 0.9921 - val_loss: 3.8403e-04 - val_acc: 0.9922\n",
      "Epoch 2398/3000\n",
      " - 2s - loss: 3.8792e-04 - acc: 0.9923 - val_loss: 3.7879e-04 - val_acc: 0.9924\n",
      "Epoch 2399/3000\n",
      " - 1s - loss: 3.8801e-04 - acc: 0.9923 - val_loss: 3.9024e-04 - val_acc: 0.9920\n",
      "Epoch 2400/3000\n",
      "\n",
      "Epoch 02400: val_loss improved from 0.00038 to 0.00038, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 3.9151e-04 - acc: 0.9922 - val_loss: 3.7712e-04 - val_acc: 0.9922\n",
      "Epoch 2401/3000\n",
      " - 2s - loss: 3.9413e-04 - acc: 0.9921 - val_loss: 4.0279e-04 - val_acc: 0.9921\n",
      "Epoch 2402/3000\n",
      " - 2s - loss: 3.9034e-04 - acc: 0.9922 - val_loss: 3.8202e-04 - val_acc: 0.9922\n",
      "Epoch 2403/3000\n",
      " - 1s - loss: 3.8829e-04 - acc: 0.9923 - val_loss: 3.9178e-04 - val_acc: 0.9919\n",
      "Epoch 2404/3000\n",
      " - 1s - loss: 3.8397e-04 - acc: 0.9923 - val_loss: 3.7600e-04 - val_acc: 0.9923\n",
      "Epoch 2405/3000\n",
      " - 1s - loss: 3.8901e-04 - acc: 0.9923 - val_loss: 3.7992e-04 - val_acc: 0.9923\n",
      "Epoch 2406/3000\n",
      " - 2s - loss: 3.9148e-04 - acc: 0.9922 - val_loss: 3.8463e-04 - val_acc: 0.9924\n",
      "Epoch 2407/3000\n",
      " - 2s - loss: 3.9257e-04 - acc: 0.9922 - val_loss: 3.7610e-04 - val_acc: 0.9924\n",
      "Epoch 2408/3000\n",
      " - 2s - loss: 3.8408e-04 - acc: 0.9924 - val_loss: 3.8560e-04 - val_acc: 0.9923\n",
      "Epoch 2409/3000\n",
      " - 1s - loss: 3.8737e-04 - acc: 0.9923 - val_loss: 3.9469e-04 - val_acc: 0.9920\n",
      "Epoch 2410/3000\n",
      " - 2s - loss: 4.0007e-04 - acc: 0.9921 - val_loss: 3.9059e-04 - val_acc: 0.9922\n",
      "Epoch 2411/3000\n",
      " - 1s - loss: 3.8752e-04 - acc: 0.9923 - val_loss: 3.8281e-04 - val_acc: 0.9920\n",
      "Epoch 2412/3000\n",
      " - 1s - loss: 3.8824e-04 - acc: 0.9923 - val_loss: 3.8634e-04 - val_acc: 0.9923\n",
      "Epoch 2413/3000\n",
      " - 2s - loss: 3.9122e-04 - acc: 0.9922 - val_loss: 3.8608e-04 - val_acc: 0.9921\n",
      "Epoch 2414/3000\n",
      " - 2s - loss: 3.8315e-04 - acc: 0.9923 - val_loss: 4.1647e-04 - val_acc: 0.9920\n",
      "Epoch 2415/3000\n",
      " - 1s - loss: 3.9540e-04 - acc: 0.9922 - val_loss: 3.9174e-04 - val_acc: 0.9919\n",
      "Epoch 2416/3000\n",
      " - 2s - loss: 3.9023e-04 - acc: 0.9922 - val_loss: 3.8897e-04 - val_acc: 0.9919\n",
      "Epoch 2417/3000\n",
      " - 1s - loss: 3.9281e-04 - acc: 0.9922 - val_loss: 3.7619e-04 - val_acc: 0.9920\n",
      "Epoch 2418/3000\n",
      " - 2s - loss: 3.8893e-04 - acc: 0.9923 - val_loss: 3.7698e-04 - val_acc: 0.9924\n",
      "Epoch 2419/3000\n",
      " - 1s - loss: 3.8660e-04 - acc: 0.9923 - val_loss: 4.0742e-04 - val_acc: 0.9923\n",
      "Epoch 2420/3000\n",
      "\n",
      "Epoch 02420: val_loss did not improve from 0.00038\n",
      " - 2s - loss: 3.9394e-04 - acc: 0.9922 - val_loss: 3.7980e-04 - val_acc: 0.9922\n",
      "Epoch 2421/3000\n",
      " - 2s - loss: 3.8246e-04 - acc: 0.9923 - val_loss: 3.7512e-04 - val_acc: 0.9923\n",
      "Epoch 2422/3000\n",
      " - 2s - loss: 3.8308e-04 - acc: 0.9923 - val_loss: 3.7576e-04 - val_acc: 0.9924\n",
      "Epoch 2423/3000\n",
      " - 1s - loss: 3.8650e-04 - acc: 0.9923 - val_loss: 3.9506e-04 - val_acc: 0.9921\n",
      "Epoch 2424/3000\n",
      " - 2s - loss: 4.0028e-04 - acc: 0.9919 - val_loss: 3.7489e-04 - val_acc: 0.9922\n",
      "Epoch 2425/3000\n",
      " - 2s - loss: 3.9005e-04 - acc: 0.9923 - val_loss: 4.0005e-04 - val_acc: 0.9918\n",
      "Epoch 2426/3000\n",
      " - 1s - loss: 3.9175e-04 - acc: 0.9922 - val_loss: 3.7687e-04 - val_acc: 0.9923\n",
      "Epoch 2427/3000\n",
      " - 2s - loss: 3.8916e-04 - acc: 0.9923 - val_loss: 3.7385e-04 - val_acc: 0.9924\n",
      "Epoch 2428/3000\n",
      " - 2s - loss: 3.8326e-04 - acc: 0.9924 - val_loss: 3.9559e-04 - val_acc: 0.9921\n",
      "Epoch 2429/3000\n",
      " - 2s - loss: 3.8627e-04 - acc: 0.9923 - val_loss: 3.7523e-04 - val_acc: 0.9924\n",
      "Epoch 2430/3000\n",
      " - 2s - loss: 4.0340e-04 - acc: 0.9921 - val_loss: 3.8474e-04 - val_acc: 0.9920\n",
      "Epoch 2431/3000\n",
      " - 1s - loss: 3.8850e-04 - acc: 0.9922 - val_loss: 3.8536e-04 - val_acc: 0.9922\n",
      "Epoch 2432/3000\n",
      " - 2s - loss: 3.9450e-04 - acc: 0.9923 - val_loss: 3.7592e-04 - val_acc: 0.9923\n",
      "Epoch 2433/3000\n",
      " - 1s - loss: 3.8368e-04 - acc: 0.9924 - val_loss: 3.7682e-04 - val_acc: 0.9923\n",
      "Epoch 2434/3000\n",
      " - 2s - loss: 3.8301e-04 - acc: 0.9923 - val_loss: 3.7917e-04 - val_acc: 0.9925\n",
      "Epoch 2435/3000\n",
      " - 2s - loss: 3.8629e-04 - acc: 0.9923 - val_loss: 3.8190e-04 - val_acc: 0.9921\n",
      "Epoch 2436/3000\n",
      " - 1s - loss: 3.9702e-04 - acc: 0.9921 - val_loss: 3.8326e-04 - val_acc: 0.9920\n",
      "Epoch 2437/3000\n",
      " - 2s - loss: 3.9089e-04 - acc: 0.9923 - val_loss: 4.1068e-04 - val_acc: 0.9911\n",
      "Epoch 2438/3000\n",
      " - 2s - loss: 3.9191e-04 - acc: 0.9922 - val_loss: 3.8700e-04 - val_acc: 0.9923\n",
      "Epoch 2439/3000\n",
      " - 2s - loss: 3.8310e-04 - acc: 0.9923 - val_loss: 3.9190e-04 - val_acc: 0.9923\n",
      "Epoch 2440/3000\n",
      "\n",
      "Epoch 02440: val_loss did not improve from 0.00038\n",
      " - 1s - loss: 3.9581e-04 - acc: 0.9921 - val_loss: 3.8599e-04 - val_acc: 0.9922\n",
      "Epoch 2441/3000\n",
      " - 2s - loss: 3.8815e-04 - acc: 0.9923 - val_loss: 3.8419e-04 - val_acc: 0.9921\n",
      "Epoch 2442/3000\n",
      " - 2s - loss: 3.9244e-04 - acc: 0.9922 - val_loss: 4.0918e-04 - val_acc: 0.9919\n",
      "Epoch 2443/3000\n",
      " - 1s - loss: 3.9434e-04 - acc: 0.9921 - val_loss: 3.8209e-04 - val_acc: 0.9924\n",
      "Epoch 2444/3000\n",
      " - 1s - loss: 3.8508e-04 - acc: 0.9923 - val_loss: 3.8535e-04 - val_acc: 0.9923\n",
      "Epoch 2445/3000\n",
      " - 2s - loss: 3.8366e-04 - acc: 0.9924 - val_loss: 3.7447e-04 - val_acc: 0.9923\n",
      "Epoch 2446/3000\n",
      " - 1s - loss: 3.8723e-04 - acc: 0.9922 - val_loss: 3.8673e-04 - val_acc: 0.9919\n",
      "Epoch 2447/3000\n",
      " - 2s - loss: 3.9015e-04 - acc: 0.9922 - val_loss: 4.3485e-04 - val_acc: 0.9917\n",
      "Epoch 2448/3000\n",
      " - 1s - loss: 4.1400e-04 - acc: 0.9919 - val_loss: 3.9616e-04 - val_acc: 0.9920\n",
      "Epoch 2449/3000\n",
      " - 2s - loss: 3.9703e-04 - acc: 0.9921 - val_loss: 3.8320e-04 - val_acc: 0.9919\n",
      "Epoch 2450/3000\n",
      " - 2s - loss: 3.8897e-04 - acc: 0.9922 - val_loss: 3.8260e-04 - val_acc: 0.9921\n",
      "Epoch 2451/3000\n",
      " - 1s - loss: 3.8068e-04 - acc: 0.9924 - val_loss: 3.7577e-04 - val_acc: 0.9923\n",
      "Epoch 2452/3000\n",
      " - 2s - loss: 3.8967e-04 - acc: 0.9922 - val_loss: 3.9235e-04 - val_acc: 0.9921\n",
      "Epoch 2453/3000\n",
      " - 1s - loss: 3.8916e-04 - acc: 0.9923 - val_loss: 4.5404e-04 - val_acc: 0.9913\n",
      "Epoch 2454/3000\n",
      " - 1s - loss: 3.9083e-04 - acc: 0.9922 - val_loss: 3.7379e-04 - val_acc: 0.9923\n",
      "Epoch 2455/3000\n",
      " - 1s - loss: 3.8590e-04 - acc: 0.9924 - val_loss: 3.8352e-04 - val_acc: 0.9921\n",
      "Epoch 2456/3000\n",
      " - 2s - loss: 3.8142e-04 - acc: 0.9923 - val_loss: 3.7978e-04 - val_acc: 0.9924\n",
      "Epoch 2457/3000\n",
      " - 2s - loss: 3.8510e-04 - acc: 0.9922 - val_loss: 3.8238e-04 - val_acc: 0.9923\n",
      "Epoch 2458/3000\n",
      " - 2s - loss: 4.2764e-04 - acc: 0.9917 - val_loss: 4.1980e-04 - val_acc: 0.9913\n",
      "Epoch 2459/3000\n",
      " - 2s - loss: 3.8987e-04 - acc: 0.9922 - val_loss: 3.7597e-04 - val_acc: 0.9925\n",
      "Epoch 2460/3000\n",
      "\n",
      "Epoch 02460: val_loss did not improve from 0.00038\n",
      " - 1s - loss: 3.7763e-04 - acc: 0.9924 - val_loss: 3.8417e-04 - val_acc: 0.9921\n",
      "Epoch 2461/3000\n",
      " - 1s - loss: 3.8743e-04 - acc: 0.9923 - val_loss: 3.8693e-04 - val_acc: 0.9919\n",
      "Epoch 2462/3000\n",
      " - 1s - loss: 3.7937e-04 - acc: 0.9923 - val_loss: 3.7314e-04 - val_acc: 0.9923\n",
      "Epoch 2463/3000\n",
      " - 2s - loss: 3.7841e-04 - acc: 0.9924 - val_loss: 3.9066e-04 - val_acc: 0.9920\n",
      "Epoch 2464/3000\n",
      " - 2s - loss: 3.8531e-04 - acc: 0.9923 - val_loss: 3.8244e-04 - val_acc: 0.9923\n",
      "Epoch 2465/3000\n",
      " - 1s - loss: 3.8007e-04 - acc: 0.9923 - val_loss: 3.7442e-04 - val_acc: 0.9919\n",
      "Epoch 2466/3000\n",
      " - 1s - loss: 3.8685e-04 - acc: 0.9923 - val_loss: 3.9423e-04 - val_acc: 0.9923\n",
      "Epoch 2467/3000\n",
      " - 2s - loss: 3.8144e-04 - acc: 0.9923 - val_loss: 3.8727e-04 - val_acc: 0.9921\n",
      "Epoch 2468/3000\n",
      " - 1s - loss: 4.0379e-04 - acc: 0.9920 - val_loss: 3.9040e-04 - val_acc: 0.9922\n",
      "Epoch 2469/3000\n",
      " - 2s - loss: 3.8973e-04 - acc: 0.9922 - val_loss: 3.7977e-04 - val_acc: 0.9922\n",
      "Epoch 2470/3000\n",
      " - 2s - loss: 3.8485e-04 - acc: 0.9922 - val_loss: 3.8127e-04 - val_acc: 0.9923\n",
      "Epoch 2471/3000\n",
      " - 2s - loss: 3.8944e-04 - acc: 0.9922 - val_loss: 3.8311e-04 - val_acc: 0.9924\n",
      "Epoch 2472/3000\n",
      " - 1s - loss: 3.8779e-04 - acc: 0.9923 - val_loss: 3.7805e-04 - val_acc: 0.9924\n",
      "Epoch 2473/3000\n",
      " - 1s - loss: 3.9272e-04 - acc: 0.9920 - val_loss: 3.7933e-04 - val_acc: 0.9922\n",
      "Epoch 2474/3000\n",
      " - 2s - loss: 3.8804e-04 - acc: 0.9923 - val_loss: 3.7890e-04 - val_acc: 0.9923\n",
      "Epoch 2475/3000\n",
      " - 2s - loss: 3.8717e-04 - acc: 0.9922 - val_loss: 3.9582e-04 - val_acc: 0.9923\n",
      "Epoch 2476/3000\n",
      " - 1s - loss: 3.8448e-04 - acc: 0.9923 - val_loss: 3.8191e-04 - val_acc: 0.9918\n",
      "Epoch 2477/3000\n",
      " - 2s - loss: 3.8079e-04 - acc: 0.9923 - val_loss: 3.7680e-04 - val_acc: 0.9923\n",
      "Epoch 2478/3000\n",
      " - 1s - loss: 3.9043e-04 - acc: 0.9922 - val_loss: 3.7475e-04 - val_acc: 0.9923\n",
      "Epoch 2479/3000\n",
      " - 1s - loss: 3.7967e-04 - acc: 0.9923 - val_loss: 4.6815e-04 - val_acc: 0.9922\n",
      "Epoch 2480/3000\n",
      "\n",
      "Epoch 02480: val_loss improved from 0.00038 to 0.00038, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 3.9325e-04 - acc: 0.9922 - val_loss: 3.7630e-04 - val_acc: 0.9924\n",
      "Epoch 2481/3000\n",
      " - 1s - loss: 3.8334e-04 - acc: 0.9923 - val_loss: 3.7961e-04 - val_acc: 0.9925\n",
      "Epoch 2482/3000\n",
      " - 2s - loss: 3.8756e-04 - acc: 0.9923 - val_loss: 3.8006e-04 - val_acc: 0.9924\n",
      "Epoch 2483/3000\n",
      " - 1s - loss: 3.8009e-04 - acc: 0.9924 - val_loss: 3.8579e-04 - val_acc: 0.9924\n",
      "Epoch 2484/3000\n",
      " - 2s - loss: 3.9124e-04 - acc: 0.9922 - val_loss: 4.0712e-04 - val_acc: 0.9918\n",
      "Epoch 2485/3000\n",
      " - 2s - loss: 3.8394e-04 - acc: 0.9923 - val_loss: 3.7310e-04 - val_acc: 0.9924\n",
      "Epoch 2486/3000\n",
      " - 1s - loss: 3.8914e-04 - acc: 0.9922 - val_loss: 3.9022e-04 - val_acc: 0.9921\n",
      "Epoch 2487/3000\n",
      " - 2s - loss: 3.8998e-04 - acc: 0.9922 - val_loss: 3.9496e-04 - val_acc: 0.9920\n",
      "Epoch 2488/3000\n",
      " - 2s - loss: 3.7754e-04 - acc: 0.9924 - val_loss: 3.8565e-04 - val_acc: 0.9920\n",
      "Epoch 2489/3000\n",
      " - 1s - loss: 3.9228e-04 - acc: 0.9923 - val_loss: 3.8610e-04 - val_acc: 0.9921\n",
      "Epoch 2490/3000\n",
      " - 2s - loss: 3.8537e-04 - acc: 0.9923 - val_loss: 4.7407e-04 - val_acc: 0.9920\n",
      "Epoch 2491/3000\n",
      " - 2s - loss: 4.0223e-04 - acc: 0.9921 - val_loss: 3.8382e-04 - val_acc: 0.9922\n",
      "Epoch 2492/3000\n",
      " - 1s - loss: 3.8786e-04 - acc: 0.9922 - val_loss: 3.8284e-04 - val_acc: 0.9921\n",
      "Epoch 2493/3000\n",
      " - 2s - loss: 3.8212e-04 - acc: 0.9923 - val_loss: 3.7845e-04 - val_acc: 0.9920\n",
      "Epoch 2494/3000\n",
      " - 2s - loss: 3.7951e-04 - acc: 0.9923 - val_loss: 3.9850e-04 - val_acc: 0.9923\n",
      "Epoch 2495/3000\n",
      " - 1s - loss: 3.8254e-04 - acc: 0.9923 - val_loss: 3.9516e-04 - val_acc: 0.9921\n",
      "Epoch 2496/3000\n",
      " - 2s - loss: 3.8184e-04 - acc: 0.9923 - val_loss: 3.9024e-04 - val_acc: 0.9921\n",
      "Epoch 2497/3000\n",
      " - 2s - loss: 3.8414e-04 - acc: 0.9923 - val_loss: 3.9660e-04 - val_acc: 0.9920\n",
      "Epoch 2498/3000\n",
      " - 2s - loss: 3.8955e-04 - acc: 0.9921 - val_loss: 3.7015e-04 - val_acc: 0.9923\n",
      "Epoch 2499/3000\n",
      " - 2s - loss: 3.8951e-04 - acc: 0.9923 - val_loss: 3.7427e-04 - val_acc: 0.9924\n",
      "Epoch 2500/3000\n",
      "\n",
      "Epoch 02500: val_loss did not improve from 0.00038\n",
      " - 1s - loss: 3.8147e-04 - acc: 0.9923 - val_loss: 3.8876e-04 - val_acc: 0.9923\n",
      "Epoch 2501/3000\n",
      " - 1s - loss: 3.8132e-04 - acc: 0.9923 - val_loss: 3.7000e-04 - val_acc: 0.9923\n",
      "Epoch 2502/3000\n",
      " - 2s - loss: 3.8491e-04 - acc: 0.9923 - val_loss: 3.7596e-04 - val_acc: 0.9924\n",
      "Epoch 2503/3000\n",
      " - 2s - loss: 3.8370e-04 - acc: 0.9923 - val_loss: 3.7393e-04 - val_acc: 0.9924\n",
      "Epoch 2504/3000\n",
      " - 1s - loss: 3.8438e-04 - acc: 0.9923 - val_loss: 3.7569e-04 - val_acc: 0.9924\n",
      "Epoch 2505/3000\n",
      " - 2s - loss: 3.8375e-04 - acc: 0.9924 - val_loss: 3.8117e-04 - val_acc: 0.9923\n",
      "Epoch 2506/3000\n",
      " - 2s - loss: 3.7755e-04 - acc: 0.9924 - val_loss: 3.7917e-04 - val_acc: 0.9921\n",
      "Epoch 2507/3000\n",
      " - 2s - loss: 3.8789e-04 - acc: 0.9922 - val_loss: 3.7154e-04 - val_acc: 0.9924\n",
      "Epoch 2508/3000\n",
      " - 2s - loss: 3.7837e-04 - acc: 0.9924 - val_loss: 3.7418e-04 - val_acc: 0.9924\n",
      "Epoch 2509/3000\n",
      " - 2s - loss: 3.8466e-04 - acc: 0.9923 - val_loss: 3.9075e-04 - val_acc: 0.9920\n",
      "Epoch 2510/3000\n",
      " - 1s - loss: 3.9441e-04 - acc: 0.9921 - val_loss: 3.7588e-04 - val_acc: 0.9922\n",
      "Epoch 2511/3000\n",
      " - 1s - loss: 3.7763e-04 - acc: 0.9924 - val_loss: 3.8128e-04 - val_acc: 0.9923\n",
      "Epoch 2512/3000\n",
      " - 2s - loss: 3.8399e-04 - acc: 0.9923 - val_loss: 3.8346e-04 - val_acc: 0.9915\n",
      "Epoch 2513/3000\n",
      " - 1s - loss: 3.8198e-04 - acc: 0.9923 - val_loss: 3.7961e-04 - val_acc: 0.9924\n",
      "Epoch 2514/3000\n",
      " - 2s - loss: 3.8461e-04 - acc: 0.9923 - val_loss: 3.6936e-04 - val_acc: 0.9923\n",
      "Epoch 2515/3000\n",
      " - 2s - loss: 3.8532e-04 - acc: 0.9922 - val_loss: 3.8939e-04 - val_acc: 0.9919\n",
      "Epoch 2516/3000\n",
      " - 2s - loss: 3.8026e-04 - acc: 0.9923 - val_loss: 3.8041e-04 - val_acc: 0.9920\n",
      "Epoch 2517/3000\n",
      " - 2s - loss: 3.7422e-04 - acc: 0.9924 - val_loss: 3.7374e-04 - val_acc: 0.9923\n",
      "Epoch 2518/3000\n",
      " - 2s - loss: 3.9592e-04 - acc: 0.9921 - val_loss: 3.8838e-04 - val_acc: 0.9922\n",
      "Epoch 2519/3000\n",
      " - 2s - loss: 3.8440e-04 - acc: 0.9922 - val_loss: 3.7888e-04 - val_acc: 0.9922\n",
      "Epoch 2520/3000\n",
      "\n",
      "Epoch 02520: val_loss did not improve from 0.00038\n",
      " - 1s - loss: 3.8550e-04 - acc: 0.9923 - val_loss: 3.8916e-04 - val_acc: 0.9921\n",
      "Epoch 2521/3000\n",
      " - 2s - loss: 3.8350e-04 - acc: 0.9923 - val_loss: 3.7248e-04 - val_acc: 0.9923\n",
      "Epoch 2522/3000\n",
      " - 2s - loss: 3.8982e-04 - acc: 0.9922 - val_loss: 3.7050e-04 - val_acc: 0.9921\n",
      "Epoch 2523/3000\n",
      " - 2s - loss: 3.8473e-04 - acc: 0.9923 - val_loss: 3.7874e-04 - val_acc: 0.9924\n",
      "Epoch 2524/3000\n",
      " - 1s - loss: 3.8897e-04 - acc: 0.9921 - val_loss: 3.8129e-04 - val_acc: 0.9919\n",
      "Epoch 2525/3000\n",
      " - 2s - loss: 3.7952e-04 - acc: 0.9924 - val_loss: 3.7355e-04 - val_acc: 0.9920\n",
      "Epoch 2526/3000\n",
      " - 2s - loss: 4.1422e-04 - acc: 0.9919 - val_loss: 3.9749e-04 - val_acc: 0.9920\n",
      "Epoch 2527/3000\n",
      " - 1s - loss: 3.9146e-04 - acc: 0.9921 - val_loss: 3.8374e-04 - val_acc: 0.9921\n",
      "Epoch 2528/3000\n",
      " - 2s - loss: 3.9046e-04 - acc: 0.9921 - val_loss: 3.7948e-04 - val_acc: 0.9923\n",
      "Epoch 2529/3000\n",
      " - 1s - loss: 3.8452e-04 - acc: 0.9923 - val_loss: 4.0080e-04 - val_acc: 0.9919\n",
      "Epoch 2530/3000\n",
      " - 2s - loss: 3.8804e-04 - acc: 0.9921 - val_loss: 3.8415e-04 - val_acc: 0.9924\n",
      "Epoch 2531/3000\n",
      " - 1s - loss: 3.8112e-04 - acc: 0.9923 - val_loss: 3.7833e-04 - val_acc: 0.9924\n",
      "Epoch 2532/3000\n",
      " - 2s - loss: 3.7867e-04 - acc: 0.9923 - val_loss: 3.6651e-04 - val_acc: 0.9925\n",
      "Epoch 2533/3000\n",
      " - 1s - loss: 3.8378e-04 - acc: 0.9923 - val_loss: 3.8389e-04 - val_acc: 0.9920\n",
      "Epoch 2534/3000\n",
      " - 1s - loss: 3.9649e-04 - acc: 0.9921 - val_loss: 3.7579e-04 - val_acc: 0.9923\n",
      "Epoch 2535/3000\n",
      " - 2s - loss: 3.8177e-04 - acc: 0.9923 - val_loss: 3.6831e-04 - val_acc: 0.9922\n",
      "Epoch 2536/3000\n",
      " - 2s - loss: 3.7970e-04 - acc: 0.9923 - val_loss: 3.7341e-04 - val_acc: 0.9924\n",
      "Epoch 2537/3000\n",
      " - 2s - loss: 3.8118e-04 - acc: 0.9923 - val_loss: 3.9308e-04 - val_acc: 0.9923\n",
      "Epoch 2538/3000\n",
      " - 2s - loss: 3.9082e-04 - acc: 0.9922 - val_loss: 4.1876e-04 - val_acc: 0.9922\n",
      "Epoch 2539/3000\n",
      " - 2s - loss: 4.1056e-04 - acc: 0.9919 - val_loss: 3.7952e-04 - val_acc: 0.9921\n",
      "Epoch 2540/3000\n",
      "\n",
      "Epoch 02540: val_loss did not improve from 0.00038\n",
      " - 2s - loss: 3.7428e-04 - acc: 0.9925 - val_loss: 3.8130e-04 - val_acc: 0.9922\n",
      "Epoch 2541/3000\n",
      " - 1s - loss: 3.8086e-04 - acc: 0.9923 - val_loss: 3.7064e-04 - val_acc: 0.9920\n",
      "Epoch 2542/3000\n",
      " - 2s - loss: 3.7866e-04 - acc: 0.9923 - val_loss: 3.7691e-04 - val_acc: 0.9923\n",
      "Epoch 2543/3000\n",
      " - 1s - loss: 4.0152e-04 - acc: 0.9919 - val_loss: 3.9205e-04 - val_acc: 0.9919\n",
      "Epoch 2544/3000\n",
      " - 1s - loss: 3.9066e-04 - acc: 0.9922 - val_loss: 3.6997e-04 - val_acc: 0.9924\n",
      "Epoch 2545/3000\n",
      " - 2s - loss: 3.8462e-04 - acc: 0.9922 - val_loss: 4.1367e-04 - val_acc: 0.9914\n",
      "Epoch 2546/3000\n",
      " - 2s - loss: 3.7644e-04 - acc: 0.9923 - val_loss: 3.8788e-04 - val_acc: 0.9924\n",
      "Epoch 2547/3000\n",
      " - 2s - loss: 3.8443e-04 - acc: 0.9923 - val_loss: 3.7908e-04 - val_acc: 0.9922\n",
      "Epoch 2548/3000\n",
      " - 1s - loss: 3.8301e-04 - acc: 0.9922 - val_loss: 3.7021e-04 - val_acc: 0.9923\n",
      "Epoch 2549/3000\n",
      " - 1s - loss: 3.8440e-04 - acc: 0.9923 - val_loss: 3.8134e-04 - val_acc: 0.9923\n",
      "Epoch 2550/3000\n",
      " - 1s - loss: 3.7500e-04 - acc: 0.9924 - val_loss: 3.8716e-04 - val_acc: 0.9925\n",
      "Epoch 2551/3000\n",
      " - 2s - loss: 3.8929e-04 - acc: 0.9922 - val_loss: 3.7679e-04 - val_acc: 0.9924\n",
      "Epoch 2552/3000\n",
      " - 2s - loss: 3.7963e-04 - acc: 0.9924 - val_loss: 3.9072e-04 - val_acc: 0.9920\n",
      "Epoch 2553/3000\n",
      " - 1s - loss: 3.7952e-04 - acc: 0.9924 - val_loss: 3.6870e-04 - val_acc: 0.9925\n",
      "Epoch 2554/3000\n",
      " - 2s - loss: 3.7551e-04 - acc: 0.9924 - val_loss: 3.6791e-04 - val_acc: 0.9924\n",
      "Epoch 2555/3000\n",
      " - 2s - loss: 3.9042e-04 - acc: 0.9921 - val_loss: 3.7918e-04 - val_acc: 0.9920\n",
      "Epoch 2556/3000\n",
      " - 2s - loss: 3.8981e-04 - acc: 0.9921 - val_loss: 3.8667e-04 - val_acc: 0.9918\n",
      "Epoch 2557/3000\n",
      " - 2s - loss: 3.8323e-04 - acc: 0.9923 - val_loss: 3.8416e-04 - val_acc: 0.9921\n",
      "Epoch 2558/3000\n",
      " - 2s - loss: 3.8974e-04 - acc: 0.9923 - val_loss: 3.8183e-04 - val_acc: 0.9921\n",
      "Epoch 2559/3000\n",
      " - 2s - loss: 3.8767e-04 - acc: 0.9923 - val_loss: 3.9964e-04 - val_acc: 0.9914\n",
      "Epoch 2560/3000\n",
      "\n",
      "Epoch 02560: val_loss did not improve from 0.00038\n",
      " - 2s - loss: 3.7826e-04 - acc: 0.9923 - val_loss: 3.8572e-04 - val_acc: 0.9923\n",
      "Epoch 2561/3000\n",
      " - 1s - loss: 3.7629e-04 - acc: 0.9924 - val_loss: 3.7608e-04 - val_acc: 0.9921\n",
      "Epoch 2562/3000\n",
      " - 2s - loss: 3.7815e-04 - acc: 0.9923 - val_loss: 3.7534e-04 - val_acc: 0.9923\n",
      "Epoch 2563/3000\n",
      " - 2s - loss: 3.8073e-04 - acc: 0.9923 - val_loss: 3.8756e-04 - val_acc: 0.9922\n",
      "Epoch 2564/3000\n",
      " - 1s - loss: 3.8059e-04 - acc: 0.9923 - val_loss: 3.8360e-04 - val_acc: 0.9922\n",
      "Epoch 2565/3000\n",
      " - 2s - loss: 3.7537e-04 - acc: 0.9924 - val_loss: 3.7509e-04 - val_acc: 0.9921\n",
      "Epoch 2566/3000\n",
      " - 2s - loss: 3.8306e-04 - acc: 0.9922 - val_loss: 3.7615e-04 - val_acc: 0.9924\n",
      "Epoch 2567/3000\n",
      " - 2s - loss: 3.9177e-04 - acc: 0.9921 - val_loss: 3.7275e-04 - val_acc: 0.9924\n",
      "Epoch 2568/3000\n",
      " - 1s - loss: 3.7385e-04 - acc: 0.9924 - val_loss: 3.7545e-04 - val_acc: 0.9923\n",
      "Epoch 2569/3000\n",
      " - 2s - loss: 3.8023e-04 - acc: 0.9922 - val_loss: 3.6998e-04 - val_acc: 0.9924\n",
      "Epoch 2570/3000\n",
      " - 2s - loss: 3.8025e-04 - acc: 0.9923 - val_loss: 3.7265e-04 - val_acc: 0.9924\n",
      "Epoch 2571/3000\n",
      " - 1s - loss: 3.7473e-04 - acc: 0.9924 - val_loss: 3.8399e-04 - val_acc: 0.9922\n",
      "Epoch 2572/3000\n",
      " - 2s - loss: 3.8061e-04 - acc: 0.9923 - val_loss: 3.8052e-04 - val_acc: 0.9921\n",
      "Epoch 2573/3000\n",
      " - 2s - loss: 3.8144e-04 - acc: 0.9923 - val_loss: 3.7798e-04 - val_acc: 0.9922\n",
      "Epoch 2574/3000\n",
      " - 2s - loss: 3.8952e-04 - acc: 0.9922 - val_loss: 3.9252e-04 - val_acc: 0.9920\n",
      "Epoch 2575/3000\n",
      " - 2s - loss: 3.8209e-04 - acc: 0.9923 - val_loss: 3.7603e-04 - val_acc: 0.9919\n",
      "Epoch 2576/3000\n",
      " - 2s - loss: 3.8138e-04 - acc: 0.9923 - val_loss: 3.9292e-04 - val_acc: 0.9921\n",
      "Epoch 2577/3000\n",
      " - 2s - loss: 3.8281e-04 - acc: 0.9923 - val_loss: 3.8906e-04 - val_acc: 0.9922\n",
      "Epoch 2578/3000\n",
      " - 2s - loss: 3.7423e-04 - acc: 0.9924 - val_loss: 3.8496e-04 - val_acc: 0.9922\n",
      "Epoch 2579/3000\n",
      " - 2s - loss: 3.8108e-04 - acc: 0.9923 - val_loss: 4.1937e-04 - val_acc: 0.9915\n",
      "Epoch 2580/3000\n",
      "\n",
      "Epoch 02580: val_loss improved from 0.00038 to 0.00038, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 3.8300e-04 - acc: 0.9922 - val_loss: 3.7612e-04 - val_acc: 0.9924\n",
      "Epoch 2581/3000\n",
      " - 1s - loss: 3.7399e-04 - acc: 0.9924 - val_loss: 3.8054e-04 - val_acc: 0.9924\n",
      "Epoch 2582/3000\n",
      " - 1s - loss: 3.8507e-04 - acc: 0.9922 - val_loss: 3.8984e-04 - val_acc: 0.9919\n",
      "Epoch 2583/3000\n",
      " - 1s - loss: 3.7916e-04 - acc: 0.9922 - val_loss: 3.9873e-04 - val_acc: 0.9916\n",
      "Epoch 2584/3000\n",
      " - 1s - loss: 3.7870e-04 - acc: 0.9923 - val_loss: 3.7020e-04 - val_acc: 0.9923\n",
      "Epoch 2585/3000\n",
      " - 2s - loss: 3.7814e-04 - acc: 0.9923 - val_loss: 3.7666e-04 - val_acc: 0.9922\n",
      "Epoch 2586/3000\n",
      " - 2s - loss: 3.8834e-04 - acc: 0.9922 - val_loss: 3.9510e-04 - val_acc: 0.9918\n",
      "Epoch 2587/3000\n",
      " - 1s - loss: 3.8404e-04 - acc: 0.9922 - val_loss: 3.7941e-04 - val_acc: 0.9922\n",
      "Epoch 2588/3000\n",
      " - 1s - loss: 3.9193e-04 - acc: 0.9920 - val_loss: 3.7358e-04 - val_acc: 0.9921\n",
      "Epoch 2589/3000\n",
      " - 2s - loss: 3.7778e-04 - acc: 0.9923 - val_loss: 3.7401e-04 - val_acc: 0.9923\n",
      "Epoch 2590/3000\n",
      " - 2s - loss: 3.8057e-04 - acc: 0.9923 - val_loss: 3.9256e-04 - val_acc: 0.9922\n",
      "Epoch 2591/3000\n",
      " - 2s - loss: 3.8346e-04 - acc: 0.9922 - val_loss: 3.7095e-04 - val_acc: 0.9922\n",
      "Epoch 2592/3000\n",
      " - 1s - loss: 3.8153e-04 - acc: 0.9922 - val_loss: 4.0585e-04 - val_acc: 0.9923\n",
      "Epoch 2593/3000\n",
      " - 2s - loss: 3.8307e-04 - acc: 0.9923 - val_loss: 3.6829e-04 - val_acc: 0.9922\n",
      "Epoch 2594/3000\n",
      " - 2s - loss: 3.7625e-04 - acc: 0.9923 - val_loss: 3.8133e-04 - val_acc: 0.9923\n",
      "Epoch 2595/3000\n",
      " - 2s - loss: 3.7904e-04 - acc: 0.9923 - val_loss: 3.7484e-04 - val_acc: 0.9922\n",
      "Epoch 2596/3000\n",
      " - 2s - loss: 3.7559e-04 - acc: 0.9924 - val_loss: 3.9287e-04 - val_acc: 0.9919\n",
      "Epoch 2597/3000\n",
      " - 1s - loss: 3.7514e-04 - acc: 0.9924 - val_loss: 3.8497e-04 - val_acc: 0.9920\n",
      "Epoch 2598/3000\n",
      " - 2s - loss: 3.7523e-04 - acc: 0.9924 - val_loss: 3.6751e-04 - val_acc: 0.9924\n",
      "Epoch 2599/3000\n",
      " - 1s - loss: 3.7568e-04 - acc: 0.9924 - val_loss: 3.9439e-04 - val_acc: 0.9922\n",
      "Epoch 2600/3000\n",
      "\n",
      "Epoch 02600: val_loss did not improve from 0.00038\n",
      " - 2s - loss: 3.8210e-04 - acc: 0.9922 - val_loss: 3.8818e-04 - val_acc: 0.9919\n",
      "Epoch 2601/3000\n",
      " - 2s - loss: 3.8797e-04 - acc: 0.9922 - val_loss: 3.7323e-04 - val_acc: 0.9924\n",
      "Epoch 2602/3000\n",
      " - 2s - loss: 3.7436e-04 - acc: 0.9924 - val_loss: 3.7464e-04 - val_acc: 0.9922\n",
      "Epoch 2603/3000\n",
      " - 1s - loss: 3.7994e-04 - acc: 0.9924 - val_loss: 3.7828e-04 - val_acc: 0.9920\n",
      "Epoch 2604/3000\n",
      " - 1s - loss: 3.7645e-04 - acc: 0.9923 - val_loss: 3.7115e-04 - val_acc: 0.9924\n",
      "Epoch 2605/3000\n",
      " - 1s - loss: 3.7353e-04 - acc: 0.9924 - val_loss: 3.6899e-04 - val_acc: 0.9924\n",
      "Epoch 2606/3000\n",
      " - 1s - loss: 3.7065e-04 - acc: 0.9925 - val_loss: 3.7814e-04 - val_acc: 0.9923\n",
      "Epoch 2607/3000\n",
      " - 1s - loss: 3.7501e-04 - acc: 0.9924 - val_loss: 3.7470e-04 - val_acc: 0.9923\n",
      "Epoch 2608/3000\n",
      " - 1s - loss: 3.9148e-04 - acc: 0.9922 - val_loss: 3.9020e-04 - val_acc: 0.9923\n",
      "Epoch 2609/3000\n",
      " - 1s - loss: 3.7952e-04 - acc: 0.9924 - val_loss: 3.8296e-04 - val_acc: 0.9919\n",
      "Epoch 2610/3000\n",
      " - 2s - loss: 3.9079e-04 - acc: 0.9922 - val_loss: 3.6656e-04 - val_acc: 0.9924\n",
      "Epoch 2611/3000\n",
      " - 2s - loss: 3.7535e-04 - acc: 0.9924 - val_loss: 3.9785e-04 - val_acc: 0.9923\n",
      "Epoch 2612/3000\n",
      " - 2s - loss: 3.8808e-04 - acc: 0.9922 - val_loss: 3.7192e-04 - val_acc: 0.9923\n",
      "Epoch 2613/3000\n",
      " - 2s - loss: 3.7907e-04 - acc: 0.9924 - val_loss: 3.7485e-04 - val_acc: 0.9919\n",
      "Epoch 2614/3000\n",
      " - 2s - loss: 3.7566e-04 - acc: 0.9924 - val_loss: 4.3825e-04 - val_acc: 0.9917\n",
      "Epoch 2615/3000\n",
      " - 1s - loss: 3.7661e-04 - acc: 0.9923 - val_loss: 3.6334e-04 - val_acc: 0.9923\n",
      "Epoch 2616/3000\n",
      " - 1s - loss: 3.7603e-04 - acc: 0.9924 - val_loss: 3.7693e-04 - val_acc: 0.9919\n",
      "Epoch 2617/3000\n",
      " - 2s - loss: 3.7681e-04 - acc: 0.9923 - val_loss: 4.1876e-04 - val_acc: 0.9922\n",
      "Epoch 2618/3000\n",
      " - 2s - loss: 3.9061e-04 - acc: 0.9921 - val_loss: 3.7689e-04 - val_acc: 0.9924\n",
      "Epoch 2619/3000\n",
      " - 2s - loss: 3.8033e-04 - acc: 0.9923 - val_loss: 3.8369e-04 - val_acc: 0.9919\n",
      "Epoch 2620/3000\n",
      "\n",
      "Epoch 02620: val_loss improved from 0.00038 to 0.00037, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 3.7926e-04 - acc: 0.9923 - val_loss: 3.6938e-04 - val_acc: 0.9923\n",
      "Epoch 2621/3000\n",
      " - 2s - loss: 3.7225e-04 - acc: 0.9924 - val_loss: 3.7538e-04 - val_acc: 0.9924\n",
      "Epoch 2622/3000\n",
      " - 2s - loss: 3.7952e-04 - acc: 0.9923 - val_loss: 3.8027e-04 - val_acc: 0.9923\n",
      "Epoch 2623/3000\n",
      " - 2s - loss: 3.8684e-04 - acc: 0.9922 - val_loss: 3.8636e-04 - val_acc: 0.9916\n",
      "Epoch 2624/3000\n",
      " - 2s - loss: 3.7456e-04 - acc: 0.9923 - val_loss: 3.6257e-04 - val_acc: 0.9925\n",
      "Epoch 2625/3000\n",
      " - 2s - loss: 3.7528e-04 - acc: 0.9924 - val_loss: 3.8761e-04 - val_acc: 0.9924\n",
      "Epoch 2626/3000\n",
      " - 2s - loss: 3.8932e-04 - acc: 0.9921 - val_loss: 3.8427e-04 - val_acc: 0.9923\n",
      "Epoch 2627/3000\n",
      " - 2s - loss: 3.8020e-04 - acc: 0.9924 - val_loss: 4.2356e-04 - val_acc: 0.9920\n",
      "Epoch 2628/3000\n",
      " - 2s - loss: 3.8340e-04 - acc: 0.9923 - val_loss: 3.6404e-04 - val_acc: 0.9923\n",
      "Epoch 2629/3000\n",
      " - 2s - loss: 3.7319e-04 - acc: 0.9924 - val_loss: 3.6558e-04 - val_acc: 0.9923\n",
      "Epoch 2630/3000\n",
      " - 1s - loss: 3.8160e-04 - acc: 0.9923 - val_loss: 3.7275e-04 - val_acc: 0.9923\n",
      "Epoch 2631/3000\n",
      " - 1s - loss: 3.7922e-04 - acc: 0.9923 - val_loss: 3.7053e-04 - val_acc: 0.9923\n",
      "Epoch 2632/3000\n",
      " - 1s - loss: 3.8213e-04 - acc: 0.9922 - val_loss: 3.6477e-04 - val_acc: 0.9925\n",
      "Epoch 2633/3000\n",
      " - 2s - loss: 3.6996e-04 - acc: 0.9925 - val_loss: 3.7166e-04 - val_acc: 0.9924\n",
      "Epoch 2634/3000\n",
      " - 1s - loss: 3.7763e-04 - acc: 0.9924 - val_loss: 3.8398e-04 - val_acc: 0.9918\n",
      "Epoch 2635/3000\n",
      " - 1s - loss: 3.7629e-04 - acc: 0.9923 - val_loss: 3.6253e-04 - val_acc: 0.9923\n",
      "Epoch 2636/3000\n",
      " - 2s - loss: 3.7532e-04 - acc: 0.9924 - val_loss: 3.8284e-04 - val_acc: 0.9920\n",
      "Epoch 2637/3000\n",
      " - 2s - loss: 3.7068e-04 - acc: 0.9925 - val_loss: 3.7122e-04 - val_acc: 0.9925\n",
      "Epoch 2638/3000\n",
      " - 2s - loss: 3.7410e-04 - acc: 0.9924 - val_loss: 3.7264e-04 - val_acc: 0.9922\n",
      "Epoch 2639/3000\n",
      " - 1s - loss: 3.7996e-04 - acc: 0.9923 - val_loss: 3.7196e-04 - val_acc: 0.9923\n",
      "Epoch 2640/3000\n",
      "\n",
      "Epoch 02640: val_loss did not improve from 0.00037\n",
      " - 1s - loss: 3.7435e-04 - acc: 0.9924 - val_loss: 3.8270e-04 - val_acc: 0.9923\n",
      "Epoch 2641/3000\n",
      " - 1s - loss: 3.7308e-04 - acc: 0.9924 - val_loss: 4.0130e-04 - val_acc: 0.9923\n",
      "Epoch 2642/3000\n",
      " - 2s - loss: 3.8085e-04 - acc: 0.9923 - val_loss: 3.6519e-04 - val_acc: 0.9925\n",
      "Epoch 2643/3000\n",
      " - 1s - loss: 3.7526e-04 - acc: 0.9924 - val_loss: 3.7058e-04 - val_acc: 0.9923\n",
      "Epoch 2644/3000\n",
      " - 2s - loss: 3.7733e-04 - acc: 0.9924 - val_loss: 3.7475e-04 - val_acc: 0.9925\n",
      "Epoch 2645/3000\n",
      " - 1s - loss: 3.8981e-04 - acc: 0.9922 - val_loss: 3.8964e-04 - val_acc: 0.9921\n",
      "Epoch 2646/3000\n",
      " - 2s - loss: 3.8235e-04 - acc: 0.9923 - val_loss: 3.6627e-04 - val_acc: 0.9923\n",
      "Epoch 2647/3000\n",
      " - 1s - loss: 3.8015e-04 - acc: 0.9924 - val_loss: 3.7603e-04 - val_acc: 0.9923\n",
      "Epoch 2648/3000\n",
      " - 1s - loss: 3.7487e-04 - acc: 0.9924 - val_loss: 3.6270e-04 - val_acc: 0.9923\n",
      "Epoch 2649/3000\n",
      " - 2s - loss: 3.6998e-04 - acc: 0.9925 - val_loss: 3.7337e-04 - val_acc: 0.9924\n",
      "Epoch 2650/3000\n",
      " - 1s - loss: 3.7413e-04 - acc: 0.9924 - val_loss: 3.7312e-04 - val_acc: 0.9924\n",
      "Epoch 2651/3000\n",
      " - 1s - loss: 3.7799e-04 - acc: 0.9924 - val_loss: 3.9175e-04 - val_acc: 0.9921\n",
      "Epoch 2652/3000\n",
      " - 1s - loss: 3.8135e-04 - acc: 0.9923 - val_loss: 3.6352e-04 - val_acc: 0.9925\n",
      "Epoch 2653/3000\n",
      " - 2s - loss: 3.6844e-04 - acc: 0.9925 - val_loss: 3.7417e-04 - val_acc: 0.9924\n",
      "Epoch 2654/3000\n",
      " - 2s - loss: 3.8198e-04 - acc: 0.9922 - val_loss: 3.7587e-04 - val_acc: 0.9925\n",
      "Epoch 2655/3000\n",
      " - 2s - loss: 3.8026e-04 - acc: 0.9924 - val_loss: 4.2503e-04 - val_acc: 0.9914\n",
      "Epoch 2656/3000\n",
      " - 2s - loss: 3.9567e-04 - acc: 0.9920 - val_loss: 3.6719e-04 - val_acc: 0.9925\n",
      "Epoch 2657/3000\n",
      " - 2s - loss: 3.7683e-04 - acc: 0.9923 - val_loss: 3.6681e-04 - val_acc: 0.9921\n",
      "Epoch 2658/3000\n",
      " - 2s - loss: 3.7373e-04 - acc: 0.9924 - val_loss: 3.6278e-04 - val_acc: 0.9923\n",
      "Epoch 2659/3000\n",
      " - 1s - loss: 3.7447e-04 - acc: 0.9924 - val_loss: 3.6494e-04 - val_acc: 0.9924\n",
      "Epoch 2660/3000\n",
      "\n",
      "Epoch 02660: val_loss did not improve from 0.00037\n",
      " - 1s - loss: 3.8044e-04 - acc: 0.9923 - val_loss: 3.7082e-04 - val_acc: 0.9921\n",
      "Epoch 2661/3000\n",
      " - 2s - loss: 3.7373e-04 - acc: 0.9924 - val_loss: 3.6368e-04 - val_acc: 0.9923\n",
      "Epoch 2662/3000\n",
      " - 2s - loss: 3.8064e-04 - acc: 0.9922 - val_loss: 3.6137e-04 - val_acc: 0.9925\n",
      "Epoch 2663/3000\n",
      " - 2s - loss: 3.7245e-04 - acc: 0.9924 - val_loss: 3.7033e-04 - val_acc: 0.9921\n",
      "Epoch 2664/3000\n",
      " - 2s - loss: 3.7195e-04 - acc: 0.9924 - val_loss: 3.7190e-04 - val_acc: 0.9925\n",
      "Epoch 2665/3000\n",
      " - 2s - loss: 3.7554e-04 - acc: 0.9924 - val_loss: 3.9587e-04 - val_acc: 0.9921\n",
      "Epoch 2666/3000\n",
      " - 2s - loss: 3.7799e-04 - acc: 0.9923 - val_loss: 3.6890e-04 - val_acc: 0.9924\n",
      "Epoch 2667/3000\n",
      " - 1s - loss: 3.7055e-04 - acc: 0.9924 - val_loss: 3.6591e-04 - val_acc: 0.9924\n",
      "Epoch 2668/3000\n",
      " - 1s - loss: 3.7456e-04 - acc: 0.9924 - val_loss: 3.8198e-04 - val_acc: 0.9921\n",
      "Epoch 2669/3000\n",
      " - 2s - loss: 3.8010e-04 - acc: 0.9923 - val_loss: 3.6961e-04 - val_acc: 0.9924\n",
      "Epoch 2670/3000\n",
      " - 1s - loss: 3.7529e-04 - acc: 0.9924 - val_loss: 3.8434e-04 - val_acc: 0.9923\n",
      "Epoch 2671/3000\n",
      " - 1s - loss: 3.6843e-04 - acc: 0.9925 - val_loss: 3.8680e-04 - val_acc: 0.9923\n",
      "Epoch 2672/3000\n",
      " - 2s - loss: 3.7531e-04 - acc: 0.9924 - val_loss: 3.7348e-04 - val_acc: 0.9923\n",
      "Epoch 2673/3000\n",
      " - 2s - loss: 3.6922e-04 - acc: 0.9925 - val_loss: 3.5868e-04 - val_acc: 0.9925\n",
      "Epoch 2674/3000\n",
      " - 2s - loss: 3.7005e-04 - acc: 0.9924 - val_loss: 3.6532e-04 - val_acc: 0.9924\n",
      "Epoch 2675/3000\n",
      " - 1s - loss: 3.6991e-04 - acc: 0.9925 - val_loss: 3.7083e-04 - val_acc: 0.9925\n",
      "Epoch 2676/3000\n",
      " - 1s - loss: 3.7463e-04 - acc: 0.9924 - val_loss: 4.3917e-04 - val_acc: 0.9922\n",
      "Epoch 2677/3000\n",
      " - 2s - loss: 3.9020e-04 - acc: 0.9921 - val_loss: 3.8719e-04 - val_acc: 0.9920\n",
      "Epoch 2678/3000\n",
      " - 2s - loss: 3.7677e-04 - acc: 0.9923 - val_loss: 3.6718e-04 - val_acc: 0.9925\n",
      "Epoch 2679/3000\n",
      " - 1s - loss: 3.7638e-04 - acc: 0.9923 - val_loss: 3.9032e-04 - val_acc: 0.9918\n",
      "Epoch 2680/3000\n",
      "\n",
      "Epoch 02680: val_loss did not improve from 0.00037\n",
      " - 1s - loss: 3.9545e-04 - acc: 0.9919 - val_loss: 3.8700e-04 - val_acc: 0.9922\n",
      "Epoch 2681/3000\n",
      " - 2s - loss: 3.7900e-04 - acc: 0.9923 - val_loss: 3.6637e-04 - val_acc: 0.9922\n",
      "Epoch 2682/3000\n",
      " - 2s - loss: 3.7915e-04 - acc: 0.9923 - val_loss: 3.6211e-04 - val_acc: 0.9923\n",
      "Epoch 2683/3000\n",
      " - 1s - loss: 3.8190e-04 - acc: 0.9923 - val_loss: 3.7080e-04 - val_acc: 0.9924\n",
      "Epoch 2684/3000\n",
      " - 2s - loss: 3.7118e-04 - acc: 0.9924 - val_loss: 3.6413e-04 - val_acc: 0.9925\n",
      "Epoch 2685/3000\n",
      " - 1s - loss: 3.6939e-04 - acc: 0.9924 - val_loss: 3.7052e-04 - val_acc: 0.9920\n",
      "Epoch 2686/3000\n",
      " - 1s - loss: 3.7462e-04 - acc: 0.9924 - val_loss: 4.3948e-04 - val_acc: 0.9918\n",
      "Epoch 2687/3000\n",
      " - 1s - loss: 3.8573e-04 - acc: 0.9922 - val_loss: 4.1294e-04 - val_acc: 0.9918\n",
      "Epoch 2688/3000\n",
      " - 2s - loss: 3.7165e-04 - acc: 0.9924 - val_loss: 3.7406e-04 - val_acc: 0.9921\n",
      "Epoch 2689/3000\n",
      " - 1s - loss: 3.7380e-04 - acc: 0.9923 - val_loss: 3.8629e-04 - val_acc: 0.9922\n",
      "Epoch 2690/3000\n",
      " - 2s - loss: 3.7511e-04 - acc: 0.9924 - val_loss: 4.2763e-04 - val_acc: 0.9919\n",
      "Epoch 2691/3000\n",
      " - 2s - loss: 3.9904e-04 - acc: 0.9920 - val_loss: 3.7162e-04 - val_acc: 0.9924\n",
      "Epoch 2692/3000\n",
      " - 2s - loss: 3.7152e-04 - acc: 0.9924 - val_loss: 3.6903e-04 - val_acc: 0.9923\n",
      "Epoch 2693/3000\n",
      " - 2s - loss: 3.6518e-04 - acc: 0.9925 - val_loss: 3.7061e-04 - val_acc: 0.9922\n",
      "Epoch 2694/3000\n",
      " - 2s - loss: 3.6839e-04 - acc: 0.9925 - val_loss: 3.6218e-04 - val_acc: 0.9921\n",
      "Epoch 2695/3000\n",
      " - 2s - loss: 3.6878e-04 - acc: 0.9925 - val_loss: 3.8809e-04 - val_acc: 0.9921\n",
      "Epoch 2696/3000\n",
      " - 2s - loss: 3.8195e-04 - acc: 0.9923 - val_loss: 3.7341e-04 - val_acc: 0.9923\n",
      "Epoch 2697/3000\n",
      " - 2s - loss: 3.7232e-04 - acc: 0.9924 - val_loss: 3.7274e-04 - val_acc: 0.9922\n",
      "Epoch 2698/3000\n",
      " - 1s - loss: 3.6942e-04 - acc: 0.9925 - val_loss: 3.9892e-04 - val_acc: 0.9924\n",
      "Epoch 2699/3000\n",
      " - 2s - loss: 3.6949e-04 - acc: 0.9925 - val_loss: 3.7034e-04 - val_acc: 0.9922\n",
      "Epoch 2700/3000\n",
      "\n",
      "Epoch 02700: val_loss improved from 0.00037 to 0.00036, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 3.9152e-04 - acc: 0.9920 - val_loss: 3.5895e-04 - val_acc: 0.9923\n",
      "Epoch 2701/3000\n",
      " - 2s - loss: 3.6752e-04 - acc: 0.9925 - val_loss: 3.7020e-04 - val_acc: 0.9925\n",
      "Epoch 2702/3000\n",
      " - 1s - loss: 3.9101e-04 - acc: 0.9920 - val_loss: 3.8606e-04 - val_acc: 0.9919\n",
      "Epoch 2703/3000\n",
      " - 2s - loss: 3.8276e-04 - acc: 0.9922 - val_loss: 3.6378e-04 - val_acc: 0.9923\n",
      "Epoch 2704/3000\n",
      " - 1s - loss: 3.7396e-04 - acc: 0.9923 - val_loss: 3.7232e-04 - val_acc: 0.9920\n",
      "Epoch 2705/3000\n",
      " - 1s - loss: 3.7244e-04 - acc: 0.9924 - val_loss: 3.8268e-04 - val_acc: 0.9923\n",
      "Epoch 2706/3000\n",
      " - 1s - loss: 3.8560e-04 - acc: 0.9922 - val_loss: 3.7911e-04 - val_acc: 0.9921\n",
      "Epoch 2707/3000\n",
      " - 2s - loss: 3.7218e-04 - acc: 0.9924 - val_loss: 3.6842e-04 - val_acc: 0.9921\n",
      "Epoch 2708/3000\n",
      " - 1s - loss: 3.7250e-04 - acc: 0.9924 - val_loss: 3.6823e-04 - val_acc: 0.9922\n",
      "Epoch 2709/3000\n",
      " - 2s - loss: 3.7189e-04 - acc: 0.9924 - val_loss: 3.7379e-04 - val_acc: 0.9924\n",
      "Epoch 2710/3000\n",
      " - 1s - loss: 3.8068e-04 - acc: 0.9923 - val_loss: 3.6174e-04 - val_acc: 0.9924\n",
      "Epoch 2711/3000\n",
      " - 1s - loss: 3.8113e-04 - acc: 0.9923 - val_loss: 4.0657e-04 - val_acc: 0.9921\n",
      "Epoch 2712/3000\n",
      " - 1s - loss: 3.8268e-04 - acc: 0.9922 - val_loss: 3.9720e-04 - val_acc: 0.9919\n",
      "Epoch 2713/3000\n",
      " - 2s - loss: 3.6988e-04 - acc: 0.9925 - val_loss: 3.7913e-04 - val_acc: 0.9922\n",
      "Epoch 2714/3000\n",
      " - 1s - loss: 3.7048e-04 - acc: 0.9925 - val_loss: 3.6518e-04 - val_acc: 0.9925\n",
      "Epoch 2715/3000\n",
      " - 1s - loss: 3.7148e-04 - acc: 0.9924 - val_loss: 3.6189e-04 - val_acc: 0.9926\n",
      "Epoch 2716/3000\n",
      " - 1s - loss: 3.6914e-04 - acc: 0.9925 - val_loss: 3.7496e-04 - val_acc: 0.9923\n",
      "Epoch 2717/3000\n",
      " - 2s - loss: 3.6955e-04 - acc: 0.9925 - val_loss: 3.8792e-04 - val_acc: 0.9918\n",
      "Epoch 2718/3000\n",
      " - 2s - loss: 3.7856e-04 - acc: 0.9923 - val_loss: 3.7691e-04 - val_acc: 0.9920\n",
      "Epoch 2719/3000\n",
      " - 2s - loss: 3.7333e-04 - acc: 0.9924 - val_loss: 3.7222e-04 - val_acc: 0.9922\n",
      "Epoch 2720/3000\n",
      "\n",
      "Epoch 02720: val_loss did not improve from 0.00036\n",
      " - 2s - loss: 3.7655e-04 - acc: 0.9923 - val_loss: 3.7045e-04 - val_acc: 0.9920\n",
      "Epoch 2721/3000\n",
      " - 2s - loss: 3.7210e-04 - acc: 0.9924 - val_loss: 3.8334e-04 - val_acc: 0.9919\n",
      "Epoch 2722/3000\n",
      " - 2s - loss: 3.6908e-04 - acc: 0.9925 - val_loss: 3.6093e-04 - val_acc: 0.9924\n",
      "Epoch 2723/3000\n",
      " - 2s - loss: 3.7379e-04 - acc: 0.9924 - val_loss: 3.6461e-04 - val_acc: 0.9924\n",
      "Epoch 2724/3000\n",
      " - 1s - loss: 3.6629e-04 - acc: 0.9925 - val_loss: 3.6310e-04 - val_acc: 0.9924\n",
      "Epoch 2725/3000\n",
      " - 1s - loss: 3.7243e-04 - acc: 0.9924 - val_loss: 3.7157e-04 - val_acc: 0.9924\n",
      "Epoch 2726/3000\n",
      " - 1s - loss: 3.7494e-04 - acc: 0.9924 - val_loss: 3.7056e-04 - val_acc: 0.9921\n",
      "Epoch 2727/3000\n",
      " - 2s - loss: 3.7251e-04 - acc: 0.9924 - val_loss: 3.6587e-04 - val_acc: 0.9922\n",
      "Epoch 2728/3000\n",
      " - 1s - loss: 3.7724e-04 - acc: 0.9924 - val_loss: 3.9081e-04 - val_acc: 0.9919\n",
      "Epoch 2729/3000\n",
      " - 2s - loss: 3.8256e-04 - acc: 0.9921 - val_loss: 3.7158e-04 - val_acc: 0.9922\n",
      "Epoch 2730/3000\n",
      " - 2s - loss: 3.6942e-04 - acc: 0.9925 - val_loss: 3.5616e-04 - val_acc: 0.9923\n",
      "Epoch 2731/3000\n",
      " - 1s - loss: 3.6761e-04 - acc: 0.9924 - val_loss: 3.6078e-04 - val_acc: 0.9921\n",
      "Epoch 2732/3000\n",
      " - 2s - loss: 3.6628e-04 - acc: 0.9924 - val_loss: 3.5965e-04 - val_acc: 0.9923\n",
      "Epoch 2733/3000\n",
      " - 1s - loss: 3.6892e-04 - acc: 0.9924 - val_loss: 3.6092e-04 - val_acc: 0.9925\n",
      "Epoch 2734/3000\n",
      " - 1s - loss: 3.7305e-04 - acc: 0.9924 - val_loss: 3.7736e-04 - val_acc: 0.9921\n",
      "Epoch 2735/3000\n",
      " - 1s - loss: 3.7213e-04 - acc: 0.9924 - val_loss: 3.5759e-04 - val_acc: 0.9926\n",
      "Epoch 2736/3000\n",
      " - 2s - loss: 3.8954e-04 - acc: 0.9921 - val_loss: 3.8045e-04 - val_acc: 0.9919\n",
      "Epoch 2737/3000\n",
      " - 1s - loss: 3.7390e-04 - acc: 0.9923 - val_loss: 3.6016e-04 - val_acc: 0.9925\n",
      "Epoch 2738/3000\n",
      " - 1s - loss: 3.7089e-04 - acc: 0.9924 - val_loss: 3.6062e-04 - val_acc: 0.9925\n",
      "Epoch 2739/3000\n",
      " - 1s - loss: 3.6866e-04 - acc: 0.9924 - val_loss: 3.7461e-04 - val_acc: 0.9923\n",
      "Epoch 2740/3000\n",
      "\n",
      "Epoch 02740: val_loss did not improve from 0.00036\n",
      " - 2s - loss: 3.7251e-04 - acc: 0.9924 - val_loss: 3.6545e-04 - val_acc: 0.9920\n",
      "Epoch 2741/3000\n",
      " - 2s - loss: 3.6764e-04 - acc: 0.9925 - val_loss: 3.6421e-04 - val_acc: 0.9924\n",
      "Epoch 2742/3000\n",
      " - 1s - loss: 3.7510e-04 - acc: 0.9923 - val_loss: 3.7024e-04 - val_acc: 0.9918\n",
      "Epoch 2743/3000\n",
      " - 1s - loss: 3.8191e-04 - acc: 0.9923 - val_loss: 4.1135e-04 - val_acc: 0.9919\n",
      "Epoch 2744/3000\n",
      " - 2s - loss: 3.7174e-04 - acc: 0.9923 - val_loss: 3.6431e-04 - val_acc: 0.9923\n",
      "Epoch 2745/3000\n",
      " - 1s - loss: 3.6598e-04 - acc: 0.9925 - val_loss: 3.6417e-04 - val_acc: 0.9924\n",
      "Epoch 2746/3000\n",
      " - 2s - loss: 3.7058e-04 - acc: 0.9924 - val_loss: 3.6391e-04 - val_acc: 0.9925\n",
      "Epoch 2747/3000\n",
      " - 2s - loss: 3.7024e-04 - acc: 0.9924 - val_loss: 3.8342e-04 - val_acc: 0.9919\n",
      "Epoch 2748/3000\n",
      " - 1s - loss: 3.7526e-04 - acc: 0.9923 - val_loss: 3.7438e-04 - val_acc: 0.9924\n",
      "Epoch 2749/3000\n",
      " - 1s - loss: 3.7624e-04 - acc: 0.9923 - val_loss: 3.6647e-04 - val_acc: 0.9921\n",
      "Epoch 2750/3000\n",
      " - 2s - loss: 3.9058e-04 - acc: 0.9921 - val_loss: 3.6633e-04 - val_acc: 0.9923\n",
      "Epoch 2751/3000\n",
      " - 2s - loss: 3.7599e-04 - acc: 0.9924 - val_loss: 4.0206e-04 - val_acc: 0.9921\n",
      "Epoch 2752/3000\n",
      " - 2s - loss: 3.7835e-04 - acc: 0.9923 - val_loss: 3.6620e-04 - val_acc: 0.9925\n",
      "Epoch 2753/3000\n",
      " - 1s - loss: 3.7304e-04 - acc: 0.9924 - val_loss: 3.6156e-04 - val_acc: 0.9924\n",
      "Epoch 2754/3000\n",
      " - 1s - loss: 3.7460e-04 - acc: 0.9924 - val_loss: 3.9886e-04 - val_acc: 0.9923\n",
      "Epoch 2755/3000\n",
      " - 2s - loss: 3.8322e-04 - acc: 0.9922 - val_loss: 3.6225e-04 - val_acc: 0.9923\n",
      "Epoch 2756/3000\n",
      " - 1s - loss: 3.8114e-04 - acc: 0.9922 - val_loss: 3.6705e-04 - val_acc: 0.9925\n",
      "Epoch 2757/3000\n",
      " - 1s - loss: 3.6529e-04 - acc: 0.9925 - val_loss: 3.7832e-04 - val_acc: 0.9922\n",
      "Epoch 2758/3000\n",
      " - 2s - loss: 3.7318e-04 - acc: 0.9924 - val_loss: 3.7023e-04 - val_acc: 0.9923\n",
      "Epoch 2759/3000\n",
      " - 2s - loss: 3.8123e-04 - acc: 0.9923 - val_loss: 3.6923e-04 - val_acc: 0.9923\n",
      "Epoch 2760/3000\n",
      "\n",
      "Epoch 02760: val_loss improved from 0.00036 to 0.00036, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 3.6561e-04 - acc: 0.9924 - val_loss: 3.5892e-04 - val_acc: 0.9924\n",
      "Epoch 2761/3000\n",
      " - 2s - loss: 3.6433e-04 - acc: 0.9925 - val_loss: 3.5848e-04 - val_acc: 0.9924\n",
      "Epoch 2762/3000\n",
      " - 2s - loss: 3.6906e-04 - acc: 0.9924 - val_loss: 3.7133e-04 - val_acc: 0.9920\n",
      "Epoch 2763/3000\n",
      " - 2s - loss: 3.6930e-04 - acc: 0.9924 - val_loss: 3.8691e-04 - val_acc: 0.9921\n",
      "Epoch 2764/3000\n",
      " - 2s - loss: 3.7687e-04 - acc: 0.9922 - val_loss: 3.7087e-04 - val_acc: 0.9920\n",
      "Epoch 2765/3000\n",
      " - 2s - loss: 3.7139e-04 - acc: 0.9923 - val_loss: 3.6814e-04 - val_acc: 0.9925\n",
      "Epoch 2766/3000\n",
      " - 2s - loss: 3.6753e-04 - acc: 0.9925 - val_loss: 3.7362e-04 - val_acc: 0.9922\n",
      "Epoch 2767/3000\n",
      " - 2s - loss: 3.7262e-04 - acc: 0.9924 - val_loss: 3.6100e-04 - val_acc: 0.9922\n",
      "Epoch 2768/3000\n",
      " - 2s - loss: 3.7126e-04 - acc: 0.9923 - val_loss: 3.6526e-04 - val_acc: 0.9924\n",
      "Epoch 2769/3000\n",
      " - 1s - loss: 3.8575e-04 - acc: 0.9922 - val_loss: 3.8575e-04 - val_acc: 0.9917\n",
      "Epoch 2770/3000\n",
      " - 2s - loss: 3.7501e-04 - acc: 0.9923 - val_loss: 3.7680e-04 - val_acc: 0.9917\n",
      "Epoch 2771/3000\n",
      " - 2s - loss: 3.7238e-04 - acc: 0.9924 - val_loss: 3.8135e-04 - val_acc: 0.9922\n",
      "Epoch 2772/3000\n",
      " - 2s - loss: 3.7437e-04 - acc: 0.9924 - val_loss: 3.7519e-04 - val_acc: 0.9917\n",
      "Epoch 2773/3000\n",
      " - 2s - loss: 3.7270e-04 - acc: 0.9924 - val_loss: 3.7274e-04 - val_acc: 0.9922\n",
      "Epoch 2774/3000\n",
      " - 1s - loss: 3.7127e-04 - acc: 0.9924 - val_loss: 3.6643e-04 - val_acc: 0.9925\n",
      "Epoch 2775/3000\n",
      " - 2s - loss: 3.6732e-04 - acc: 0.9924 - val_loss: 3.6108e-04 - val_acc: 0.9925\n",
      "Epoch 2776/3000\n",
      " - 1s - loss: 3.6365e-04 - acc: 0.9925 - val_loss: 3.6292e-04 - val_acc: 0.9922\n",
      "Epoch 2777/3000\n",
      " - 2s - loss: 3.7629e-04 - acc: 0.9923 - val_loss: 3.6506e-04 - val_acc: 0.9922\n",
      "Epoch 2778/3000\n",
      " - 2s - loss: 3.6777e-04 - acc: 0.9924 - val_loss: 3.7131e-04 - val_acc: 0.9923\n",
      "Epoch 2779/3000\n",
      " - 1s - loss: 3.6815e-04 - acc: 0.9925 - val_loss: 3.6718e-04 - val_acc: 0.9925\n",
      "Epoch 2780/3000\n",
      "\n",
      "Epoch 02780: val_loss did not improve from 0.00036\n",
      " - 2s - loss: 3.6772e-04 - acc: 0.9925 - val_loss: 3.6112e-04 - val_acc: 0.9920\n",
      "Epoch 2781/3000\n",
      " - 2s - loss: 3.6943e-04 - acc: 0.9924 - val_loss: 3.6893e-04 - val_acc: 0.9923\n",
      "Epoch 2782/3000\n",
      " - 1s - loss: 3.6852e-04 - acc: 0.9924 - val_loss: 3.6883e-04 - val_acc: 0.9922\n",
      "Epoch 2783/3000\n",
      " - 1s - loss: 3.6391e-04 - acc: 0.9925 - val_loss: 3.5698e-04 - val_acc: 0.9924\n",
      "Epoch 2784/3000\n",
      " - 1s - loss: 3.6550e-04 - acc: 0.9924 - val_loss: 3.6996e-04 - val_acc: 0.9922\n",
      "Epoch 2785/3000\n",
      " - 2s - loss: 3.6461e-04 - acc: 0.9925 - val_loss: 3.7629e-04 - val_acc: 0.9922\n",
      "Epoch 2786/3000\n",
      " - 2s - loss: 3.7114e-04 - acc: 0.9924 - val_loss: 3.6530e-04 - val_acc: 0.9923\n",
      "Epoch 2787/3000\n",
      " - 1s - loss: 3.7116e-04 - acc: 0.9924 - val_loss: 3.5845e-04 - val_acc: 0.9926\n",
      "Epoch 2788/3000\n",
      " - 2s - loss: 3.6545e-04 - acc: 0.9924 - val_loss: 3.6574e-04 - val_acc: 0.9922\n",
      "Epoch 2789/3000\n",
      " - 1s - loss: 3.6636e-04 - acc: 0.9925 - val_loss: 3.7847e-04 - val_acc: 0.9920\n",
      "Epoch 2790/3000\n",
      " - 1s - loss: 3.8527e-04 - acc: 0.9923 - val_loss: 3.6582e-04 - val_acc: 0.9919\n",
      "Epoch 2791/3000\n",
      " - 2s - loss: 3.6074e-04 - acc: 0.9925 - val_loss: 3.6525e-04 - val_acc: 0.9922\n",
      "Epoch 2792/3000\n",
      " - 2s - loss: 3.7157e-04 - acc: 0.9923 - val_loss: 3.5930e-04 - val_acc: 0.9926\n",
      "Epoch 2793/3000\n",
      " - 2s - loss: 3.6229e-04 - acc: 0.9925 - val_loss: 3.6030e-04 - val_acc: 0.9923\n",
      "Epoch 2794/3000\n",
      " - 1s - loss: 3.6739e-04 - acc: 0.9924 - val_loss: 3.6108e-04 - val_acc: 0.9923\n",
      "Epoch 2795/3000\n",
      " - 1s - loss: 3.7266e-04 - acc: 0.9924 - val_loss: 3.5876e-04 - val_acc: 0.9927\n",
      "Epoch 2796/3000\n",
      " - 2s - loss: 3.6765e-04 - acc: 0.9924 - val_loss: 3.6252e-04 - val_acc: 0.9925\n",
      "Epoch 2797/3000\n",
      " - 1s - loss: 3.6605e-04 - acc: 0.9924 - val_loss: 3.6235e-04 - val_acc: 0.9925\n",
      "Epoch 2798/3000\n",
      " - 1s - loss: 3.7937e-04 - acc: 0.9922 - val_loss: 3.7530e-04 - val_acc: 0.9921\n",
      "Epoch 2799/3000\n",
      " - 2s - loss: 3.6910e-04 - acc: 0.9924 - val_loss: 3.7588e-04 - val_acc: 0.9923\n",
      "Epoch 2800/3000\n",
      "\n",
      "Epoch 02800: val_loss did not improve from 0.00036\n",
      " - 2s - loss: 3.6948e-04 - acc: 0.9924 - val_loss: 3.6583e-04 - val_acc: 0.9921\n",
      "Epoch 2801/3000\n",
      " - 1s - loss: 3.6666e-04 - acc: 0.9924 - val_loss: 3.7513e-04 - val_acc: 0.9922\n",
      "Epoch 2802/3000\n",
      " - 1s - loss: 3.6766e-04 - acc: 0.9924 - val_loss: 3.5527e-04 - val_acc: 0.9925\n",
      "Epoch 2803/3000\n",
      " - 2s - loss: 3.7652e-04 - acc: 0.9923 - val_loss: 3.6683e-04 - val_acc: 0.9921\n",
      "Epoch 2804/3000\n",
      " - 1s - loss: 3.6803e-04 - acc: 0.9924 - val_loss: 3.5691e-04 - val_acc: 0.9926\n",
      "Epoch 2805/3000\n",
      " - 1s - loss: 3.6522e-04 - acc: 0.9924 - val_loss: 3.9244e-04 - val_acc: 0.9925\n",
      "Epoch 2806/3000\n",
      " - 2s - loss: 3.7140e-04 - acc: 0.9924 - val_loss: 3.6458e-04 - val_acc: 0.9924\n",
      "Epoch 2807/3000\n",
      " - 1s - loss: 3.6971e-04 - acc: 0.9924 - val_loss: 3.8373e-04 - val_acc: 0.9919\n",
      "Epoch 2808/3000\n",
      " - 2s - loss: 3.6929e-04 - acc: 0.9924 - val_loss: 3.6415e-04 - val_acc: 0.9923\n",
      "Epoch 2809/3000\n",
      " - 2s - loss: 3.7478e-04 - acc: 0.9923 - val_loss: 3.6045e-04 - val_acc: 0.9924\n",
      "Epoch 2810/3000\n",
      " - 1s - loss: 3.8828e-04 - acc: 0.9921 - val_loss: 3.7618e-04 - val_acc: 0.9921\n",
      "Epoch 2811/3000\n",
      " - 1s - loss: 3.6942e-04 - acc: 0.9924 - val_loss: 3.6491e-04 - val_acc: 0.9925\n",
      "Epoch 2812/3000\n",
      " - 2s - loss: 3.6579e-04 - acc: 0.9924 - val_loss: 3.6949e-04 - val_acc: 0.9922\n",
      "Epoch 2813/3000\n",
      " - 1s - loss: 3.8029e-04 - acc: 0.9922 - val_loss: 4.0406e-04 - val_acc: 0.9924\n",
      "Epoch 2814/3000\n",
      " - 2s - loss: 3.7642e-04 - acc: 0.9923 - val_loss: 3.7871e-04 - val_acc: 0.9919\n",
      "Epoch 2815/3000\n",
      " - 2s - loss: 3.6955e-04 - acc: 0.9924 - val_loss: 3.6412e-04 - val_acc: 0.9924\n",
      "Epoch 2816/3000\n",
      " - 2s - loss: 3.6414e-04 - acc: 0.9925 - val_loss: 3.6584e-04 - val_acc: 0.9923\n",
      "Epoch 2817/3000\n",
      " - 2s - loss: 3.6827e-04 - acc: 0.9924 - val_loss: 3.6918e-04 - val_acc: 0.9921\n",
      "Epoch 2818/3000\n",
      " - 2s - loss: 3.6401e-04 - acc: 0.9925 - val_loss: 3.6258e-04 - val_acc: 0.9923\n",
      "Epoch 2819/3000\n",
      " - 2s - loss: 3.6661e-04 - acc: 0.9925 - val_loss: 3.6305e-04 - val_acc: 0.9923\n",
      "Epoch 2820/3000\n",
      "\n",
      "Epoch 02820: val_loss did not improve from 0.00036\n",
      " - 1s - loss: 3.7178e-04 - acc: 0.9924 - val_loss: 3.6441e-04 - val_acc: 0.9922\n",
      "Epoch 2821/3000\n",
      " - 2s - loss: 3.7248e-04 - acc: 0.9923 - val_loss: 3.6229e-04 - val_acc: 0.9922\n",
      "Epoch 2822/3000\n",
      " - 2s - loss: 3.6983e-04 - acc: 0.9923 - val_loss: 3.8254e-04 - val_acc: 0.9923\n",
      "Epoch 2823/3000\n",
      " - 2s - loss: 3.6946e-04 - acc: 0.9924 - val_loss: 3.8676e-04 - val_acc: 0.9914\n",
      "Epoch 2824/3000\n",
      " - 1s - loss: 3.7589e-04 - acc: 0.9922 - val_loss: 3.6021e-04 - val_acc: 0.9922\n",
      "Epoch 2825/3000\n",
      " - 2s - loss: 3.6651e-04 - acc: 0.9924 - val_loss: 3.6476e-04 - val_acc: 0.9925\n",
      "Epoch 2826/3000\n",
      " - 1s - loss: 3.6164e-04 - acc: 0.9925 - val_loss: 3.7068e-04 - val_acc: 0.9922\n",
      "Epoch 2827/3000\n",
      " - 2s - loss: 3.6717e-04 - acc: 0.9924 - val_loss: 3.5782e-04 - val_acc: 0.9925\n",
      "Epoch 2828/3000\n",
      " - 2s - loss: 3.6639e-04 - acc: 0.9925 - val_loss: 3.7249e-04 - val_acc: 0.9922\n",
      "Epoch 2829/3000\n",
      " - 2s - loss: 3.6908e-04 - acc: 0.9923 - val_loss: 3.6346e-04 - val_acc: 0.9923\n",
      "Epoch 2830/3000\n",
      " - 1s - loss: 3.7638e-04 - acc: 0.9923 - val_loss: 3.5516e-04 - val_acc: 0.9925\n",
      "Epoch 2831/3000\n",
      " - 1s - loss: 3.6315e-04 - acc: 0.9925 - val_loss: 3.5639e-04 - val_acc: 0.9922\n",
      "Epoch 2832/3000\n",
      " - 2s - loss: 3.6347e-04 - acc: 0.9925 - val_loss: 4.0534e-04 - val_acc: 0.9918\n",
      "Epoch 2833/3000\n",
      " - 1s - loss: 3.7516e-04 - acc: 0.9923 - val_loss: 3.6317e-04 - val_acc: 0.9924\n",
      "Epoch 2834/3000\n",
      " - 1s - loss: 3.6473e-04 - acc: 0.9925 - val_loss: 3.5307e-04 - val_acc: 0.9924\n",
      "Epoch 2835/3000\n",
      " - 1s - loss: 3.7107e-04 - acc: 0.9923 - val_loss: 3.5508e-04 - val_acc: 0.9922\n",
      "Epoch 2836/3000\n",
      " - 2s - loss: 3.7414e-04 - acc: 0.9923 - val_loss: 3.8016e-04 - val_acc: 0.9923\n",
      "Epoch 2837/3000\n",
      " - 2s - loss: 3.7701e-04 - acc: 0.9922 - val_loss: 3.6784e-04 - val_acc: 0.9920\n",
      "Epoch 2838/3000\n",
      " - 1s - loss: 3.6805e-04 - acc: 0.9924 - val_loss: 3.6311e-04 - val_acc: 0.9922\n",
      "Epoch 2839/3000\n",
      " - 2s - loss: 3.6675e-04 - acc: 0.9924 - val_loss: 3.6880e-04 - val_acc: 0.9926\n",
      "Epoch 2840/3000\n",
      "\n",
      "Epoch 02840: val_loss did not improve from 0.00036\n",
      " - 2s - loss: 3.6613e-04 - acc: 0.9924 - val_loss: 3.6795e-04 - val_acc: 0.9921\n",
      "Epoch 2841/3000\n",
      " - 2s - loss: 3.6928e-04 - acc: 0.9924 - val_loss: 3.5761e-04 - val_acc: 0.9925\n",
      "Epoch 2842/3000\n",
      " - 2s - loss: 3.7334e-04 - acc: 0.9924 - val_loss: 3.6044e-04 - val_acc: 0.9923\n",
      "Epoch 2843/3000\n",
      " - 2s - loss: 3.6001e-04 - acc: 0.9926 - val_loss: 3.6442e-04 - val_acc: 0.9924\n",
      "Epoch 2844/3000\n",
      " - 2s - loss: 3.7327e-04 - acc: 0.9923 - val_loss: 3.7025e-04 - val_acc: 0.9923\n",
      "Epoch 2845/3000\n",
      " - 2s - loss: 3.6218e-04 - acc: 0.9925 - val_loss: 3.6364e-04 - val_acc: 0.9924\n",
      "Epoch 2846/3000\n",
      " - 2s - loss: 3.6333e-04 - acc: 0.9925 - val_loss: 3.7165e-04 - val_acc: 0.9926\n",
      "Epoch 2847/3000\n",
      " - 2s - loss: 3.7000e-04 - acc: 0.9924 - val_loss: 3.6483e-04 - val_acc: 0.9926\n",
      "Epoch 2848/3000\n",
      " - 2s - loss: 3.6499e-04 - acc: 0.9925 - val_loss: 4.2100e-04 - val_acc: 0.9912\n",
      "Epoch 2849/3000\n",
      " - 2s - loss: 3.8535e-04 - acc: 0.9922 - val_loss: 3.6064e-04 - val_acc: 0.9925\n",
      "Epoch 2850/3000\n",
      " - 2s - loss: 3.7106e-04 - acc: 0.9924 - val_loss: 3.7358e-04 - val_acc: 0.9920\n",
      "Epoch 2851/3000\n",
      " - 1s - loss: 3.6381e-04 - acc: 0.9924 - val_loss: 3.6076e-04 - val_acc: 0.9922\n",
      "Epoch 2852/3000\n",
      " - 2s - loss: 3.7736e-04 - acc: 0.9923 - val_loss: 3.8266e-04 - val_acc: 0.9923\n",
      "Epoch 2853/3000\n",
      " - 1s - loss: 3.6922e-04 - acc: 0.9924 - val_loss: 4.5826e-04 - val_acc: 0.9918\n",
      "Epoch 2854/3000\n",
      " - 2s - loss: 3.8333e-04 - acc: 0.9921 - val_loss: 3.8858e-04 - val_acc: 0.9921\n",
      "Epoch 2855/3000\n",
      " - 2s - loss: 3.6790e-04 - acc: 0.9924 - val_loss: 3.5726e-04 - val_acc: 0.9925\n",
      "Epoch 2856/3000\n",
      " - 1s - loss: 3.6494e-04 - acc: 0.9925 - val_loss: 3.6522e-04 - val_acc: 0.9925\n",
      "Epoch 2857/3000\n",
      " - 1s - loss: 3.5773e-04 - acc: 0.9926 - val_loss: 3.6207e-04 - val_acc: 0.9923\n",
      "Epoch 2858/3000\n",
      " - 1s - loss: 3.6162e-04 - acc: 0.9925 - val_loss: 3.6211e-04 - val_acc: 0.9923\n",
      "Epoch 2859/3000\n",
      " - 2s - loss: 3.7848e-04 - acc: 0.9922 - val_loss: 3.5819e-04 - val_acc: 0.9926\n",
      "Epoch 2860/3000\n",
      "\n",
      "Epoch 02860: val_loss improved from 0.00036 to 0.00036, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 3.6146e-04 - acc: 0.9926 - val_loss: 3.5571e-04 - val_acc: 0.9924\n",
      "Epoch 2861/3000\n",
      " - 2s - loss: 3.6489e-04 - acc: 0.9925 - val_loss: 3.5928e-04 - val_acc: 0.9924\n",
      "Epoch 2862/3000\n",
      " - 1s - loss: 3.7075e-04 - acc: 0.9924 - val_loss: 3.7299e-04 - val_acc: 0.9917\n",
      "Epoch 2863/3000\n",
      " - 1s - loss: 3.6810e-04 - acc: 0.9924 - val_loss: 3.6225e-04 - val_acc: 0.9923\n",
      "Epoch 2864/3000\n",
      " - 2s - loss: 3.6215e-04 - acc: 0.9924 - val_loss: 3.5989e-04 - val_acc: 0.9923\n",
      "Epoch 2865/3000\n",
      " - 1s - loss: 3.6365e-04 - acc: 0.9925 - val_loss: 3.6305e-04 - val_acc: 0.9924\n",
      "Epoch 2866/3000\n",
      " - 2s - loss: 3.7200e-04 - acc: 0.9924 - val_loss: 3.5705e-04 - val_acc: 0.9926\n",
      "Epoch 2867/3000\n",
      " - 2s - loss: 3.5987e-04 - acc: 0.9925 - val_loss: 3.7013e-04 - val_acc: 0.9924\n",
      "Epoch 2868/3000\n",
      " - 2s - loss: 3.6741e-04 - acc: 0.9924 - val_loss: 3.5671e-04 - val_acc: 0.9924\n",
      "Epoch 2869/3000\n",
      " - 2s - loss: 3.7883e-04 - acc: 0.9922 - val_loss: 3.6462e-04 - val_acc: 0.9924\n",
      "Epoch 2870/3000\n",
      " - 2s - loss: 3.6602e-04 - acc: 0.9925 - val_loss: 3.5484e-04 - val_acc: 0.9922\n",
      "Epoch 2871/3000\n",
      " - 2s - loss: 3.7119e-04 - acc: 0.9924 - val_loss: 3.7467e-04 - val_acc: 0.9924\n",
      "Epoch 2872/3000\n",
      " - 1s - loss: 3.6948e-04 - acc: 0.9924 - val_loss: 3.5844e-04 - val_acc: 0.9922\n",
      "Epoch 2873/3000\n",
      " - 2s - loss: 3.6380e-04 - acc: 0.9924 - val_loss: 3.5686e-04 - val_acc: 0.9924\n",
      "Epoch 2874/3000\n",
      " - 1s - loss: 3.6419e-04 - acc: 0.9925 - val_loss: 3.8897e-04 - val_acc: 0.9918\n",
      "Epoch 2875/3000\n",
      " - 1s - loss: 3.7117e-04 - acc: 0.9923 - val_loss: 3.6481e-04 - val_acc: 0.9923\n",
      "Epoch 2876/3000\n",
      " - 2s - loss: 3.7030e-04 - acc: 0.9924 - val_loss: 3.8209e-04 - val_acc: 0.9919\n",
      "Epoch 2877/3000\n",
      " - 1s - loss: 3.6723e-04 - acc: 0.9924 - val_loss: 3.7125e-04 - val_acc: 0.9923\n",
      "Epoch 2878/3000\n",
      " - 2s - loss: 3.6065e-04 - acc: 0.9925 - val_loss: 3.5523e-04 - val_acc: 0.9925\n",
      "Epoch 2879/3000\n",
      " - 2s - loss: 3.6579e-04 - acc: 0.9924 - val_loss: 3.7624e-04 - val_acc: 0.9922\n",
      "Epoch 2880/3000\n",
      "\n",
      "Epoch 02880: val_loss did not improve from 0.00036\n",
      " - 2s - loss: 3.6645e-04 - acc: 0.9924 - val_loss: 3.8436e-04 - val_acc: 0.9926\n",
      "Epoch 2881/3000\n",
      " - 2s - loss: 3.6618e-04 - acc: 0.9925 - val_loss: 3.5570e-04 - val_acc: 0.9924\n",
      "Epoch 2882/3000\n",
      " - 2s - loss: 3.6817e-04 - acc: 0.9924 - val_loss: 3.7419e-04 - val_acc: 0.9920\n",
      "Epoch 2883/3000\n",
      " - 1s - loss: 3.6432e-04 - acc: 0.9924 - val_loss: 3.5841e-04 - val_acc: 0.9923\n",
      "Epoch 2884/3000\n",
      " - 2s - loss: 3.6927e-04 - acc: 0.9924 - val_loss: 3.5856e-04 - val_acc: 0.9926\n",
      "Epoch 2885/3000\n",
      " - 1s - loss: 3.6340e-04 - acc: 0.9925 - val_loss: 3.8540e-04 - val_acc: 0.9920\n",
      "Epoch 2886/3000\n",
      " - 1s - loss: 3.7073e-04 - acc: 0.9924 - val_loss: 3.5581e-04 - val_acc: 0.9926\n",
      "Epoch 2887/3000\n",
      " - 2s - loss: 3.5798e-04 - acc: 0.9926 - val_loss: 3.6830e-04 - val_acc: 0.9924\n",
      "Epoch 2888/3000\n",
      " - 1s - loss: 3.7238e-04 - acc: 0.9924 - val_loss: 3.5685e-04 - val_acc: 0.9922\n",
      "Epoch 2889/3000\n",
      " - 1s - loss: 3.6833e-04 - acc: 0.9924 - val_loss: 3.5872e-04 - val_acc: 0.9923\n",
      "Epoch 2890/3000\n",
      " - 2s - loss: 3.6616e-04 - acc: 0.9924 - val_loss: 3.5971e-04 - val_acc: 0.9926\n",
      "Epoch 2891/3000\n",
      " - 2s - loss: 3.6774e-04 - acc: 0.9923 - val_loss: 3.5439e-04 - val_acc: 0.9925\n",
      "Epoch 2892/3000\n",
      " - 2s - loss: 3.6179e-04 - acc: 0.9925 - val_loss: 3.6466e-04 - val_acc: 0.9924\n",
      "Epoch 2893/3000\n",
      " - 1s - loss: 3.6495e-04 - acc: 0.9925 - val_loss: 3.9174e-04 - val_acc: 0.9919\n",
      "Epoch 2894/3000\n",
      " - 2s - loss: 3.6557e-04 - acc: 0.9924 - val_loss: 3.8625e-04 - val_acc: 0.9921\n",
      "Epoch 2895/3000\n",
      " - 1s - loss: 3.6577e-04 - acc: 0.9924 - val_loss: 3.5814e-04 - val_acc: 0.9922\n",
      "Epoch 2896/3000\n",
      " - 1s - loss: 3.6296e-04 - acc: 0.9925 - val_loss: 3.7801e-04 - val_acc: 0.9921\n",
      "Epoch 2897/3000\n",
      " - 2s - loss: 3.6502e-04 - acc: 0.9924 - val_loss: 3.5072e-04 - val_acc: 0.9926\n",
      "Epoch 2898/3000\n",
      " - 1s - loss: 3.7258e-04 - acc: 0.9923 - val_loss: 3.5976e-04 - val_acc: 0.9924\n",
      "Epoch 2899/3000\n",
      " - 2s - loss: 3.6851e-04 - acc: 0.9924 - val_loss: 3.5848e-04 - val_acc: 0.9924\n",
      "Epoch 2900/3000\n",
      "\n",
      "Epoch 02900: val_loss did not improve from 0.00036\n",
      " - 2s - loss: 3.7049e-04 - acc: 0.9924 - val_loss: 3.6384e-04 - val_acc: 0.9920\n",
      "Epoch 2901/3000\n",
      " - 1s - loss: 3.6553e-04 - acc: 0.9924 - val_loss: 3.5620e-04 - val_acc: 0.9926\n",
      "Epoch 2902/3000\n",
      " - 1s - loss: 3.6528e-04 - acc: 0.9924 - val_loss: 3.6301e-04 - val_acc: 0.9923\n",
      "Epoch 2903/3000\n",
      " - 1s - loss: 3.6477e-04 - acc: 0.9925 - val_loss: 3.6554e-04 - val_acc: 0.9926\n",
      "Epoch 2904/3000\n",
      " - 2s - loss: 3.7704e-04 - acc: 0.9923 - val_loss: 4.8534e-04 - val_acc: 0.9909\n",
      "Epoch 2905/3000\n",
      " - 2s - loss: 3.8910e-04 - acc: 0.9920 - val_loss: 3.6044e-04 - val_acc: 0.9923\n",
      "Epoch 2906/3000\n",
      " - 1s - loss: 3.6958e-04 - acc: 0.9924 - val_loss: 3.6277e-04 - val_acc: 0.9922\n",
      "Epoch 2907/3000\n",
      " - 2s - loss: 3.6797e-04 - acc: 0.9924 - val_loss: 3.5417e-04 - val_acc: 0.9922\n",
      "Epoch 2908/3000\n",
      " - 2s - loss: 3.5762e-04 - acc: 0.9925 - val_loss: 3.5286e-04 - val_acc: 0.9925\n",
      "Epoch 2909/3000\n",
      " - 2s - loss: 3.6376e-04 - acc: 0.9924 - val_loss: 3.5434e-04 - val_acc: 0.9922\n",
      "Epoch 2910/3000\n",
      " - 2s - loss: 3.5582e-04 - acc: 0.9926 - val_loss: 3.6060e-04 - val_acc: 0.9926\n",
      "Epoch 2911/3000\n",
      " - 2s - loss: 3.5835e-04 - acc: 0.9926 - val_loss: 3.5212e-04 - val_acc: 0.9924\n",
      "Epoch 2912/3000\n",
      " - 2s - loss: 3.6221e-04 - acc: 0.9925 - val_loss: 3.5393e-04 - val_acc: 0.9923\n",
      "Epoch 2913/3000\n",
      " - 1s - loss: 3.6896e-04 - acc: 0.9924 - val_loss: 3.5704e-04 - val_acc: 0.9927\n",
      "Epoch 2914/3000\n",
      " - 2s - loss: 3.6190e-04 - acc: 0.9925 - val_loss: 3.9315e-04 - val_acc: 0.9922\n",
      "Epoch 2915/3000\n",
      " - 2s - loss: 3.6470e-04 - acc: 0.9925 - val_loss: 3.6203e-04 - val_acc: 0.9925\n",
      "Epoch 2916/3000\n",
      " - 2s - loss: 3.5818e-04 - acc: 0.9926 - val_loss: 3.5211e-04 - val_acc: 0.9925\n",
      "Epoch 2917/3000\n",
      " - 2s - loss: 3.6087e-04 - acc: 0.9925 - val_loss: 3.5123e-04 - val_acc: 0.9925\n",
      "Epoch 2918/3000\n",
      " - 1s - loss: 3.5903e-04 - acc: 0.9925 - val_loss: 3.5599e-04 - val_acc: 0.9925\n",
      "Epoch 2919/3000\n",
      " - 2s - loss: 3.6209e-04 - acc: 0.9925 - val_loss: 3.5186e-04 - val_acc: 0.9925\n",
      "Epoch 2920/3000\n",
      "\n",
      "Epoch 02920: val_loss did not improve from 0.00036\n",
      " - 2s - loss: 3.5899e-04 - acc: 0.9925 - val_loss: 3.5677e-04 - val_acc: 0.9924\n",
      "Epoch 2921/3000\n",
      " - 1s - loss: 3.5935e-04 - acc: 0.9925 - val_loss: 3.6182e-04 - val_acc: 0.9926\n",
      "Epoch 2922/3000\n",
      " - 2s - loss: 3.6545e-04 - acc: 0.9924 - val_loss: 3.5097e-04 - val_acc: 0.9924\n",
      "Epoch 2923/3000\n",
      " - 2s - loss: 3.6392e-04 - acc: 0.9924 - val_loss: 3.5156e-04 - val_acc: 0.9925\n",
      "Epoch 2924/3000\n",
      " - 2s - loss: 3.6827e-04 - acc: 0.9924 - val_loss: 3.5942e-04 - val_acc: 0.9922\n",
      "Epoch 2925/3000\n",
      " - 1s - loss: 3.6445e-04 - acc: 0.9924 - val_loss: 3.5994e-04 - val_acc: 0.9925\n",
      "Epoch 2926/3000\n",
      " - 1s - loss: 3.6940e-04 - acc: 0.9924 - val_loss: 3.9490e-04 - val_acc: 0.9921\n",
      "Epoch 2927/3000\n",
      " - 1s - loss: 3.7525e-04 - acc: 0.9923 - val_loss: 3.5792e-04 - val_acc: 0.9921\n",
      "Epoch 2928/3000\n",
      " - 2s - loss: 3.6575e-04 - acc: 0.9924 - val_loss: 3.9243e-04 - val_acc: 0.9923\n",
      "Epoch 2929/3000\n",
      " - 2s - loss: 3.6380e-04 - acc: 0.9925 - val_loss: 3.8553e-04 - val_acc: 0.9918\n",
      "Epoch 2930/3000\n",
      " - 2s - loss: 3.6834e-04 - acc: 0.9923 - val_loss: 3.6682e-04 - val_acc: 0.9925\n",
      "Epoch 2931/3000\n",
      " - 2s - loss: 3.6419e-04 - acc: 0.9924 - val_loss: 3.6289e-04 - val_acc: 0.9921\n",
      "Epoch 2932/3000\n",
      " - 2s - loss: 3.7141e-04 - acc: 0.9923 - val_loss: 3.9733e-04 - val_acc: 0.9919\n",
      "Epoch 2933/3000\n",
      " - 2s - loss: 3.7541e-04 - acc: 0.9923 - val_loss: 3.6881e-04 - val_acc: 0.9923\n",
      "Epoch 2934/3000\n",
      " - 2s - loss: 3.6817e-04 - acc: 0.9924 - val_loss: 3.7126e-04 - val_acc: 0.9926\n",
      "Epoch 2935/3000\n",
      " - 1s - loss: 3.6349e-04 - acc: 0.9925 - val_loss: 3.6292e-04 - val_acc: 0.9922\n",
      "Epoch 2936/3000\n",
      " - 2s - loss: 3.6724e-04 - acc: 0.9924 - val_loss: 3.5390e-04 - val_acc: 0.9924\n",
      "Epoch 2937/3000\n",
      " - 2s - loss: 3.6299e-04 - acc: 0.9925 - val_loss: 3.5327e-04 - val_acc: 0.9924\n",
      "Epoch 2938/3000\n",
      " - 1s - loss: 3.6285e-04 - acc: 0.9925 - val_loss: 3.5178e-04 - val_acc: 0.9926\n",
      "Epoch 2939/3000\n",
      " - 2s - loss: 3.6142e-04 - acc: 0.9925 - val_loss: 3.6486e-04 - val_acc: 0.9925\n",
      "Epoch 2940/3000\n",
      "\n",
      "Epoch 02940: val_loss did not improve from 0.00036\n",
      " - 1s - loss: 3.7970e-04 - acc: 0.9923 - val_loss: 3.7324e-04 - val_acc: 0.9924\n",
      "Epoch 2941/3000\n",
      " - 1s - loss: 3.5829e-04 - acc: 0.9926 - val_loss: 3.6028e-04 - val_acc: 0.9923\n",
      "Epoch 2942/3000\n",
      " - 1s - loss: 3.5995e-04 - acc: 0.9926 - val_loss: 3.6039e-04 - val_acc: 0.9922\n",
      "Epoch 2943/3000\n",
      " - 1s - loss: 3.6383e-04 - acc: 0.9924 - val_loss: 3.7491e-04 - val_acc: 0.9920\n",
      "Epoch 2944/3000\n",
      " - 1s - loss: 3.6477e-04 - acc: 0.9924 - val_loss: 3.5751e-04 - val_acc: 0.9924\n",
      "Epoch 2945/3000\n",
      " - 1s - loss: 3.6799e-04 - acc: 0.9925 - val_loss: 3.5389e-04 - val_acc: 0.9926\n",
      "Epoch 2946/3000\n",
      " - 2s - loss: 3.6010e-04 - acc: 0.9924 - val_loss: 3.6628e-04 - val_acc: 0.9922\n",
      "Epoch 2947/3000\n",
      " - 2s - loss: 3.5764e-04 - acc: 0.9925 - val_loss: 3.5361e-04 - val_acc: 0.9925\n",
      "Epoch 2948/3000\n",
      " - 2s - loss: 3.5387e-04 - acc: 0.9926 - val_loss: 3.5770e-04 - val_acc: 0.9924\n",
      "Epoch 2949/3000\n",
      " - 2s - loss: 3.5469e-04 - acc: 0.9926 - val_loss: 3.5097e-04 - val_acc: 0.9925\n",
      "Epoch 2950/3000\n",
      " - 2s - loss: 3.6134e-04 - acc: 0.9925 - val_loss: 3.6023e-04 - val_acc: 0.9926\n",
      "Epoch 2951/3000\n",
      " - 2s - loss: 3.6077e-04 - acc: 0.9924 - val_loss: 3.5842e-04 - val_acc: 0.9922\n",
      "Epoch 2952/3000\n",
      " - 2s - loss: 3.6212e-04 - acc: 0.9925 - val_loss: 3.5431e-04 - val_acc: 0.9924\n",
      "Epoch 2953/3000\n",
      " - 2s - loss: 3.6574e-04 - acc: 0.9924 - val_loss: 3.6121e-04 - val_acc: 0.9922\n",
      "Epoch 2954/3000\n",
      " - 2s - loss: 3.6352e-04 - acc: 0.9924 - val_loss: 3.7254e-04 - val_acc: 0.9923\n",
      "Epoch 2955/3000\n",
      " - 2s - loss: 3.6622e-04 - acc: 0.9923 - val_loss: 3.6762e-04 - val_acc: 0.9924\n",
      "Epoch 2956/3000\n",
      " - 2s - loss: 3.6557e-04 - acc: 0.9924 - val_loss: 3.4964e-04 - val_acc: 0.9926\n",
      "Epoch 2957/3000\n",
      " - 2s - loss: 3.5522e-04 - acc: 0.9926 - val_loss: 3.5841e-04 - val_acc: 0.9925\n",
      "Epoch 2958/3000\n",
      " - 2s - loss: 3.6006e-04 - acc: 0.9924 - val_loss: 3.6713e-04 - val_acc: 0.9923\n",
      "Epoch 2959/3000\n",
      " - 2s - loss: 3.6479e-04 - acc: 0.9925 - val_loss: 3.4657e-04 - val_acc: 0.9926\n",
      "Epoch 2960/3000\n",
      "\n",
      "Epoch 02960: val_loss did not improve from 0.00036\n",
      " - 2s - loss: 3.6488e-04 - acc: 0.9924 - val_loss: 3.6384e-04 - val_acc: 0.9923\n",
      "Epoch 2961/3000\n",
      " - 1s - loss: 3.5795e-04 - acc: 0.9925 - val_loss: 3.6866e-04 - val_acc: 0.9921\n",
      "Epoch 2962/3000\n",
      " - 1s - loss: 3.7349e-04 - acc: 0.9922 - val_loss: 3.6094e-04 - val_acc: 0.9925\n",
      "Epoch 2963/3000\n",
      " - 1s - loss: 3.5706e-04 - acc: 0.9926 - val_loss: 3.6405e-04 - val_acc: 0.9922\n",
      "Epoch 2964/3000\n",
      " - 1s - loss: 3.6787e-04 - acc: 0.9924 - val_loss: 3.6596e-04 - val_acc: 0.9925\n",
      "Epoch 2965/3000\n",
      " - 2s - loss: 3.6186e-04 - acc: 0.9925 - val_loss: 3.5933e-04 - val_acc: 0.9925\n",
      "Epoch 2966/3000\n",
      " - 1s - loss: 3.5747e-04 - acc: 0.9925 - val_loss: 3.5947e-04 - val_acc: 0.9924\n",
      "Epoch 2967/3000\n",
      " - 2s - loss: 3.6112e-04 - acc: 0.9924 - val_loss: 3.6582e-04 - val_acc: 0.9923\n",
      "Epoch 2968/3000\n",
      " - 2s - loss: 3.7366e-04 - acc: 0.9923 - val_loss: 3.6952e-04 - val_acc: 0.9924\n",
      "Epoch 2969/3000\n",
      " - 2s - loss: 3.6386e-04 - acc: 0.9925 - val_loss: 3.4607e-04 - val_acc: 0.9927\n",
      "Epoch 2970/3000\n",
      " - 2s - loss: 3.5510e-04 - acc: 0.9926 - val_loss: 3.5404e-04 - val_acc: 0.9923\n",
      "Epoch 2971/3000\n",
      " - 1s - loss: 3.5544e-04 - acc: 0.9926 - val_loss: 3.5240e-04 - val_acc: 0.9926\n",
      "Epoch 2972/3000\n",
      " - 2s - loss: 3.6355e-04 - acc: 0.9925 - val_loss: 3.7168e-04 - val_acc: 0.9923\n",
      "Epoch 2973/3000\n",
      " - 2s - loss: 3.7220e-04 - acc: 0.9923 - val_loss: 3.9539e-04 - val_acc: 0.9921\n",
      "Epoch 2974/3000\n",
      " - 1s - loss: 3.5988e-04 - acc: 0.9924 - val_loss: 3.6587e-04 - val_acc: 0.9919\n",
      "Epoch 2975/3000\n",
      " - 2s - loss: 3.6222e-04 - acc: 0.9925 - val_loss: 3.5441e-04 - val_acc: 0.9923\n",
      "Epoch 2976/3000\n",
      " - 1s - loss: 3.5996e-04 - acc: 0.9926 - val_loss: 3.4821e-04 - val_acc: 0.9925\n",
      "Epoch 2977/3000\n",
      " - 2s - loss: 3.5969e-04 - acc: 0.9925 - val_loss: 3.6295e-04 - val_acc: 0.9926\n",
      "Epoch 2978/3000\n",
      " - 1s - loss: 3.6626e-04 - acc: 0.9924 - val_loss: 3.6738e-04 - val_acc: 0.9922\n",
      "Epoch 2979/3000\n",
      " - 2s - loss: 3.6398e-04 - acc: 0.9924 - val_loss: 3.6207e-04 - val_acc: 0.9923\n",
      "Epoch 2980/3000\n",
      "\n",
      "Epoch 02980: val_loss improved from 0.00036 to 0.00035, saving model to ./weights.best.cntk.hdf5\n",
      " - 2s - loss: 3.5807e-04 - acc: 0.9925 - val_loss: 3.4919e-04 - val_acc: 0.9924\n",
      "Epoch 2981/3000\n",
      " - 2s - loss: 3.5646e-04 - acc: 0.9926 - val_loss: 3.4914e-04 - val_acc: 0.9925\n",
      "Epoch 2982/3000\n",
      " - 2s - loss: 3.5955e-04 - acc: 0.9926 - val_loss: 3.9232e-04 - val_acc: 0.9915\n",
      "Epoch 2983/3000\n",
      " - 1s - loss: 3.6130e-04 - acc: 0.9924 - val_loss: 3.6121e-04 - val_acc: 0.9919\n",
      "Epoch 2984/3000\n",
      " - 2s - loss: 3.5777e-04 - acc: 0.9925 - val_loss: 3.5157e-04 - val_acc: 0.9923\n",
      "Epoch 2985/3000\n",
      " - 1s - loss: 3.5879e-04 - acc: 0.9925 - val_loss: 3.6619e-04 - val_acc: 0.9923\n",
      "Epoch 2986/3000\n",
      " - 1s - loss: 3.5907e-04 - acc: 0.9925 - val_loss: 3.5984e-04 - val_acc: 0.9921\n",
      "Epoch 2987/3000\n",
      " - 1s - loss: 3.5579e-04 - acc: 0.9927 - val_loss: 3.4760e-04 - val_acc: 0.9924\n",
      "Epoch 2988/3000\n",
      " - 2s - loss: 3.6381e-04 - acc: 0.9925 - val_loss: 3.4945e-04 - val_acc: 0.9925\n",
      "Epoch 2989/3000\n",
      " - 2s - loss: 3.6846e-04 - acc: 0.9924 - val_loss: 3.7908e-04 - val_acc: 0.9924\n",
      "Epoch 2990/3000\n",
      " - 1s - loss: 3.6226e-04 - acc: 0.9925 - val_loss: 3.5215e-04 - val_acc: 0.9922\n",
      "Epoch 2991/3000\n",
      " - 1s - loss: 3.5964e-04 - acc: 0.9925 - val_loss: 3.8012e-04 - val_acc: 0.9923\n",
      "Epoch 2992/3000\n",
      " - 1s - loss: 3.5691e-04 - acc: 0.9926 - val_loss: 3.6270e-04 - val_acc: 0.9924\n",
      "Epoch 2993/3000\n",
      " - 1s - loss: 3.5675e-04 - acc: 0.9926 - val_loss: 3.5959e-04 - val_acc: 0.9923\n",
      "Epoch 2994/3000\n",
      " - 2s - loss: 3.5821e-04 - acc: 0.9926 - val_loss: 3.7457e-04 - val_acc: 0.9921\n",
      "Epoch 2995/3000\n",
      " - 1s - loss: 3.6212e-04 - acc: 0.9925 - val_loss: 3.5727e-04 - val_acc: 0.9921\n",
      "Epoch 2996/3000\n",
      " - 1s - loss: 3.6733e-04 - acc: 0.9923 - val_loss: 3.5727e-04 - val_acc: 0.9921\n",
      "Epoch 2997/3000\n",
      " - 2s - loss: 3.5874e-04 - acc: 0.9926 - val_loss: 3.5369e-04 - val_acc: 0.9925\n",
      "Epoch 2998/3000\n",
      " - 2s - loss: 3.6495e-04 - acc: 0.9924 - val_loss: 3.5138e-04 - val_acc: 0.9925\n",
      "Epoch 2999/3000\n",
      " - 2s - loss: 3.6069e-04 - acc: 0.9925 - val_loss: 3.5305e-04 - val_acc: 0.9925\n",
      "Epoch 3000/3000\n",
      "\n",
      "Epoch 03000: val_loss did not improve from 0.00035\n",
      " - 2s - loss: 3.6037e-04 - acc: 0.9925 - val_loss: 3.6815e-04 - val_acc: 0.9924\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "batch_size = 1024*32\n",
    "epochs = 3000\n",
    "vsplit = 0.2\n",
    "\n",
    "loss_type='mse'\n",
    "\n",
    "adam_op = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999,epsilon=1e-8, decay=0.0, amsgrad=True)\n",
    "\n",
    "model.compile(loss=loss_type, optimizer=adam_op, metrics=['accuracy'])\n",
    "# model.compile(loss=cubic_loss, optimizer=adam_op, metrics=['accuracy'])\n",
    "\n",
    "# checkpoint (save the best model based validate loss)\n",
    "filepath = \"./weights.best.cntk.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='min',\n",
    "                             period=20)\n",
    "\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=vsplit,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks_list,\n",
    "    shuffle=True)\n",
    "\n",
    "model.save('trained_fgm_nn.H5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LsrHilCnti4G"
   },
   "source": [
    "## TPU training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FjnfVehAthg9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "batch_size = 1024*128\n",
    "epochs = 100\n",
    "vsplit = 0.2\n",
    "\n",
    "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
    "    model,\n",
    "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
    "        tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
    "    )\n",
    ")\n",
    "\n",
    "tpu_model.compile(\n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate=1e-4),\n",
    "    loss=tf.keras.losses.mae,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "tpu_model.fit(\n",
    "    X_train,y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=vsplit\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WiABe74SgU9U"
   },
   "source": [
    "## Training loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "hFkbKI3ygRgp",
    "outputId": "0478ea98-ee53-483a-dcbd-83d0d0e2ced6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3XmcU+W9x/HPL5nJDJvDKiKgoKjVugCitbVW6woq2tZ9qestWuuttnXBtm73tmrba69SV7xS9xW1uIAiiktdkEVQ9k2UAWRnGJbZkuf+cc4wYUhmJjNJTiZ836/XvJKcnJz8DpnJl+d5znmOOecQERFpqlDQBYiISOui4BARkZQoOEREJCUKDhERSYmCQ0REUqLgEBGRlCg4REQkJQoOERFJiYJDRERSouAQaSEzW2Jm15vZF2a22cweNbPuZjbOzMrNbIKZdTKzYjN7yszWmtkGM5tsZt39bZT4r1thZsvM7E9mFg5630QSKQi6AJE8cQZwAt7f1OfAAOByYDYwDvg18C1QAvQGKoH+wFb/9Y8DK4F+QDvgdWAp8HDW9kCkidTiEEmPfzjnVjrnlgEfApOcc5875yqBV/CCpBroAvRzzkWdc1Odcxv9VscQ4Frn3Gbn3Crgf4FzA9oXkQapxSGSHivj7m9N8Lg98CRea+M5M+sIPAX8AdgTKARWmFnta0J4LQ6RnKPgEMkS51w1cDtwu5n1AcYC8/zbSqCrc64msAJFmkhdVSJZYmY/NrOD/EHvjXhdV1Hn3ApgPHC3me1iZiEz29vMjg60YJEkFBwi2bMbMBovNOYA7+N1VwFcBETwBtPX++v1CKBGkUaZLuQkIiKpUItDRERSouAQEZGUKDhERCQlCg4REUlJXp7H0bVrV9enT5+gyxARaVWmTp26xjnXrbH18io4zGwoMLRfv35MmTIl6HJERFoVM/u6KevlVVeVc+4159ywkpKSoEsREclbeRUcIiKSeXkVHGY21MxGlpWVBV2KiEjeyqsxDufca8BrgwYN+kXQtYhI61JdXU1paSkVFRVBl5JxxcXF9OrVi8LCwma9Pq+CQ0SkuUpLS+nQoQN9+vQhbnr7vOOcY+3atZSWltK3b99mbSOvuqpERJqroqKCLl265HVoAJgZXbp0aVHLKq+CQ2McItIS+R4atVq6n3kVHC09HPflaaU8M+mbNFclIpJf8io4WmrM9OU8P0VX6xSR7NuwYQMPPPBAyq87+eST2bBhQwYqSk7BEcfMGzgSEcm2ZMERjUYbfN3YsWPp2LFjpspKKK+OqoqfcqQ5QmYoN0QkCMOHD2fRokX079+fwsJC2rdvT48ePZg+fTqzZ8/mJz/5CUuXLqWiooJrrrmGYcOGAdCnTx+mTJnCpk2bGDJkCD/84Q/5+OOP6dmzJ2PGjKFNmzZprzWvgqOl53EYEFNyiOz0bn9tFrOXb0zrNg/YfRduHfrdpM/fddddzJw5k+nTp/Pee+9xyimnMHPmzG2HzI4aNYrOnTuzdetWDjvsMM444wy6dOmy3TYWLFjAs88+yyOPPMLZZ5/NSy+9xIUXXpjW/YA8C46WMrU4RCRHHH744dudZzFixAheeeUVAJYuXcqCBQt2CI6+ffvSv39/AA499FCWLFmSkdoUHHHM1OIQERpsGWRLu3bttt1/7733mDBhAp988glt27blmGOOSXgeRlFR0bb74XCYrVu3ZqQ2DY7HCe0ch3CLSA7q0KED5eXlCZ8rKyujU6dOtG3blrlz5/Lpp59mubrt5VWLo6WD44apxSEigejSpQtHHnkkBx54IG3atKF79+7bnhs8eDAPPfQQBx98MPvttx9HHHFEgJWC5ePhp4MGDXLNuZDTVU9PZcHKTbz926MzUJWI5LI5c+aw//77B11G1iTaXzOb6pwb1Nhr1VUVx0wtDhGRxig44hjoqCoRkUYoOOKEzFBuiIg0TMERR4fjiog0Lq+Co6XTqmvKERGRxuVVcLR0WvUBZe8wuHpCmqsSEckveRUcLXVY2VucXvNW0GWIyE6oudOqA9xzzz1s2bIlzRUlp+CIZ0aIWNBViMhOqDUFR16dOd5SzkKEFRwiEoD4adVPOOEEdt11V1544QUqKyv56U9/yu23387mzZs5++yzKS0tJRqNcvPNN7Ny5UqWL1/Oj3/8Y7p27crEiRMzXquCI44jhA7IFRHGDYdvv0zvNnc7CIbclfTp+GnVx48fz+jRo/nss89wznHaaafxwQcfsHr1anbffXfeeOMNwJvDqqSkhL///e9MnDiRrl27prfmJNRVFcdZiJBTi0NEgjV+/HjGjx/PgAEDGDhwIHPnzmXBggUcdNBBTJgwgRtvvJEPP/yQ5h4I1FJ51eJo6SSHzkKYuqpEpIGWQTY457jpppu44oordnhu6tSpjB07lptuuokTTzyRW265Jev15VWLo6WH4zpChNRVJSIBiJ9W/aSTTmLUqFFs2rQJgGXLlrFq1SqWL19O27ZtufDCC7nuuuuYNm3aDq/NhrxqcbSYjqoSkYDET6s+ZMgQzj//fL7//e8D0L59e5566ikWLlzI9ddfTygUorCwkAcffBCAYcOGMWTIEHr06JGVwXFNqx5nxr1n0Wn9DPa4bX4GqhKRXKZp1TWterM4dDiuiEhjFBxxvMHx/GuBiYikk4IjnoUI5WHXnYg0TT523SfS0v1UcMRxFtLguMhOqri4mLVr1+Z9eDjnWLt2LcXFxc3eho6qiqfgENlp9erVi9LSUlavXh10KRlXXFxMr169mv16BUcctThEdl6FhYX07ds36DJaBXVVxdHguIhI4/IqOFp6BUB05riISKPyKjhaOuUImlZdRKRReRUcLaVJDkVEGqfgiOe3OPL9cDwRkZZQcMQJhQswHNVRBYeISDIKjjihkDc4XhVVd5WISDIKjjgWLqTQolRV1wRdiohIzlJwxCvwTsGvqtwacCEiIrlLwRGvsA0ANRVbAi5ERCR3KTjiWKHX4qiuUnCIiCSj4IhjfoujWl1VIiJJKTjihAqLAIgqOEREklJwxAnVjnFUKThERJJRcMQJRbzgiCk4RESSUnDEKfCDI6rgEBFJKueDw8z2MrNHzWx0pt+roMhvcVRXZPqtRERarYwGh5mNMrNVZjaz3vLBZjbPzBaa2fCGtuGcW+ycuzyTddYqKGoLqMUhItKQTF869jHgPuCJ2gVmFgbuB04ASoHJZvYqEAburPf6y5xzqzJc4zaRYq/F4dTiEBFJKqPB4Zz7wMz61Ft8OLDQObcYwMyeA053zt0JnNrc9zKzYcAwgD322KNZ2ygsagdATCcAiogkFcQYR09gadzjUn9ZQmbWxcweAgaY2U3J1nPOjXTODXLODerWrVuzCov4YxyuprJZrxcR2RlkuqsqEUuwLOkFMJxza4ErM1dOnaI23hiHuqpERJILosVRCvSOe9wLWJ6ODZvZUDMbWVZW1qzXF0S84KBGwSEikkwQwTEZ2MfM+ppZBDgXeDUdG3bOveacG1ZSUtK8DYRCVLswpuAQEUkq04fjPgt8AuxnZqVmdrlzrga4GngLmAO84Jyblck6UlFpEYhqjENEJJlMH1V1XpLlY4Gx6X4/MxsKDO3Xr1+zt1FFBNPguIhIUjl/5ngqWtxVBVRZhJBaHCIiSeVVcKRDjYJDRKRBeRUcLT2qCqDaIoRjCg4RkWTyKjjS0VVVE1JwiIg0JK+CIx2ioQgFsaqgyxARyVkKjnqioSIFh4hIAxQc9dSEiihwCg4RkWTyKjjSMTgeCxdRqOAQEUkqr4IjHYPjTsEhItKgvAqOdIiFiyhScIiIJKXgqK+giAgKDhGRZPIqONIxxkFBMRGqicaSXiJERGSnllfBkZYxjoJiiqyGyurqNFYmIpI/8io40sEKigGo3Lo14EpERHKTgqMeK/SCo6pSwSEikoiCo55QbXBs3RxwJSIiuUnBUU9ti6O6Si0OEZFE8io40nFUVTjiB0fllnSVJSKSV/IqONJxVFW4sA0A1RrjEBFJKK+CIx3CRV6Lo6aqIuBKRERyk4KjnsJIW0DBISKSjIKjnoJIEQBRDY6LiCSk4KinsMhrcUSrdPlYEZFEFBz1FPpjHLFqtThERBJRcNQTqW1xVKvFISKSSF4FRzrO44gUey0OV6PBcRGRRPIqONJxHkdRsdficGpxiIgklFfBkQ5W4B1VpRaHiEhiCo76wl5wUKOrAIqIJKLgqC9cQA0hUItDRCQhBUcCVUSwqFocIiKJKDgSqLFCiGpwXEQkEQVHAtVECEfVVSUikoiCI4GqUBFhtThERBJScCRQFSqmIKopR0REEsmr4EjHmeMA1aFiIjF1VYmIJJJXwZGOM8cBqsNtKFRwiIgk1KTgMLNrzGwX8zxqZtPM7MRMFxeUaKiYIqfgEBFJpKktjsuccxuBE4FuwKXAXRmrKmDRgjZEnAbHRUQSaWpwmH97MvBP59yMuGV5J1bYlmK1OEREEmpqcEw1s/F4wfGWmXUAYpkrK1hW2JY2VFIdzdtdFBFptoImrnc50B9Y7JzbYmad8bqr8lIo0pZiKimvqKFzu0jQ5YiI5JSmtji+D8xzzm0wswuBPwItO+Y1h4WL2hGxKOWbtwRdiohIzmlqcDwIbDGzQ4AbgK+BJzJWVcDCxe0B2LxpY8CViIjknqYGR41zzgGnA/c65+4FOmSurGAV+sGxRcEhIrKDpo5xlJvZTcDPgaPMLAwUZq6sYBW27wxA5cY1AVciIpJ7mtriOAeoxDuf41ugJ/C3jFUVsEjH3QGIblwRcCUiIrmnScHhh8XTQImZnQpUOOfydoyjbafuALjNanGIiNTX1ClHzgY+A84CzgYmmdmZmSwsSO394IhtXhtwJSIiuaepYxx/AA5zzq0CMLNuwARgdKYKC1KoTQkxDLd1fdCliIjknKaOcYRqQ8O3NoXXtoiZ/cTMHjGzMVmbWDEUZhPtCVcoOERE6mvql/+bZvaWmV1iZpcAbwBjG3uRmY0ys1VmNrPe8sFmNs/MFprZ8Ia24Zz7l3PuF8AleIP0WVFeUEKkQmMcIiL1Namryjl3vZmdARyJN7nhSOfcK0146WPAfcSdLOgfyns/cAJQCkw2s1eBMHBnvddfFtfS+aP/uqzYUrwbHTatzNbbiYi0Gk0d48A59xLwUiobd859YGZ96i0+HFjonFsMYGbPAac75+4ETq2/DTMzvCncxznnpqXy/i1R3b4n3coXsrUqSptIOFtvKyKS8xrsqjKzcjPbmOCn3Myae1p1T2Bp3ONSf1ky/wkcD5xpZlc2UOswM5tiZlNWr17dzNLqhHfZja6UsWzdphZvS0QknzTY4nDOZWJakUTX8XAN1DACGNHYRp1zI4GRAIMGDUq6vaYq7rQbYXPMXbyEfrsd0tLNiYjkjSCuOV4K9I573AtYno4Nm9lQMxtZVtbyiXu77rYHAFtXzG3xtkRE8kkQwTEZ2MfM+ppZBDgXeDUdG3bOveacG1ZSUtLibbXruicAp828psXbEhHJJxkNDjN7FvgE2M/MSs3scudcDXA18BYwB3jBOTcrk3U0y24HAVDktlKjKwGKiGzT5KOqmsM5d16S5WNpwnkgqTKzocDQfv36tXxjhcXb7i5etZF9e3Rs+TZFRPJAEF1VGZPOriqAWf1vAeCOp9KecSIirVZeBUe67dN7NwAe2/zLgCsREckdCo4GRParmxorqnEOEREgz4IjnYfjAtC+27a7a1aWpmebIiKtXF4FR7rHOLbz4iXp36aISCuUV8GRCVUDLwNgl43zA65ERCQ3KDgaEenzAwAqKQy4EhGR3JBXwZH2MQ6Ag88CoGN0HRWVVenbrohIK5VXwZHRMQ5gzZg/ZGS7IiKtSV4FR6b1mj0y6BJERAKn4GiCmi77BV2CiEjOUHA0QcHgO4IuQUQkZ+RVcGRkcBxgn+O33V26VlcEFJGdW14FR6YHxwHuGPlExrYtItIa5FVwZMNVFY8EXYKISKAUHE3kwkUAHGSLYcGEgKsREQmOgqOJ7Gdxh+K+fXNwhYiIBEzB0VQHnL7tbixWE2AhIiLByqvgyNhRVd7G6+5vXJ7+7YuItBJ5FRzZOKoKIFSlQ3JFZOeVV8GRaWX9fhp0CSIigVNwpKDdOZqrSkREwZGCgsLItvuuemuAlYiIBEfBkaK1HfYHoHL0LwOuREQkGAqOFNV0+y4AxfNeCbgSEZFg5FVwZPRw3Fon3F53f/PazL2PiEiOyqvgyMbhuLvuulvdg+fOy9j7iIjkqrwKjmywcEHdg6WTgitERCQgCg4REUmJgqMZ3LUz6x6snB1cISIiAVBwNIN17L3tfvkidVeJyM5FwdFCHcZfG3QJIiJZpeBopuqjfx90CSIigVBwNFPhMTdsu3/hw+8HWImISHYpOJor7vocT604jRWPnh9gMSIi2aPgaIlrZmy722PpGwEWIiKSPXkVHFmZciRepz7bPZz273HZeV8RkQDlVXBk6wqA27mkrqUxcMK5cP/3svfeIiIByKvgCESfH7K2z6l1j1fPDa4WEZEsUHCkQZcz/r7d4/mfarxDRPKXgiMdOnTf7uG+b57P1slPwsQ7AypIRCRzFBzp8vvl2z1s88bV8P5dcM9B8PYtARUlIpJ+Co50ibSDC17acfmGb+Cje2HRu9mvSUQkAxQc6bTP8TB8aeLnnvwp3FYCnz+V3ZpERNJMwZFuxbskbnnUGvMrWPFF9uoREUkzBUcm7HM8HHpp8ucXjIdoTfbqERFJIwVHpgy9B66eSuUBZ+343Lv/TWzinbB2UfbrEhFpIQVHJnXtR9Fpdyd8KvTv/4F/DIRXroTqiiwXJiLSfAqOTCsugV9PJ/rdMxI/P+NZeOyU7NYkItICCo5s6NyX8FmjYOiIxM8vmwJjroaNK+Cfp8Dk/8tufSIiKTDnXNA1pN2gQYPclClTgi4jsWVT4ZFjEz61se2e7LLla+/BrRu2u+aHiEimmdlU59ygxtbL+RaHme1vZg+Z2Wgz+2XQ9bRYz0PhlvXw/at3eGpbaACVj5y4/ZPPngdfvJDp6kREGpXR4DCzUWa2ysxm1ls+2MzmmdlCMxve0Dacc3Occ1cCZwONJmGrEArBSX+G819MukrR8s/oP/w5YjU13lnn88bCy7/IYpEiIolltKvKzH4EbAKecM4d6C8LA/OBE4BSYDJwHhAG6s8KeJlzbpWZnQYMB+5zzj3T2PvmdFdVfdEaWDwRnj6zaetf+RHsduD2y6oroKBIXVsi0iI50VXlnPsAWFdv8eHAQufcYudcFfAccLpz7kvn3Kn1flb523nVOfcD4IJk72Vmw8xsiplNWb16daZ2Kf3CBbDPCXDzGrj2y0ZXj62ev/2Cqs3w5+7w7p8yVKCIyPaCGOPoCcRP6FTqL0vIzI4xsxFm9jAwNtl6zrmRzrlBzrlB3bp1S1+12RIuhI57wG1l3hhIEqGXLoXbSli6ZiOsng8VG70nPrnPmwvrk/uzVLCI7KwKAnjPRP0pSfvLnHPvAe9lqpicFArB71fANx/jXrsWK9tx4sTe9/UGYI3bha4G1PgnEb71ezjiKnVbiUjGBNHiKAV6xz3uBSxPsm5KzGyomY0sKytLx+aCFWkL/Y7HfjMTfjsX9h2ccLWutnHHhbd3pPpl/wC0Gc97LZHqrRksVkR2Jhk/j8PM+gCvxw2OF+ANjh8HLMMbHD/fOTcrXe/ZqgbHUzVvHDx7buqvO+R82PckWPi2N7X7bXkQriKSVk0dHM/0UVXPAscAXYGVwK3OuUfN7GTgHrwjqUY55/6czvfN6+CoNXcszH0Dpjfz+h69j4CfPQzrv4Yue8PSSdB1X9i6AbauhwNOS2+9IpLzciI4ss3MhgJD+/Xr94sFCxYEXU52OAfVW2DLWhg1BDaWpme7apGI7HRy4nDcbHPOveacG1ZSUhJ0Kdlj5l22tuMe8NtZcO1MOP0BOOG/0vs+0WqY9oQ3n1Yib98KTyWZyFFE8koQR1VJJnXsDQP8012OvMZrkdw3CNYuTGkzD9/5a/7jqL0JT7iFLQN+QdsVk+Bb/8qF1y+CSHsoLK57wUf3eLcrZkCPQ5Jv+J8nw+Y1cPVnKdUjIrlDXVU7k1jUG7/4295p2dy7u17EsauegN/Mhv89oO6J/hd4V0DsfdiOL7rNbw3W7wqb8zqsnAnHNDgDjYhk0E45xlFrpxgcT4eyUu9//1MeJbrPSYSfT3pifvP8fjlg3qHFtZIFR7LlIpI1TQ0OdVXtzEp6eT+n/YMweF/aleUwZRSEi+DNG1u2/Tt2ByD6g99QMegKCl/7FZHa527vhOt5KNWXjCdSEDfUVrER3rwJOu0JHfeEQ85pWQ0iknZqcUjTfP0x/HNI2jd7TdVV3HvB4fDiJYlXyFYLxDlY/xV03is77yeSg3bKo6ry6szxXLPnD7wv8Vs3wHUL4ZS74aJXcX2PadFm7408kDw0gMqFH8K4G72urA/vxq2YwbLHL6eqOlq30vLPE1+rZMm/vdet+6rxQj66F0YM8F5T37rFXrDkolgU3v8rVOh3XrJHLQ5pucpyKOrgfYl9ch+sWUBN212x+W8SXp22CQEaFTv5bmq+nUVk2ii4cQnVT59LYemn3uHJtUeaLXwHeh/u1Vu9Fe7/Hgy9Bz59EBaM99aJb+V8OxMeOtI7imz4NxAKe8srNsKaBdDr0KztX0JzXoPnL4QBP4fT7wu2Fmn1NMYh2VPUwbsNhb1DgPF/sU64xVu+dpF3O+E2mPNqxsoIjf1d3RjKX/pQ6N99d+YSjlp8BeElHxIqXwbArDPeoXR1GSdt+NobU1k9t25Ds8fA/qd558iU+SdUVm2CBW/Dfv6cYS/8HBa/B3/4Fj4aASU9YcCFjRcZrfZO1uywW8PrjRsOkx5svKuuptK7rd7S+HuLpImCQzKvi3/47zlP7vjc2kXel/K0J2HfwVRNf57IrPReIvfYRX/dYdl3XzqO79Y+iA8NgBcugnOfge+cAqG6P5HowneYXHgYfbu0pfvi9wComjOOyHt3eCsUtoXvnAqPnwrH3+Z179Wa8Zw3ncvKmfD5k17gFLZJXvSkB73bWMybLblRjcyGvGUdtO3chO2INE7BIcGqDZVTvJMGI/scD2c9sv06S/4N7brB6nmwZh7s0gs+HgGrZhOLtCdUtSn9dT13/g6LwpNHMvHjch5yvXnMb9pEXr60boXRcff9Awmiv55BZftetH3lCm95gR8WVVsaDo5a0UoI1VsvWu11q+13ctzCuC7nWf+CFy/2utaKS2Dx+/DEaXD+C95El7nMOe+nSWEpQcmr4Ig7ATDoUiSd+vzQu+22X92y/ucB/tEdznldNoXFEK3BvTkcKsuw3kfAG79Nayk3FT6b0vrhEYcwquZ0rq79S6vxprevnPkqZQecx6TpXzJr/gIO+c6+HLrvnkwZ8wDHdFzJtjNf/rwbdN4b1i2CG77yWg0f/A3e/wtcMHr7N5v5Mkx73GtdgDeeM/9NaN/de/zM2XVdX1Vb4I4ecNo/YOBFKf87AN4YT7Qauh/Q+LpNNe4G+Gzkjl1030yC+eO8llw61Y7x5vL1a2IxePtmOOw/oHPfoKsBNDguOwPnvC+G8m+hbRdY8QUsegdmPAtH/Y7Yx/8gVL+7Kgd9E+lH+3bt6Lx+xo5Phou81gngQgVYrCbuuQhEq7z7tV/IaxfBPwbiOvXBrqm3venPeK856EzvcSwGU0d5A/CxqPcFfuAZdSdtxh98kEy0Bt79bzjil94Y0qGXQkFk+3W2boC/7Ondv3VD3Zf5a9fA1Me8+2f+E/odD8W7NPx+janYCM9fAF99AKf+Lwy6rGXbS6fyldChe93jFV/Aw0dBj/5wxfsZfWsNjovUqv0Cqh2Q7nWo93P0DQCE4ge1YzGo3gyVm7z5vTr08K6uWFnufTG//1f4+iM46Gz4Mr1jMY3Zo2ohVCV50g8NYPvQgLrQAKr+9Z9Epj+x7fGmdSuJba2mZPojULkR16YTNs77d+HdP8GProMxv/Iev/G7um127FN3f8xV3r/RwIvhmbPgqN/BnkfCPQfDUb+BVXO8VgTUzWlWsRGOvr5uG199AI8PrXscq/Eupwx1oQFed+D+p3njZf93vDcGddmbSf5REnjoKOhzlPfF/NUH3rJpT6QvOGLRuiPvmmPuG1436UWvwl5He8tczL+NJn9dlik4ROKFQt5RYkUdYJceOz6/1zF198+IG4uJResmgYxF4ZtPYfFE2H0AsUgHrLIc+/Bvmay8SeJDA6CDbYW/dN32eLsOm/Vf1YVGff937PaP3/gt0bdvI1y1karSzynfeyhdyr6B13+T+PUT/+T9Gx9xJcx/C14etv3zH/wPtOkIXfbZ8bXrFnu3pZMTb3vdYijpXRc8tb760PuMvv1i+9mjo/WCtiHv/Bd8eHfdwQ2xGJSvgE3fwiP+v8nQEXDoxU3fZrylk7zbZVPrgiMHKThE0iEUht0H1D3uNQh+cLX3VO2y4/7o3caiXvdZOMGf37Jp0KmPd0LfiP4ArNpjCLt+My5jpadLuMq7jHGkcj1dZj/RyNrAmzeyZPx99Ikt3fG59+9K/rqVM+u6yYCyLdWUtC2kqiZG2ZpSuj00wLtQ2VG/g00rvQDa+1jvaLfaTaxaybbOIL+F9m1ZBZ99OYchH59D6OjrCX/vF97Y2SPHweA7oO+PvNAAb+zpvOdhzXxv/CF+nOi1X28fHFVbYNVs73eiMR/d693WtjJylMY4RFqrynIvYMpXwqcPeF9WXfp5Xz6D7/K6h6Y/Q8zCxA45j4Jx1wVdcUZ85A5mUvdz+e2q3zf5NRtcOzra5m2Pl1y9nLP+519MLr6qbqVjbybWYwChp3/mPY50gKryuucL23ndmoArbIvFn0vTdT/vfJ0bFsHoy2GmfyDDLeu3P2Js6WTvCLgfXQ+vX1u3/Md/2NaVyrKpXmumZA+4eAzMHw+HD6vbzooZ3lQ5tedTtcBOOTuuplUXaUBNlTcmUPuFU/9xtNrrNlo6CY67xevqWTkLNiyFrvsQ++R+qqJQNPtFrHJjcPvRyi36zpWs7v8rli+Zx88+PTPhOuUDhtHh85FJt7HDMifIAAAIBUlEQVT2x3+ly9FXeJ/NPQd6Cwde5B0l1wI7ZXDUUotDJCBb1nmD8e27eyd2hgq8L7eqcuh5KCybRmzKY4SOuQHadCL60jDC817f4X/zO/wPXpru+sXQrkuzXqqjqkQk++LPTq/tOum2b92yngMJ9Ry47WH4vKcTbsbAm0ssVOCPU3T2ruuydpHXEtqll9dSilbD27d44wdb1nlzim1c5o0VrZ7jnST5iT+H19B7vUN7gWikhHBVGau6HsGuaz5N4z9A8FauWU33ZgZHU6nFISJSqzas6h+RVWvzWu9w7K/e9w7Vriz3ToQsKIJoFdXdDya68D2KI4W4aBX2zScAVPX8HpFlk6huvzvhLWsIxZIdV91yq379Nbt27tis16qrSsEhIq1J5SYoar/j8rJlgIP1S7xJN79zKrHyldjsV7Clk2Dzaqiu8GZTOPBMb8LNZlJXlYhIa5IoNKAuCEp6bVsUKmrvnZwZEM0kJiIiKVFwiIhISvIqOHTpWBGRzMur4HDOveacG1ZSUtL4yiIi0ix5FRwiIpJ5Cg4REUmJgkNERFKi4BARkZTk5ZnjZrYa+LqZL+8KrEljOUHSvuSefNkP0L7kqpbsy57OuW6NrZSXwdESZjalKafctwbal9yTL/sB2pdclY19UVeViIikRMEhIiIpUXDsKPllt1of7UvuyZf9AO1Lrsr4vmiMQ0REUqIWh4iIpETBISIiKVFwxDGzwWY2z8wWmtnwoOtpjJktMbMvzWy6mU3xl3U2s7fNbIF/28lfbmY2wt+3L8xsYMNbz3jto8xslZnNjFuWcu1mdrG//gIzuziH9uU2M1vmfzbTzezkuOdu8vdlnpmdFLc80N8/M+ttZhPNbI6ZzTKza/zlre5zaWBfWuPnUmxmn5nZDH9fbveX9zWzSf6/8fNmFvGXF/mPF/rP92lsH1PmnNOPN84TBhYBewERYAZwQNB1NVLzEqBrvWV/BYb794cDf/HvnwyMAww4ApgUcO0/AgYCM5tbO9AZWOzfdvLvd8qRfbkNuC7Bugf4v1tFQF//dy6cC79/QA9goH+/AzDfr7fVfS4N7Etr/FwMaO/fLwQm+f/eLwDn+ssfAn7p378KeMi/fy7wfEP72Jya1OKocziw0Dm32DlXBTwHnB5wTc1xOvC4f/9x4Cdxy59wnk+BjmbWI4gCAZxzHwDr6i1OtfaTgLedc+ucc+uBt4HBma9+e0n2JZnTgeecc5XOua+AhXi/e4H//jnnVjjnpvn3y4E5QE9a4efSwL4kk8ufi3PObfIfFvo/DjgWGO0vr/+51H5eo4HjzMxIvo8pU3DU6QksjXtcSsO/aLnAAePNbKqZDfOXdXfOrQDvjwfY1V/eGvYv1dpzfZ+u9rtwRtV279BK9sXv3hiA97/bVv251NsXaIWfi5mFzWw6sAoviBcBG5xzNQnq2laz/3wZ0IU07ouCo44lWJbrxyof6ZwbCAwBfmVmP2pg3da4f7WS1Z7L+/QgsDfQH1gB3O0vz/l9MbP2wEvAtc65jQ2tmmBZru9Lq/xcnHNR51x/oBdeK2H/RKv5txnfFwVHnVKgd9zjXsDygGppEufccv92FfAK3i/UytouKP92lb96a9i/VGvP2X1yzq30/9hjwCPUdQnk9L6YWSHeF+3TzrmX/cWt8nNJtC+t9XOp5ZzbALyHN8bR0cwKEtS1rWb/+RK8rtS07YuCo85kYB//SIUI3qDSqwHXlJSZtTOzDrX3gROBmXg11x7FcjEwxr//KnCRfyTMEUBZbfdDDkm19reAE82sk9/lcKK/LHD1xo9+ivfZgLcv5/pHvvQF9gE+Iwd+//x+8EeBOc65v8c91eo+l2T70ko/l25m1tG/3wY4Hm/MZiJwpr9a/c+l9vM6E3jXeaPjyfYxddk8OiDXf/COEpmP13/4h6DraaTWvfCOkJgBzKqtF68v8x1ggX/b2dUdmXG/v29fAoMCrv9ZvK6Carz/CV3enNqBy/AG+RYCl+bQvjzp1/qF/wfbI279P/j7Mg8Ykiu/f8AP8bouvgCm+z8nt8bPpYF9aY2fy8HA537NM4Fb/OV74X3xLwReBIr85cX+44X+83s1to+p/mjKERERSYm6qkREJCUKDhERSYmCQ0REUqLgEBGRlCg4REQkJQoOkRxjZseY2etB1yGSjIJDRERSouAQaSYzu9C/TsJ0M3vYn4huk5ndbWbTzOwdM+vmr9vfzD71J9d7xequadHPzCb411qYZmZ7+5tvb2ajzWyumT3tnwktkhMUHCLNYGb7A+fgTTTZH4gCFwDtgGnOm3zyfeBW/yVPADc65w7GO3O5dvnTwP3OuUOAH+CdgQ7ebK7X4l1DYS/gyIzvlEgTFTS+iogkcBxwKDDZbwy0wZv8LwY876/zFPCymZUAHZ1z7/vLHwde9Oca6+mcewXAOVcB4G/vM+dcqf94OtAH+Hfmd0ukcQoOkeYx4HHn3E3bLTS7ud56Dc3p01D3U2Xc/Sj6W5Ucoq4qkeZ5BzjTzHaFbdfl3hPvb6p2xtLzgX8758qA9WZ2lL/858D7zrs+RKmZ/cTfRpGZtc3qXog0g/4XI9IMzrnZZvZHvCswhvBmxv0VsBn4rplNxbvy2jn+Sy4GHvKDYTFwqb/858DDZvZf/jbOyuJuiDSLZscVSSMz2+Scax90HSKZpK4qERFJiVocIiKSErU4REQkJQoOERFJiYJDRERSouAQEZGUKDhERCQl/w/3xcE4ui4HFwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.semilogy(history.history['loss'])\n",
    "if vsplit:\n",
    "    plt.semilogy(history.history['val_loss'])\n",
    "plt.title(loss_type)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v2U7mKjFgZv2"
   },
   "source": [
    "# Inference test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uHyzB-fi-R4"
   },
   "source": [
    "## prepare frontend for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "a5CBg_vigeHQ"
   },
   "outputs": [],
   "source": [
    "#@title import plotly\n",
    "import plotly.plotly as py\n",
    "import numpy as np\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "# from plotly.graph_objs import Contours, Histogram2dContour, Marker, Scatter\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "def configure_plotly_browser_state():\n",
    "  import IPython\n",
    "  display(IPython.core.display.HTML('''\n",
    "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
    "        <script>\n",
    "          requirejs.config({\n",
    "            paths: {\n",
    "              base: '/static/base',\n",
    "              plotly: 'https://cdn.plot.ly/plotly-1.5.1.min.js?noext',\n",
    "            },\n",
    "          });\n",
    "        </script>\n",
    "        '''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rpOu8UG0jFrx"
   },
   "source": [
    "## prepare data for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kN37vmdOlgrl"
   },
   "source": [
    "## TPU data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zRdPMLAL0K5x"
   },
   "outputs": [],
   "source": [
    "cpu_model = tpu_model.sync_to_cpu()\n",
    "predict_val=cpu_model.predict(X_test)\n",
    "\n",
    "X_test_df = pd.DataFrame(in_scaler.inverse_transform(X_test),columns=input_features)\n",
    "y_test_df = pd.DataFrame(out_scaler.inverse_transform(y_test),columns=labels)\n",
    "\n",
    "predict_val = model.predict(X_test)\n",
    "predict_df = pd.DataFrame(out_scaler.inverse_transform(predict_val), columns=labels)\n",
    "\n",
    "test_data=pd.concat([X_test_df,y_test_df],axis=1)\n",
    "pred_data=pd.concat([X_test_df,predict_df],axis=1)\n",
    "\n",
    "test_data.to_hdf('sim_check.H5',key='test')\n",
    "pred_data.to_hdf('sim_check.H5',key='pred')\n",
    "\n",
    "df_test=pd.read_hdf('sim_check.H5',key='test')\n",
    "df_pred=pd.read_hdf('sim_check.H5',key='pred')\n",
    "zeta_level=list(set(df_test['zeta']))\n",
    "zeta_level.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MlkIsUPZljN8"
   },
   "source": [
    "## GPU data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SvY3Iy8Whkla"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"./weights.best.cntk.hdf5\")\n",
    "\n",
    "x_test_df = pd.DataFrame(in_scaler.inverse_transform(x_test),columns=input_features)\n",
    "y_test_df = pd.DataFrame(out_scaler.inverse_transform(y_test),columns=labels)\n",
    "\n",
    "predict_val = model.predict(x_test,batch_size=1024)\n",
    "predict_df = pd.DataFrame(out_scaler.inverse_transform(predict_val), columns=labels)\n",
    "\n",
    "test_data=pd.concat([x_test_df,y_test_df],axis=1)\n",
    "pred_data=pd.concat([x_test_df,predict_df],axis=1)\n",
    "\n",
    "!rm sim_check.h5\n",
    "test_data.to_hdf('sim_check.h5',key='test')\n",
    "pred_data.to_hdf('sim_check.h5',key='pred')\n",
    "\n",
    "df_test=pd.read_hdf('sim_check.h5',key='test')\n",
    "df_pred=pd.read_hdf('sim_check.h5',key='pred')\n",
    "\n",
    "zeta_level=list(set(df_test['zeta']))\n",
    "zeta_level.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b8NffHeFjRmS"
   },
   "source": [
    "## interactive plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542,
     "resources": {
      "http://localhost:8080/static/components/requirejs/require.js": {
       "data": "/** vim: et:ts=4:sw=4:sts=4
 * @license RequireJS 2.1.22 Copyright (c) 2010-2015, The Dojo Foundation All Rights Reserved.
 * Available via the MIT or new BSD license.
 * see: http://github.com/jrburke/requirejs for details
 */
//Not using strict: uneven strict support in browsers, #392, and causes
//problems with requirejs.exec()/transpiler plugins that may not be strict.
/*jslint regexp: true, nomen: true, sloppy: true */
/*global window, navigator, document, importScripts, setTimeout, opera */

var requirejs, require, define;
(function (global) {
    var req, s, head, baseElement, dataMain, src,
        interactiveScript, currentlyAddingScript, mainScript, subPath,
        version = '2.1.22',
        commentRegExp = /(\/\*([\s\S]*?)\*\/|([^:]|^)\/\/(.*)$)/mg,
        cjsRequireRegExp = /[^.]\s*require\s*\(\s*["']([^'"\s]+)["']\s*\)/g,
        jsSuffixRegExp = /\.js$/,
        currDirRegExp = /^\.\//,
        op = Object.prototype,
        ostring = op.toString,
        hasOwn = op.hasOwnProperty,
        ap = Array.prototype,
        isBrowser = !!(typeof window !== 'undefined' && typeof navigator !== 'undefined' && window.document),
        isWebWorker = !isBrowser && typeof importScripts !== 'undefined',
        //PS3 indicates loaded and complete, but need to wait for complete
        //specifically. Sequence is 'loading', 'loaded', execution,
        // then 'complete'. The UA check is unfortunate, but not sure how
        //to feature test w/o causing perf issues.
        readyRegExp = isBrowser && navigator.platform === 'PLAYSTATION 3' ?
                      /^complete$/ : /^(complete|loaded)$/,
        defContextName = '_',
        //Oh the tragedy, detecting opera. See the usage of isOpera for reason.
        isOpera = typeof opera !== 'undefined' && opera.toString() === '[object Opera]',
        contexts = {},
        cfg = {},
        globalDefQueue = [],
        useInteractive = false;

    function isFunction(it) {
        return ostring.call(it) === '[object Function]';
    }

    function isArray(it) {
        return ostring.call(it) === '[object Array]';
    }

    /**
     * Helper function for iterating over an array. If the func returns
     * a true value, it will break out of the loop.
     */
    function each(ary, func) {
        if (ary) {
            var i;
            for (i = 0; i < ary.length; i += 1) {
                if (ary[i] && func(ary[i], i, ary)) {
                    break;
                }
            }
        }
    }

    /**
     * Helper function for iterating over an array backwards. If the func
     * returns a true value, it will break out of the loop.
     */
    function eachReverse(ary, func) {
        if (ary) {
            var i;
            for (i = ary.length - 1; i > -1; i -= 1) {
                if (ary[i] && func(ary[i], i, ary)) {
                    break;
                }
            }
        }
    }

    function hasProp(obj, prop) {
        return hasOwn.call(obj, prop);
    }

    function getOwn(obj, prop) {
        return hasProp(obj, prop) && obj[prop];
    }

    /**
     * Cycles over properties in an object and calls a function for each
     * property value. If the function returns a truthy value, then the
     * iteration is stopped.
     */
    function eachProp(obj, func) {
        var prop;
        for (prop in obj) {
            if (hasProp(obj, prop)) {
                if (func(obj[prop], prop)) {
                    break;
                }
            }
        }
    }

    /**
     * Simple function to mix in properties from source into target,
     * but only if target does not already have a property of the same name.
     */
    function mixin(target, source, force, deepStringMixin) {
        if (source) {
            eachProp(source, function (value, prop) {
                if (force || !hasProp(target, prop)) {
                    if (deepStringMixin && typeof value === 'object' && value &&
                        !isArray(value) && !isFunction(value) &&
                        !(value instanceof RegExp)) {

                        if (!target[prop]) {
                            target[prop] = {};
                        }
                        mixin(target[prop], value, force, deepStringMixin);
                    } else {
                        target[prop] = value;
                    }
                }
            });
        }
        return target;
    }

    //Similar to Function.prototype.bind, but the 'this' object is specified
    //first, since it is easier to read/figure out what 'this' will be.
    function bind(obj, fn) {
        return function () {
            return fn.apply(obj, arguments);
        };
    }

    function scripts() {
        return document.getElementsByTagName('script');
    }

    function defaultOnError(err) {
        throw err;
    }

    //Allow getting a global that is expressed in
    //dot notation, like 'a.b.c'.
    function getGlobal(value) {
        if (!value) {
            return value;
        }
        var g = global;
        each(value.split('.'), function (part) {
            g = g[part];
        });
        return g;
    }

    /**
     * Constructs an error with a pointer to an URL with more information.
     * @param {String} id the error ID that maps to an ID on a web page.
     * @param {String} message human readable error.
     * @param {Error} [err] the original error, if there is one.
     *
     * @returns {Error}
     */
    function makeError(id, msg, err, requireModules) {
        var e = new Error(msg + '\nhttp://requirejs.org/docs/errors.html#' + id);
        e.requireType = id;
        e.requireModules = requireModules;
        if (err) {
            e.originalError = err;
        }
        return e;
    }

    if (typeof define !== 'undefined') {
        //If a define is already in play via another AMD loader,
        //do not overwrite.
        return;
    }

    if (typeof requirejs !== 'undefined') {
        if (isFunction(requirejs)) {
            //Do not overwrite an existing requirejs instance.
            return;
        }
        cfg = requirejs;
        requirejs = undefined;
    }

    //Allow for a require config object
    if (typeof require !== 'undefined' && !isFunction(require)) {
        //assume it is a config object.
        cfg = require;
        require = undefined;
    }

    function newContext(contextName) {
        var inCheckLoaded, Module, context, handlers,
            checkLoadedTimeoutId,
            config = {
                //Defaults. Do not set a default for map
                //config to speed up normalize(), which
                //will run faster if there is no default.
                waitSeconds: 7,
                baseUrl: './',
                paths: {},
                bundles: {},
                pkgs: {},
                shim: {},
                config: {}
            },
            registry = {},
            //registry of just enabled modules, to speed
            //cycle breaking code when lots of modules
            //are registered, but not activated.
            enabledRegistry = {},
            undefEvents = {},
            defQueue = [],
            defined = {},
            urlFetched = {},
            bundlesMap = {},
            requireCounter = 1,
            unnormalizedCounter = 1;

        /**
         * Trims the . and .. from an array of path segments.
         * It will keep a leading path segment if a .. will become
         * the first path segment, to help with module name lookups,
         * which act like paths, but can be remapped. But the end result,
         * all paths that use this function should look normalized.
         * NOTE: this method MODIFIES the input array.
         * @param {Array} ary the array of path segments.
         */
        function trimDots(ary) {
            var i, part;
            for (i = 0; i < ary.length; i++) {
                part = ary[i];
                if (part === '.') {
                    ary.splice(i, 1);
                    i -= 1;
                } else if (part === '..') {
                    // If at the start, or previous value is still ..,
                    // keep them so that when converted to a path it may
                    // still work when converted to a path, even though
                    // as an ID it is less than ideal. In larger point
                    // releases, may be better to just kick out an error.
                    if (i === 0 || (i === 1 && ary[2] === '..') || ary[i - 1] === '..') {
                        continue;
                    } else if (i > 0) {
                        ary.splice(i - 1, 2);
                        i -= 2;
                    }
                }
            }
        }

        /**
         * Given a relative module name, like ./something, normalize it to
         * a real name that can be mapped to a path.
         * @param {String} name the relative name
         * @param {String} baseName a real name that the name arg is relative
         * to.
         * @param {Boolean} applyMap apply the map config to the value. Should
         * only be done if this normalization is for a dependency ID.
         * @returns {String} normalized name
         */
        function normalize(name, baseName, applyMap) {
            var pkgMain, mapValue, nameParts, i, j, nameSegment, lastIndex,
                foundMap, foundI, foundStarMap, starI, normalizedBaseParts,
                baseParts = (baseName && baseName.split('/')),
                map = config.map,
                starMap = map && map['*'];

            //Adjust any relative paths.
            if (name) {
                name = name.split('/');
                lastIndex = name.length - 1;

                // If wanting node ID compatibility, strip .js from end
                // of IDs. Have to do this here, and not in nameToUrl
                // because node allows either .js or non .js to map
                // to same file.
                if (config.nodeIdCompat && jsSuffixRegExp.test(name[lastIndex])) {
                    name[lastIndex] = name[lastIndex].replace(jsSuffixRegExp, '');
                }

                // Starts with a '.' so need the baseName
                if (name[0].charAt(0) === '.' && baseParts) {
                    //Convert baseName to array, and lop off the last part,
                    //so that . matches that 'directory' and not name of the baseName's
                    //module. For instance, baseName of 'one/two/three', maps to
                    //'one/two/three.js', but we want the directory, 'one/two' for
                    //this normalization.
                    normalizedBaseParts = baseParts.slice(0, baseParts.length - 1);
                    name = normalizedBaseParts.concat(name);
                }

                trimDots(name);
                name = name.join('/');
            }

            //Apply map config if available.
            if (applyMap && map && (baseParts || starMap)) {
                nameParts = name.split('/');

                outerLoop: for (i = nameParts.length; i > 0; i -= 1) {
                    nameSegment = nameParts.slice(0, i).join('/');

                    if (baseParts) {
                        //Find the longest baseName segment match in the config.
                        //So, do joins on the biggest to smallest lengths of baseParts.
                        for (j = baseParts.length; j > 0; j -= 1) {
                            mapValue = getOwn(map, baseParts.slice(0, j).join('/'));

                            //baseName segment has config, find if it has one for
                            //this name.
                            if (mapValue) {
                                mapValue = getOwn(mapValue, nameSegment);
                                if (mapValue) {
                                    //Match, update name to the new value.
                                    foundMap = mapValue;
                                    foundI = i;
                                    break outerLoop;
                                }
                            }
                        }
                    }

                    //Check for a star map match, but just hold on to it,
                    //if there is a shorter segment match later in a matching
                    //config, then favor over this star map.
                    if (!foundStarMap && starMap && getOwn(starMap, nameSegment)) {
                        foundStarMap = getOwn(starMap, nameSegment);
                        starI = i;
                    }
                }

                if (!foundMap && foundStarMap) {
                    foundMap = foundStarMap;
                    foundI = starI;
                }

                if (foundMap) {
                    nameParts.splice(0, foundI, foundMap);
                    name = nameParts.join('/');
                }
            }

            // If the name points to a package's name, use
            // the package main instead.
            pkgMain = getOwn(config.pkgs, name);

            return pkgMain ? pkgMain : name;
        }

        function removeScript(name) {
            if (isBrowser) {
                each(scripts(), function (scriptNode) {
                    if (scriptNode.getAttribute('data-requiremodule') === name &&
                            scriptNode.getAttribute('data-requirecontext') === context.contextName) {
                        scriptNode.parentNode.removeChild(scriptNode);
                        return true;
                    }
                });
            }
        }

        function hasPathFallback(id) {
            var pathConfig = getOwn(config.paths, id);
            if (pathConfig && isArray(pathConfig) && pathConfig.length > 1) {
                //Pop off the first array value, since it failed, and
                //retry
                pathConfig.shift();
                context.require.undef(id);

                //Custom require that does not do map translation, since
                //ID is "absolute", already mapped/resolved.
                context.makeRequire(null, {
                    skipMap: true
                })([id]);

                return true;
            }
        }

        //Turns a plugin!resource to [plugin, resource]
        //with the plugin being undefined if the name
        //did not have a plugin prefix.
        function splitPrefix(name) {
            var prefix,
                index = name ? name.indexOf('!') : -1;
            if (index > -1) {
                prefix = name.substring(0, index);
                name = name.substring(index + 1, name.length);
            }
            return [prefix, name];
        }

        /**
         * Creates a module mapping that includes plugin prefix, module
         * name, and path. If parentModuleMap is provided it will
         * also normalize the name via require.normalize()
         *
         * @param {String} name the module name
         * @param {String} [parentModuleMap] parent module map
         * for the module name, used to resolve relative names.
         * @param {Boolean} isNormalized: is the ID already normalized.
         * This is true if this call is done for a define() module ID.
         * @param {Boolean} applyMap: apply the map config to the ID.
         * Should only be true if this map is for a dependency.
         *
         * @returns {Object}
         */
        function makeModuleMap(name, parentModuleMap, isNormalized, applyMap) {
            var url, pluginModule, suffix, nameParts,
                prefix = null,
                parentName = parentModuleMap ? parentModuleMap.name : null,
                originalName = name,
                isDefine = true,
                normalizedName = '';

            //If no name, then it means it is a require call, generate an
            //internal name.
            if (!name) {
                isDefine = false;
                name = '_@r' + (requireCounter += 1);
            }

            nameParts = splitPrefix(name);
            prefix = nameParts[0];
            name = nameParts[1];

            if (prefix) {
                prefix = normalize(prefix, parentName, applyMap);
                pluginModule = getOwn(defined, prefix);
            }

            //Account for relative paths if there is a base name.
            if (name) {
                if (prefix) {
                    if (pluginModule && pluginModule.normalize) {
                        //Plugin is loaded, use its normalize method.
                        normalizedName = pluginModule.normalize(name, function (name) {
                            return normalize(name, parentName, applyMap);
                        });
                    } else {
                        // If nested plugin references, then do not try to
                        // normalize, as it will not normalize correctly. This
                        // places a restriction on resourceIds, and the longer
                        // term solution is not to normalize until plugins are
                        // loaded and all normalizations to allow for async
                        // loading of a loader plugin. But for now, fixes the
                        // common uses. Details in #1131
                        normalizedName = name.indexOf('!') === -1 ?
                                         normalize(name, parentName, applyMap) :
                                         name;
                    }
                } else {
                    //A regular module.
                    normalizedName = normalize(name, parentName, applyMap);

                    //Normalized name may be a plugin ID due to map config
                    //application in normalize. The map config values must
                    //already be normalized, so do not need to redo that part.
                    nameParts = splitPrefix(normalizedName);
                    prefix = nameParts[0];
                    normalizedName = nameParts[1];
                    isNormalized = true;

                    url = context.nameToUrl(normalizedName);
                }
            }

            //If the id is a plugin id that cannot be determined if it needs
            //normalization, stamp it with a unique ID so two matching relative
            //ids that may conflict can be separate.
            suffix = prefix && !pluginModule && !isNormalized ?
                     '_unnormalized' + (unnormalizedCounter += 1) :
                     '';

            return {
                prefix: prefix,
                name: normalizedName,
                parentMap: parentModuleMap,
                unnormalized: !!suffix,
                url: url,
                originalName: originalName,
                isDefine: isDefine,
                id: (prefix ?
                        prefix + '!' + normalizedName :
                        normalizedName) + suffix
            };
        }

        function getModule(depMap) {
            var id = depMap.id,
                mod = getOwn(registry, id);

            if (!mod) {
                mod = registry[id] = new context.Module(depMap);
            }

            return mod;
        }

        function on(depMap, name, fn) {
            var id = depMap.id,
                mod = getOwn(registry, id);

            if (hasProp(defined, id) &&
                    (!mod || mod.defineEmitComplete)) {
                if (name === 'defined') {
                    fn(defined[id]);
                }
            } else {
                mod = getModule(depMap);
                if (mod.error && name === 'error') {
                    fn(mod.error);
                } else {
                    mod.on(name, fn);
                }
            }
        }

        function onError(err, errback) {
            var ids = err.requireModules,
                notified = false;

            if (errback) {
                errback(err);
            } else {
                each(ids, function (id) {
                    var mod = getOwn(registry, id);
                    if (mod) {
                        //Set error on module, so it skips timeout checks.
                        mod.error = err;
                        if (mod.events.error) {
                            notified = true;
                            mod.emit('error', err);
                        }
                    }
                });

                if (!notified) {
                    req.onError(err);
                }
            }
        }

        /**
         * Internal method to transfer globalQueue items to this context's
         * defQueue.
         */
        function takeGlobalQueue() {
            //Push all the globalDefQueue items into the context's defQueue
            if (globalDefQueue.length) {
                each(globalDefQueue, function(queueItem) {
                    var id = queueItem[0];
                    if (typeof id === 'string') {
                        context.defQueueMap[id] = true;
                    }
                    defQueue.push(queueItem);
                });
                globalDefQueue = [];
            }
        }

        handlers = {
            'require': function (mod) {
                if (mod.require) {
                    return mod.require;
                } else {
                    return (mod.require = context.makeRequire(mod.map));
                }
            },
            'exports': function (mod) {
                mod.usingExports = true;
                if (mod.map.isDefine) {
                    if (mod.exports) {
                        return (defined[mod.map.id] = mod.exports);
                    } else {
                        return (mod.exports = defined[mod.map.id] = {});
                    }
                }
            },
            'module': function (mod) {
                if (mod.module) {
                    return mod.module;
                } else {
                    return (mod.module = {
                        id: mod.map.id,
                        uri: mod.map.url,
                        config: function () {
                            return getOwn(config.config, mod.map.id) || {};
                        },
                        exports: mod.exports || (mod.exports = {})
                    });
                }
            }
        };

        function cleanRegistry(id) {
            //Clean up machinery used for waiting modules.
            delete registry[id];
            delete enabledRegistry[id];
        }

        function breakCycle(mod, traced, processed) {
            var id = mod.map.id;

            if (mod.error) {
                mod.emit('error', mod.error);
            } else {
                traced[id] = true;
                each(mod.depMaps, function (depMap, i) {
                    var depId = depMap.id,
                        dep = getOwn(registry, depId);

                    //Only force things that have not completed
                    //being defined, so still in the registry,
                    //and only if it has not been matched up
                    //in the module already.
                    if (dep && !mod.depMatched[i] && !processed[depId]) {
                        if (getOwn(traced, depId)) {
                            mod.defineDep(i, defined[depId]);
                            mod.check(); //pass false?
                        } else {
                            breakCycle(dep, traced, processed);
                        }
                    }
                });
                processed[id] = true;
            }
        }

        function checkLoaded() {
            var err, usingPathFallback,
                waitInterval = config.waitSeconds * 1000,
                //It is possible to disable the wait interval by using waitSeconds of 0.
                expired = waitInterval && (context.startTime + waitInterval) < new Date().getTime(),
                noLoads = [],
                reqCalls = [],
                stillLoading = false,
                needCycleCheck = true;

            //Do not bother if this call was a result of a cycle break.
            if (inCheckLoaded) {
                return;
            }

            inCheckLoaded = true;

            //Figure out the state of all the modules.
            eachProp(enabledRegistry, function (mod) {
                var map = mod.map,
                    modId = map.id;

                //Skip things that are not enabled or in error state.
                if (!mod.enabled) {
                    return;
                }

                if (!map.isDefine) {
                    reqCalls.push(mod);
                }

                if (!mod.error) {
                    //If the module should be executed, and it has not
                    //been inited and time is up, remember it.
                    if (!mod.inited && expired) {
                        if (hasPathFallback(modId)) {
                            usingPathFallback = true;
                            stillLoading = true;
                        } else {
                            noLoads.push(modId);
                            removeScript(modId);
                        }
                    } else if (!mod.inited && mod.fetched && map.isDefine) {
                        stillLoading = true;
                        if (!map.prefix) {
                            //No reason to keep looking for unfinished
                            //loading. If the only stillLoading is a
                            //plugin resource though, keep going,
                            //because it may be that a plugin resource
                            //is waiting on a non-plugin cycle.
                            return (needCycleCheck = false);
                        }
                    }
                }
            });

            if (expired && noLoads.length) {
                //If wait time expired, throw error of unloaded modules.
                err = makeError('timeout', 'Load timeout for modules: ' + noLoads, null, noLoads);
                err.contextName = context.contextName;
                return onError(err);
            }

            //Not expired, check for a cycle.
            if (needCycleCheck) {
                each(reqCalls, function (mod) {
                    breakCycle(mod, {}, {});
                });
            }

            //If still waiting on loads, and the waiting load is something
            //other than a plugin resource, or there are still outstanding
            //scripts, then just try back later.
            if ((!expired || usingPathFallback) && stillLoading) {
                //Something is still waiting to load. Wait for it, but only
                //if a timeout is not already in effect.
                if ((isBrowser || isWebWorker) && !checkLoadedTimeoutId) {
                    checkLoadedTimeoutId = setTimeout(function () {
                        checkLoadedTimeoutId = 0;
                        checkLoaded();
                    }, 50);
                }
            }

            inCheckLoaded = false;
        }

        Module = function (map) {
            this.events = getOwn(undefEvents, map.id) || {};
            this.map = map;
            this.shim = getOwn(config.shim, map.id);
            this.depExports = [];
            this.depMaps = [];
            this.depMatched = [];
            this.pluginMaps = {};
            this.depCount = 0;

            /* this.exports this.factory
               this.depMaps = [],
               this.enabled, this.fetched
            */
        };

        Module.prototype = {
            init: function (depMaps, factory, errback, options) {
                options = options || {};

                //Do not do more inits if already done. Can happen if there
                //are multiple define calls for the same module. That is not
                //a normal, common case, but it is also not unexpected.
                if (this.inited) {
                    return;
                }

                this.factory = factory;

                if (errback) {
                    //Register for errors on this module.
                    this.on('error', errback);
                } else if (this.events.error) {
                    //If no errback already, but there are error listeners
                    //on this module, set up an errback to pass to the deps.
                    errback = bind(this, function (err) {
                        this.emit('error', err);
                    });
                }

                //Do a copy of the dependency array, so that
                //source inputs are not modified. For example
                //"shim" deps are passed in here directly, and
                //doing a direct modification of the depMaps array
                //would affect that config.
                this.depMaps = depMaps && depMaps.slice(0);

                this.errback = errback;

                //Indicate this module has be initialized
                this.inited = true;

                this.ignore = options.ignore;

                //Could have option to init this module in enabled mode,
                //or could have been previously marked as enabled. However,
                //the dependencies are not known until init is called. So
                //if enabled previously, now trigger dependencies as enabled.
                if (options.enabled || this.enabled) {
                    //Enable this module and dependencies.
                    //Will call this.check()
                    this.enable();
                } else {
                    this.check();
                }
            },

            defineDep: function (i, depExports) {
                //Because of cycles, defined callback for a given
                //export can be called more than once.
                if (!this.depMatched[i]) {
                    this.depMatched[i] = true;
                    this.depCount -= 1;
                    this.depExports[i] = depExports;
                }
            },

            fetch: function () {
                if (this.fetched) {
                    return;
                }
                this.fetched = true;

                context.startTime = (new Date()).getTime();

                var map = this.map;

                //If the manager is for a plugin managed resource,
                //ask the plugin to load it now.
                if (this.shim) {
                    context.makeRequire(this.map, {
                        enableBuildCallback: true
                    })(this.shim.deps || [], bind(this, function () {
                        return map.prefix ? this.callPlugin() : this.load();
                    }));
                } else {
                    //Regular dependency.
                    return map.prefix ? this.callPlugin() : this.load();
                }
            },

            load: function () {
                var url = this.map.url;

                //Regular dependency.
                if (!urlFetched[url]) {
                    urlFetched[url] = true;
                    context.load(this.map.id, url);
                }
            },

            /**
             * Checks if the module is ready to define itself, and if so,
             * define it.
             */
            check: function () {
                if (!this.enabled || this.enabling) {
                    return;
                }

                var err, cjsModule,
                    id = this.map.id,
                    depExports = this.depExports,
                    exports = this.exports,
                    factory = this.factory;

                if (!this.inited) {
                    // Only fetch if not already in the defQueue.
                    if (!hasProp(context.defQueueMap, id)) {
                        this.fetch();
                    }
                } else if (this.error) {
                    this.emit('error', this.error);
                } else if (!this.defining) {
                    //The factory could trigger another require call
                    //that would result in checking this module to
                    //define itself again. If already in the process
                    //of doing that, skip this work.
                    this.defining = true;

                    if (this.depCount < 1 && !this.defined) {
                        if (isFunction(factory)) {
                            try {
                                exports = context.execCb(id, factory, depExports, exports);
                            } catch (e) {
                                err = e;
                            }

                            // Favor return value over exports. If node/cjs in play,
                            // then will not have a return value anyway. Favor
                            // module.exports assignment over exports object.
                            if (this.map.isDefine && exports === undefined) {
                                cjsModule = this.module;
                                if (cjsModule) {
                                    exports = cjsModule.exports;
                                } else if (this.usingExports) {
                                    //exports already set the defined value.
                                    exports = this.exports;
                                }
                            }

                            if (err) {
                                // If there is an error listener, favor passing
                                // to that instead of throwing an error. However,
                                // only do it for define()'d  modules. require
                                // errbacks should not be called for failures in
                                // their callbacks (#699). However if a global
                                // onError is set, use that.
                                if ((this.events.error && this.map.isDefine) ||
                                    req.onError !== defaultOnError) {
                                    err.requireMap = this.map;
                                    err.requireModules = this.map.isDefine ? [this.map.id] : null;
                                    err.requireType = this.map.isDefine ? 'define' : 'require';
                                    return onError((this.error = err));
                                } else if (typeof console !== 'undefined' &&
                                           console.error) {
                                    // Log the error for debugging. If promises could be
                                    // used, this would be different, but making do.
                                    console.error(err);
                                } else {
                                    // Do not want to completely lose the error. While this
                                    // will mess up processing and lead to similar results
                                    // as bug 1440, it at least surfaces the error.
                                    req.onError(err);
                                }
                            }
                        } else {
                            //Just a literal value
                            exports = factory;
                        }

                        this.exports = exports;

                        if (this.map.isDefine && !this.ignore) {
                            defined[id] = exports;

                            if (req.onResourceLoad) {
                                var resLoadMaps = [];
                                each(this.depMaps, function (depMap) {
                                    resLoadMaps.push(depMap.normalizedMap || depMap);
                                });
                                req.onResourceLoad(context, this.map, resLoadMaps);
                            }
                        }

                        //Clean up
                        cleanRegistry(id);

                        this.defined = true;
                    }

                    //Finished the define stage. Allow calling check again
                    //to allow define notifications below in the case of a
                    //cycle.
                    this.defining = false;

                    if (this.defined && !this.defineEmitted) {
                        this.defineEmitted = true;
                        this.emit('defined', this.exports);
                        this.defineEmitComplete = true;
                    }

                }
            },

            callPlugin: function () {
                var map = this.map,
                    id = map.id,
                    //Map already normalized the prefix.
                    pluginMap = makeModuleMap(map.prefix);

                //Mark this as a dependency for this plugin, so it
                //can be traced for cycles.
                this.depMaps.push(pluginMap);

                on(pluginMap, 'defined', bind(this, function (plugin) {
                    var load, normalizedMap, normalizedMod,
                        bundleId = getOwn(bundlesMap, this.map.id),
                        name = this.map.name,
                        parentName = this.map.parentMap ? this.map.parentMap.name : null,
                        localRequire = context.makeRequire(map.parentMap, {
                            enableBuildCallback: true
                        });

                    //If current map is not normalized, wait for that
                    //normalized name to load instead of continuing.
                    if (this.map.unnormalized) {
                        //Normalize the ID if the plugin allows it.
                        if (plugin.normalize) {
                            name = plugin.normalize(name, function (name) {
                                return normalize(name, parentName, true);
                            }) || '';
                        }

                        //prefix and name should already be normalized, no need
                        //for applying map config again either.
                        normalizedMap = makeModuleMap(map.prefix + '!' + name,
                                                      this.map.parentMap);
                        on(normalizedMap,
                            'defined', bind(this, function (value) {
                                this.map.normalizedMap = normalizedMap;
                                this.init([], function () { return value; }, null, {
                                    enabled: true,
                                    ignore: true
                                });
                            }));

                        normalizedMod = getOwn(registry, normalizedMap.id);
                        if (normalizedMod) {
                            //Mark this as a dependency for this plugin, so it
                            //can be traced for cycles.
                            this.depMaps.push(normalizedMap);

                            if (this.events.error) {
                                normalizedMod.on('error', bind(this, function (err) {
                                    this.emit('error', err);
                                }));
                            }
                            normalizedMod.enable();
                        }

                        return;
                    }

                    //If a paths config, then just load that file instead to
                    //resolve the plugin, as it is built into that paths layer.
                    if (bundleId) {
                        this.map.url = context.nameToUrl(bundleId);
                        this.load();
                        return;
                    }

                    load = bind(this, function (value) {
                        this.init([], function () { return value; }, null, {
                            enabled: true
                        });
                    });

                    load.error = bind(this, function (err) {
                        this.inited = true;
                        this.error = err;
                        err.requireModules = [id];

                        //Remove temp unnormalized modules for this module,
                        //since they will never be resolved otherwise now.
                        eachProp(registry, function (mod) {
                            if (mod.map.id.indexOf(id + '_unnormalized') === 0) {
                                cleanRegistry(mod.map.id);
                            }
                        });

                        onError(err);
                    });

                    //Allow plugins to load other code without having to know the
                    //context or how to 'complete' the load.
                    load.fromText = bind(this, function (text, textAlt) {
                        /*jslint evil: true */
                        var moduleName = map.name,
                            moduleMap = makeModuleMap(moduleName),
                            hasInteractive = useInteractive;

                        //As of 2.1.0, support just passing the text, to reinforce
                        //fromText only being called once per resource. Still
                        //support old style of passing moduleName but discard
                        //that moduleName in favor of the internal ref.
                        if (textAlt) {
                            text = textAlt;
                        }

                        //Turn off interactive script matching for IE for any define
                        //calls in the text, then turn it back on at the end.
                        if (hasInteractive) {
                            useInteractive = false;
                        }

                        //Prime the system by creating a module instance for
                        //it.
                        getModule(moduleMap);

                        //Transfer any config to this other module.
                        if (hasProp(config.config, id)) {
                            config.config[moduleName] = config.config[id];
                        }

                        try {
                            req.exec(text);
                        } catch (e) {
                            return onError(makeError('fromtexteval',
                                             'fromText eval for ' + id +
                                            ' failed: ' + e,
                                             e,
                                             [id]));
                        }

                        if (hasInteractive) {
                            useInteractive = true;
                        }

                        //Mark this as a dependency for the plugin
                        //resource
                        this.depMaps.push(moduleMap);

                        //Support anonymous modules.
                        context.completeLoad(moduleName);

                        //Bind the value of that module to the value for this
                        //resource ID.
                        localRequire([moduleName], load);
                    });

                    //Use parentName here since the plugin's name is not reliable,
                    //could be some weird string with no path that actually wants to
                    //reference the parentName's path.
                    plugin.load(map.name, localRequire, load, config);
                }));

                context.enable(pluginMap, this);
                this.pluginMaps[pluginMap.id] = pluginMap;
            },

            enable: function () {
                enabledRegistry[this.map.id] = this;
                this.enabled = true;

                //Set flag mentioning that the module is enabling,
                //so that immediate calls to the defined callbacks
                //for dependencies do not trigger inadvertent load
                //with the depCount still being zero.
                this.enabling = true;

                //Enable each dependency
                each(this.depMaps, bind(this, function (depMap, i) {
                    var id, mod, handler;

                    if (typeof depMap === 'string') {
                        //Dependency needs to be converted to a depMap
                        //and wired up to this module.
                        depMap = makeModuleMap(depMap,
                                               (this.map.isDefine ? this.map : this.map.parentMap),
                                               false,
                                               !this.skipMap);
                        this.depMaps[i] = depMap;

                        handler = getOwn(handlers, depMap.id);

                        if (handler) {
                            this.depExports[i] = handler(this);
                            return;
                        }

                        this.depCount += 1;

                        on(depMap, 'defined', bind(this, function (depExports) {
                            if (this.undefed) {
                                return;
                            }
                            this.defineDep(i, depExports);
                            this.check();
                        }));

                        if (this.errback) {
                            on(depMap, 'error', bind(this, this.errback));
                        } else if (this.events.error) {
                            // No direct errback on this module, but something
                            // else is listening for errors, so be sure to
                            // propagate the error correctly.
                            on(depMap, 'error', bind(this, function(err) {
                                this.emit('error', err);
                            }));
                        }
                    }

                    id = depMap.id;
                    mod = registry[id];

                    //Skip special modules like 'require', 'exports', 'module'
                    //Also, don't call enable if it is already enabled,
                    //important in circular dependency cases.
                    if (!hasProp(handlers, id) && mod && !mod.enabled) {
                        context.enable(depMap, this);
                    }
                }));

                //Enable each plugin that is used in
                //a dependency
                eachProp(this.pluginMaps, bind(this, function (pluginMap) {
                    var mod = getOwn(registry, pluginMap.id);
                    if (mod && !mod.enabled) {
                        context.enable(pluginMap, this);
                    }
                }));

                this.enabling = false;

                this.check();
            },

            on: function (name, cb) {
                var cbs = this.events[name];
                if (!cbs) {
                    cbs = this.events[name] = [];
                }
                cbs.push(cb);
            },

            emit: function (name, evt) {
                each(this.events[name], function (cb) {
                    cb(evt);
                });
                if (name === 'error') {
                    //Now that the error handler was triggered, remove
                    //the listeners, since this broken Module instance
                    //can stay around for a while in the registry.
                    delete this.events[name];
                }
            }
        };

        function callGetModule(args) {
            //Skip modules already defined.
            if (!hasProp(defined, args[0])) {
                getModule(makeModuleMap(args[0], null, true)).init(args[1], args[2]);
            }
        }

        function removeListener(node, func, name, ieName) {
            //Favor detachEvent because of IE9
            //issue, see attachEvent/addEventListener comment elsewhere
            //in this file.
            if (node.detachEvent && !isOpera) {
                //Probably IE. If not it will throw an error, which will be
                //useful to know.
                if (ieName) {
                    node.detachEvent(ieName, func);
                }
            } else {
                node.removeEventListener(name, func, false);
            }
        }

        /**
         * Given an event from a script node, get the requirejs info from it,
         * and then removes the event listeners on the node.
         * @param {Event} evt
         * @returns {Object}
         */
        function getScriptData(evt) {
            //Using currentTarget instead of target for Firefox 2.0's sake. Not
            //all old browsers will be supported, but this one was easy enough
            //to support and still makes sense.
            var node = evt.currentTarget || evt.srcElement;

            //Remove the listeners once here.
            removeListener(node, context.onScriptLoad, 'load', 'onreadystatechange');
            removeListener(node, context.onScriptError, 'error');

            return {
                node: node,
                id: node && node.getAttribute('data-requiremodule')
            };
        }

        function intakeDefines() {
            var args;

            //Any defined modules in the global queue, intake them now.
            takeGlobalQueue();

            //Make sure any remaining defQueue items get properly processed.
            while (defQueue.length) {
                args = defQueue.shift();
                if (args[0] === null) {
                    return onError(makeError('mismatch', 'Mismatched anonymous define() module: ' +
                        args[args.length - 1]));
                } else {
                    //args are id, deps, factory. Should be normalized by the
                    //define() function.
                    callGetModule(args);
                }
            }
            context.defQueueMap = {};
        }

        context = {
            config: config,
            contextName: contextName,
            registry: registry,
            defined: defined,
            urlFetched: urlFetched,
            defQueue: defQueue,
            defQueueMap: {},
            Module: Module,
            makeModuleMap: makeModuleMap,
            nextTick: req.nextTick,
            onError: onError,

            /**
             * Set a configuration for the context.
             * @param {Object} cfg config object to integrate.
             */
            configure: function (cfg) {
                //Make sure the baseUrl ends in a slash.
                if (cfg.baseUrl) {
                    if (cfg.baseUrl.charAt(cfg.baseUrl.length - 1) !== '/') {
                        cfg.baseUrl += '/';
                    }
                }

                //Save off the paths since they require special processing,
                //they are additive.
                var shim = config.shim,
                    objs = {
                        paths: true,
                        bundles: true,
                        config: true,
                        map: true
                    };

                eachProp(cfg, function (value, prop) {
                    if (objs[prop]) {
                        if (!config[prop]) {
                            config[prop] = {};
                        }
                        mixin(config[prop], value, true, true);
                    } else {
                        config[prop] = value;
                    }
                });

                //Reverse map the bundles
                if (cfg.bundles) {
                    eachProp(cfg.bundles, function (value, prop) {
                        each(value, function (v) {
                            if (v !== prop) {
                                bundlesMap[v] = prop;
                            }
                        });
                    });
                }

                //Merge shim
                if (cfg.shim) {
                    eachProp(cfg.shim, function (value, id) {
                        //Normalize the structure
                        if (isArray(value)) {
                            value = {
                                deps: value
                            };
                        }
                        if ((value.exports || value.init) && !value.exportsFn) {
                            value.exportsFn = context.makeShimExports(value);
                        }
                        shim[id] = value;
                    });
                    config.shim = shim;
                }

                //Adjust packages if necessary.
                if (cfg.packages) {
                    each(cfg.packages, function (pkgObj) {
                        var location, name;

                        pkgObj = typeof pkgObj === 'string' ? {name: pkgObj} : pkgObj;

                        name = pkgObj.name;
                        location = pkgObj.location;
                        if (location) {
                            config.paths[name] = pkgObj.location;
                        }

                        //Save pointer to main module ID for pkg name.
                        //Remove leading dot in main, so main paths are normalized,
                        //and remove any trailing .js, since different package
                        //envs have different conventions: some use a module name,
                        //some use a file name.
                        config.pkgs[name] = pkgObj.name + '/' + (pkgObj.main || 'main')
                                     .replace(currDirRegExp, '')
                                     .replace(jsSuffixRegExp, '');
                    });
                }

                //If there are any "waiting to execute" modules in the registry,
                //update the maps for them, since their info, like URLs to load,
                //may have changed.
                eachProp(registry, function (mod, id) {
                    //If module already has init called, since it is too
                    //late to modify them, and ignore unnormalized ones
                    //since they are transient.
                    if (!mod.inited && !mod.map.unnormalized) {
                        mod.map = makeModuleMap(id, null, true);
                    }
                });

                //If a deps array or a config callback is specified, then call
                //require with those args. This is useful when require is defined as a
                //config object before require.js is loaded.
                if (cfg.deps || cfg.callback) {
                    context.require(cfg.deps || [], cfg.callback);
                }
            },

            makeShimExports: function (value) {
                function fn() {
                    var ret;
                    if (value.init) {
                        ret = value.init.apply(global, arguments);
                    }
                    return ret || (value.exports && getGlobal(value.exports));
                }
                return fn;
            },

            makeRequire: function (relMap, options) {
                options = options || {};

                function localRequire(deps, callback, errback) {
                    var id, map, requireMod;

                    if (options.enableBuildCallback && callback && isFunction(callback)) {
                        callback.__requireJsBuild = true;
                    }

                    if (typeof deps === 'string') {
                        if (isFunction(callback)) {
                            //Invalid call
                            return onError(makeError('requireargs', 'Invalid require call'), errback);
                        }

                        //If require|exports|module are requested, get the
                        //value for them from the special handlers. Caveat:
                        //this only works while module is being defined.
                        if (relMap && hasProp(handlers, deps)) {
                            return handlers[deps](registry[relMap.id]);
                        }

                        //Synchronous access to one module. If require.get is
                        //available (as in the Node adapter), prefer that.
                        if (req.get) {
                            return req.get(context, deps, relMap, localRequire);
                        }

                        //Normalize module name, if it contains . or ..
                        map = makeModuleMap(deps, relMap, false, true);
                        id = map.id;

                        if (!hasProp(defined, id)) {
                            return onError(makeError('notloaded', 'Module name "' +
                                        id +
                                        '" has not been loaded yet for context: ' +
                                        contextName +
                                        (relMap ? '' : '. Use require([])')));
                        }
                        return defined[id];
                    }

                    //Grab defines waiting in the global queue.
                    intakeDefines();

                    //Mark all the dependencies as needing to be loaded.
                    context.nextTick(function () {
                        //Some defines could have been added since the
                        //require call, collect them.
                        intakeDefines();

                        requireMod = getModule(makeModuleMap(null, relMap));

                        //Store if map config should be applied to this require
                        //call for dependencies.
                        requireMod.skipMap = options.skipMap;

                        requireMod.init(deps, callback, errback, {
                            enabled: true
                        });

                        checkLoaded();
                    });

                    return localRequire;
                }

                mixin(localRequire, {
                    isBrowser: isBrowser,

                    /**
                     * Converts a module name + .extension into an URL path.
                     * *Requires* the use of a module name. It does not support using
                     * plain URLs like nameToUrl.
                     */
                    toUrl: function (moduleNamePlusExt) {
                        var ext,
                            index = moduleNamePlusExt.lastIndexOf('.'),
                            segment = moduleNamePlusExt.split('/')[0],
                            isRelative = segment === '.' || segment === '..';

                        //Have a file extension alias, and it is not the
                        //dots from a relative path.
                        if (index !== -1 && (!isRelative || index > 1)) {
                            ext = moduleNamePlusExt.substring(index, moduleNamePlusExt.length);
                            moduleNamePlusExt = moduleNamePlusExt.substring(0, index);
                        }

                        return context.nameToUrl(normalize(moduleNamePlusExt,
                                                relMap && relMap.id, true), ext,  true);
                    },

                    defined: function (id) {
                        return hasProp(defined, makeModuleMap(id, relMap, false, true).id);
                    },

                    specified: function (id) {
                        id = makeModuleMap(id, relMap, false, true).id;
                        return hasProp(defined, id) || hasProp(registry, id);
                    }
                });

                //Only allow undef on top level require calls
                if (!relMap) {
                    localRequire.undef = function (id) {
                        //Bind any waiting define() calls to this context,
                        //fix for #408
                        takeGlobalQueue();

                        var map = makeModuleMap(id, relMap, true),
                            mod = getOwn(registry, id);

                        mod.undefed = true;
                        removeScript(id);

                        delete defined[id];
                        delete urlFetched[map.url];
                        delete undefEvents[id];

                        //Clean queued defines too. Go backwards
                        //in array so that the splices do not
                        //mess up the iteration.
                        eachReverse(defQueue, function(args, i) {
                            if (args[0] === id) {
                                defQueue.splice(i, 1);
                            }
                        });
                        delete context.defQueueMap[id];

                        if (mod) {
                            //Hold on to listeners in case the
                            //module will be attempted to be reloaded
                            //using a different config.
                            if (mod.events.defined) {
                                undefEvents[id] = mod.events;
                            }

                            cleanRegistry(id);
                        }
                    };
                }

                return localRequire;
            },

            /**
             * Called to enable a module if it is still in the registry
             * awaiting enablement. A second arg, parent, the parent module,
             * is passed in for context, when this method is overridden by
             * the optimizer. Not shown here to keep code compact.
             */
            enable: function (depMap) {
                var mod = getOwn(registry, depMap.id);
                if (mod) {
                    getModule(depMap).enable();
                }
            },

            /**
             * Internal method used by environment adapters to complete a load event.
             * A load event could be a script load or just a load pass from a synchronous
             * load call.
             * @param {String} moduleName the name of the module to potentially complete.
             */
            completeLoad: function (moduleName) {
                var found, args, mod,
                    shim = getOwn(config.shim, moduleName) || {},
                    shExports = shim.exports;

                takeGlobalQueue();

                while (defQueue.length) {
                    args = defQueue.shift();
                    if (args[0] === null) {
                        args[0] = moduleName;
                        //If already found an anonymous module and bound it
                        //to this name, then this is some other anon module
                        //waiting for its completeLoad to fire.
                        if (found) {
                            break;
                        }
                        found = true;
                    } else if (args[0] === moduleName) {
                        //Found matching define call for this script!
                        found = true;
                    }

                    callGetModule(args);
                }
                context.defQueueMap = {};

                //Do this after the cycle of callGetModule in case the result
                //of those calls/init calls changes the registry.
                mod = getOwn(registry, moduleName);

                if (!found && !hasProp(defined, moduleName) && mod && !mod.inited) {
                    if (config.enforceDefine && (!shExports || !getGlobal(shExports))) {
                        if (hasPathFallback(moduleName)) {
                            return;
                        } else {
                            return onError(makeError('nodefine',
                                             'No define call for ' + moduleName,
                                             null,
                                             [moduleName]));
                        }
                    } else {
                        //A script that does not call define(), so just simulate
                        //the call for it.
                        callGetModule([moduleName, (shim.deps || []), shim.exportsFn]);
                    }
                }

                checkLoaded();
            },

            /**
             * Converts a module name to a file path. Supports cases where
             * moduleName may actually be just an URL.
             * Note that it **does not** call normalize on the moduleName,
             * it is assumed to have already been normalized. This is an
             * internal API, not a public one. Use toUrl for the public API.
             */
            nameToUrl: function (moduleName, ext, skipExt) {
                var paths, syms, i, parentModule, url,
                    parentPath, bundleId,
                    pkgMain = getOwn(config.pkgs, moduleName);

                if (pkgMain) {
                    moduleName = pkgMain;
                }

                bundleId = getOwn(bundlesMap, moduleName);

                if (bundleId) {
                    return context.nameToUrl(bundleId, ext, skipExt);
                }

                //If a colon is in the URL, it indicates a protocol is used and it is just
                //an URL to a file, or if it starts with a slash, contains a query arg (i.e. ?)
                //or ends with .js, then assume the user meant to use an url and not a module id.
                //The slash is important for protocol-less URLs as well as full paths.
                if (req.jsExtRegExp.test(moduleName)) {
                    //Just a plain path, not module name lookup, so just return it.
                    //Add extension if it is included. This is a bit wonky, only non-.js things pass
                    //an extension, this method probably needs to be reworked.
                    url = moduleName + (ext || '');
                } else {
                    //A module that needs to be converted to a path.
                    paths = config.paths;

                    syms = moduleName.split('/');
                    //For each module name segment, see if there is a path
                    //registered for it. Start with most specific name
                    //and work up from it.
                    for (i = syms.length; i > 0; i -= 1) {
                        parentModule = syms.slice(0, i).join('/');

                        parentPath = getOwn(paths, parentModule);
                        if (parentPath) {
                            //If an array, it means there are a few choices,
                            //Choose the one that is desired
                            if (isArray(parentPath)) {
                                parentPath = parentPath[0];
                            }
                            syms.splice(0, i, parentPath);
                            break;
                        }
                    }

                    //Join the path parts together, then figure out if baseUrl is needed.
                    url = syms.join('/');
                    url += (ext || (/^data\:|\?/.test(url) || skipExt ? '' : '.js'));
                    url = (url.charAt(0) === '/' || url.match(/^[\w\+\.\-]+:/) ? '' : config.baseUrl) + url;
                }

                return config.urlArgs ? url +
                                        ((url.indexOf('?') === -1 ? '?' : '&') +
                                         config.urlArgs) : url;
            },

            //Delegates to req.load. Broken out as a separate function to
            //allow overriding in the optimizer.
            load: function (id, url) {
                req.load(context, id, url);
            },

            /**
             * Executes a module callback function. Broken out as a separate function
             * solely to allow the build system to sequence the files in the built
             * layer in the right sequence.
             *
             * @private
             */
            execCb: function (name, callback, args, exports) {
                return callback.apply(exports, args);
            },

            /**
             * callback for script loads, used to check status of loading.
             *
             * @param {Event} evt the event from the browser for the script
             * that was loaded.
             */
            onScriptLoad: function (evt) {
                //Using currentTarget instead of target for Firefox 2.0's sake. Not
                //all old browsers will be supported, but this one was easy enough
                //to support and still makes sense.
                if (evt.type === 'load' ||
                        (readyRegExp.test((evt.currentTarget || evt.srcElement).readyState))) {
                    //Reset interactive script so a script node is not held onto for
                    //to long.
                    interactiveScript = null;

                    //Pull out the name of the module and the context.
                    var data = getScriptData(evt);
                    context.completeLoad(data.id);
                }
            },

            /**
             * Callback for script errors.
             */
            onScriptError: function (evt) {
                var data = getScriptData(evt);
                if (!hasPathFallback(data.id)) {
                    var parents = [];
                    eachProp(registry, function(value, key) {
                        if (key.indexOf('_@r') !== 0) {
                            each(value.depMaps, function(depMap) {
                                if (depMap.id === data.id) {
                                    parents.push(key);
                                }
                                return true;
                            });
                        }
                    });
                    return onError(makeError('scripterror', 'Script error for "' + data.id +
                                             (parents.length ?
                                             '", needed by: ' + parents.join(', ') :
                                             '"'), evt, [data.id]));
                }
            }
        };

        context.require = context.makeRequire();
        return context;
    }

    /**
     * Main entry point.
     *
     * If the only argument to require is a string, then the module that
     * is represented by that string is fetched for the appropriate context.
     *
     * If the first argument is an array, then it will be treated as an array
     * of dependency string names to fetch. An optional function callback can
     * be specified to execute when all of those dependencies are available.
     *
     * Make a local req variable to help Caja compliance (it assumes things
     * on a require that are not standardized), and to give a short
     * name for minification/local scope use.
     */
    req = requirejs = function (deps, callback, errback, optional) {

        //Find the right context, use default
        var context, config,
            contextName = defContextName;

        // Determine if have config object in the call.
        if (!isArray(deps) && typeof deps !== 'string') {
            // deps is a config object
            config = deps;
            if (isArray(callback)) {
                // Adjust args if there are dependencies
                deps = callback;
                callback = errback;
                errback = optional;
            } else {
                deps = [];
            }
        }

        if (config && config.context) {
            contextName = config.context;
        }

        context = getOwn(contexts, contextName);
        if (!context) {
            context = contexts[contextName] = req.s.newContext(contextName);
        }

        if (config) {
            context.configure(config);
        }

        return context.require(deps, callback, errback);
    };

    /**
     * Support require.config() to make it easier to cooperate with other
     * AMD loaders on globally agreed names.
     */
    req.config = function (config) {
        return req(config);
    };

    /**
     * Execute something after the current tick
     * of the event loop. Override for other envs
     * that have a better solution than setTimeout.
     * @param  {Function} fn function to execute later.
     */
    req.nextTick = typeof setTimeout !== 'undefined' ? function (fn) {
        setTimeout(fn, 4);
    } : function (fn) { fn(); };

    /**
     * Export require as a global, but only if it does not already exist.
     */
    if (!require) {
        require = req;
    }

    req.version = version;

    //Used to filter out dependencies that are already paths.
    req.jsExtRegExp = /^\/|:|\?|\.js$/;
    req.isBrowser = isBrowser;
    s = req.s = {
        contexts: contexts,
        newContext: newContext
    };

    //Create default context.
    req({});

    //Exports some context-sensitive methods on global require.
    each([
        'toUrl',
        'undef',
        'defined',
        'specified'
    ], function (prop) {
        //Reference from contexts instead of early binding to default context,
        //so that during builds, the latest instance of the default context
        //with its config gets used.
        req[prop] = function () {
            var ctx = contexts[defContextName];
            return ctx.require[prop].apply(ctx, arguments);
        };
    });

    if (isBrowser) {
        head = s.head = document.getElementsByTagName('head')[0];
        //If BASE tag is in play, using appendChild is a problem for IE6.
        //When that browser dies, this can be removed. Details in this jQuery bug:
        //http://dev.jquery.com/ticket/2709
        baseElement = document.getElementsByTagName('base')[0];
        if (baseElement) {
            head = s.head = baseElement.parentNode;
        }
    }

    /**
     * Any errors that require explicitly generates will be passed to this
     * function. Intercept/override it if you want custom error handling.
     * @param {Error} err the error object.
     */
    req.onError = defaultOnError;

    /**
     * Creates the node for the load command. Only used in browser envs.
     */
    req.createNode = function (config, moduleName, url) {
        var node = config.xhtml ?
                document.createElementNS('http://www.w3.org/1999/xhtml', 'html:script') :
                document.createElement('script');
        node.type = config.scriptType || 'text/javascript';
        node.charset = 'utf-8';
        node.async = true;
        return node;
    };

    /**
     * Does the request to load a module for the browser case.
     * Make this a separate function to allow other environments
     * to override it.
     *
     * @param {Object} context the require context to find state.
     * @param {String} moduleName the name of the module.
     * @param {Object} url the URL to the module.
     */
    req.load = function (context, moduleName, url) {
        var config = (context && context.config) || {},
            node;
        if (isBrowser) {
            //In the browser so use a script tag
            node = req.createNode(config, moduleName, url);
            if (config.onNodeCreated) {
                config.onNodeCreated(node, config, moduleName, url);
            }

            node.setAttribute('data-requirecontext', context.contextName);
            node.setAttribute('data-requiremodule', moduleName);

            //Set up load listener. Test attachEvent first because IE9 has
            //a subtle issue in its addEventListener and script onload firings
            //that do not match the behavior of all other browsers with
            //addEventListener support, which fire the onload event for a
            //script right after the script execution. See:
            //https://connect.microsoft.com/IE/feedback/details/648057/script-onload-event-is-not-fired-immediately-after-script-execution
            //UNFORTUNATELY Opera implements attachEvent but does not follow the script
            //script execution mode.
            if (node.attachEvent &&
                    //Check if node.attachEvent is artificially added by custom script or
                    //natively supported by browser
                    //read https://github.com/jrburke/requirejs/issues/187
                    //if we can NOT find [native code] then it must NOT natively supported.
                    //in IE8, node.attachEvent does not have toString()
                    //Note the test for "[native code" with no closing brace, see:
                    //https://github.com/jrburke/requirejs/issues/273
                    !(node.attachEvent.toString && node.attachEvent.toString().indexOf('[native code') < 0) &&
                    !isOpera) {
                //Probably IE. IE (at least 6-8) do not fire
                //script onload right after executing the script, so
                //we cannot tie the anonymous define call to a name.
                //However, IE reports the script as being in 'interactive'
                //readyState at the time of the define call.
                useInteractive = true;

                node.attachEvent('onreadystatechange', context.onScriptLoad);
                //It would be great to add an error handler here to catch
                //404s in IE9+. However, onreadystatechange will fire before
                //the error handler, so that does not help. If addEventListener
                //is used, then IE will fire error before load, but we cannot
                //use that pathway given the connect.microsoft.com issue
                //mentioned above about not doing the 'script execute,
                //then fire the script load event listener before execute
                //next script' that other browsers do.
                //Best hope: IE10 fixes the issues,
                //and then destroys all installs of IE 6-9.
                //node.attachEvent('onerror', context.onScriptError);
            } else {
                node.addEventListener('load', context.onScriptLoad, false);
                node.addEventListener('error', context.onScriptError, false);
            }
            node.src = url;

            //For some cache cases in IE 6-8, the script executes before the end
            //of the appendChild execution, so to tie an anonymous define
            //call to the module name (which is stored on the node), hold on
            //to a reference to this node, but clear after the DOM insertion.
            currentlyAddingScript = node;
            if (baseElement) {
                head.insertBefore(node, baseElement);
            } else {
                head.appendChild(node);
            }
            currentlyAddingScript = null;

            return node;
        } else if (isWebWorker) {
            try {
                //In a web worker, use importScripts. This is not a very
                //efficient use of importScripts, importScripts will block until
                //its script is downloaded and evaluated. However, if web workers
                //are in play, the expectation is that a build has been done so
                //that only one script needs to be loaded anyway. This may need
                //to be reevaluated if other use cases become common.
                importScripts(url);

                //Account for anonymous modules
                context.completeLoad(moduleName);
            } catch (e) {
                context.onError(makeError('importscripts',
                                'importScripts failed for ' +
                                    moduleName + ' at ' + url,
                                e,
                                [moduleName]));
            }
        }
    };

    function getInteractiveScript() {
        if (interactiveScript && interactiveScript.readyState === 'interactive') {
            return interactiveScript;
        }

        eachReverse(scripts(), function (script) {
            if (script.readyState === 'interactive') {
                return (interactiveScript = script);
            }
        });
        return interactiveScript;
    }

    //Look for a data-main script attribute, which could also adjust the baseUrl.
    if (isBrowser && !cfg.skipDataMain) {
        //Figure out baseUrl. Get it from the script tag with require.js in it.
        eachReverse(scripts(), function (script) {
            //Set the 'head' where we can append children by
            //using the script's parent.
            if (!head) {
                head = script.parentNode;
            }

            //Look for a data-main attribute to set main script for the page
            //to load. If it is there, the path to data main becomes the
            //baseUrl, if it is not already set.
            dataMain = script.getAttribute('data-main');
            if (dataMain) {
                //Preserve dataMain in case it is a path (i.e. contains '?')
                mainScript = dataMain;

                //Set final baseUrl if there is not already an explicit one.
                if (!cfg.baseUrl) {
                    //Pull off the directory of data-main for use as the
                    //baseUrl.
                    src = mainScript.split('/');
                    mainScript = src.pop();
                    subPath = src.length ? src.join('/')  + '/' : './';

                    cfg.baseUrl = subPath;
                }

                //Strip off any trailing .js since mainScript is now
                //like a module name.
                mainScript = mainScript.replace(jsSuffixRegExp, '');

                //If mainScript is still a path, fall back to dataMain
                if (req.jsExtRegExp.test(mainScript)) {
                    mainScript = dataMain;
                }

                //Put the data-main script in the files to load.
                cfg.deps = cfg.deps ? cfg.deps.concat(mainScript) : [mainScript];

                return true;
            }
        });
    }

    /**
     * The function that handles definitions of modules. Differs from
     * require() in that a string for the module should be the first argument,
     * and the function to execute after dependencies are loaded should
     * return a value to define the module corresponding to the first argument's
     * name.
     */
    define = function (name, deps, callback) {
        var node, context;

        //Allow for anonymous modules
        if (typeof name !== 'string') {
            //Adjust args appropriately
            callback = deps;
            deps = name;
            name = null;
        }

        //This module may not have dependencies
        if (!isArray(deps)) {
            callback = deps;
            deps = null;
        }

        //If no name, and callback is a function, then figure out if it a
        //CommonJS thing with dependencies.
        if (!deps && isFunction(callback)) {
            deps = [];
            //Remove comments from the callback string,
            //look for require calls, and pull them into the dependencies,
            //but only if there are function args.
            if (callback.length) {
                callback
                    .toString()
                    .replace(commentRegExp, '')
                    .replace(cjsRequireRegExp, function (match, dep) {
                        deps.push(dep);
                    });

                //May be a CommonJS thing even without require calls, but still
                //could use exports, and module. Avoid doing exports and module
                //work though if it just needs require.
                //REQUIRES the function to expect the CommonJS variables in the
                //order listed below.
                deps = (callback.length === 1 ? ['require'] : ['require', 'exports', 'module']).concat(deps);
            }
        }

        //If in IE 6-8 and hit an anonymous define() call, do the interactive
        //work.
        if (useInteractive) {
            node = currentlyAddingScript || getInteractiveScript();
            if (node) {
                if (!name) {
                    name = node.getAttribute('data-requiremodule');
                }
                context = contexts[node.getAttribute('data-requirecontext')];
            }
        }

        //Always save off evaluating the def call until the script onload handler.
        //This allows multiple modules to be in a file without prematurely
        //tracing dependencies, and allows for anonymous module support,
        //where the module name is not known until the script onload event
        //occurs. If no context, use the global queue, and get it processed
        //in the onscript load callback.
        if (context) {
            context.defQueue.push([name, deps, callback]);
            context.defQueueMap[name] = true;
        } else {
            globalDefQueue.push([name, deps, callback]);
        }
    };

    define.amd = {
        jQuery: true
    };

    /**
     * Executes the text. Normally just uses eval, but can be modified
     * to use a better, environment-specific call. Only used for transpiling
     * loader plugins, not for plain JS modules.
     * @param {String} text the text to execute/evaluate.
     */
    req.exec = function (text) {
        /*jslint evil: true */
        return eval(text);
    };

    //Set up with config info.
    req(cfg);
}(this));
",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "9-ivyMjeiNcF",
    "outputId": "3cd8cd7a-ee15-4b89-ece5-e65483c7d84e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "size": 1
         },
         "mode": "markers",
         "name": "test data from table",
         "type": "scatter3d",
         "uid": "ea2546fc-d534-4caf-ad7e-94118df1e789",
         "visible": true,
         "x": [
          0.564,
          0.088,
          0.012,
          0.252,
          0.9,
          0.432,
          0.166,
          0.41,
          0.544,
          0.112,
          0.498,
          0.534,
          0.37,
          0.112,
          0.048,
          0.396,
          0.622,
          0.676,
          0.72,
          0.414,
          0.722,
          0.556,
          0.238,
          0.602,
          0.664,
          0.822,
          0.134,
          0.39,
          0.25,
          0.742,
          0.54,
          0.496,
          0.722,
          0.156,
          0.388,
          0.394,
          0.658,
          0.912,
          0.738,
          0.696,
          0.528,
          0.666,
          0.716,
          0.834,
          0.11,
          0.798,
          0.564,
          0.766,
          0.676,
          0.006,
          0.224,
          0.516,
          0.276,
          0.13,
          0.526,
          0.03,
          0.416,
          0.128,
          0.008,
          0.078,
          0.636,
          0.624,
          0.6,
          0.67,
          0.696,
          0.764,
          0.12,
          0.858,
          0.996,
          0.492,
          0.434,
          0.19,
          0.566,
          0.1,
          0.336,
          0.694,
          0.7,
          0.174,
          0.104,
          0.358,
          0.872,
          0.9,
          0.002,
          0.55,
          0.118,
          0.092,
          0.208,
          0.302,
          0.974,
          0.344,
          0.018,
          0.68,
          0.662,
          0.532,
          0.608,
          0.752,
          0.966,
          0.554,
          0.608,
          0.28,
          0.564,
          0.136,
          0.754,
          0.282,
          0.18,
          0.816,
          0.18,
          0.02,
          0.794,
          0.172,
          0.46,
          0.178,
          0.7,
          0.95,
          0.128,
          0.568,
          0.838,
          0.57,
          0.382,
          0.388,
          0.96,
          0.324,
          0.908,
          0.924,
          0.248,
          0.684,
          0.39,
          0.868,
          0.98,
          1,
          0.422,
          0.03,
          0.432,
          0.806,
          0.47,
          0.374,
          0.362,
          0.338,
          0.096,
          0.336,
          0.7,
          0.48,
          0.11,
          0.154,
          0.48,
          0.932,
          0.184,
          0.426,
          0.64,
          0.366,
          0.892,
          0.862,
          0.712,
          0.224,
          0.976,
          0.428,
          0.34,
          0.036,
          0.256,
          0.704,
          0.196,
          0.802,
          0.314,
          0.044,
          0.324,
          0.412,
          0.13,
          0.594,
          0.064,
          0.832,
          0.682,
          0.584,
          0.972,
          0.984,
          0.678,
          0.39,
          0.21,
          0.552,
          0.368,
          0.866,
          0.308,
          0.232,
          0.846,
          0.796,
          0.056,
          0.018,
          0.62,
          0.43,
          0.894,
          0.718,
          0.492,
          0.292,
          0.854,
          0.78,
          0.204,
          0.862,
          0.138,
          0.268,
          0.768,
          0.232,
          0.752,
          0.87,
          0.208,
          0.25,
          0.076,
          0.594,
          0.964,
          0.45,
          0.366,
          0.07,
          0.892,
          0.7,
          0.138,
          0.706,
          0.362,
          0.28,
          0.486,
          0.892,
          0.85,
          0.036,
          0.736,
          0.356,
          0.916,
          0.346,
          0.088,
          0.47,
          0.668,
          0.01,
          0.81,
          0.462,
          0.81,
          0.822,
          0.548,
          0.124,
          0.44,
          0.82,
          0.922,
          0.454,
          0.88,
          0.738,
          0.284,
          0.924,
          0.118,
          0.52,
          0.838,
          0.72,
          0.206,
          0.974,
          0.592,
          0.598,
          0.444,
          0.538,
          0.038,
          0.192,
          0.166,
          0.722,
          0.63,
          0.032,
          0.078,
          0.51,
          0.166,
          0.664,
          0.73,
          0.404,
          0.29,
          0.702,
          0.948,
          0.256,
          0.584,
          0.358,
          0.762,
          0.496,
          0.97,
          0.812,
          0.724,
          0.92,
          0.576,
          0.02,
          0.358,
          0.332,
          0.2,
          0.154,
          0.01,
          0.346,
          0.956,
          0.872,
          0.618,
          0.038,
          0.804,
          0.718,
          0.01,
          0.078,
          0.634,
          0.82,
          0.146,
          0.292,
          0.69,
          0.804,
          0.438,
          0.93,
          0.35,
          0.116,
          0.114,
          0.764,
          0.594,
          0.64,
          0.284,
          0.142,
          0.698,
          0.63,
          0.31,
          0.77,
          0.75,
          0.794,
          0.078,
          0.734,
          0.276,
          0.908,
          0.072,
          0.098,
          0.824,
          0.528,
          0.9,
          0.452,
          0.502,
          0.878,
          0.758,
          0.256,
          0.514,
          0.916,
          0.712,
          0.392,
          0.49,
          0.494,
          0.122,
          0.824,
          0.784,
          0.64,
          0.69,
          0.356,
          0.182,
          0.916,
          0.634,
          0.422,
          0.496,
          0.514,
          0.824,
          0.394,
          0.382,
          0.41,
          0.662,
          0.646,
          0.082,
          0.476,
          0.926,
          0.454,
          0.81,
          0.826,
          0.954,
          0.12,
          0.32,
          0.484,
          0.93,
          0.496,
          0.356,
          0.038,
          0.718,
          0.4,
          0.572,
          0.11,
          0.734,
          0.372,
          0.488,
          0.424,
          0.872,
          0.222,
          0.378,
          0.98,
          0.726,
          0.564,
          0.378,
          0.302,
          0.868,
          0.322,
          0.696,
          0.372,
          0.398,
          0.918,
          0.846,
          0.532,
          0.318,
          0.974,
          0.258,
          0.862,
          0.534,
          0.83,
          0.79,
          0.838,
          0.946,
          0.146,
          0.45,
          0.35,
          0.63,
          0.958,
          0.2,
          0.47,
          0.434,
          0.296,
          0.506,
          0.06,
          0.758,
          0.054,
          0.774,
          0.072,
          0.964,
          0.06,
          0.824,
          0.082,
          0.196,
          0.294,
          0.45,
          0.204,
          0.804,
          0.918,
          0.036,
          0.122,
          0.254,
          0.498,
          0.24,
          0.27,
          0.942,
          0.208,
          0.064,
          0.572,
          0.644,
          0.856,
          0.9,
          0.536,
          0.912,
          0.35,
          0.87,
          0.33,
          0.29,
          0.748,
          0.004,
          0.832,
          0.48,
          0.25,
          0.99,
          0.306,
          0.456,
          0.56,
          0.664,
          0.788,
          0.368,
          0.506,
          0.366,
          0.59,
          0.58,
          0.516,
          0.782,
          0.178,
          0.61,
          0.636,
          0.538,
          0.124,
          0.13,
          0.956,
          0.74,
          0.986,
          0.586,
          0.312,
          0.68,
          0.502,
          0.808,
          0.354,
          0.952,
          0.416,
          0.36,
          0.938,
          0.896,
          0.108,
          0.44,
          0.244,
          0.092,
          0.688,
          0.01,
          0.196,
          0.92,
          0.296,
          0.234,
          0.08,
          0.598,
          0.258,
          0.404,
          0.112,
          0.104,
          0.06,
          0.456,
          0.8,
          0.042,
          0.686,
          0.504,
          0.284,
          0.136,
          0.14,
          0.87,
          0.014,
          0.552,
          0.056,
          0.632,
          0.91,
          0.962,
          0.688,
          0.816,
          0.81,
          0.994,
          0.65,
          0.88,
          0.852,
          0.452,
          0.382,
          0.824,
          0.27,
          0.022,
          0.684,
          0.008,
          0.006,
          0.124,
          0.212,
          0.936,
          0.556,
          0.076,
          0.166,
          0.034,
          0.15,
          0.716,
          0.222,
          0.88,
          0.03,
          0.438,
          0.726,
          0.438,
          0.776,
          0.646,
          0.36,
          0.958,
          0.024,
          1,
          0.11,
          0.898,
          0.16,
          0.436,
          0.012,
          0.366,
          0.204,
          0.57,
          0.974,
          0.272,
          0.67,
          0.246,
          0.444,
          0.794,
          0.002,
          0.52,
          0.05,
          0.506,
          0.038,
          0.328,
          0.104,
          0.55,
          0.334,
          0.226,
          0.858,
          0.816,
          0.884,
          0.112,
          0.288,
          0.876,
          0.734,
          0.028,
          0.022,
          0.066,
          0.782,
          0.332,
          0.92,
          0.594,
          0.344,
          0.698,
          0.846,
          0.782,
          0.784,
          0.454,
          0.682,
          0.824,
          0.938,
          0.586,
          0.8,
          0.178,
          0.11,
          0.402,
          0.618,
          0.722,
          0.35,
          0.992,
          0.416,
          0.052,
          0.342,
          0.254,
          0.982,
          0.366,
          0.316,
          0.602,
          0.818,
          0.378,
          0.712,
          0.42,
          0.67,
          0.886,
          0.654,
          0.532,
          0.216,
          0.234,
          0.762,
          0.808,
          0.598,
          0.666,
          0.074,
          0.018,
          0.466,
          0.346,
          0.754,
          0.708,
          0.53,
          0.578,
          0.514,
          0.548,
          0.13,
          0.2,
          0.544,
          0.698,
          0.848,
          0.294,
          0.078,
          0.064,
          0.044,
          0.048,
          0.312,
          0.358,
          0.338,
          0.36,
          0.154,
          0.186,
          0.018,
          0.9,
          0.926,
          0.35,
          0.628,
          0.178,
          0.036,
          0.59,
          0.928,
          0.366,
          0.172,
          0.78,
          0.558,
          0.834,
          0.216,
          0.668,
          0.616,
          0.332,
          0.578,
          0.838,
          0.472,
          0.644,
          0.46,
          0.732,
          0.602,
          0.6,
          0.732,
          0.318,
          0.938,
          0.142,
          0.104,
          0.5,
          0.452,
          0.968,
          0.776,
          0.334,
          0.604,
          0.326,
          0.762,
          0.51,
          0.228,
          0.848,
          0.168,
          0.204,
          0.386,
          0.72,
          0.056,
          0.442,
          0.78,
          0.322,
          0.27,
          0.946,
          0.498,
          0.398,
          0.698,
          0.892,
          0.086,
          0.528,
          0.898,
          0.602,
          0.826,
          0.344,
          0.556,
          0.53,
          0.232,
          0.12,
          0.176,
          0.066,
          0.082,
          0.98,
          0.562,
          0.818,
          0.886,
          0.868,
          0.498,
          0.7,
          0.42,
          0.804,
          0.648,
          0.306,
          0.1,
          0.986,
          0.8,
          0.678,
          0.416,
          0.192,
          0.526,
          0.714,
          0.966,
          0.468,
          0.09,
          0.712,
          0.2,
          0.406,
          0.304,
          0.166,
          0.942,
          0.482,
          0.908,
          0.926,
          0.732,
          0.082,
          0.698,
          0.598,
          0.034,
          0.128,
          0.83,
          0.258,
          0.97,
          0.916,
          0.022,
          0.23,
          0.292,
          0.53,
          0.582,
          0.09,
          0.656,
          0.212,
          0.752,
          0.802,
          0.368,
          0.776,
          0.85,
          0.784,
          0.71,
          0.566,
          0.326,
          0.494,
          0.742,
          0.138,
          0.392,
          0.648,
          0.982,
          0.42,
          0.842,
          0.524,
          0.154,
          0.114,
          0.478,
          0.496,
          0.224,
          0.462,
          0.918,
          0.186,
          0.882,
          0.102,
          0.7,
          0.508,
          0.476,
          0.204,
          0.314,
          0.06,
          0.056,
          0.552,
          0.522,
          0.474,
          0.416,
          0.708,
          0.724,
          0.886,
          0.092,
          0.984,
          0.716,
          0.54,
          0.646,
          0.388,
          0.878,
          0.644,
          0.322,
          0.696,
          0.28,
          0.886,
          0.608,
          0.77,
          0.004,
          0.874,
          0.15,
          0.004,
          0.342,
          0.68,
          0.314,
          0.474,
          0.72,
          0.616,
          0.722,
          0.564,
          0.086,
          0.408,
          0.244,
          0.62,
          0.428,
          0.528,
          0.952,
          0.532,
          0.828,
          0.028,
          0.314,
          0.646,
          0.328,
          0.618,
          0.662,
          0.59,
          0.634,
          0.874,
          0.244,
          0.65,
          0.374,
          0.302,
          0.132,
          0.566,
          0.88,
          0.136,
          0.608,
          0.716,
          0.792,
          0.026,
          0.334,
          0.94,
          0.796,
          0.15,
          0.476,
          0.484,
          0.606,
          0.776,
          0.632,
          0.218,
          0.866,
          0.146,
          0.134,
          0.574,
          0.222,
          0.412,
          0.334,
          0.866,
          0.25,
          0.592,
          0.974,
          0.86,
          0.334,
          0.53,
          0.894,
          0.498,
          0.47,
          0.916,
          0.494,
          0.166,
          0.098,
          0.142,
          0.912,
          0.672,
          0.116,
          0.962,
          0.864,
          0.376,
          0.324,
          0.384,
          0.594,
          0.682,
          0.048,
          0.842,
          0.25,
          0.162,
          0.858,
          0.224,
          0.488,
          0.846,
          0.706,
          0.764,
          0.404,
          0.342,
          0.184,
          0.74,
          0.404,
          0.372,
          0.366,
          0.934,
          0.01,
          0.324,
          0.118,
          0.454,
          0.81,
          0.262,
          0.81,
          0.192,
          0.286,
          0.598,
          0.232,
          0.424,
          0.584,
          0.704,
          0.54,
          0.488,
          0.148,
          0.12,
          0.424,
          0.728,
          0.976,
          0.714,
          0.084,
          0.69,
          0.568,
          0.642,
          0.86,
          0.356,
          0.614,
          0.984,
          0.194,
          0.402,
          0.572,
          0.634,
          0.14,
          0.91,
          0.844,
          0.036,
          0.916,
          0.256,
          0.65,
          0.724,
          0.86,
          0.082,
          0.098,
          0.122,
          0.146,
          0.218,
          0.862,
          0.564,
          0,
          0.538,
          0.936,
          0.68,
          0.248,
          0.41,
          0.822,
          0.292,
          0.75,
          0.882,
          0.818,
          0.766,
          0.672,
          0.1,
          0.42,
          0.56,
          0.278,
          0.776,
          0.382,
          0.256,
          0.576,
          0.844,
          0.49,
          0.432,
          0.182,
          0.322,
          0.774,
          0.702,
          0.04,
          0.722,
          0.766,
          0.728,
          0.228,
          0.198,
          0.796,
          0.748,
          0.128,
          0.634,
          0.244,
          0.444,
          0.698,
          0.614,
          0.43,
          0.266,
          0.82,
          0.732,
          0.558,
          0.204,
          0.936,
          0.012,
          0.752,
          0.464,
          0.596,
          0.75,
          0.722,
          0.538,
          0.218,
          0.698,
          0.63,
          0,
          0.364,
          0.494,
          0.868,
          0.092,
          0.898,
          0.962,
          0.91,
          0.168,
          0.322,
          0.972,
          0.23,
          0.236,
          0.988,
          0.926,
          0.638,
          0.018,
          0.542,
          0.874,
          0.722,
          0,
          0.888,
          0.87,
          0.85,
          0.448,
          0.75,
          0.93,
          0.792,
          0.466,
          0.818,
          0.512,
          0.698,
          0.618,
          0.594,
          0.16,
          0.554,
          0.668,
          0.028,
          0.172,
          0.212,
          0.298,
          0.25,
          0.714,
          0.094,
          0.61,
          0.656,
          0.236,
          0.102,
          0.524,
          0.866,
          0.388,
          0.828,
          0.7,
          0.474,
          0.54,
          0.3,
          0.268,
          0.12,
          0.712,
          0.116,
          0.988,
          0.842,
          0.532,
          0.674,
          0.322,
          0.076,
          0.272,
          0.13,
          0.166,
          0.182,
          0.056,
          0.71,
          0.654,
          0.04,
          0.98,
          0.808,
          0.776,
          0.122,
          0.006,
          0.24,
          0.388,
          0.952,
          0.428,
          0.18,
          0.726,
          0.288,
          0.094,
          0.552,
          0.668,
          0.274,
          0.384,
          0.992,
          0.012,
          0.268,
          0.694,
          0.218,
          0.8,
          0.162,
          0.494,
          0.244,
          0.516,
          0.358,
          0.992,
          0.032,
          0.23,
          0.438,
          0.718,
          0.834,
          0.486,
          0.078,
          0.822,
          0.956,
          0.148,
          0.858,
          0.576,
          0.61,
          0.09,
          0.682,
          0.178,
          0.57,
          0.016,
          0.32,
          0.394,
          0.872,
          0.18,
          0.6,
          0.958,
          0.172,
          0.274,
          0.96,
          0.478,
          0.076,
          0.488,
          0.596,
          0.46,
          0.514,
          0.086,
          0.93,
          0.224,
          0.682,
          0.958,
          0.834,
          0.776,
          0.302,
          0.278,
          0.704,
          0.224,
          0.212,
          0.598,
          0.696,
          0.514,
          0.096,
          0.134,
          0.53,
          0.82,
          0.162,
          0.132,
          0.482,
          0.042,
          0.546,
          0.556,
          0.834,
          0.652,
          0.158,
          0.198,
          0.452,
          0.216,
          0.826,
          0.418,
          0.298,
          0.082,
          0.5,
          0.756,
          0.73,
          0.398,
          0.668,
          0.424,
          0.196,
          0.088,
          0.134,
          0.864,
          0.57,
          0.44,
          0.594,
          0.012,
          0.652,
          0.138,
          0.206,
          0.5,
          0.128,
          0.438,
          0.024,
          0.508,
          0.438
         ],
         "y": [
          0.896,
          0.686,
          0.71,
          0.372,
          0.698,
          0.168,
          0.392,
          0.572,
          0.698,
          0.054,
          0.706,
          0.178,
          0.606,
          0.648,
          0.918,
          0.772,
          0.294,
          0.544,
          0.146,
          0.124,
          0.692,
          0.56,
          0.576,
          0.954,
          0.3,
          0.298,
          0.192,
          0.962,
          0.726,
          0.904,
          0.284,
          0.614,
          0.156,
          0.322,
          0.542,
          0.146,
          0.824,
          0.608,
          0.43,
          0.204,
          0.994,
          0.126,
          0.424,
          0.23,
          0.322,
          0.68,
          0.316,
          0.444,
          0.714,
          0.758,
          0.506,
          0.592,
          0.808,
          0.772,
          0.86,
          0.148,
          0.08,
          0.638,
          0.614,
          0.712,
          0.486,
          0.46,
          0.862,
          0.196,
          0.822,
          0.152,
          0.002,
          0.818,
          0.506,
          0.13,
          0.432,
          0.484,
          0.662,
          0.802,
          0.122,
          0.602,
          0.488,
          0.55,
          0.656,
          0.222,
          0.76,
          0.122,
          0.19,
          0.114,
          0.024,
          0.58,
          0.638,
          0.292,
          0.726,
          0.76,
          0.988,
          0.01,
          0.33,
          0.76,
          0.002,
          0.148,
          0.122,
          0.008,
          0.61,
          0.092,
          0.074,
          0.74,
          0.38,
          0.784,
          0.216,
          0.138,
          0.186,
          0.502,
          0.526,
          0.43,
          0.012,
          0.462,
          0.428,
          0.614,
          0.712,
          0.67,
          0.904,
          0.974,
          0.338,
          0.61,
          0.654,
          0.586,
          0.294,
          0.75,
          0.254,
          0.074,
          0.148,
          0.918,
          0.436,
          0.074,
          0.36,
          0.718,
          0.482,
          0.864,
          0.936,
          0.95,
          0.768,
          0.956,
          0.488,
          0.674,
          0.96,
          0.782,
          0.272,
          0.248,
          0.552,
          0.316,
          0.58,
          0.73,
          0.864,
          0.236,
          0.156,
          0.11,
          0.85,
          0.654,
          0.726,
          0.05,
          0.054,
          0.502,
          0.366,
          0.608,
          0.81,
          0.934,
          0.464,
          0.442,
          0.502,
          0.058,
          0.34,
          0.004,
          0.916,
          0.704,
          0.452,
          0.428,
          0.036,
          0.054,
          0.42,
          0.238,
          0.762,
          0.044,
          0.208,
          0.356,
          0.164,
          0.198,
          0.314,
          0.95,
          0.552,
          0.82,
          0.564,
          0.714,
          0.382,
          0.266,
          0.682,
          0.938,
          0.346,
          0.812,
          0.404,
          0.736,
          0.236,
          0.93,
          0.574,
          0.99,
          0.626,
          0.66,
          0.718,
          0.786,
          0.89,
          0.45,
          0.954,
          0.454,
          0.15,
          0.774,
          0.846,
          0.126,
          0.38,
          0.862,
          0.742,
          0.042,
          0.42,
          0.578,
          0.05,
          0.39,
          0.91,
          0.586,
          0.64,
          0.074,
          0.72,
          0.892,
          0.056,
          0.148,
          0.484,
          0.23,
          0.526,
          0.594,
          0.016,
          0.734,
          0.348,
          0.53,
          0.926,
          0.564,
          0.824,
          0.094,
          0.454,
          0.018,
          0.022,
          0.604,
          0.57,
          0.158,
          0.35,
          0.54,
          0.96,
          0.76,
          0.184,
          0.768,
          0.532,
          0.378,
          0.41,
          0.884,
          0.954,
          0.27,
          0.294,
          0.19,
          0.724,
          0.334,
          0.498,
          0.128,
          0.47,
          0.98,
          0.562,
          0.854,
          0.544,
          0.886,
          0.15,
          0.65,
          0.174,
          0.244,
          0.354,
          0.856,
          0.184,
          0.434,
          0.536,
          0.734,
          0.08,
          0.03,
          0.236,
          0.242,
          0.824,
          0.434,
          0.69,
          0.65,
          0.006,
          0.674,
          0.38,
          0.728,
          0.538,
          0.134,
          0.704,
          0.286,
          0.34,
          0.14,
          0.098,
          0.454,
          0.586,
          0.814,
          0.608,
          0.462,
          0.288,
          0.192,
          0.266,
          0.946,
          0.24,
          0.16,
          0.228,
          0.064,
          0.022,
          0.546,
          0.004,
          0.524,
          0.774,
          0.832,
          0.942,
          0.378,
          0.284,
          0.09,
          0.794,
          0.724,
          0.588,
          0.024,
          0.912,
          0.18,
          0.86,
          0.848,
          0.558,
          0.298,
          0.328,
          0.968,
          0.29,
          0.064,
          0.458,
          0.748,
          0.646,
          0.08,
          0.256,
          0.028,
          0.842,
          0.978,
          0.044,
          0.81,
          0.94,
          0.392,
          0.444,
          0.108,
          0.372,
          0.884,
          0.072,
          0.184,
          0.608,
          0.392,
          0.854,
          0.02,
          0.904,
          0.988,
          0,
          0.928,
          0.002,
          0.532,
          0.014,
          0.652,
          0.686,
          0.326,
          0.148,
          0.764,
          0.15,
          0.062,
          0.642,
          0.734,
          0.426,
          0.132,
          0.502,
          0.482,
          0.756,
          0.236,
          0.108,
          0.464,
          0.454,
          0.396,
          0.782,
          0.982,
          0.332,
          0.894,
          0.71,
          0.594,
          0.996,
          0.028,
          0.8,
          0.342,
          0.478,
          0.836,
          0.892,
          0.238,
          0.704,
          0.694,
          0.914,
          0.91,
          0.282,
          0.42,
          0.206,
          0.93,
          0.052,
          0.45,
          0.974,
          0.836,
          0.194,
          0.6,
          0.688,
          0.994,
          0.908,
          0.524,
          0.112,
          0.058,
          0.092,
          0.112,
          0.08,
          0.12,
          0.568,
          0.854,
          0.024,
          0.106,
          0.024,
          0.902,
          0.964,
          0.112,
          0.656,
          0.984,
          0.182,
          0.79,
          0.086,
          0.972,
          0.164,
          0.538,
          0.332,
          0.448,
          0.714,
          0.29,
          0.826,
          0.252,
          0.512,
          0.38,
          0.698,
          0.544,
          0.006,
          0.464,
          0.652,
          0.402,
          0.396,
          0.176,
          0.342,
          0.358,
          0.902,
          0.502,
          0.26,
          0.922,
          0.296,
          0.868,
          0.788,
          0.814,
          0.518,
          0.92,
          0.242,
          0.374,
          0.338,
          0.232,
          0.354,
          0.274,
          0.734,
          0.686,
          0.29,
          0.374,
          0.456,
          0.838,
          0.478,
          0.218,
          0.012,
          0.982,
          0.514,
          0.758,
          0.68,
          0.92,
          0.74,
          0.788,
          0.692,
          0.066,
          0.934,
          0.51,
          0.812,
          0.436,
          0.072,
          0.022,
          0.586,
          0.664,
          0.45,
          0.656,
          0.032,
          0.046,
          0.562,
          0.978,
          0.23,
          0.292,
          0.598,
          0.95,
          0.788,
          0.77,
          0.72,
          0.092,
          0.51,
          0.75,
          0.884,
          0.128,
          0.15,
          0.454,
          0.136,
          0.662,
          0.232,
          0.776,
          0.584,
          0.17,
          0.74,
          0.976,
          0.96,
          0.712,
          0.368,
          0.068,
          0.478,
          0.712,
          0.334,
          0.316,
          0.992,
          0.776,
          0.45,
          0.506,
          0.092,
          0.362,
          0.708,
          0.86,
          0.952,
          0.836,
          0.468,
          0.222,
          0.434,
          0.128,
          0.668,
          0.604,
          0.032,
          0.454,
          0.956,
          0.452,
          0.776,
          0.65,
          0.102,
          0.604,
          0.656,
          0.448,
          0.91,
          0.05,
          0.928,
          0.536,
          0.452,
          0.096,
          0.786,
          0.462,
          0.3,
          0.132,
          0.888,
          0.926,
          0,
          0.318,
          0.128,
          0.788,
          0.424,
          0.434,
          0.734,
          0.37,
          0.214,
          0.284,
          0.116,
          0.216,
          0.918,
          0.972,
          0.946,
          0.462,
          0.792,
          0.428,
          0.938,
          0.93,
          0.5,
          0.306,
          0.352,
          0.344,
          0.836,
          0.77,
          0.856,
          0.106,
          0.892,
          0.866,
          0.046,
          0.972,
          0.728,
          0.602,
          0.262,
          0.64,
          0.544,
          0.66,
          0.9,
          0.084,
          0.298,
          0.966,
          0.908,
          0.48,
          0.586,
          0.048,
          0.27,
          0.952,
          0.484,
          0.294,
          0.578,
          0.374,
          0.03,
          0.958,
          0.018,
          0.086,
          0.85,
          0.492,
          0.846,
          0.496,
          0.03,
          0.344,
          0.796,
          0.054,
          0.108,
          0.142,
          0.782,
          0.092,
          0.374,
          0.956,
          0.92,
          0.908,
          0.472,
          0.748,
          0.942,
          0.602,
          0.002,
          0.106,
          0.996,
          0.228,
          0.804,
          0.146,
          0.99,
          0.664,
          0.748,
          0.816,
          0.946,
          0.792,
          0.158,
          0.044,
          0.674,
          0.298,
          0.818,
          0.39,
          0.028,
          0.514,
          0.838,
          0.03,
          0.626,
          0.474,
          0.564,
          0.956,
          0.79,
          0.732,
          0.476,
          0.112,
          0.792,
          0.9,
          0.168,
          0.776,
          0.864,
          0.978,
          0.41,
          0.882,
          0.852,
          0.594,
          0.562,
          0.808,
          0.174,
          0.512,
          0.21,
          0.716,
          0.586,
          0.926,
          0.278,
          0.84,
          0.096,
          0.62,
          0.83,
          0.982,
          0.328,
          0.266,
          0.844,
          0.324,
          0.572,
          0.1,
          0.03,
          0.012,
          0.862,
          0.034,
          0.694,
          0.984,
          0.504,
          0.398,
          0.242,
          0.29,
          0.152,
          0.812,
          0.658,
          0.728,
          0.552,
          0.522,
          0.02,
          0.104,
          0.85,
          0.182,
          0.48,
          0.302,
          0.736,
          0.268,
          0.926,
          0.462,
          0.296,
          0.672,
          0.51,
          0.33,
          0.02,
          0.206,
          0.596,
          0.168,
          0.594,
          0.994,
          0.236,
          0.678,
          0.46,
          0.334,
          0.002,
          0.89,
          1,
          0.668,
          0.122,
          0.828,
          0.296,
          0.966,
          0.968,
          0.904,
          0.436,
          0.922,
          0.62,
          0.454,
          0.83,
          0.532,
          0.204,
          0.374,
          0.326,
          0.978,
          0.088,
          0.17,
          0.9,
          0.522,
          0.262,
          0.622,
          0.796,
          0.204,
          0.832,
          0.708,
          0.536,
          0.104,
          0.978,
          0.394,
          0.794,
          0.666,
          0.5,
          0.016,
          0.376,
          0.33,
          0.456,
          0.374,
          0.952,
          0.104,
          0.212,
          0.472,
          0.02,
          0.69,
          0.074,
          0.768,
          0.308,
          0.446,
          0.41,
          0.158,
          0.922,
          0.31,
          0.624,
          0.89,
          0.494,
          0.72,
          0.832,
          0.814,
          0.732,
          0.036,
          0.256,
          0.364,
          0.676,
          0.326,
          0.124,
          0.866,
          0.668,
          0.494,
          0.192,
          0.75,
          0.252,
          0.874,
          0.854,
          0.814,
          0.344,
          0.938,
          0.854,
          0.234,
          0.492,
          0.86,
          0.932,
          0.13,
          0.102,
          0.984,
          0.936,
          0.96,
          0.184,
          0.38,
          0.958,
          0.52,
          0.076,
          0.46,
          0.016,
          0.182,
          0.056,
          0.922,
          0.724,
          0.704,
          0.564,
          0.536,
          0.166,
          0.41,
          0.916,
          0.544,
          0.326,
          0.246,
          0.516,
          0.606,
          0.008,
          0.5,
          0.376,
          0.252,
          0.904,
          0.576,
          0.622,
          0.332,
          0.98,
          0.976,
          0.978,
          0.418,
          0.7,
          0.276,
          0.412,
          0.91,
          0.08,
          0.51,
          0.83,
          0.64,
          0.078,
          0.714,
          0.388,
          0.426,
          0.196,
          0.388,
          0.51,
          0.904,
          0.996,
          0.044,
          0.404,
          0.186,
          0.524,
          0.734,
          0.554,
          0.284,
          0.834,
          0.212,
          0.22,
          0.916,
          0.774,
          0.58,
          0.89,
          0.664,
          0.518,
          0.37,
          0.33,
          0.928,
          0.938,
          0.646,
          0.502,
          0.334,
          0.96,
          0.278,
          0.094,
          0.028,
          0.306,
          0.174,
          0.758,
          0.402,
          0.654,
          0.798,
          0.224,
          0.876,
          0.598,
          0.7,
          0.354,
          0.284,
          0.126,
          0.906,
          0.626,
          0.648,
          0.866,
          0.61,
          0.196,
          0.932,
          0.53,
          0.662,
          0.63,
          0.608,
          0.168,
          0.194,
          0.532,
          0.956,
          0.804,
          0.478,
          0.054,
          0.642,
          0.894,
          0.704,
          0.678,
          0.014,
          0.536,
          0.734,
          0.012,
          0.354,
          0.684,
          0.662,
          0.218,
          0.11,
          0.244,
          0.212,
          0.33,
          0.468,
          0.572,
          0.92,
          0.01,
          0.042,
          0.858,
          0.808,
          0.014,
          0.442,
          0.716,
          0.9,
          0.152,
          0.386,
          0.466,
          0.51,
          0.102,
          0.24,
          0.424,
          0.94,
          0.74,
          0.502,
          0.49,
          0.282,
          0.044,
          0.184,
          0.47,
          0.81,
          0.478,
          0.868,
          0.256,
          0.452,
          0.56,
          0.796,
          0.634,
          0.964,
          0.956,
          0.988,
          0.062,
          0.484,
          0.11,
          0.558,
          0.018,
          0.674,
          0.184,
          0.126,
          0.482,
          0.93,
          0.048,
          0.712,
          0.436,
          0.826,
          0.864,
          0.218,
          0.656,
          0.734,
          0.262,
          0.468,
          0.072,
          0.458,
          0.088,
          0.178,
          0.486,
          0.606,
          0.546,
          0.894,
          0.092,
          0.364,
          0.984,
          0.93,
          0.066,
          0.508,
          0.632,
          0.088,
          0.472,
          0.388,
          0.216,
          0.806,
          0.002,
          0.956,
          0.572,
          0.302,
          0.388,
          0.178,
          0.15,
          0.57,
          0.118,
          0.252,
          0.192,
          0.396,
          0.044,
          0.502,
          0.228,
          0.224,
          0.97,
          0.67,
          0.746,
          0.648,
          0.05,
          0.868,
          0.754,
          0.558,
          0.714,
          0.486,
          0.184,
          0.932,
          0.842,
          0.276,
          0.948,
          0.474,
          0.324,
          0.854,
          0.44,
          0.17,
          0.204,
          0.012,
          0.334,
          0.204,
          0.028,
          0.496,
          0.254,
          0.326,
          0.634,
          0.04,
          0.83,
          0.02,
          0.174,
          0.94,
          0.724,
          0.57,
          0.864,
          0.524,
          0.444,
          0.384,
          0.918,
          0.474,
          0.112,
          0.324,
          0.162,
          0.628,
          0.038,
          0.442,
          0.414,
          0.564,
          0.43,
          0.41,
          0.47,
          0.294,
          0.806,
          0.69,
          0.338,
          0.596,
          0.94,
          0.162,
          0.398,
          0.206,
          0.334,
          0.018,
          0.514,
          0.744,
          0.236,
          0.742,
          0.778,
          0.642,
          0.402,
          0.102,
          0.296,
          0.028,
          0.33,
          0.058,
          0.428,
          0.336,
          0.552,
          0.534,
          0.034,
          0.976,
          0.222,
          0.332,
          0.318,
          0.146,
          0.922,
          0.018,
          0.054,
          0.298,
          0.9,
          0.25,
          0.782,
          0.952,
          0.468,
          0.826,
          0.146,
          0,
          0.592,
          0.244,
          0.29,
          0.828,
          0.57,
          0.88,
          0.016,
          0.796,
          0.578,
          0.576,
          0.768,
          0.05,
          0.084,
          0.86,
          0.696,
          0.408,
          0.524,
          0.144,
          0.222,
          0.956,
          0.758,
          0.358,
          0.25,
          0.246,
          0.058,
          0.06,
          0.73,
          0.496,
          0.3,
          0.848,
          0.998,
          0.242,
          0.822,
          0.604,
          0.636,
          1,
          0.372,
          0.618,
          0.108,
          0.682,
          0.846,
          0.202,
          0.018,
          0.586,
          0.814,
          0.01,
          0.588,
          0.428,
          0.278,
          0.994,
          0.584,
          0.436,
          0.554,
          0.46,
          0.764,
          0.168,
          0.284,
          0.524,
          0.34,
          0.356,
          0.54,
          0.582,
          0.816,
          0.786,
          0.65,
          0.712,
          0.48,
          0.676,
          0.594,
          0.06,
          0.734,
          0.79,
          0.536,
          0.468,
          0.538,
          0.398,
          0.8,
          0.04
         ],
         "z": [
          3.452539999999999,
          3265.64,
          368.48799999999994,
          0.010680899999982785,
          0.9747289999999964,
          7.584459922327369e-07,
          3.3975599999999986,
          2.155489999999986,
          4.444670000000002,
          0.15415500000000293,
          5.018000000000001,
          1.0457999621849012e-06,
          3.445210000000003,
          1046.12,
          5079.73,
          6.724169999999987,
          0.0001396810000073856,
          0.7647200000000112,
          1.1142799394292524e-07,
          6.284639653131308e-08,
          2.6537899999999865,
          1.3624399999999923,
          3.322959999999995,
          1.380899999999997,
          0.0001575469999863799,
          7.693609998682405e-05,
          2.477710000000002,
          1.6801000000000101,
          8.400010000000009,
          1.915459999999996,
          0.00011311099999034013,
          2.9779299999999864,
          1.9333199929860712e-07,
          3.0554799999999886,
          1.3940599999999677,
          2.411609898445022e-07,
          3.662349999999975,
          0.4909330000000125,
          0.024439499999971304,
          2.4261699991257046e-06,
          0.16173399999996718,
          4.03593958253623e-08,
          0.021030400000000782,
          4.285389991309785e-06,
          54.81989999999999,
          1.83920999999998,
          0.00039086399999632704,
          0.03729029999999511,
          3.3120600000000024,
          137.539,
          1.217630000000014,
          2.2760100000000136,
          8.063080000000014,
          835.042,
          4.579679999999996,
          5.489139999999992,
          3.559819106158102e-09,
          438.363,
          87.273,
          4781.9,
          0.22892400000000634,
          0.10565199999999209,
          3.8337300000000027,
          1.802610000822824e-06,
          3.267470000000003,
          1.319639579833165e-07,
          0.0002675220000014633,
          1.5367200000000025,
          0.00496183999999289,
          7.867021167839994e-08,
          0.05681010000000697,
          2.6509299999999882,
          3.6251000000000033,
          3670.33,
          6.311501010713982e-08,
          1.6060400000000072,
          0.19984999999999786,
          14.513499999999993,
          1557.0700000000002,
          1.1651600004825013e-05,
          1.4153200000000083,
          9.465793482377194e-09,
          0.10110499999998979,
          2.568040713413211e-08,
          0.015704300000010107,
          1385.5100000000002,
          9.233609999999999,
          0.00024310000000582477,
          0.2737209999999948,
          7.253829999999994,
          26.1755,
          2.1714186004828662e-11,
          0.000534652999959917,
          5.174679999999967,
          0,
          1.1022100920854427e-07,
          3.218701749574393e-09,
          8.739675649849232e-11,
          2.230000000000018,
          4.879299808635551e-08,
          1.7739125723892357e-09,
          523.133,
          0.003017989999989368,
          8.07605000000001,
          0.10172900000000595,
          4.600730107995332e-08,
          0.06002989999998931,
          212.352,
          0.34520599999999035,
          3.6293699999999944,
          3.680611371237319e-11,
          3.779799999999966,
          0.026061199999986684,
          0.2954379999999901,
          700.349,
          3.7590099999999893,
          1.2027400000000057,
          0.7371180000000095,
          0.001345079999993004,
          3.481519999999989,
          0.3194249999999954,
          2.9622500000000116,
          3.3997200006297135e-05,
          0.8319979999999987,
          0.00032665800000586387,
          1.2856560260843253e-09,
          2.711070123950776e-07,
          0.8525180000000034,
          0.0023520700000005945,
          4.888534022029489e-12,
          0.0030899600000111604,
          2484,
          0.31798599999999055,
          1.8439199999999971,
          2.670819999999992,
          2.395280000000014,
          7.0911000000000115,
          2.1787199999999984,
          539.776,
          5.888149999999996,
          0.8797979999999939,
          5.796670000000006,
          31.192999999999998,
          1.4119699999999966,
          1.405779999999993,
          6.096219999562891e-05,
          12.256699999999995,
          6.08802,
          3.4216900000000123,
          2.1273500010465796e-05,
          7.510857358283829e-08,
          6.112458095230977e-09,
          2.885089999999991,
          7.792740000000009,
          0.2527900000000045,
          4.460503078007605e-10,
          6.886864412081195e-10,
          686.727,
          0.007681120000000874,
          1.6512899999999888,
          26.72030000000001,
          1.0308100000000024,
          0.21908799999999928,
          528.542,
          0.6554040000000043,
          8.022027486731531e-10,
          22.181600000000003,
          0,
          5923.56,
          1.6692099999999925,
          0.06735390000000052,
          0.03613809999998807,
          7.929656931082718e-12,
          1.6655121726216748e-11,
          0.020174600000018472,
          2.2301200004903876e-05,
          15.274699999999996,
          2.2743051886209287e-10,
          6.06962001370448e-06,
          0.0006131389999666226,
          7.708750047186186e-07,
          0.0004832420000013826,
          0.00012706999999068103,
          0.7805759999999964,
          1808.02,
          1386.79,
          1.2384700000000066,
          5.826740000000001,
          0.0014190400000018144,
          3.334269999299977e-05,
          4.664389999999997,
          3.469690000000014,
          0.00043978499999752785,
          2.401980000000009,
          0.2693259999999782,
          1.4800600000000088,
          3.7993199999999945,
          4.1815400000000125,
          0.8710509999999658,
          0.6025440000000231,
          1.6271600000000035,
          1.0741600000000346,
          14.129700000000014,
          8.989779999999996,
          6858.88,
          0.07985199999998827,
          0.12491499999998723,
          0.12554900000000657,
          3.161979975629947e-07,
          7116.04,
          1.0957500000000095,
          3.625089561865025e-08,
          20.810400000000016,
          2.8177900000000022,
          6.909369999999996,
          3.728473529918119e-09,
          0.03220409999997287,
          0.42766000000000304,
          1.169837560155429e-10,
          231.838,
          1.8548900000000117,
          2.8208700000000135,
          0.612829000000005,
          2.6698785404732917e-09,
          3935.2499999999995,
          4.319819999999993,
          3.937543624488171e-10,
          0.5239250000000197,
          0.11276099999997768,
          1.3888599994515971e-05,
          0.31839400000001206,
          0.8563589999999976,
          3.3367086871294305e-11,
          967.255,
          0.0018269400000008318,
          0.3271119999999996,
          0.45638099999999326,
          1.7794700000000034,
          1.2850500000000125,
          4.067317149747396e-09,
          0.16716800000000376,
          5.5990767577895895e-12,
          0.012958800000006931,
          2.5720799999999997,
          0.5756110000000092,
          2.179180000894121e-07,
          0.07958690000000956,
          0.05718279999999254,
          1.1965199999999925,
          4.444919999999996,
          1.6875299877483485e-06,
          5.134879999999981,
          983.863,
          0.4022390000000087,
          4.270399999999995,
          2.386599999999987,
          1.2837500000000261,
          50.58779999999999,
          123.889,
          1.996099996404155e-06,
          86.8498,
          0.0006206669999926362,
          0.2361229999999921,
          8.150360031322634e-08,
          0.2773599999999874,
          0.3673660000000041,
          0.16449800000000891,
          7.81044,
          0.9818620000000067,
          5.444289999999995,
          1.1868598903674865e-07,
          3.9281699999999944,
          5.4750586286900216e-08,
          8.876489999920523e-06,
          0.0011597099999960392,
          0.7848500000000058,
          1.2868900114426651e-06,
          110.854,
          1.3101100000000372,
          7.140240000000006,
          0.00045708400000421534,
          0.002335390000013149,
          2.7761099999999885,
          2.8350799993859255e-05,
          0.47119199999997363,
          0.013869400000004362,
          3.6196899999999914,
          2472.75,
          0,
          2.500380000000007,
          15.246499999999997,
          5187.63,
          0.7753419999999949,
          3.5343191484571435e-08,
          245.13,
          0.00019875399999591536,
          0.0007340209999995295,
          5.494919719239988e-08,
          1.1382411457816488e-08,
          0.015979399999991983,
          2.8471800000000087,
          1921.38,
          712.952,
          0.07059939999999187,
          0.00011734800000340329,
          1.6189100051633432e-06,
          9.472350001260565e-05,
          264.463,
          1.2013400009891484e-05,
          3.217220125861786e-07,
          1.6559699986373744e-05,
          4.733919922728091e-10,
          2.546585164964199e-11,
          0.5034909999999968,
          0.0028628299999979845,
          0.4277669999999887,
          8.175780000000003,
          0.9688739999999996,
          2562.66,
          166.484,
          4.327770000145392e-05,
          5.617096121568466e-09,
          1.1105699999999956,
          5.739210000000014,
          2.234579999999994,
          1.446665010007564e-11,
          1.6669499999999857,
          2.1010500006468646e-05,
          4.695619999999963,
          0.8469619999999907,
          0.8569450000000245,
          0.00026278999999362895,
          0.0007419670000103906,
          1.1260800000000017,
          20.38839999999999,
          3.622346866904991e-10,
          0.05689830000002871,
          3.9312500000000057,
          2.3552099999999996,
          3.929130798496772e-09,
          0.1565520000000049,
          1.3386625141720288e-11,
          3.7572099999999864,
          0.8029200000000003,
          2.558522282924969e-10,
          5.319889999999987,
          0.8272819999999967,
          0.012160700000009683,
          0.09848450000001208,
          2.290801148774335e-08,
          0.0029759800000022096,
          3.039050000000003,
          1.0670900000000074,
          1.5904000179034483e-06,
          0.4128310000000113,
          0.010956599999985883,
          1.877510000000001,
          1.5091927707544528e-11,
          0.34152299999999514,
          130.065,
          0,
          2.9375499999999874,
          0,
          0.9525820000000067,
          4.945377440890297e-11,
          2506.46,
          2.6315199999999948,
          0.000802854999989222,
          1.902189978864044e-07,
          2156.02,
          1.3264900644571753e-07,
          1.1288818768662168e-09,
          3.7872800000000097,
          6.155619999999999,
          0.010299099999997452,
          0.0002720850000059727,
          0.6025889999999947,
          0.011232900000010204,
          3.0189499999999896,
          1.4628600013111281e-05,
          2.415168864899897e-08,
          0.22369000000000483,
          0.03013229999999112,
          0.01623609999998621,
          3.3888399999999876,
          0.679081999999994,
          0.0010289900000088892,
          0.6589639999999974,
          1.5572400000000073,
          2.2515199999999993,
          0.19397599999999215,
          4.149569576838985e-12,
          8.59814,
          0.00035562200000072153,
          0.23116099999998596,
          1.773239999999987,
          1.7116399999999885,
          5.9226700273029564e-06,
          0.5365409999999997,
          231.058,
          3.7110299999999654,
          4.567129999999992,
          8.418970000434456e-05,
          0.002631549999989602,
          0.012316099999992502,
          2.932469999999995,
          5.078391041024588e-10,
          0.13999600000002488,
          0.8468269999999904,
          8663.05,
          1.2002999767446454e-06,
          2601.6,
          2.1253499999999974,
          93.26859999999999,
          0.2578269999999918,
          1451.19,
          8.8457454694435e-09,
          0.5777390000000082,
          0.0011061600000061844,
          5.2720196208611014e-08,
          3.352568000991596e-09,
          0.0010981200000230729,
          0.6769290000000012,
          0.8103059999999971,
          0.04537279999996713,
          0.6686489999999878,
          5.770209554611938e-08,
          3.7909099999999682,
          2.3972200000000043,
          3.8528798995685065e-07,
          0.46858499999996184,
          2.366989999999987,
          29.4247,
          4.762229999999988,
          3.2451907827635296e-09,
          0.27100699999999733,
          1.0750400747383537e-07,
          0.9829440000000034,
          0.00015042100000073333,
          0.11889700000000403,
          1.328930000000014,
          0.00021067800000196257,
          7.618429999999989,
          1.664199999140692e-05,
          11.560200000000009,
          0.002061080000032689,
          5.068479999999994,
          1.9066799999999944,
          0,
          0.22205099999999334,
          4.292460000000034,
          0.01330459999999789,
          0.008023710000003348,
          4.294340385513351e-07,
          0.0016287200000135726,
          0.0024449899999865465,
          4.787769999999995,
          0.3972040000000163,
          3.880119999166709e-05,
          2.9810799999999915,
          8.700440000097842e-05,
          64.4702,
          4.3425200000000075,
          3.963169999999991,
          0.6530520000000308,
          1009.21,
          6.9627900000000125,
          0.0004188409999983378,
          0.0005658860000323784,
          3.986399974564847e-07,
          0.0017395499999963704,
          0.00011371900001222457,
          3.419810000000041,
          4.647129999999976,
          6.0253800000964475e-05,
          0.006150240000010854,
          0.011800800000003164,
          6.0604999999999905,
          0.3174860000000024,
          9.401929901287076e-07,
          7.077005648170598e-12,
          296.136,
          0.7239940000000047,
          9.191969999999998,
          2796.26,
          1.9687099999999873,
          308.204,
          25.749799999999993,
          0.7636980000000051,
          3.6382914458954474e-09,
          5.172429999999991,
          1048.35,
          4.389039999999994,
          0.10151500000000624,
          2.1187531729083275e-09,
          0.017785699999990356,
          935.761,
          4238.32,
          0.10699299999998857,
          1.6157800000000009,
          0.11407199999999307,
          1.8417267710901797e-10,
          1.5690099999999916,
          1.0062200000000132,
          3.982200000000006,
          6.751210000000015,
          0.6538070000000005,
          210.522,
          4.988319999999987,
          7213.27,
          3.818659999999994,
          1.2248619896126911e-09,
          0.04476059999998938,
          3.4154900000000055,
          1.5796300000000087,
          2.5983013074437622e-08,
          3.215461674699327e-09,
          0.07989520000003836,
          2.6637991368261282e-08,
          1.2362300000000346,
          1.5442599988091388e-05,
          6.886989999999997,
          0.7522130000000118,
          3.2398799874044926e-06,
          1510.92,
          0.48973399999997014,
          59.05359999999999,
          105.569,
          42.84,
          7.474450001154764e-05,
          0.03174830000000384,
          4.514419999999973,
          198.218,
          1.310939999999988,
          38.2158,
          275.65,
          0.05585719999996286,
          1.264819999999986,
          1.6331114238710143e-09,
          124.199,
          5.650830000000013,
          2.647340000000014,
          2.0503300000000024,
          2.3364899999999977,
          0.12803400000001375,
          1.161500000534943e-05,
          0.004550969999996823,
          2.050759999999997,
          0.010339899999991076,
          832.908,
          2.162892087653745e-11,
          11.127299999999991,
          1.8558999999999912,
          45.136700000000005,
          7.065359999999998,
          11.090100000000007,
          1.1302489610898192e-08,
          0.1394380000000126,
          5.967870000000005,
          0.06035610000000702,
          6.00039000000001,
          4.3360159907024354e-10,
          1.1727500000000077,
          5.641250000000014,
          0.10166599999999448,
          2.893969999999996,
          5.503489999999999,
          516.799,
          0.00031585100001052524,
          3.531860000000023,
          3.7676999999999907,
          3.897580000000005,
          0,
          0.00013814600001182953,
          2.516250674489129e-08,
          1.291640000000001,
          145.664,
          0.07893160000000421,
          1.3251900000000205,
          0.0021678200000110337,
          17.586299999999994,
          27.702200000000005,
          6.071509999999989,
          3.023530013024356e-06,
          4.315339999999992,
          0.15056100000001038,
          1.6969899999999996,
          0.19627700000000914,
          3.3573299999999904,
          0.013378200000005336,
          1.0618599999999958,
          1.195130000000006,
          0.5027240000000006,
          0.00019060299999296149,
          0.0006788780000022143,
          0.0001731970000093952,
          4.318309999999997,
          2.2249199999999973,
          65.1322,
          1.2710700000000088,
          4.874059999999986,
          3.5995299999999872,
          1.630553470022278e-10,
          1.2233300000000042,
          0.08784660000000599,
          3.065110000000004,
          93.3365,
          4.800700000000006,
          1.8680099999999982,
          0.1494599999999764,
          4.867009999999993,
          5.968502136965981e-09,
          0.00017202399999405316,
          0.43686199999999076,
          4.454329999999999,
          0.15188099999997462,
          2.540469999999999,
          2.2316726244753227e-10,
          1.5912099996739926e-05,
          1.2623099999999852,
          0.2777460000000076,
          0.011885500000005322,
          3.5281400000000076,
          0.002265489999984993,
          3.54702933691442e-11,
          1.2508400000000108,
          2.461320036672987e-11,
          2.1259000000000015,
          1457.65,
          0.39752999999998906,
          6.635619999999989,
          0.20409100000000535,
          5.3944404498906806e-11,
          0.0013129099999957816,
          4.680820000000011,
          5.021263405069476e-10,
          1.7549893982504727e-08,
          1.1192499999999939,
          21.8193,
          6.205738145581563e-09,
          0.0028746899999987363,
          0.5001800000000003,
          4.478170000000006,
          5704.73,
          899.924,
          5352.24,
          2157.71,
          3.614120000000014,
          0,
          2.268200205435278e-08,
          0.18186000000000035,
          1.0625400000000127,
          41.2474,
          1.7322699999999998,
          0.05369440000004033,
          0.6247250000000122,
          7.0982899999999916,
          4.03834999999998,
          36.5424,
          4787.87,
          3.1909300446386624e-07,
          3.6550318327499554e-11,
          5.621430000000004,
          0.6423939999999959,
          2.3808099999999968,
          0.00814729999999031,
          2.646061147970613e-11,
          1.6827299999999923,
          3.445369999999997,
          7.09405867382884e-11,
          4.383659999999992,
          0.18503999999998655,
          0.5279830000000061,
          1.7374399999999923,
          3.961119999999994,
          5.749539999999996,
          0.12500700000001075,
          2.0003312783956062e-08,
          4.446789999999993,
          2.0573400000000106,
          9.221820107541134e-07,
          0.6909499999999866,
          515.156,
          412.333,
          0.021165599999989126,
          4.760680000000008,
          0.31848499999998126,
          1.0776600000000087,
          2.1072200000000123,
          4.345210000000009,
          1.2362299912638264e-06,
          0.2938509999999894,
          5.161079997151319e-06,
          9.767619999999994,
          0.6657910000000413,
          85.9106,
          0.02743670000000975,
          6.338040000000007,
          4.961890454069362e-09,
          3077.97,
          5.902659999999997,
          0.23789500000000885,
          0.000990182000009554,
          0.00012323799995783702,
          0.5511710000000107,
          0.0006182500000022628,
          2.1993300000000033,
          6.960704013181385e-09,
          1.9952040020143613e-11,
          0.01438759999996364,
          4.5237900000000195,
          2.503952600818593e-11,
          3.8264499999999657,
          0.16275400000000673,
          0.6684860000000015,
          0.01152070000000549,
          2.0365700009961074e-05,
          0.0030234600000085265,
          2.581299999999999,
          69.7843,
          4038.68,
          4770.73,
          0.05424339999999006,
          0.6753530000000012,
          1.574562702444382e-11,
          3.422229610805516e-09,
          1.3223500000000001,
          1.376189999291455e-06,
          0.15820899999999938,
          0.00029527899999948204,
          2.102100000000007,
          4.523070001027918e-05,
          4.068729999999988,
          361.121,
          5.6457600408066355e-06,
          1.7569499999999891,
          0.37926799999999616,
          0.0009237719999930505,
          3.4072299996523725e-05,
          4.153170010567919e-06,
          1.4071099999999888,
          4.5405926130115404e-08,
          2.5594199999999887,
          96.3681,
          9.662990009928762e-06,
          14.740399999999994,
          0.16690700000000902,
          0.0013064699999745244,
          9.914749966810632e-06,
          0.4792590000000132,
          0.07340320000000133,
          0.7927540000000022,
          7.00470081937965e-09,
          2.847139999999996,
          115.909,
          0.724897999999996,
          0.8946320000000014,
          3971.36,
          70.18919999999999,
          1.0470899999999972,
          4.794090000000011,
          0.006850359999987177,
          0.8885970000000043,
          340.844,
          0.0006610190000060356,
          0.0069677699999886045,
          0.0006289039999956003,
          0.5806609999999921,
          1.5706900000000132,
          5.101790065964451e-07,
          12.334100000000007,
          0.382394000000005,
          1.9835800003420445e-05,
          4.010210000000001,
          2.4846200000000067,
          1.1971399942467542e-06,
          2.2747100000000273,
          2.915930000000003,
          0.8856290000000229,
          2.0628391439458937e-08,
          0.7029029999999636,
          0.005645820000012236,
          582.09,
          5.186229999999995,
          0.32410200000001055,
          1.3358203432289883e-12,
          0.005993780000011384,
          0.0002499290000059773,
          0.11702099999999405,
          6.532589999999999,
          779.961,
          1.5669911590521224e-08,
          5.823070011956588e-06,
          0.5536309999999958,
          4.6497916628140956e-11,
          0.7770189999999957,
          0.0015933800000027531,
          1.3115300000000047,
          67.6515,
          0.05113719999999944,
          0.020826999999997042,
          4.0781500842967944e-07,
          13.915999999999997,
          0.00048403299999222327,
          3234.76,
          7699.05,
          0.3521560000000079,
          4.960090000000008,
          5.539299999999997,
          6.358460000000008,
          3.10902999999999,
          7.830180948076304e-11,
          8.911919991305695e-06,
          179.074,
          0.14421100000001275,
          0.0003800199999943743,
          4.933340846946521e-08,
          3.3356899999999996,
          5.273400000000009,
          0.0959013000000084,
          1.6009200010103086e-06,
          7.425600000000003,
          2.0075999970003977e-05,
          6.617580000000004,
          1.1265199999999709,
          4.268029999999982,
          0.0006424910000077944,
          53.2761,
          1.2450900000000047,
          1.5705299999999909,
          9.591520000000003,
          6.358039999999988,
          1.718529999999987,
          1.1031195867872157e-07,
          1.382579739583889e-08,
          0.2619019999999921,
          1.9351000000000056,
          0.8152809999999988,
          1.3233099878107168e-06,
          253.98700000000002,
          1.842029999999994,
          1.263760000000019,
          1.7706440758047393e-09,
          0.16072500000001355,
          3.484501576167531e-11,
          1.3159203149371024e-07,
          5.549907200474991e-10,
          1.059410000000014,
          2250.29,
          6.820930000000004,
          1.153729999999996,
          1.3718700000000013,
          4.580469976644963e-07,
          0.014307999999999765,
          2.7076800000000105,
          0.863851000000011,
          0.00016860299999166273,
          0.0003912070000069434,
          0.47334699999998975,
          3.423329999999993,
          1.4387069313670509e-10,
          106.989,
          0.004485019999975748,
          7.924829986905024e-06,
          632.719,
          1.5117400000000032,
          1.8020500000000084,
          0.000355534999982865,
          98.8853,
          1.0323999999999955,
          0.0833507000000111,
          0.01178680000001009,
          189.971,
          9.311240000897669e-05,
          0.023736299999995936,
          2.768270000000001,
          1.3654357644554693e-09,
          0.43344999999999345,
          13.1233,
          0.9775989999999979,
          0.05244170000000281,
          512.029,
          0.007233420000005708,
          0.17568299999999226,
          3.2119100126237754e-06,
          0.011320899999986977,
          0.15783400000000825,
          6.133209999999991,
          0.11593400000000997,
          1.3216094885137863e-11,
          0.0045893299999875126,
          2.239099984535642e-06,
          0.7558250000000157,
          1.1328300000000127,
          1.4020800000000122,
          0.00013032300000759278,
          0.8804930000000013,
          5.846179988111544e-06,
          0.358776000000006,
          3076.55,
          433.399,
          0.35762099999999464,
          2.710219999999964,
          964.613,
          0.05371710000000007,
          0.001108369999997194,
          0.0009870739999939815,
          3.850490000000036,
          3.000450000000029,
          3.084569999999985,
          0.3080750000000023,
          195.919,
          0.46336500000001024,
          0.0005309469999872363,
          0.02681229999998891,
          2.262368070660159e-11,
          0.008096419999986892,
          9.341040083654661e-07,
          1.6999299999999948,
          0.008889890000034484,
          1.884539999999987,
          6.601709999999997,
          1.3067999987015355e-05,
          46.1302,
          1.3076000000000363,
          5.84778,
          0.0026388500000109616,
          0.00015590800001064054,
          7.975415883265669e-09,
          397.352,
          4.437000000000012,
          786.9159999999999,
          5.144849999999991,
          1.0808800000000076,
          1.6842399986671808e-05,
          1.0203799999999603,
          4.800900000000013,
          5.9972899999999925,
          2.7233799999999917,
          5.003880000000009,
          7.6912900226489e-07,
          2.0633100064060272e-06,
          0.5594550000000424,
          1.5136799999999937,
          5.6422000000000025,
          32.08359999999999,
          0.10037900000000377,
          4.2606899999999825,
          2.1857899999999972,
          0.238773000000009,
          2.581690000000009,
          0.020433800000034807,
          0.6325929999999573,
          4.61672999999999,
          2.4414248400717042e-11,
          0.0005882620000079442,
          5.962099999999992,
          3.2241699999999867,
          2.444029973958095e-07,
          0.002481039999992163,
          2.823450000732919e-05,
          4.9450000005890615e-06,
          0.0005789429999936146,
          47.707899999999995,
          0.3288119999999992,
          0.9843630000000019,
          0.007710470000006353,
          3.68913788406644e-11,
          7.700510000000008,
          3.8404700000000105,
          2.1174173525650986e-11,
          0.020790099999999256,
          4490.79,
          3620.2,
          2.304360000000031,
          13.119400000000013,
          0.5637199999999609,
          0.16254599999999186,
          1.1460201676527504e-08,
          3.1047399886574567e-06,
          0.034211300000009714,
          0.3008350000000064,
          3.454829999999987,
          0.8194520000000125,
          0.41575599999995916,
          4.050239999742189e-05,
          1.2898340173705947e-09,
          7.587850063828228e-07,
          0.04551609999998618,
          1.9922500000000127,
          0.11607699999999,
          3.0631300000000294,
          40.0967,
          0.12284600000000978,
          1.3501599999999883,
          8.109610000000004,
          1.5647400000000005,
          1.592410000000001,
          2.6363200000000404,
          0.28087899999999877,
          2.8038016353093553e-10,
          0.30267200000000116,
          2.5158101379929576e-08,
          10.601499999999987,
          5.3887561080046e-11,
          2.003860000000003,
          9.044699993410177e-07,
          5.328180000000003,
          0.15563499999998953,
          1.294729999999987,
          1.8394530343357474e-10,
          9.646559999999994,
          0.736818999999997,
          2.1761000000000195,
          2.3951900000000137,
          5.578570000000013,
          2.956860000000006,
          8.84805,
          5.5699900002537106e-05,
          0.10922700000000418,
          1.3722001312999055e-09,
          0.15014700000000403,
          2.669059995241696e-07,
          4.039619909690373e-07,
          0.16854799999998704,
          2.417110000000008,
          3.8831900000000132,
          0.514316000000008,
          0.15014500000000908,
          0.0015643499999953292,
          0.5013509999999997,
          2.2353300000000047,
          5.909441824769601e-10,
          0.31227000000001226,
          3.178689999999989,
          9.349009999937152e-05,
          0.12429599999998686,
          0.006282559999959858,
          1.617669994402604e-06,
          6.99436,
          0,
          0.43436700000000883,
          1298.9900000000002,
          5.192950001742247e-05,
          0.0006452679999711108,
          2.019829992150335e-07,
          0.07916729999999461,
          2.41028,
          2.0640129605453694e-09,
          0.0016503599999850849,
          0.0002854889999923671,
          0.0002902290000008634,
          3.75734998669941e-11,
          0.3507020000000125,
          8.45338000000001,
          9.089609989132441e-06,
          0.258624999999995,
          2.4190000000000396,
          0.3899199999999894,
          0.8619999999999948,
          1.013802375382511e-10,
          1.400839999999988,
          6.0697999999999865,
          0.7438779999999952,
          0.7155860000000018,
          0.13081399999998666,
          1.620749998210158e-06,
          0.9774199999999951,
          5.009590000000003,
          5.3664299997535636e-05,
          1.5293499999999938,
          0.17802399999999352,
          2.308529999999962,
          4.407160000000005,
          0.04569580000000428,
          7.808099999999996,
          0.1661139999999932,
          1.285670009565365e-06,
          0.0013314999999920474,
          7.835010001144838e-05,
          4.5560000216937624e-11,
          624.636,
          2.8020299993158915e-05,
          0.000460306000007904,
          6.033060000000006,
          0.11339699999999198,
          5.035259999999994,
          1.1624479157035239e-11,
          1.1165500382048776e-06,
          0.808480000000003,
          3.141919999999999,
          1.868930000000006,
          4.372140000000002,
          1.1297199999999918,
          0.12568999999999164,
          63.45970000000001,
          1.8600199999999916,
          197.953,
          6.108393790782429e-10,
          0.00019459099999608043,
          4.5322599362407345e-07,
          2.1738499999999874,
          2.4559199118812103e-10,
          594.778,
          0.039455900000035626,
          218.33,
          5.506079999999997,
          1.3656100000000038,
          864.97,
          0.00010716299999558032,
          3.805080000000004,
          3455.2699999999995,
          4.367020000017874e-05,
          0.9446389999999951,
          1.052899999999994,
          2.8814900000000137,
          7.245280000000008,
          0.00024995300000796306,
          0.0011304999999879328,
          3.524291969370097e-12,
          0.7395080000000007,
          45.464,
          9.193269988827524e-06,
          7.753489999999999,
          4213.45,
          3.3138800000000117,
          0.010038900000012063,
          1.498569872637745e-07,
          0.0002458479999916108,
          1.3358203432289883e-12,
          12.885400000000004,
          5.515749990081531e-08,
          0.026582399999995232,
          0.023681100000004562,
          0.5406910000000096,
          24.453599999999994,
          1.2423129192029592e-10,
          1.3881900000000087,
          8.782729963741076e-06,
          0.0010975200000018503,
          8.090259996151872e-06,
          5.949330000000003,
          6.489039999999989,
          4.141043064009864e-11,
          2.913793650805019e-10,
          7.174949996624491e-05,
          3.945760000000007,
          73.0806,
          1.9842700000000093,
          0.1605289999999968,
          28.770100000000014,
          1.5147499999999923,
          1.6873300978659245e-07,
          0,
          1620.0900000000001,
          1.5014399991741811e-05,
          0.3502890000000036,
          4.568160000000006,
          241.228,
          5.979569999999995,
          4.476419235288631e-11,
          1.4198000000000093,
          14.427400000000006,
          1.5426000000000215,
          0.4668230000000051,
          0.0018389300000194453,
          7.090361009431945e-08,
          0.3864870000000167,
          5.053570000000008,
          424.399,
          0.8233649999999955,
          1.4336603726405883e-07,
          9.798900009627687e-06,
          1.5992400000000089,
          4951.93,
          0.000346465999996326,
          0.0027059300000189523,
          1.6354899997850225e-05,
          5.7269744502264075e-11,
          2.595470505184494e-10,
          2.375840000000011,
          0.5813510000000122,
          0.0003925350000031358,
          2.9844699999999875,
          0.2514600000000087,
          0.00665835000000925,
          4.320789999999988,
          1.6289899999999875,
          3.4456399999999974,
          8.720400000000012,
          24.584299999999985,
          2.8799899999999923,
          6.988983614064637e-09,
          85.3156,
          894.155,
          3.760489960313862e-06,
          0.03175590000000739,
          1.9885800000000131,
          4.834190000000007,
          1.1254996934439987e-11,
          1.5615200000000016,
          9.372299999999996,
          0.04971249999999827,
          0.1877749999999878,
          4.78146000000001,
          0.020397300000013274,
          1.6255199999999945,
          0.1988890000000083,
          5593.41,
          6.676469865851686e-07,
          5.9998399990490725e-05,
          0.43419900000000666,
          0.0014254099999959635,
          0.0015190999999958876,
          1.2657600000000002,
          7.816579999999988,
          5613.79,
          707.902,
          1.0600000000000023,
          4.372080000000011,
          0.29532199999999875,
          3.632710000000003,
          161.672,
          5.441052053356543e-10,
          454.789,
          18.02090000000001,
          1.020309999999995,
          97.7445,
          1.1905499999999734,
          113.886,
          5.441370000000006,
          2.1364598978834692e-10
         ]
        },
        {
         "marker": {
          "size": 1
         },
         "mode": "markers",
         "name": "prediction from neural networks",
         "type": "scatter3d",
         "uid": "1fc1ae8e-1a04-47ff-bc78-07fb5b074ea9",
         "visible": true,
         "x": [
          0.564,
          0.088,
          0.012,
          0.252,
          0.9,
          0.432,
          0.166,
          0.41,
          0.544,
          0.112,
          0.498,
          0.534,
          0.37,
          0.112,
          0.048,
          0.396,
          0.622,
          0.676,
          0.72,
          0.414,
          0.722,
          0.556,
          0.238,
          0.602,
          0.664,
          0.822,
          0.134,
          0.39,
          0.25,
          0.742,
          0.54,
          0.496,
          0.722,
          0.156,
          0.388,
          0.394,
          0.658,
          0.912,
          0.738,
          0.696,
          0.528,
          0.666,
          0.716,
          0.834,
          0.11,
          0.798,
          0.564,
          0.766,
          0.676,
          0.006,
          0.224,
          0.516,
          0.276,
          0.13,
          0.526,
          0.03,
          0.416,
          0.128,
          0.008,
          0.078,
          0.636,
          0.624,
          0.6,
          0.67,
          0.696,
          0.764,
          0.12,
          0.858,
          0.996,
          0.492,
          0.434,
          0.19,
          0.566,
          0.1,
          0.336,
          0.694,
          0.7,
          0.174,
          0.104,
          0.358,
          0.872,
          0.9,
          0.002,
          0.55,
          0.118,
          0.092,
          0.208,
          0.302,
          0.974,
          0.344,
          0.018,
          0.68,
          0.662,
          0.532,
          0.608,
          0.752,
          0.966,
          0.554,
          0.608,
          0.28,
          0.564,
          0.136,
          0.754,
          0.282,
          0.18,
          0.816,
          0.18,
          0.02,
          0.794,
          0.172,
          0.46,
          0.178,
          0.7,
          0.95,
          0.128,
          0.568,
          0.838,
          0.57,
          0.382,
          0.388,
          0.96,
          0.324,
          0.908,
          0.924,
          0.248,
          0.684,
          0.39,
          0.868,
          0.98,
          1,
          0.422,
          0.03,
          0.432,
          0.806,
          0.47,
          0.374,
          0.362,
          0.338,
          0.096,
          0.336,
          0.7,
          0.48,
          0.11,
          0.154,
          0.48,
          0.932,
          0.184,
          0.426,
          0.64,
          0.366,
          0.892,
          0.862,
          0.712,
          0.224,
          0.976,
          0.428,
          0.34,
          0.036,
          0.256,
          0.704,
          0.196,
          0.802,
          0.314,
          0.044,
          0.324,
          0.412,
          0.13,
          0.594,
          0.064,
          0.832,
          0.682,
          0.584,
          0.972,
          0.984,
          0.678,
          0.39,
          0.21,
          0.552,
          0.368,
          0.866,
          0.308,
          0.232,
          0.846,
          0.796,
          0.056,
          0.018,
          0.62,
          0.43,
          0.894,
          0.718,
          0.492,
          0.292,
          0.854,
          0.78,
          0.204,
          0.862,
          0.138,
          0.268,
          0.768,
          0.232,
          0.752,
          0.87,
          0.208,
          0.25,
          0.076,
          0.594,
          0.964,
          0.45,
          0.366,
          0.07,
          0.892,
          0.7,
          0.138,
          0.706,
          0.362,
          0.28,
          0.486,
          0.892,
          0.85,
          0.036,
          0.736,
          0.356,
          0.916,
          0.346,
          0.088,
          0.47,
          0.668,
          0.01,
          0.81,
          0.462,
          0.81,
          0.822,
          0.548,
          0.124,
          0.44,
          0.82,
          0.922,
          0.454,
          0.88,
          0.738,
          0.284,
          0.924,
          0.118,
          0.52,
          0.838,
          0.72,
          0.206,
          0.974,
          0.592,
          0.598,
          0.444,
          0.538,
          0.038,
          0.192,
          0.166,
          0.722,
          0.63,
          0.032,
          0.078,
          0.51,
          0.166,
          0.664,
          0.73,
          0.404,
          0.29,
          0.702,
          0.948,
          0.256,
          0.584,
          0.358,
          0.762,
          0.496,
          0.97,
          0.812,
          0.724,
          0.92,
          0.576,
          0.02,
          0.358,
          0.332,
          0.2,
          0.154,
          0.01,
          0.346,
          0.956,
          0.872,
          0.618,
          0.038,
          0.804,
          0.718,
          0.01,
          0.078,
          0.634,
          0.82,
          0.146,
          0.292,
          0.69,
          0.804,
          0.438,
          0.93,
          0.35,
          0.116,
          0.114,
          0.764,
          0.594,
          0.64,
          0.284,
          0.142,
          0.698,
          0.63,
          0.31,
          0.77,
          0.75,
          0.794,
          0.078,
          0.734,
          0.276,
          0.908,
          0.072,
          0.098,
          0.824,
          0.528,
          0.9,
          0.452,
          0.502,
          0.878,
          0.758,
          0.256,
          0.514,
          0.916,
          0.712,
          0.392,
          0.49,
          0.494,
          0.122,
          0.824,
          0.784,
          0.64,
          0.69,
          0.356,
          0.182,
          0.916,
          0.634,
          0.422,
          0.496,
          0.514,
          0.824,
          0.394,
          0.382,
          0.41,
          0.662,
          0.646,
          0.082,
          0.476,
          0.926,
          0.454,
          0.81,
          0.826,
          0.954,
          0.12,
          0.32,
          0.484,
          0.93,
          0.496,
          0.356,
          0.038,
          0.718,
          0.4,
          0.572,
          0.11,
          0.734,
          0.372,
          0.488,
          0.424,
          0.872,
          0.222,
          0.378,
          0.98,
          0.726,
          0.564,
          0.378,
          0.302,
          0.868,
          0.322,
          0.696,
          0.372,
          0.398,
          0.918,
          0.846,
          0.532,
          0.318,
          0.974,
          0.258,
          0.862,
          0.534,
          0.83,
          0.79,
          0.838,
          0.946,
          0.146,
          0.45,
          0.35,
          0.63,
          0.958,
          0.2,
          0.47,
          0.434,
          0.296,
          0.506,
          0.06,
          0.758,
          0.054,
          0.774,
          0.072,
          0.964,
          0.06,
          0.824,
          0.082,
          0.196,
          0.294,
          0.45,
          0.204,
          0.804,
          0.918,
          0.036,
          0.122,
          0.254,
          0.498,
          0.24,
          0.27,
          0.942,
          0.208,
          0.064,
          0.572,
          0.644,
          0.856,
          0.9,
          0.536,
          0.912,
          0.35,
          0.87,
          0.33,
          0.29,
          0.748,
          0.004,
          0.832,
          0.48,
          0.25,
          0.99,
          0.306,
          0.456,
          0.56,
          0.664,
          0.788,
          0.368,
          0.506,
          0.366,
          0.59,
          0.58,
          0.516,
          0.782,
          0.178,
          0.61,
          0.636,
          0.538,
          0.124,
          0.13,
          0.956,
          0.74,
          0.986,
          0.586,
          0.312,
          0.68,
          0.502,
          0.808,
          0.354,
          0.952,
          0.416,
          0.36,
          0.938,
          0.896,
          0.108,
          0.44,
          0.244,
          0.092,
          0.688,
          0.01,
          0.196,
          0.92,
          0.296,
          0.234,
          0.08,
          0.598,
          0.258,
          0.404,
          0.112,
          0.104,
          0.06,
          0.456,
          0.8,
          0.042,
          0.686,
          0.504,
          0.284,
          0.136,
          0.14,
          0.87,
          0.014,
          0.552,
          0.056,
          0.632,
          0.91,
          0.962,
          0.688,
          0.816,
          0.81,
          0.994,
          0.65,
          0.88,
          0.852,
          0.452,
          0.382,
          0.824,
          0.27,
          0.022,
          0.684,
          0.008,
          0.006,
          0.124,
          0.212,
          0.936,
          0.556,
          0.076,
          0.166,
          0.034,
          0.15,
          0.716,
          0.222,
          0.88,
          0.03,
          0.438,
          0.726,
          0.438,
          0.776,
          0.646,
          0.36,
          0.958,
          0.024,
          1,
          0.11,
          0.898,
          0.16,
          0.436,
          0.012,
          0.366,
          0.204,
          0.57,
          0.974,
          0.272,
          0.67,
          0.246,
          0.444,
          0.794,
          0.002,
          0.52,
          0.05,
          0.506,
          0.038,
          0.328,
          0.104,
          0.55,
          0.334,
          0.226,
          0.858,
          0.816,
          0.884,
          0.112,
          0.288,
          0.876,
          0.734,
          0.028,
          0.022,
          0.066,
          0.782,
          0.332,
          0.92,
          0.594,
          0.344,
          0.698,
          0.846,
          0.782,
          0.784,
          0.454,
          0.682,
          0.824,
          0.938,
          0.586,
          0.8,
          0.178,
          0.11,
          0.402,
          0.618,
          0.722,
          0.35,
          0.992,
          0.416,
          0.052,
          0.342,
          0.254,
          0.982,
          0.366,
          0.316,
          0.602,
          0.818,
          0.378,
          0.712,
          0.42,
          0.67,
          0.886,
          0.654,
          0.532,
          0.216,
          0.234,
          0.762,
          0.808,
          0.598,
          0.666,
          0.074,
          0.018,
          0.466,
          0.346,
          0.754,
          0.708,
          0.53,
          0.578,
          0.514,
          0.548,
          0.13,
          0.2,
          0.544,
          0.698,
          0.848,
          0.294,
          0.078,
          0.064,
          0.044,
          0.048,
          0.312,
          0.358,
          0.338,
          0.36,
          0.154,
          0.186,
          0.018,
          0.9,
          0.926,
          0.35,
          0.628,
          0.178,
          0.036,
          0.59,
          0.928,
          0.366,
          0.172,
          0.78,
          0.558,
          0.834,
          0.216,
          0.668,
          0.616,
          0.332,
          0.578,
          0.838,
          0.472,
          0.644,
          0.46,
          0.732,
          0.602,
          0.6,
          0.732,
          0.318,
          0.938,
          0.142,
          0.104,
          0.5,
          0.452,
          0.968,
          0.776,
          0.334,
          0.604,
          0.326,
          0.762,
          0.51,
          0.228,
          0.848,
          0.168,
          0.204,
          0.386,
          0.72,
          0.056,
          0.442,
          0.78,
          0.322,
          0.27,
          0.946,
          0.498,
          0.398,
          0.698,
          0.892,
          0.086,
          0.528,
          0.898,
          0.602,
          0.826,
          0.344,
          0.556,
          0.53,
          0.232,
          0.12,
          0.176,
          0.066,
          0.082,
          0.98,
          0.562,
          0.818,
          0.886,
          0.868,
          0.498,
          0.7,
          0.42,
          0.804,
          0.648,
          0.306,
          0.1,
          0.986,
          0.8,
          0.678,
          0.416,
          0.192,
          0.526,
          0.714,
          0.966,
          0.468,
          0.09,
          0.712,
          0.2,
          0.406,
          0.304,
          0.166,
          0.942,
          0.482,
          0.908,
          0.926,
          0.732,
          0.082,
          0.698,
          0.598,
          0.034,
          0.128,
          0.83,
          0.258,
          0.97,
          0.916,
          0.022,
          0.23,
          0.292,
          0.53,
          0.582,
          0.09,
          0.656,
          0.212,
          0.752,
          0.802,
          0.368,
          0.776,
          0.85,
          0.784,
          0.71,
          0.566,
          0.326,
          0.494,
          0.742,
          0.138,
          0.392,
          0.648,
          0.982,
          0.42,
          0.842,
          0.524,
          0.154,
          0.114,
          0.478,
          0.496,
          0.224,
          0.462,
          0.918,
          0.186,
          0.882,
          0.102,
          0.7,
          0.508,
          0.476,
          0.204,
          0.314,
          0.06,
          0.056,
          0.552,
          0.522,
          0.474,
          0.416,
          0.708,
          0.724,
          0.886,
          0.092,
          0.984,
          0.716,
          0.54,
          0.646,
          0.388,
          0.878,
          0.644,
          0.322,
          0.696,
          0.28,
          0.886,
          0.608,
          0.77,
          0.004,
          0.874,
          0.15,
          0.004,
          0.342,
          0.68,
          0.314,
          0.474,
          0.72,
          0.616,
          0.722,
          0.564,
          0.086,
          0.408,
          0.244,
          0.62,
          0.428,
          0.528,
          0.952,
          0.532,
          0.828,
          0.028,
          0.314,
          0.646,
          0.328,
          0.618,
          0.662,
          0.59,
          0.634,
          0.874,
          0.244,
          0.65,
          0.374,
          0.302,
          0.132,
          0.566,
          0.88,
          0.136,
          0.608,
          0.716,
          0.792,
          0.026,
          0.334,
          0.94,
          0.796,
          0.15,
          0.476,
          0.484,
          0.606,
          0.776,
          0.632,
          0.218,
          0.866,
          0.146,
          0.134,
          0.574,
          0.222,
          0.412,
          0.334,
          0.866,
          0.25,
          0.592,
          0.974,
          0.86,
          0.334,
          0.53,
          0.894,
          0.498,
          0.47,
          0.916,
          0.494,
          0.166,
          0.098,
          0.142,
          0.912,
          0.672,
          0.116,
          0.962,
          0.864,
          0.376,
          0.324,
          0.384,
          0.594,
          0.682,
          0.048,
          0.842,
          0.25,
          0.162,
          0.858,
          0.224,
          0.488,
          0.846,
          0.706,
          0.764,
          0.404,
          0.342,
          0.184,
          0.74,
          0.404,
          0.372,
          0.366,
          0.934,
          0.01,
          0.324,
          0.118,
          0.454,
          0.81,
          0.262,
          0.81,
          0.192,
          0.286,
          0.598,
          0.232,
          0.424,
          0.584,
          0.704,
          0.54,
          0.488,
          0.148,
          0.12,
          0.424,
          0.728,
          0.976,
          0.714,
          0.084,
          0.69,
          0.568,
          0.642,
          0.86,
          0.356,
          0.614,
          0.984,
          0.194,
          0.402,
          0.572,
          0.634,
          0.14,
          0.91,
          0.844,
          0.036,
          0.916,
          0.256,
          0.65,
          0.724,
          0.86,
          0.082,
          0.098,
          0.122,
          0.146,
          0.218,
          0.862,
          0.564,
          0,
          0.538,
          0.936,
          0.68,
          0.248,
          0.41,
          0.822,
          0.292,
          0.75,
          0.882,
          0.818,
          0.766,
          0.672,
          0.1,
          0.42,
          0.56,
          0.278,
          0.776,
          0.382,
          0.256,
          0.576,
          0.844,
          0.49,
          0.432,
          0.182,
          0.322,
          0.774,
          0.702,
          0.04,
          0.722,
          0.766,
          0.728,
          0.228,
          0.198,
          0.796,
          0.748,
          0.128,
          0.634,
          0.244,
          0.444,
          0.698,
          0.614,
          0.43,
          0.266,
          0.82,
          0.732,
          0.558,
          0.204,
          0.936,
          0.012,
          0.752,
          0.464,
          0.596,
          0.75,
          0.722,
          0.538,
          0.218,
          0.698,
          0.63,
          0,
          0.364,
          0.494,
          0.868,
          0.092,
          0.898,
          0.962,
          0.91,
          0.168,
          0.322,
          0.972,
          0.23,
          0.236,
          0.988,
          0.926,
          0.638,
          0.018,
          0.542,
          0.874,
          0.722,
          0,
          0.888,
          0.87,
          0.85,
          0.448,
          0.75,
          0.93,
          0.792,
          0.466,
          0.818,
          0.512,
          0.698,
          0.618,
          0.594,
          0.16,
          0.554,
          0.668,
          0.028,
          0.172,
          0.212,
          0.298,
          0.25,
          0.714,
          0.094,
          0.61,
          0.656,
          0.236,
          0.102,
          0.524,
          0.866,
          0.388,
          0.828,
          0.7,
          0.474,
          0.54,
          0.3,
          0.268,
          0.12,
          0.712,
          0.116,
          0.988,
          0.842,
          0.532,
          0.674,
          0.322,
          0.076,
          0.272,
          0.13,
          0.166,
          0.182,
          0.056,
          0.71,
          0.654,
          0.04,
          0.98,
          0.808,
          0.776,
          0.122,
          0.006,
          0.24,
          0.388,
          0.952,
          0.428,
          0.18,
          0.726,
          0.288,
          0.094,
          0.552,
          0.668,
          0.274,
          0.384,
          0.992,
          0.012,
          0.268,
          0.694,
          0.218,
          0.8,
          0.162,
          0.494,
          0.244,
          0.516,
          0.358,
          0.992,
          0.032,
          0.23,
          0.438,
          0.718,
          0.834,
          0.486,
          0.078,
          0.822,
          0.956,
          0.148,
          0.858,
          0.576,
          0.61,
          0.09,
          0.682,
          0.178,
          0.57,
          0.016,
          0.32,
          0.394,
          0.872,
          0.18,
          0.6,
          0.958,
          0.172,
          0.274,
          0.96,
          0.478,
          0.076,
          0.488,
          0.596,
          0.46,
          0.514,
          0.086,
          0.93,
          0.224,
          0.682,
          0.958,
          0.834,
          0.776,
          0.302,
          0.278,
          0.704,
          0.224,
          0.212,
          0.598,
          0.696,
          0.514,
          0.096,
          0.134,
          0.53,
          0.82,
          0.162,
          0.132,
          0.482,
          0.042,
          0.546,
          0.556,
          0.834,
          0.652,
          0.158,
          0.198,
          0.452,
          0.216,
          0.826,
          0.418,
          0.298,
          0.082,
          0.5,
          0.756,
          0.73,
          0.398,
          0.668,
          0.424,
          0.196,
          0.088,
          0.134,
          0.864,
          0.57,
          0.44,
          0.594,
          0.012,
          0.652,
          0.138,
          0.206,
          0.5,
          0.128,
          0.438,
          0.024,
          0.508,
          0.438
         ],
         "y": [
          0.896,
          0.686,
          0.71,
          0.372,
          0.698,
          0.168,
          0.392,
          0.572,
          0.698,
          0.054,
          0.706,
          0.178,
          0.606,
          0.648,
          0.918,
          0.772,
          0.294,
          0.544,
          0.146,
          0.124,
          0.692,
          0.56,
          0.576,
          0.954,
          0.3,
          0.298,
          0.192,
          0.962,
          0.726,
          0.904,
          0.284,
          0.614,
          0.156,
          0.322,
          0.542,
          0.146,
          0.824,
          0.608,
          0.43,
          0.204,
          0.994,
          0.126,
          0.424,
          0.23,
          0.322,
          0.68,
          0.316,
          0.444,
          0.714,
          0.758,
          0.506,
          0.592,
          0.808,
          0.772,
          0.86,
          0.148,
          0.08,
          0.638,
          0.614,
          0.712,
          0.486,
          0.46,
          0.862,
          0.196,
          0.822,
          0.152,
          0.002,
          0.818,
          0.506,
          0.13,
          0.432,
          0.484,
          0.662,
          0.802,
          0.122,
          0.602,
          0.488,
          0.55,
          0.656,
          0.222,
          0.76,
          0.122,
          0.19,
          0.114,
          0.024,
          0.58,
          0.638,
          0.292,
          0.726,
          0.76,
          0.988,
          0.01,
          0.33,
          0.76,
          0.002,
          0.148,
          0.122,
          0.008,
          0.61,
          0.092,
          0.074,
          0.74,
          0.38,
          0.784,
          0.216,
          0.138,
          0.186,
          0.502,
          0.526,
          0.43,
          0.012,
          0.462,
          0.428,
          0.614,
          0.712,
          0.67,
          0.904,
          0.974,
          0.338,
          0.61,
          0.654,
          0.586,
          0.294,
          0.75,
          0.254,
          0.074,
          0.148,
          0.918,
          0.436,
          0.074,
          0.36,
          0.718,
          0.482,
          0.864,
          0.936,
          0.95,
          0.768,
          0.956,
          0.488,
          0.674,
          0.96,
          0.782,
          0.272,
          0.248,
          0.552,
          0.316,
          0.58,
          0.73,
          0.864,
          0.236,
          0.156,
          0.11,
          0.85,
          0.654,
          0.726,
          0.05,
          0.054,
          0.502,
          0.366,
          0.608,
          0.81,
          0.934,
          0.464,
          0.442,
          0.502,
          0.058,
          0.34,
          0.004,
          0.916,
          0.704,
          0.452,
          0.428,
          0.036,
          0.054,
          0.42,
          0.238,
          0.762,
          0.044,
          0.208,
          0.356,
          0.164,
          0.198,
          0.314,
          0.95,
          0.552,
          0.82,
          0.564,
          0.714,
          0.382,
          0.266,
          0.682,
          0.938,
          0.346,
          0.812,
          0.404,
          0.736,
          0.236,
          0.93,
          0.574,
          0.99,
          0.626,
          0.66,
          0.718,
          0.786,
          0.89,
          0.45,
          0.954,
          0.454,
          0.15,
          0.774,
          0.846,
          0.126,
          0.38,
          0.862,
          0.742,
          0.042,
          0.42,
          0.578,
          0.05,
          0.39,
          0.91,
          0.586,
          0.64,
          0.074,
          0.72,
          0.892,
          0.056,
          0.148,
          0.484,
          0.23,
          0.526,
          0.594,
          0.016,
          0.734,
          0.348,
          0.53,
          0.926,
          0.564,
          0.824,
          0.094,
          0.454,
          0.018,
          0.022,
          0.604,
          0.57,
          0.158,
          0.35,
          0.54,
          0.96,
          0.76,
          0.184,
          0.768,
          0.532,
          0.378,
          0.41,
          0.884,
          0.954,
          0.27,
          0.294,
          0.19,
          0.724,
          0.334,
          0.498,
          0.128,
          0.47,
          0.98,
          0.562,
          0.854,
          0.544,
          0.886,
          0.15,
          0.65,
          0.174,
          0.244,
          0.354,
          0.856,
          0.184,
          0.434,
          0.536,
          0.734,
          0.08,
          0.03,
          0.236,
          0.242,
          0.824,
          0.434,
          0.69,
          0.65,
          0.006,
          0.674,
          0.38,
          0.728,
          0.538,
          0.134,
          0.704,
          0.286,
          0.34,
          0.14,
          0.098,
          0.454,
          0.586,
          0.814,
          0.608,
          0.462,
          0.288,
          0.192,
          0.266,
          0.946,
          0.24,
          0.16,
          0.228,
          0.064,
          0.022,
          0.546,
          0.004,
          0.524,
          0.774,
          0.832,
          0.942,
          0.378,
          0.284,
          0.09,
          0.794,
          0.724,
          0.588,
          0.024,
          0.912,
          0.18,
          0.86,
          0.848,
          0.558,
          0.298,
          0.328,
          0.968,
          0.29,
          0.064,
          0.458,
          0.748,
          0.646,
          0.08,
          0.256,
          0.028,
          0.842,
          0.978,
          0.044,
          0.81,
          0.94,
          0.392,
          0.444,
          0.108,
          0.372,
          0.884,
          0.072,
          0.184,
          0.608,
          0.392,
          0.854,
          0.02,
          0.904,
          0.988,
          0,
          0.928,
          0.002,
          0.532,
          0.014,
          0.652,
          0.686,
          0.326,
          0.148,
          0.764,
          0.15,
          0.062,
          0.642,
          0.734,
          0.426,
          0.132,
          0.502,
          0.482,
          0.756,
          0.236,
          0.108,
          0.464,
          0.454,
          0.396,
          0.782,
          0.982,
          0.332,
          0.894,
          0.71,
          0.594,
          0.996,
          0.028,
          0.8,
          0.342,
          0.478,
          0.836,
          0.892,
          0.238,
          0.704,
          0.694,
          0.914,
          0.91,
          0.282,
          0.42,
          0.206,
          0.93,
          0.052,
          0.45,
          0.974,
          0.836,
          0.194,
          0.6,
          0.688,
          0.994,
          0.908,
          0.524,
          0.112,
          0.058,
          0.092,
          0.112,
          0.08,
          0.12,
          0.568,
          0.854,
          0.024,
          0.106,
          0.024,
          0.902,
          0.964,
          0.112,
          0.656,
          0.984,
          0.182,
          0.79,
          0.086,
          0.972,
          0.164,
          0.538,
          0.332,
          0.448,
          0.714,
          0.29,
          0.826,
          0.252,
          0.512,
          0.38,
          0.698,
          0.544,
          0.006,
          0.464,
          0.652,
          0.402,
          0.396,
          0.176,
          0.342,
          0.358,
          0.902,
          0.502,
          0.26,
          0.922,
          0.296,
          0.868,
          0.788,
          0.814,
          0.518,
          0.92,
          0.242,
          0.374,
          0.338,
          0.232,
          0.354,
          0.274,
          0.734,
          0.686,
          0.29,
          0.374,
          0.456,
          0.838,
          0.478,
          0.218,
          0.012,
          0.982,
          0.514,
          0.758,
          0.68,
          0.92,
          0.74,
          0.788,
          0.692,
          0.066,
          0.934,
          0.51,
          0.812,
          0.436,
          0.072,
          0.022,
          0.586,
          0.664,
          0.45,
          0.656,
          0.032,
          0.046,
          0.562,
          0.978,
          0.23,
          0.292,
          0.598,
          0.95,
          0.788,
          0.77,
          0.72,
          0.092,
          0.51,
          0.75,
          0.884,
          0.128,
          0.15,
          0.454,
          0.136,
          0.662,
          0.232,
          0.776,
          0.584,
          0.17,
          0.74,
          0.976,
          0.96,
          0.712,
          0.368,
          0.068,
          0.478,
          0.712,
          0.334,
          0.316,
          0.992,
          0.776,
          0.45,
          0.506,
          0.092,
          0.362,
          0.708,
          0.86,
          0.952,
          0.836,
          0.468,
          0.222,
          0.434,
          0.128,
          0.668,
          0.604,
          0.032,
          0.454,
          0.956,
          0.452,
          0.776,
          0.65,
          0.102,
          0.604,
          0.656,
          0.448,
          0.91,
          0.05,
          0.928,
          0.536,
          0.452,
          0.096,
          0.786,
          0.462,
          0.3,
          0.132,
          0.888,
          0.926,
          0,
          0.318,
          0.128,
          0.788,
          0.424,
          0.434,
          0.734,
          0.37,
          0.214,
          0.284,
          0.116,
          0.216,
          0.918,
          0.972,
          0.946,
          0.462,
          0.792,
          0.428,
          0.938,
          0.93,
          0.5,
          0.306,
          0.352,
          0.344,
          0.836,
          0.77,
          0.856,
          0.106,
          0.892,
          0.866,
          0.046,
          0.972,
          0.728,
          0.602,
          0.262,
          0.64,
          0.544,
          0.66,
          0.9,
          0.084,
          0.298,
          0.966,
          0.908,
          0.48,
          0.586,
          0.048,
          0.27,
          0.952,
          0.484,
          0.294,
          0.578,
          0.374,
          0.03,
          0.958,
          0.018,
          0.086,
          0.85,
          0.492,
          0.846,
          0.496,
          0.03,
          0.344,
          0.796,
          0.054,
          0.108,
          0.142,
          0.782,
          0.092,
          0.374,
          0.956,
          0.92,
          0.908,
          0.472,
          0.748,
          0.942,
          0.602,
          0.002,
          0.106,
          0.996,
          0.228,
          0.804,
          0.146,
          0.99,
          0.664,
          0.748,
          0.816,
          0.946,
          0.792,
          0.158,
          0.044,
          0.674,
          0.298,
          0.818,
          0.39,
          0.028,
          0.514,
          0.838,
          0.03,
          0.626,
          0.474,
          0.564,
          0.956,
          0.79,
          0.732,
          0.476,
          0.112,
          0.792,
          0.9,
          0.168,
          0.776,
          0.864,
          0.978,
          0.41,
          0.882,
          0.852,
          0.594,
          0.562,
          0.808,
          0.174,
          0.512,
          0.21,
          0.716,
          0.586,
          0.926,
          0.278,
          0.84,
          0.096,
          0.62,
          0.83,
          0.982,
          0.328,
          0.266,
          0.844,
          0.324,
          0.572,
          0.1,
          0.03,
          0.012,
          0.862,
          0.034,
          0.694,
          0.984,
          0.504,
          0.398,
          0.242,
          0.29,
          0.152,
          0.812,
          0.658,
          0.728,
          0.552,
          0.522,
          0.02,
          0.104,
          0.85,
          0.182,
          0.48,
          0.302,
          0.736,
          0.268,
          0.926,
          0.462,
          0.296,
          0.672,
          0.51,
          0.33,
          0.02,
          0.206,
          0.596,
          0.168,
          0.594,
          0.994,
          0.236,
          0.678,
          0.46,
          0.334,
          0.002,
          0.89,
          1,
          0.668,
          0.122,
          0.828,
          0.296,
          0.966,
          0.968,
          0.904,
          0.436,
          0.922,
          0.62,
          0.454,
          0.83,
          0.532,
          0.204,
          0.374,
          0.326,
          0.978,
          0.088,
          0.17,
          0.9,
          0.522,
          0.262,
          0.622,
          0.796,
          0.204,
          0.832,
          0.708,
          0.536,
          0.104,
          0.978,
          0.394,
          0.794,
          0.666,
          0.5,
          0.016,
          0.376,
          0.33,
          0.456,
          0.374,
          0.952,
          0.104,
          0.212,
          0.472,
          0.02,
          0.69,
          0.074,
          0.768,
          0.308,
          0.446,
          0.41,
          0.158,
          0.922,
          0.31,
          0.624,
          0.89,
          0.494,
          0.72,
          0.832,
          0.814,
          0.732,
          0.036,
          0.256,
          0.364,
          0.676,
          0.326,
          0.124,
          0.866,
          0.668,
          0.494,
          0.192,
          0.75,
          0.252,
          0.874,
          0.854,
          0.814,
          0.344,
          0.938,
          0.854,
          0.234,
          0.492,
          0.86,
          0.932,
          0.13,
          0.102,
          0.984,
          0.936,
          0.96,
          0.184,
          0.38,
          0.958,
          0.52,
          0.076,
          0.46,
          0.016,
          0.182,
          0.056,
          0.922,
          0.724,
          0.704,
          0.564,
          0.536,
          0.166,
          0.41,
          0.916,
          0.544,
          0.326,
          0.246,
          0.516,
          0.606,
          0.008,
          0.5,
          0.376,
          0.252,
          0.904,
          0.576,
          0.622,
          0.332,
          0.98,
          0.976,
          0.978,
          0.418,
          0.7,
          0.276,
          0.412,
          0.91,
          0.08,
          0.51,
          0.83,
          0.64,
          0.078,
          0.714,
          0.388,
          0.426,
          0.196,
          0.388,
          0.51,
          0.904,
          0.996,
          0.044,
          0.404,
          0.186,
          0.524,
          0.734,
          0.554,
          0.284,
          0.834,
          0.212,
          0.22,
          0.916,
          0.774,
          0.58,
          0.89,
          0.664,
          0.518,
          0.37,
          0.33,
          0.928,
          0.938,
          0.646,
          0.502,
          0.334,
          0.96,
          0.278,
          0.094,
          0.028,
          0.306,
          0.174,
          0.758,
          0.402,
          0.654,
          0.798,
          0.224,
          0.876,
          0.598,
          0.7,
          0.354,
          0.284,
          0.126,
          0.906,
          0.626,
          0.648,
          0.866,
          0.61,
          0.196,
          0.932,
          0.53,
          0.662,
          0.63,
          0.608,
          0.168,
          0.194,
          0.532,
          0.956,
          0.804,
          0.478,
          0.054,
          0.642,
          0.894,
          0.704,
          0.678,
          0.014,
          0.536,
          0.734,
          0.012,
          0.354,
          0.684,
          0.662,
          0.218,
          0.11,
          0.244,
          0.212,
          0.33,
          0.468,
          0.572,
          0.92,
          0.01,
          0.042,
          0.858,
          0.808,
          0.014,
          0.442,
          0.716,
          0.9,
          0.152,
          0.386,
          0.466,
          0.51,
          0.102,
          0.24,
          0.424,
          0.94,
          0.74,
          0.502,
          0.49,
          0.282,
          0.044,
          0.184,
          0.47,
          0.81,
          0.478,
          0.868,
          0.256,
          0.452,
          0.56,
          0.796,
          0.634,
          0.964,
          0.956,
          0.988,
          0.062,
          0.484,
          0.11,
          0.558,
          0.018,
          0.674,
          0.184,
          0.126,
          0.482,
          0.93,
          0.048,
          0.712,
          0.436,
          0.826,
          0.864,
          0.218,
          0.656,
          0.734,
          0.262,
          0.468,
          0.072,
          0.458,
          0.088,
          0.178,
          0.486,
          0.606,
          0.546,
          0.894,
          0.092,
          0.364,
          0.984,
          0.93,
          0.066,
          0.508,
          0.632,
          0.088,
          0.472,
          0.388,
          0.216,
          0.806,
          0.002,
          0.956,
          0.572,
          0.302,
          0.388,
          0.178,
          0.15,
          0.57,
          0.118,
          0.252,
          0.192,
          0.396,
          0.044,
          0.502,
          0.228,
          0.224,
          0.97,
          0.67,
          0.746,
          0.648,
          0.05,
          0.868,
          0.754,
          0.558,
          0.714,
          0.486,
          0.184,
          0.932,
          0.842,
          0.276,
          0.948,
          0.474,
          0.324,
          0.854,
          0.44,
          0.17,
          0.204,
          0.012,
          0.334,
          0.204,
          0.028,
          0.496,
          0.254,
          0.326,
          0.634,
          0.04,
          0.83,
          0.02,
          0.174,
          0.94,
          0.724,
          0.57,
          0.864,
          0.524,
          0.444,
          0.384,
          0.918,
          0.474,
          0.112,
          0.324,
          0.162,
          0.628,
          0.038,
          0.442,
          0.414,
          0.564,
          0.43,
          0.41,
          0.47,
          0.294,
          0.806,
          0.69,
          0.338,
          0.596,
          0.94,
          0.162,
          0.398,
          0.206,
          0.334,
          0.018,
          0.514,
          0.744,
          0.236,
          0.742,
          0.778,
          0.642,
          0.402,
          0.102,
          0.296,
          0.028,
          0.33,
          0.058,
          0.428,
          0.336,
          0.552,
          0.534,
          0.034,
          0.976,
          0.222,
          0.332,
          0.318,
          0.146,
          0.922,
          0.018,
          0.054,
          0.298,
          0.9,
          0.25,
          0.782,
          0.952,
          0.468,
          0.826,
          0.146,
          0,
          0.592,
          0.244,
          0.29,
          0.828,
          0.57,
          0.88,
          0.016,
          0.796,
          0.578,
          0.576,
          0.768,
          0.05,
          0.084,
          0.86,
          0.696,
          0.408,
          0.524,
          0.144,
          0.222,
          0.956,
          0.758,
          0.358,
          0.25,
          0.246,
          0.058,
          0.06,
          0.73,
          0.496,
          0.3,
          0.848,
          0.998,
          0.242,
          0.822,
          0.604,
          0.636,
          1,
          0.372,
          0.618,
          0.108,
          0.682,
          0.846,
          0.202,
          0.018,
          0.586,
          0.814,
          0.01,
          0.588,
          0.428,
          0.278,
          0.994,
          0.584,
          0.436,
          0.554,
          0.46,
          0.764,
          0.168,
          0.284,
          0.524,
          0.34,
          0.356,
          0.54,
          0.582,
          0.816,
          0.786,
          0.65,
          0.712,
          0.48,
          0.676,
          0.594,
          0.06,
          0.734,
          0.79,
          0.536,
          0.468,
          0.538,
          0.398,
          0.8,
          0.04
         ],
         "z": [
          -2.480553150177002,
          3308.45654296875,
          250.89016723632812,
          -8.782692909240723,
          -6.5947041511535645,
          -3.5767903327941895,
          0.8637766242027283,
          7.0900187492370605,
          7.9286723136901855,
          4.1530070304870605,
          11.958273887634277,
          -2.1825642585754395,
          13.61685848236084,
          1012.861328125,
          5039.23486328125,
          -14.143486976623535,
          3.1514811515808105,
          -9.794014930725098,
          -2.279778003692627,
          -2.4518513679504395,
          -1.2506033182144165,
          -2.979301929473877,
          7.7502055168151855,
          7.5335612297058105,
          3.7879862785339355,
          -3.923485279083252,
          10.55228328704834,
          1.446128249168396,
          20.70470428466797,
          7.0601725578308105,
          1.320548415184021,
          3.158271312713623,
          -2.196953296661377,
          5.2316203117370605,
          7.3718180656433105,
          -2.1478352546691895,
          -7.253685474395752,
          -3.1715474128723145,
          -1.391029953956604,
          -1.240486741065979,
          -6.7279744148254395,
          -2.0306477546691895,
          -1.637703537940979,
          1.1375192403793335,
          65.13308715820312,
          0.5690836310386658,
          4.2601542472839355,
          -0.8917623162269592,
          -2.137108325958252,
          142.60946655273438,
          17.47907257080078,
          2.0423808097839355,
          16.29010772705078,
          832.6754760742188,
          8.747092247009277,
          -3.260948657989502,
          -2.8321919441223145,
          443.0783386230469,
          96.26815795898438,
          4784.97314453125,
          7.035590648651123,
          3.602027416229248,
          -6.646446704864502,
          -0.7123189568519592,
          -1.4564443826675415,
          -1.250465989112854,
          11.926032066345215,
          -0.8983388543128967,
          -12.016640663146973,
          -5.757347583770752,
          -2.097435474395752,
          -1.272072434425354,
          5.9465861320495605,
          3696.685302734375,
          1.041037917137146,
          -1.097176194190979,
          2.243506908416748,
          -2.408134937286377,
          1547.2430419921875,
          -4.715965747833252,
          -3.3454365730285645,
          0.27146095037460327,
          1.992118239402771,
          -3.8429646492004395,
          -4.370201587677002,
          1371.149169921875,
          7.250495433807373,
          3.138190746307373,
          9.933600425720215,
          22.313209533691406,
          28.869361877441406,
          5.4115824699401855,
          3.869513988494873,
          9.137152671813965,
          1.8456186056137085,
          -1.569191575050354,
          -5.1600728034973145,
          -0.21286828815937042,
          -5.9484333992004395,
          1.981986403465271,
          -2.562828540802002,
          511.74188232421875,
          1.735068678855896,
          23.51020050048828,
          -10.232720375061035,
          1.129416823387146,
          -6.1815876960754395,
          194.58755493164062,
          1.943503737449646,
          -12.323067665100098,
          0.19457189738750458,
          -13.19533634185791,
          4.098121166229248,
          -10.43428897857666,
          733.6649780273438,
          7.003364086151123,
          0.6272653937339783,
          0.002250123769044876,
          13.31101131439209,
          13.828330039978027,
          -0.004540037363767624,
          7.7209696769714355,
          4.1763224601745605,
          -0.34978538751602173,
          0.14957372844219208,
          2.2939982414245605,
          -2.049004077911377,
          4.1839823722839355,
          -6.4353413581848145,
          -12.010201454162598,
          11.950568199157715,
          2488.61865234375,
          0.25412696599960327,
          4.636695384979248,
          2.730353832244873,
          5.2997355461120605,
          9.108466148376465,
          -2.824059009552002,
          525.388427734375,
          6.1866068840026855,
          1.617484450340271,
          -23.99903106689453,
          38.45990753173828,
          -9.297066688537598,
          -4.6900105476379395,
          3.355659008026123,
          -19.284461975097656,
          -2.3819661140441895,
          -2.648582935333252,
          -3.481743335723877,
          1.895957350730896,
          -0.7834249138832092,
          -1.466988205909729,
          14.958762168884277,
          9.449225425720215,
          -2.524162769317627,
          -0.43857628107070923,
          701.3951416015625,
          -6.4092183113098145,
          2.447974681854248,
          5.7669901847839355,
          -2.100609302520752,
          0.43636268377304077,
          519.8712158203125,
          7.7160868644714355,
          -2.3256306648254395,
          47.13230895996094,
          2.238135814666748,
          5951.19677734375,
          5.6339335441589355,
          5.460914134979248,
          -2.868736743927002,
          -5.7113728523254395,
          -8.058449745178223,
          1.817893385887146,
          -6.533195972442627,
          20.219459533691406,
          -4.4895710945129395,
          -4.728386402130127,
          -2.899590015411377,
          -3.0653157234191895,
          10.036810874938965,
          -3.756676197052002,
          -3.4821858406066895,
          1855.9100341796875,
          1363.152099609375,
          -5.835838794708252,
          3.2180399894714355,
          -2.6160664558410645,
          2.199347972869873,
          13.201804161071777,
          7.9070658683776855,
          -3.4525532722473145,
          6.885413646697998,
          -14.327141761779785,
          -3.612846851348877,
          5.241736888885498,
          10.157797813415527,
          4.949714183807373,
          -4.1891560554504395,
          -3.676384449005127,
          -1.5662161111831665,
          7.340522289276123,
          5.2047648429870605,
          6936.92626953125,
          -1.4924246072769165,
          -4.8258137702941895,
          -2.7368245124816895,
          -1.295082688331604,
          7108.228515625,
          2.5823283195495605,
          -2.0512166023254395,
          54.914215087890625,
          -5.148155689239502,
          7.653754711151123,
          0.5477365851402283,
          4.198066234588623,
          -2.833458423614502,
          1.8126291036605835,
          263.2430114746094,
          12.35678768157959,
          14.06742000579834,
          -1.4929434061050415,
          -0.7883840203285217,
          3851.714599609375,
          10.082633018493652,
          3.260291576385498,
          3.211860179901123,
          -1.612404465675354,
          -4.540184497833252,
          4.8282999992370605,
          -6.450523853302002,
          -0.9830861687660217,
          958.0809326171875,
          12.11148738861084,
          6.205543041229248,
          -1.2248769998550415,
          -1.5583425760269165,
          0.34416908025741577,
          1.9745858907699585,
          -3.1693196296691895,
          5.908790111541748,
          -4.829033374786377,
          2.977302074432373,
          -3.227715015411377,
          -2.2119832038879395,
          -3.4415669441223145,
          -6.266869068145752,
          2.8439555168151855,
          -0.5949483513832092,
          -4.0935139656066895,
          5.8243632316589355,
          949.8460693359375,
          -19.221397399902344,
          1.8429330587387085,
          0.7872080206871033,
          6.262855052947998,
          39.206199645996094,
          111.4852523803711,
          -1.7455984354019165,
          73.61568450927734,
          3.267188549041748,
          -2.263664722442627,
          -2.188560962677002,
          1.0444711446762085,
          -2.9340596199035645,
          -1.727821946144104,
          -4.671654224395752,
          -5.225273609161377,
          11.12668514251709,
          -1.3045278787612915,
          -3.211876392364502,
          -2.647575855255127,
          -2.0763936042785645,
          2.466834545135498,
          1.9706796407699585,
          -1.941719651222229,
          85.48980712890625,
          9.087653160095215,
          30.649925231933594,
          2.0100321769714355,
          -2.665825366973877,
          -22.914268493652344,
          -0.30123192071914673,
          2.334723949432373,
          1.490714430809021,
          3.6348490715026855,
          2486.057861328125,
          2.616736888885498,
          1.771354079246521,
          52.03877258300781,
          5190.5302734375,
          -1.9641653299331665,
          1.3919137716293335,
          261.6324157714844,
          2.122352123260498,
          2.0239481925964355,
          0.5443033576011658,
          -3.5039753913879395,
          0.06917516887187958,
          14.028861045837402,
          1829.685302734375,
          668.5145874023438,
          0.20020239055156708,
          2.906806468963623,
          -0.13376672565937042,
          1.7247689962387085,
          276.9812927246094,
          1.024772047996521,
          -2.905449390411377,
          1.939963698387146,
          6.1245951652526855,
          4.8687663078308105,
          6.707770824432373,
          13.782660484313965,
          -8.563637733459473,
          16.38709259033203,
          3.4068217277526855,
          2541.965087890625,
          159.1702423095703,
          -3.7055745124816895,
          -4.3325886726379395,
          0.7085031867027283,
          3.782203197479248,
          -0.5105977654457092,
          7.6130595207214355,
          0.5943064093589783,
          4.3694987297058105,
          9.821585655212402,
          2.4492716789245605,
          -5.2194905281066895,
          8.358878135681152,
          7.910468578338623,
          0.25362342596054077,
          40.88801574707031,
          2.594031810760498,
          1.0996469259262085,
          -2.122429370880127,
          5.0964274406433105,
          -0.8858113884925842,
          -13.858880043029785,
          4.5819926261901855,
          -11.25466251373291,
          -10.715859413146973,
          -5.1850056648254395,
          2.415381908416748,
          -2.8765339851379395,
          -3.2036824226379395,
          -2.915703296661377,
          -1.8870474100112915,
          -2.147148609161377,
          -0.7872548699378967,
          -7.3736958503723145,
          -2.5479817390441895,
          -9.518731117248535,
          6.3104472160339355,
          5.0809550285339355,
          1.9130014181137085,
          -4.2662739753723145,
          180.7364044189453,
          -5.2805256843566895,
          1.5279306173324585,
          8.03391170501709,
          -0.9406209588050842,
          0.42295020818710327,
          2517.757568359375,
          0.6338419318199158,
          18.04833221435547,
          -3.525261402130127,
          2122.16357421875,
          -2.2315754890441895,
          -1.3010183572769165,
          0.41811317205429077,
          -5.811760425567627,
          0.8106302618980408,
          5.4695963859558105,
          6.938636302947998,
          -5.564232349395752,
          4.3973307609558105,
          0.5050882697105408,
          -0.8877950310707092,
          0.059958864003419876,
          3.499335765838623,
          -11.430001258850098,
          -1.154121994972229,
          -6.9978413581848145,
          18.047935485839844,
          0.28259986639022827,
          1.862204909324646,
          3.432044506072998,
          -19.51685333251953,
          -5.4404988288879395,
          13.981635093688965,
          -3.124718189239502,
          0.9420847296714783,
          2.4223856925964355,
          2.1400980949401855,
          1.0978463888168335,
          8.244589805603027,
          252.1836395263672,
          10.90604305267334,
          -0.6210408806800842,
          2.8592143058776855,
          -1.950203537940979,
          1.500144362449646,
          5.5595622062683105,
          -2.6934285163879395,
          -3.6729207038879395,
          -0.003960203379392624,
          8640.46875,
          -2.381676197052002,
          2599.672607421875,
          -0.8692250847816467,
          85.78836822509766,
          -5.5704426765441895,
          1431.7188720703125,
          1.3387216329574585,
          -10.861641883850098,
          1.2680734395980835,
          2.4086527824401855,
          -3.596123218536377,
          7.325141429901123,
          1.033011794090271,
          2.189460277557373,
          -3.476219654083252,
          -5.688316822052002,
          -3.7858357429504395,
          6.2001872062683105,
          7.7084574699401855,
          3.1371684074401855,
          1.5119699239730835,
          23.82190704345703,
          20.11896514892578,
          -0.47121483087539673,
          -1.076180100440979,
          -3.797874927520752,
          1.633750319480896,
          -1.2138906717300415,
          1.730735182762146,
          -1.4490286111831665,
          -4.723045825958252,
          4.6452555656433105,
          10.24973201751709,
          0.45229285955429077,
          39.343589782714844,
          -3.5259785652160645,
          11.908392906188965,
          8.889121055603027,
          2.602057933807373,
          0.18538610637187958,
          7.5049357414245605,
          -1.276405930519104,
          0.27233070135116577,
          -0.5871358513832092,
          8.016409873962402,
          2.678962230682373,
          1.575919508934021,
          -1.1514517068862915,
          2.0055155754089355,
          7.381934642791748,
          -0.44634300470352173,
          93.91497802734375,
          -0.5645223259925842,
          -8.418007850646973,
          -3.681663990020752,
          986.9517822265625,
          17.170448303222656,
          -1.385109543800354,
          2.968268871307373,
          -1.4600454568862915,
          0.08797399699687958,
          2.0502848625183105,
          -0.7232289910316467,
          13.255866050720215,
          -3.157829761505127,
          -2.7230916023254395,
          -2.418907642364502,
          -16.97565460205078,
          6.6079630851745605,
          0.8410562872886658,
          8.435233116149902,
          313.6339111328125,
          -2.5544819831848145,
          23.38343048095703,
          2828.560791015625,
          7.315070629119873,
          202.834716796875,
          12.95505428314209,
          -0.9402700066566467,
          0.38895362615585327,
          20.704917907714844,
          1071.0067138671875,
          -4.313835620880127,
          -14.824410438537598,
          -2.430931568145752,
          -4.014397144317627,
          934.6068725585938,
          4203.349609375,
          -0.6523213982582092,
          -8.714760780334473,
          -2.4549641609191895,
          5.3919291496276855,
          -0.9328847527503967,
          -1.290718674659729,
          6.799872875213623,
          14.31247615814209,
          -1.374703049659729,
          252.19895935058594,
          1.4492257833480835,
          7234.14697265625,
          -1.5638357400894165,
          -0.6497274041175842,
          -1.5850149393081665,
          -1.786659836769104,
          2.8097758293151855,
          1.059745192527771,
          -6.8119587898254395,
          5.0863871574401855,
          1.756247878074646,
          -2.594810962677002,
          -4.9535908699035645,
          -4.8593525886535645,
          -5.360496997833252,
          0.012290406972169876,
          1509.501708984375,
          0.32646888494491577,
          97.2983627319336,
          130.79730224609375,
          78.4240493774414,
          1.9755319356918335,
          0.8616556525230408,
          8.774344444274902,
          197.3580780029297,
          -5.1092305183410645,
          149.52593994140625,
          288.6331787109375,
          -2.7063984870910645,
          18.08934783935547,
          -0.09388025104999542,
          135.13035583496094,
          6.396125316619873,
          -1.1148000955581665,
          -1.489754319190979,
          6.246161937713623,
          7.173133373260498,
          -4.9419941902160645,
          -2.385216236114502,
          9.500296592712402,
          2.940162181854248,
          785.7981567382812,
          4.887336254119873,
          18.12255096435547,
          -3.471916675567627,
          44.309913635253906,
          6.284247875213623,
          10.373251914978027,
          -2.459404468536377,
          -7.594383716583252,
          6.773169994354248,
          4.4460368156433105,
          7.2399821281433105,
          -2.874657154083252,
          -1.4739309549331665,
          48.96488952636719,
          1.945029616355896,
          10.92996883392334,
          -9.93380069732666,
          514.5319213867188,
          5.054145336151123,
          -5.9178242683410645,
          -3.3813557624816895,
          -0.48516136407852173,
          -11.308220863342285,
          -3.220116138458252,
          1.332145094871521,
          -1.796120285987854,
          171.92518615722656,
          -8.234551429748535,
          -3.954704761505127,
          4.000403881072998,
          -10.868935585021973,
          40.299278259277344,
          6.908576488494873,
          -1.807320237159729,
          -0.07941491901874542,
          2.0549540519714355,
          7.317176342010498,
          1.427482008934021,
          -1.023445725440979,
          -0.6831899285316467,
          -3.5041584968566895,
          -1.5481497049331665,
          -1.9549795389175415,
          4.169806957244873,
          -3.894798755645752,
          1.836326003074646,
          -3.7320332527160645,
          5.705909252166748,
          87.93343353271484,
          -8.082451820373535,
          2.134955883026123,
          -4.8100666999816895,
          6.718207836151123,
          2.913123607635498,
          5.6219401359558105,
          9.608023643493652,
          103.51310729980469,
          0.41832679510116577,
          9.027091026306152,
          -0.40869957208633423,
          5.1713786125183105,
          0.5483774542808533,
          3.107978343963623,
          -5.160728931427002,
          -5.9888386726379395,
          2.5432353019714355,
          7.005897045135498,
          4.110480785369873,
          2.077003002166748,
          2.6435465812683105,
          0.002387452870607376,
          -3.424004077911377,
          5.4752116203308105,
          2.257392406463623,
          3.946052074432373,
          1.6122812032699585,
          3.0097575187683105,
          7.5256876945495605,
          1461.8544921875,
          0.5158914923667908,
          6.197089672088623,
          -3.559013843536377,
          4.904181957244873,
          0.6662973761558533,
          -1.429115891456604,
          -6.322594165802002,
          -3.6484456062316895,
          13.278830528259277,
          13.33225154876709,
          -3.414543628692627,
          1.5759958028793335,
          -3.829094409942627,
          -0.8265004754066467,
          5687.51025390625,
          890.6498413085938,
          5398.46728515625,
          2247.063720703125,
          4.536170482635498,
          -2.204857349395752,
          0.7363352179527283,
          -24.209983825683594,
          -7.097465991973877,
          19.97791290283203,
          5.790748119354248,
          -3.2516255378723145,
          2.0822062492370605,
          16.666282653808594,
          -8.778145790100098,
          87.79090881347656,
          4770.8173828125,
          -3.023643970489502,
          0.45323890447616577,
          11.79196834564209,
          -12.859490394592285,
          7.086982250213623,
          -1.200234055519104,
          2.5842814445495605,
          17.23120880126953,
          -7.8908467292785645,
          1.9851449728012085,
          1.7938302755355835,
          1.356284499168396,
          -2.6384663581848145,
          -0.48458153009414673,
          -1.489113450050354,
          2.6411662101745605,
          -0.13188989460468292,
          -1.761360764503479,
          -2.0926594734191895,
          9.718817710876465,
          -3.2827534675598145,
          3.6491618156433105,
          472.4629211425781,
          419.04913330078125,
          3.1247477531433105,
          -1.4370657205581665,
          0.5912088751792908,
          -0.08237512409687042,
          11.52701473236084,
          -4.4998555183410645,
          -3.3554158210754395,
          -7.1611714363098145,
          -2.2135396003723145,
          11.144400596618652,
          -3.6549153327941895,
          123.53722381591797,
          -6.6168904304504395,
          -3.973137378692627,
          1.554679274559021,
          3084.65283203125,
          -25.524208068847656,
          -6.719658374786377,
          7.4601664543151855,
          0.43639320135116577,
          1.280112624168396,
          6.200873851776123,
          9.189200401306152,
          -0.33982139825820923,
          5.8304362297058105,
          15.126730918884277,
          7.641028881072998,
          4.383155345916748,
          5.108283519744873,
          -6.871513843536377,
          7.7898783683776855,
          -1.009499192237854,
          -0.29442650079727173,
          -4.400597095489502,
          13.32230281829834,
          67.58470153808594,
          3979.50830078125,
          4758.443359375,
          -7.3897786140441895,
          -3.8712239265441895,
          2.254279613494873,
          0.40943092107772827,
          0.9733194708824158,
          -2.057640552520752,
          3.5196452140808105,
          8.126120567321777,
          4.6132731437683105,
          2.629737377166748,
          -1.9210134744644165,
          299.3902893066406,
          3.4962992668151855,
          -0.7954946160316467,
          -1.228127121925354,
          17.58051300048828,
          8.651389122009277,
          -1.9269033670425415,
          2.968055248260498,
          -2.1866841316223145,
          3.2590250968933105,
          43.26542663574219,
          0.22470800578594208,
          2.8482279777526855,
          -1.0335012674331665,
          7.762916088104248,
          -2.1789937019348145,
          -2.4041523933410645,
          -6.8398518562316895,
          -3.501121997833252,
          -1.921303391456604,
          2.209693431854248,
          99.30109405517578,
          -0.29869896173477173,
          2.980048656463623,
          3943.45068359375,
          107.8307113647461,
          -1.314644455909729,
          1.9271005392074585,
          -3.9599080085754395,
          2.6340861320495605,
          314.7320251464844,
          8.873129844665527,
          -7.334312915802002,
          3.8163981437683105,
          -1.291145920753479,
          -3.049736499786377,
          -2.1124958992004395,
          21.66600799560547,
          -6.5823445320129395,
          -1.5647817850112915,
          9.445548057556152,
          6.304053783416748,
          3.481116771697998,
          5.9917521476745605,
          1.461081862449646,
          -5.043144702911377,
          1.096640944480896,
          -1.482094407081604,
          0.6640543341636658,
          558.3504028320312,
          15.957144737243652,
          6.301154613494873,
          -4.1775898933410645,
          8.142020225524902,
          -4.033409595489502,
          1.5663217306137085,
          29.449371337890625,
          874.44873046875,
          -5.8055195808410645,
          -2.657982349395752,
          4.993293285369873,
          -1.4007192850112915,
          -1.5206228494644165,
          -3.385155200958252,
          -1.839058518409729,
          72.42127990722656,
          -2.056663990020752,
          2.543921947479248,
          -4.208458423614502,
          33.321937561035156,
          5.3878092765808105,
          3185.56787109375,
          7805.93505859375,
          -2.229546070098877,
          11.828680992126465,
          -13.398430824279785,
          -26.666770935058594,
          2.831244945526123,
          5.833808422088623,
          3.106025218963623,
          156.34339904785156,
          3.182990550994873,
          4.190772533416748,
          -4.7090229988098145,
          -1.057564377784729,
          15.70230770111084,
          7.4676432609558105,
          -0.058632444590330124,
          23.56389617919922,
          1.929770827293396,
          -10.590401649475098,
          2.7742838859558105,
          -5.880424976348877,
          1.380576491355896,
          117.16487884521484,
          1.995322585105896,
          -5.9592366218566895,
          28.39911651611328,
          8.455771446228027,
          4.131507396697998,
          0.47177833318710327,
          -5.366051197052002,
          -6.355400562286377,
          3.3279032707214355,
          1.287406325340271,
          -1.938606858253479,
          254.2213134765625,
          0.49182838201522827,
          9.518073081970215,
          -0.8561330437660217,
          -2.923759937286377,
          -0.7210927605628967,
          -0.9503102898597717,
          -6.460411548614502,
          -1.2929617166519165,
          2313.0439453125,
          24.496864318847656,
          -11.07839298248291,
          9.070883750915527,
          -2.5988545417785645,
          0.14108984172344208,
          0.42339271306991577,
          -2.969627857208252,
          -2.0903401374816895,
          1.580222487449646,
          3.890479564666748,
          13.933920860290527,
          -0.7813649773597717,
          107.04773712158203,
          -1.861672043800354,
          2.825751781463623,
          613.02099609375,
          -7.443626880645752,
          -1.0733877420425415,
          -0.9459767937660217,
          2.2822184562683105,
          4.478705883026123,
          2.750434398651123,
          0.5713266730308533,
          207.34146118164062,
          -2.681358814239502,
          4.297156810760498,
          -2.1727375984191895,
          3.578406810760498,
          2.4576640129089355,
          6.349433422088623,
          -1.518013596534729,
          4.2248454093933105,
          532.7108154296875,
          -2.373802661895752,
          -12.655098915100098,
          -4.4752583503723145,
          -7.6223835945129395,
          6.551948070526123,
          4.8892130851745605,
          -10.078850746154785,
          -7.044884204864502,
          -1.8428884744644165,
          -4.0070271492004395,
          -2.6097798347473145,
          -3.209282398223877,
          -2.654442310333252,
          -2.8461079597473145,
          2.5931010246276855,
          -2.723564624786377,
          -10.70143985748291,
          3135.57421875,
          424.85968017578125,
          -2.585930347442627,
          5.238807201385498,
          926.9346923828125,
          -1.416542649269104,
          -2.8090291023254395,
          15.34805965423584,
          -0.016762327402830124,
          0.7663950324058533,
          1.6023019552230835,
          0.32718604803085327,
          209.19422912597656,
          -4.8743062019348145,
          -2.2094197273254395,
          -4.986412525177002,
          3.3593363761901855,
          -1.9253164529800415,
          -2.585350513458252,
          -3.252434253692627,
          3.565894603729248,
          -7.130455493927002,
          -20.81256866455078,
          -2.598930835723877,
          75.46443176269531,
          4.2246012687683105,
          6.7844462394714355,
          3.8260111808776855,
          5.906257152557373,
          -2.593437671661377,
          497.1839904785156,
          2.254859447479248,
          739.3287963867188,
          -10.64943790435791,
          -8.671975135803223,
          5.757453441619873,
          -2.0045552253723145,
          -2.3367695808410645,
          7.5217814445495605,
          -1.598244309425354,
          -3.287010669708252,
          -3.4090046882629395,
          -1.0298391580581665,
          -8.215065956115723,
          3.531562328338623,
          -16.60497283935547,
          49.07843017578125,
          5.886268138885498,
          18.13025665283203,
          6.4032816886901855,
          8.54617977142334,
          2.124335765838623,
          14.509406089782715,
          -8.113961219787598,
          7.135413646697998,
          5.0006632804870605,
          -3.1605610847473145,
          12.919577598571777,
          7.9982829093933105,
          -2.8940205574035645,
          2.448554515838623,
          -7.270927906036377,
          -0.25438743829727173,
          4.2819743156433105,
          64.37530517578125,
          -1.741341233253479,
          -0.5162435173988342,
          -4.1940083503723145,
          1.0527414083480835,
          -6.158745288848877,
          -6.0918965339660645,
          3.6401286125183105,
          1.412955641746521,
          4478.0595703125,
          3595.047119140625,
          14.009207725524902,
          49.07676696777344,
          4.619636058807373,
          7.5465006828308105,
          -2.704918384552002,
          5.0287394523620605,
          0.44701331853866577,
          -2.4366841316223145,
          -1.4755178689956665,
          8.689566612243652,
          1.7918466329574585,
          -3.709770679473877,
          0.37670081853866577,
          -2.348076343536377,
          8.483511924743652,
          1.965049147605896,
          0.9997629523277283,
          -0.038872312754392624,
          43.36143493652344,
          -4.208672046661377,
          -3.895592212677002,
          20.416038513183594,
          -9.30025577545166,
          1.739982008934021,
          16.85173797607422,
          -5.845512866973877,
          1.254020094871521,
          4.317389965057373,
          -2.8174824714660645,
          -15.225350379943848,
          -2.3220601081848145,
          -4.6919636726379395,
          -2.439354419708252,
          13.49893856048584,
          2.018958568572998,
          1.828452467918396,
          7.0034403800964355,
          9.380499839782715,
          -15.469277381896973,
          4.677527904510498,
          2.1049723625183105,
          15.76468563079834,
          9.381003379821777,
          22.825340270996094,
          -4.9600911140441895,
          0.6279215216636658,
          -1.0239492654800415,
          -3.588676929473877,
          2.236579418182373,
          2.7679972648620605,
          0.36231178045272827,
          -5.9331135749816895,
          1.981742262840271,
          -1.8293691873550415,
          7.286933422088623,
          2.6108012199401855,
          -6.370506763458252,
          3.340613842010498,
          5.9984049797058105,
          -3.988609790802002,
          -9.273873329162598,
          3.679877758026123,
          1.5889352560043335,
          -4.1229634284973145,
          14.956473350524902,
          6.632392406463623,
          -1.1966177225112915,
          -0.8698049187660217,
          1303.22412109375,
          2.403602123260498,
          -0.8729024529457092,
          1.5967477560043335,
          -0.6302877068519592,
          10.806052207946777,
          -5.542686939239502,
          -0.11327417194843292,
          11.244635581970215,
          -8.525124549865723,
          0.36867469549179077,
          4.6114726066589355,
          3.1100687980651855,
          -0.6780629754066467,
          -2.1395649909973145,
          1.418509840965271,
          13.98239803314209,
          -0.6462636590003967,
          2.3942790031433105,
          2.586738109588623,
          -10.467171669006348,
          1.6323007345199585,
          0.5609201788902283,
          -1.850838303565979,
          -3.1328511238098145,
          -2.0901265144348145,
          5.388495922088623,
          3.382606029510498,
          6.056006908416748,
          3.193610668182373,
          1.3295053243637085,
          -0.029182981699705124,
          2.9295268058776855,
          -14.095498085021973,
          -9.85176944732666,
          0.9657663702964783,
          7.223182201385498,
          9.305914878845215,
          4.772101879119873,
          639.5101928710938,
          2.3011088371276855,
          4.531257152557373,
          3.951697826385498,
          -0.6059957146644592,
          5.9275736808776855,
          8.916068077087402,
          -2.6618428230285645,
          -2.918602466583252,
          2.8912272453308105,
          -4.233757495880127,
          2.5970683097839355,
          8.600821495056152,
          -10.644967079162598,
          99.13375091552734,
          12.782614707946777,
          189.2626495361328,
          -8.003457069396973,
          -3.953331470489502,
          -2.9379658699035645,
          6.346045970916748,
          0.5008921027183533,
          599.1289672851562,
          -10.755181312561035,
          233.32460021972656,
          1.1997140645980835,
          -22.04814910888672,
          860.4420166015625,
          4.200232982635498,
          -5.664543628692627,
          3464.407470703125,
          1.8155893087387085,
          -5.8502888679504395,
          -0.6172719597816467,
          14.694174766540527,
          27.06360626220703,
          8.716132164001465,
          16.59369659423828,
          4.3082194328308105,
          -0.6862569451332092,
          33.627288818359375,
          -0.17250879108905792,
          33.98894500732422,
          4073.649658203125,
          -4.523064136505127,
          0.6787943243980408,
          2.5899271965026855,
          7.8793559074401855,
          -8.893059730529785,
          9.225226402282715,
          0.8982920050621033,
          3.491309642791748,
          2.3167948722839355,
          4.719520092010498,
          31.115684509277344,
          -4.527214527130127,
          -7.500145435333252,
          -1.564888596534729,
          9.934042930603027,
          1.332358717918396,
          -2.7102742195129395,
          17.648338317871094,
          -1.152535080909729,
          7.004554271697998,
          -3.733116626739502,
          8.41232967376709,
          53.96532440185547,
          0.07205908000469208,
          -3.7287068367004395,
          47.3377685546875,
          -0.45169883966445923,
          -3.6126790046691895,
          2.8953471183776855,
          1560.0252685546875,
          1.9159005880355835,
          -14.279335975646973,
          0.7783884406089783,
          163.97634887695312,
          6.2637858390808105,
          -0.08632715046405792,
          -2.077629566192627,
          -17.09508514404297,
          -7.691368579864502,
          4.128394603729248,
          10.758856773376465,
          1.823539137840271,
          -0.45928245782852173,
          11.968314170837402,
          436.2654113769531,
          -1.211800217628479,
          -3.376121997833252,
          -4.2656331062316895,
          3.7045817375183105,
          4897.20703125,
          0.43689674139022827,
          0.061622072011232376,
          2.046058177947998,
          -5.536339282989502,
          2.1968913078308105,
          4.0945048332214355,
          7.4821391105651855,
          1.3322519063949585,
          -2.492180347442627,
          2.149482250213623,
          1.1063607931137085,
          -6.314201831817627,
          -0.25345665216445923,
          -4.216698169708252,
          -49.989402770996094,
          59.103553771972656,
          -2.582390308380127,
          1.2900155782699585,
          98.88036346435547,
          924.2172241210938,
          -2.692894458770752,
          -5.198448657989502,
          0.9661630988121033,
          0.8484262824058533,
          0.30594581365585327,
          -12.435097694396973,
          18.999534606933594,
          -9.821343421936035,
          -9.645501136779785,
          -0.014519285410642624,
          0.17172949016094208,
          3.549628734588623,
          -0.9584737420082092,
          5595.85546875,
          -2.712181568145752,
          2.579291820526123,
          -8.271157264709473,
          16.88867950439453,
          0.056815553456544876,
          1.004386305809021,
          -13.287636756896973,
          5637.32275390625,
          704.337646484375,
          -1.158241868019104,
          9.407889366149902,
          -0.041649412363767624,
          6.7963786125183105,
          111.0923080444336,
          1.7999337911605835,
          443.4393615722656,
          3.508796215057373,
          -0.8052602410316467,
          112.62997436523438,
          -1.2262502908706665,
          97.4437484741211,
          -2.0655598640441895,
          -2.5528645515441895
         ]
        },
        {
         "marker": {
          "size": 1
         },
         "mode": "markers",
         "name": "error in difference",
         "type": "scatter3d",
         "uid": "5df1adde-322d-4525-a9b5-d9861f4fdde5",
         "x": [
          0.564,
          0.088,
          0.012,
          0.252,
          0.9,
          0.432,
          0.166,
          0.41,
          0.544,
          0.112,
          0.498,
          0.534,
          0.37,
          0.112,
          0.048,
          0.396,
          0.622,
          0.676,
          0.72,
          0.414,
          0.722,
          0.556,
          0.238,
          0.602,
          0.664,
          0.822,
          0.134,
          0.39,
          0.25,
          0.742,
          0.54,
          0.496,
          0.722,
          0.156,
          0.388,
          0.394,
          0.658,
          0.912,
          0.738,
          0.696,
          0.528,
          0.666,
          0.716,
          0.834,
          0.11,
          0.798,
          0.564,
          0.766,
          0.676,
          0.006,
          0.224,
          0.516,
          0.276,
          0.13,
          0.526,
          0.03,
          0.416,
          0.128,
          0.008,
          0.078,
          0.636,
          0.624,
          0.6,
          0.67,
          0.696,
          0.764,
          0.12,
          0.858,
          0.996,
          0.492,
          0.434,
          0.19,
          0.566,
          0.1,
          0.336,
          0.694,
          0.7,
          0.174,
          0.104,
          0.358,
          0.872,
          0.9,
          0.002,
          0.55,
          0.118,
          0.092,
          0.208,
          0.302,
          0.974,
          0.344,
          0.018,
          0.68,
          0.662,
          0.532,
          0.608,
          0.752,
          0.966,
          0.554,
          0.608,
          0.28,
          0.564,
          0.136,
          0.754,
          0.282,
          0.18,
          0.816,
          0.18,
          0.02,
          0.794,
          0.172,
          0.46,
          0.178,
          0.7,
          0.95,
          0.128,
          0.568,
          0.838,
          0.57,
          0.382,
          0.388,
          0.96,
          0.324,
          0.908,
          0.924,
          0.248,
          0.684,
          0.39,
          0.868,
          0.98,
          1,
          0.422,
          0.03,
          0.432,
          0.806,
          0.47,
          0.374,
          0.362,
          0.338,
          0.096,
          0.336,
          0.7,
          0.48,
          0.11,
          0.154,
          0.48,
          0.932,
          0.184,
          0.426,
          0.64,
          0.366,
          0.892,
          0.862,
          0.712,
          0.224,
          0.976,
          0.428,
          0.34,
          0.036,
          0.256,
          0.704,
          0.196,
          0.802,
          0.314,
          0.044,
          0.324,
          0.412,
          0.13,
          0.594,
          0.064,
          0.832,
          0.682,
          0.584,
          0.972,
          0.984,
          0.678,
          0.39,
          0.21,
          0.552,
          0.368,
          0.866,
          0.308,
          0.232,
          0.846,
          0.796,
          0.056,
          0.018,
          0.62,
          0.43,
          0.894,
          0.718,
          0.492,
          0.292,
          0.854,
          0.78,
          0.204,
          0.862,
          0.138,
          0.268,
          0.768,
          0.232,
          0.752,
          0.87,
          0.208,
          0.25,
          0.076,
          0.594,
          0.964,
          0.45,
          0.366,
          0.07,
          0.892,
          0.7,
          0.138,
          0.706,
          0.362,
          0.28,
          0.486,
          0.892,
          0.85,
          0.036,
          0.736,
          0.356,
          0.916,
          0.346,
          0.088,
          0.47,
          0.668,
          0.01,
          0.81,
          0.462,
          0.81,
          0.822,
          0.548,
          0.124,
          0.44,
          0.82,
          0.922,
          0.454,
          0.88,
          0.738,
          0.284,
          0.924,
          0.118,
          0.52,
          0.838,
          0.72,
          0.206,
          0.974,
          0.592,
          0.598,
          0.444,
          0.538,
          0.038,
          0.192,
          0.166,
          0.722,
          0.63,
          0.032,
          0.078,
          0.51,
          0.166,
          0.664,
          0.73,
          0.404,
          0.29,
          0.702,
          0.948,
          0.256,
          0.584,
          0.358,
          0.762,
          0.496,
          0.97,
          0.812,
          0.724,
          0.92,
          0.576,
          0.02,
          0.358,
          0.332,
          0.2,
          0.154,
          0.01,
          0.346,
          0.956,
          0.872,
          0.618,
          0.038,
          0.804,
          0.718,
          0.01,
          0.078,
          0.634,
          0.82,
          0.146,
          0.292,
          0.69,
          0.804,
          0.438,
          0.93,
          0.35,
          0.116,
          0.114,
          0.764,
          0.594,
          0.64,
          0.284,
          0.142,
          0.698,
          0.63,
          0.31,
          0.77,
          0.75,
          0.794,
          0.078,
          0.734,
          0.276,
          0.908,
          0.072,
          0.098,
          0.824,
          0.528,
          0.9,
          0.452,
          0.502,
          0.878,
          0.758,
          0.256,
          0.514,
          0.916,
          0.712,
          0.392,
          0.49,
          0.494,
          0.122,
          0.824,
          0.784,
          0.64,
          0.69,
          0.356,
          0.182,
          0.916,
          0.634,
          0.422,
          0.496,
          0.514,
          0.824,
          0.394,
          0.382,
          0.41,
          0.662,
          0.646,
          0.082,
          0.476,
          0.926,
          0.454,
          0.81,
          0.826,
          0.954,
          0.12,
          0.32,
          0.484,
          0.93,
          0.496,
          0.356,
          0.038,
          0.718,
          0.4,
          0.572,
          0.11,
          0.734,
          0.372,
          0.488,
          0.424,
          0.872,
          0.222,
          0.378,
          0.98,
          0.726,
          0.564,
          0.378,
          0.302,
          0.868,
          0.322,
          0.696,
          0.372,
          0.398,
          0.918,
          0.846,
          0.532,
          0.318,
          0.974,
          0.258,
          0.862,
          0.534,
          0.83,
          0.79,
          0.838,
          0.946,
          0.146,
          0.45,
          0.35,
          0.63,
          0.958,
          0.2,
          0.47,
          0.434,
          0.296,
          0.506,
          0.06,
          0.758,
          0.054,
          0.774,
          0.072,
          0.964,
          0.06,
          0.824,
          0.082,
          0.196,
          0.294,
          0.45,
          0.204,
          0.804,
          0.918,
          0.036,
          0.122,
          0.254,
          0.498,
          0.24,
          0.27,
          0.942,
          0.208,
          0.064,
          0.572,
          0.644,
          0.856,
          0.9,
          0.536,
          0.912,
          0.35,
          0.87,
          0.33,
          0.29,
          0.748,
          0.004,
          0.832,
          0.48,
          0.25,
          0.99,
          0.306,
          0.456,
          0.56,
          0.664,
          0.788,
          0.368,
          0.506,
          0.366,
          0.59,
          0.58,
          0.516,
          0.782,
          0.178,
          0.61,
          0.636,
          0.538,
          0.124,
          0.13,
          0.956,
          0.74,
          0.986,
          0.586,
          0.312,
          0.68,
          0.502,
          0.808,
          0.354,
          0.952,
          0.416,
          0.36,
          0.938,
          0.896,
          0.108,
          0.44,
          0.244,
          0.092,
          0.688,
          0.01,
          0.196,
          0.92,
          0.296,
          0.234,
          0.08,
          0.598,
          0.258,
          0.404,
          0.112,
          0.104,
          0.06,
          0.456,
          0.8,
          0.042,
          0.686,
          0.504,
          0.284,
          0.136,
          0.14,
          0.87,
          0.014,
          0.552,
          0.056,
          0.632,
          0.91,
          0.962,
          0.688,
          0.816,
          0.81,
          0.994,
          0.65,
          0.88,
          0.852,
          0.452,
          0.382,
          0.824,
          0.27,
          0.022,
          0.684,
          0.008,
          0.006,
          0.124,
          0.212,
          0.936,
          0.556,
          0.076,
          0.166,
          0.034,
          0.15,
          0.716,
          0.222,
          0.88,
          0.03,
          0.438,
          0.726,
          0.438,
          0.776,
          0.646,
          0.36,
          0.958,
          0.024,
          1,
          0.11,
          0.898,
          0.16,
          0.436,
          0.012,
          0.366,
          0.204,
          0.57,
          0.974,
          0.272,
          0.67,
          0.246,
          0.444,
          0.794,
          0.002,
          0.52,
          0.05,
          0.506,
          0.038,
          0.328,
          0.104,
          0.55,
          0.334,
          0.226,
          0.858,
          0.816,
          0.884,
          0.112,
          0.288,
          0.876,
          0.734,
          0.028,
          0.022,
          0.066,
          0.782,
          0.332,
          0.92,
          0.594,
          0.344,
          0.698,
          0.846,
          0.782,
          0.784,
          0.454,
          0.682,
          0.824,
          0.938,
          0.586,
          0.8,
          0.178,
          0.11,
          0.402,
          0.618,
          0.722,
          0.35,
          0.992,
          0.416,
          0.052,
          0.342,
          0.254,
          0.982,
          0.366,
          0.316,
          0.602,
          0.818,
          0.378,
          0.712,
          0.42,
          0.67,
          0.886,
          0.654,
          0.532,
          0.216,
          0.234,
          0.762,
          0.808,
          0.598,
          0.666,
          0.074,
          0.018,
          0.466,
          0.346,
          0.754,
          0.708,
          0.53,
          0.578,
          0.514,
          0.548,
          0.13,
          0.2,
          0.544,
          0.698,
          0.848,
          0.294,
          0.078,
          0.064,
          0.044,
          0.048,
          0.312,
          0.358,
          0.338,
          0.36,
          0.154,
          0.186,
          0.018,
          0.9,
          0.926,
          0.35,
          0.628,
          0.178,
          0.036,
          0.59,
          0.928,
          0.366,
          0.172,
          0.78,
          0.558,
          0.834,
          0.216,
          0.668,
          0.616,
          0.332,
          0.578,
          0.838,
          0.472,
          0.644,
          0.46,
          0.732,
          0.602,
          0.6,
          0.732,
          0.318,
          0.938,
          0.142,
          0.104,
          0.5,
          0.452,
          0.968,
          0.776,
          0.334,
          0.604,
          0.326,
          0.762,
          0.51,
          0.228,
          0.848,
          0.168,
          0.204,
          0.386,
          0.72,
          0.056,
          0.442,
          0.78,
          0.322,
          0.27,
          0.946,
          0.498,
          0.398,
          0.698,
          0.892,
          0.086,
          0.528,
          0.898,
          0.602,
          0.826,
          0.344,
          0.556,
          0.53,
          0.232,
          0.12,
          0.176,
          0.066,
          0.082,
          0.98,
          0.562,
          0.818,
          0.886,
          0.868,
          0.498,
          0.7,
          0.42,
          0.804,
          0.648,
          0.306,
          0.1,
          0.986,
          0.8,
          0.678,
          0.416,
          0.192,
          0.526,
          0.714,
          0.966,
          0.468,
          0.09,
          0.712,
          0.2,
          0.406,
          0.304,
          0.166,
          0.942,
          0.482,
          0.908,
          0.926,
          0.732,
          0.082,
          0.698,
          0.598,
          0.034,
          0.128,
          0.83,
          0.258,
          0.97,
          0.916,
          0.022,
          0.23,
          0.292,
          0.53,
          0.582,
          0.09,
          0.656,
          0.212,
          0.752,
          0.802,
          0.368,
          0.776,
          0.85,
          0.784,
          0.71,
          0.566,
          0.326,
          0.494,
          0.742,
          0.138,
          0.392,
          0.648,
          0.982,
          0.42,
          0.842,
          0.524,
          0.154,
          0.114,
          0.478,
          0.496,
          0.224,
          0.462,
          0.918,
          0.186,
          0.882,
          0.102,
          0.7,
          0.508,
          0.476,
          0.204,
          0.314,
          0.06,
          0.056,
          0.552,
          0.522,
          0.474,
          0.416,
          0.708,
          0.724,
          0.886,
          0.092,
          0.984,
          0.716,
          0.54,
          0.646,
          0.388,
          0.878,
          0.644,
          0.322,
          0.696,
          0.28,
          0.886,
          0.608,
          0.77,
          0.004,
          0.874,
          0.15,
          0.004,
          0.342,
          0.68,
          0.314,
          0.474,
          0.72,
          0.616,
          0.722,
          0.564,
          0.086,
          0.408,
          0.244,
          0.62,
          0.428,
          0.528,
          0.952,
          0.532,
          0.828,
          0.028,
          0.314,
          0.646,
          0.328,
          0.618,
          0.662,
          0.59,
          0.634,
          0.874,
          0.244,
          0.65,
          0.374,
          0.302,
          0.132,
          0.566,
          0.88,
          0.136,
          0.608,
          0.716,
          0.792,
          0.026,
          0.334,
          0.94,
          0.796,
          0.15,
          0.476,
          0.484,
          0.606,
          0.776,
          0.632,
          0.218,
          0.866,
          0.146,
          0.134,
          0.574,
          0.222,
          0.412,
          0.334,
          0.866,
          0.25,
          0.592,
          0.974,
          0.86,
          0.334,
          0.53,
          0.894,
          0.498,
          0.47,
          0.916,
          0.494,
          0.166,
          0.098,
          0.142,
          0.912,
          0.672,
          0.116,
          0.962,
          0.864,
          0.376,
          0.324,
          0.384,
          0.594,
          0.682,
          0.048,
          0.842,
          0.25,
          0.162,
          0.858,
          0.224,
          0.488,
          0.846,
          0.706,
          0.764,
          0.404,
          0.342,
          0.184,
          0.74,
          0.404,
          0.372,
          0.366,
          0.934,
          0.01,
          0.324,
          0.118,
          0.454,
          0.81,
          0.262,
          0.81,
          0.192,
          0.286,
          0.598,
          0.232,
          0.424,
          0.584,
          0.704,
          0.54,
          0.488,
          0.148,
          0.12,
          0.424,
          0.728,
          0.976,
          0.714,
          0.084,
          0.69,
          0.568,
          0.642,
          0.86,
          0.356,
          0.614,
          0.984,
          0.194,
          0.402,
          0.572,
          0.634,
          0.14,
          0.91,
          0.844,
          0.036,
          0.916,
          0.256,
          0.65,
          0.724,
          0.86,
          0.082,
          0.098,
          0.122,
          0.146,
          0.218,
          0.862,
          0.564,
          0,
          0.538,
          0.936,
          0.68,
          0.248,
          0.41,
          0.822,
          0.292,
          0.75,
          0.882,
          0.818,
          0.766,
          0.672,
          0.1,
          0.42,
          0.56,
          0.278,
          0.776,
          0.382,
          0.256,
          0.576,
          0.844,
          0.49,
          0.432,
          0.182,
          0.322,
          0.774,
          0.702,
          0.04,
          0.722,
          0.766,
          0.728,
          0.228,
          0.198,
          0.796,
          0.748,
          0.128,
          0.634,
          0.244,
          0.444,
          0.698,
          0.614,
          0.43,
          0.266,
          0.82,
          0.732,
          0.558,
          0.204,
          0.936,
          0.012,
          0.752,
          0.464,
          0.596,
          0.75,
          0.722,
          0.538,
          0.218,
          0.698,
          0.63,
          0,
          0.364,
          0.494,
          0.868,
          0.092,
          0.898,
          0.962,
          0.91,
          0.168,
          0.322,
          0.972,
          0.23,
          0.236,
          0.988,
          0.926,
          0.638,
          0.018,
          0.542,
          0.874,
          0.722,
          0,
          0.888,
          0.87,
          0.85,
          0.448,
          0.75,
          0.93,
          0.792,
          0.466,
          0.818,
          0.512,
          0.698,
          0.618,
          0.594,
          0.16,
          0.554,
          0.668,
          0.028,
          0.172,
          0.212,
          0.298,
          0.25,
          0.714,
          0.094,
          0.61,
          0.656,
          0.236,
          0.102,
          0.524,
          0.866,
          0.388,
          0.828,
          0.7,
          0.474,
          0.54,
          0.3,
          0.268,
          0.12,
          0.712,
          0.116,
          0.988,
          0.842,
          0.532,
          0.674,
          0.322,
          0.076,
          0.272,
          0.13,
          0.166,
          0.182,
          0.056,
          0.71,
          0.654,
          0.04,
          0.98,
          0.808,
          0.776,
          0.122,
          0.006,
          0.24,
          0.388,
          0.952,
          0.428,
          0.18,
          0.726,
          0.288,
          0.094,
          0.552,
          0.668,
          0.274,
          0.384,
          0.992,
          0.012,
          0.268,
          0.694,
          0.218,
          0.8,
          0.162,
          0.494,
          0.244,
          0.516,
          0.358,
          0.992,
          0.032,
          0.23,
          0.438,
          0.718,
          0.834,
          0.486,
          0.078,
          0.822,
          0.956,
          0.148,
          0.858,
          0.576,
          0.61,
          0.09,
          0.682,
          0.178,
          0.57,
          0.016,
          0.32,
          0.394,
          0.872,
          0.18,
          0.6,
          0.958,
          0.172,
          0.274,
          0.96,
          0.478,
          0.076,
          0.488,
          0.596,
          0.46,
          0.514,
          0.086,
          0.93,
          0.224,
          0.682,
          0.958,
          0.834,
          0.776,
          0.302,
          0.278,
          0.704,
          0.224,
          0.212,
          0.598,
          0.696,
          0.514,
          0.096,
          0.134,
          0.53,
          0.82,
          0.162,
          0.132,
          0.482,
          0.042,
          0.546,
          0.556,
          0.834,
          0.652,
          0.158,
          0.198,
          0.452,
          0.216,
          0.826,
          0.418,
          0.298,
          0.082,
          0.5,
          0.756,
          0.73,
          0.398,
          0.668,
          0.424,
          0.196,
          0.088,
          0.134,
          0.864,
          0.57,
          0.44,
          0.594,
          0.012,
          0.652,
          0.138,
          0.206,
          0.5,
          0.128,
          0.438,
          0.024,
          0.508,
          0.438
         ],
         "y": [
          0.896,
          0.686,
          0.71,
          0.372,
          0.698,
          0.168,
          0.392,
          0.572,
          0.698,
          0.054,
          0.706,
          0.178,
          0.606,
          0.648,
          0.918,
          0.772,
          0.294,
          0.544,
          0.146,
          0.124,
          0.692,
          0.56,
          0.576,
          0.954,
          0.3,
          0.298,
          0.192,
          0.962,
          0.726,
          0.904,
          0.284,
          0.614,
          0.156,
          0.322,
          0.542,
          0.146,
          0.824,
          0.608,
          0.43,
          0.204,
          0.994,
          0.126,
          0.424,
          0.23,
          0.322,
          0.68,
          0.316,
          0.444,
          0.714,
          0.758,
          0.506,
          0.592,
          0.808,
          0.772,
          0.86,
          0.148,
          0.08,
          0.638,
          0.614,
          0.712,
          0.486,
          0.46,
          0.862,
          0.196,
          0.822,
          0.152,
          0.002,
          0.818,
          0.506,
          0.13,
          0.432,
          0.484,
          0.662,
          0.802,
          0.122,
          0.602,
          0.488,
          0.55,
          0.656,
          0.222,
          0.76,
          0.122,
          0.19,
          0.114,
          0.024,
          0.58,
          0.638,
          0.292,
          0.726,
          0.76,
          0.988,
          0.01,
          0.33,
          0.76,
          0.002,
          0.148,
          0.122,
          0.008,
          0.61,
          0.092,
          0.074,
          0.74,
          0.38,
          0.784,
          0.216,
          0.138,
          0.186,
          0.502,
          0.526,
          0.43,
          0.012,
          0.462,
          0.428,
          0.614,
          0.712,
          0.67,
          0.904,
          0.974,
          0.338,
          0.61,
          0.654,
          0.586,
          0.294,
          0.75,
          0.254,
          0.074,
          0.148,
          0.918,
          0.436,
          0.074,
          0.36,
          0.718,
          0.482,
          0.864,
          0.936,
          0.95,
          0.768,
          0.956,
          0.488,
          0.674,
          0.96,
          0.782,
          0.272,
          0.248,
          0.552,
          0.316,
          0.58,
          0.73,
          0.864,
          0.236,
          0.156,
          0.11,
          0.85,
          0.654,
          0.726,
          0.05,
          0.054,
          0.502,
          0.366,
          0.608,
          0.81,
          0.934,
          0.464,
          0.442,
          0.502,
          0.058,
          0.34,
          0.004,
          0.916,
          0.704,
          0.452,
          0.428,
          0.036,
          0.054,
          0.42,
          0.238,
          0.762,
          0.044,
          0.208,
          0.356,
          0.164,
          0.198,
          0.314,
          0.95,
          0.552,
          0.82,
          0.564,
          0.714,
          0.382,
          0.266,
          0.682,
          0.938,
          0.346,
          0.812,
          0.404,
          0.736,
          0.236,
          0.93,
          0.574,
          0.99,
          0.626,
          0.66,
          0.718,
          0.786,
          0.89,
          0.45,
          0.954,
          0.454,
          0.15,
          0.774,
          0.846,
          0.126,
          0.38,
          0.862,
          0.742,
          0.042,
          0.42,
          0.578,
          0.05,
          0.39,
          0.91,
          0.586,
          0.64,
          0.074,
          0.72,
          0.892,
          0.056,
          0.148,
          0.484,
          0.23,
          0.526,
          0.594,
          0.016,
          0.734,
          0.348,
          0.53,
          0.926,
          0.564,
          0.824,
          0.094,
          0.454,
          0.018,
          0.022,
          0.604,
          0.57,
          0.158,
          0.35,
          0.54,
          0.96,
          0.76,
          0.184,
          0.768,
          0.532,
          0.378,
          0.41,
          0.884,
          0.954,
          0.27,
          0.294,
          0.19,
          0.724,
          0.334,
          0.498,
          0.128,
          0.47,
          0.98,
          0.562,
          0.854,
          0.544,
          0.886,
          0.15,
          0.65,
          0.174,
          0.244,
          0.354,
          0.856,
          0.184,
          0.434,
          0.536,
          0.734,
          0.08,
          0.03,
          0.236,
          0.242,
          0.824,
          0.434,
          0.69,
          0.65,
          0.006,
          0.674,
          0.38,
          0.728,
          0.538,
          0.134,
          0.704,
          0.286,
          0.34,
          0.14,
          0.098,
          0.454,
          0.586,
          0.814,
          0.608,
          0.462,
          0.288,
          0.192,
          0.266,
          0.946,
          0.24,
          0.16,
          0.228,
          0.064,
          0.022,
          0.546,
          0.004,
          0.524,
          0.774,
          0.832,
          0.942,
          0.378,
          0.284,
          0.09,
          0.794,
          0.724,
          0.588,
          0.024,
          0.912,
          0.18,
          0.86,
          0.848,
          0.558,
          0.298,
          0.328,
          0.968,
          0.29,
          0.064,
          0.458,
          0.748,
          0.646,
          0.08,
          0.256,
          0.028,
          0.842,
          0.978,
          0.044,
          0.81,
          0.94,
          0.392,
          0.444,
          0.108,
          0.372,
          0.884,
          0.072,
          0.184,
          0.608,
          0.392,
          0.854,
          0.02,
          0.904,
          0.988,
          0,
          0.928,
          0.002,
          0.532,
          0.014,
          0.652,
          0.686,
          0.326,
          0.148,
          0.764,
          0.15,
          0.062,
          0.642,
          0.734,
          0.426,
          0.132,
          0.502,
          0.482,
          0.756,
          0.236,
          0.108,
          0.464,
          0.454,
          0.396,
          0.782,
          0.982,
          0.332,
          0.894,
          0.71,
          0.594,
          0.996,
          0.028,
          0.8,
          0.342,
          0.478,
          0.836,
          0.892,
          0.238,
          0.704,
          0.694,
          0.914,
          0.91,
          0.282,
          0.42,
          0.206,
          0.93,
          0.052,
          0.45,
          0.974,
          0.836,
          0.194,
          0.6,
          0.688,
          0.994,
          0.908,
          0.524,
          0.112,
          0.058,
          0.092,
          0.112,
          0.08,
          0.12,
          0.568,
          0.854,
          0.024,
          0.106,
          0.024,
          0.902,
          0.964,
          0.112,
          0.656,
          0.984,
          0.182,
          0.79,
          0.086,
          0.972,
          0.164,
          0.538,
          0.332,
          0.448,
          0.714,
          0.29,
          0.826,
          0.252,
          0.512,
          0.38,
          0.698,
          0.544,
          0.006,
          0.464,
          0.652,
          0.402,
          0.396,
          0.176,
          0.342,
          0.358,
          0.902,
          0.502,
          0.26,
          0.922,
          0.296,
          0.868,
          0.788,
          0.814,
          0.518,
          0.92,
          0.242,
          0.374,
          0.338,
          0.232,
          0.354,
          0.274,
          0.734,
          0.686,
          0.29,
          0.374,
          0.456,
          0.838,
          0.478,
          0.218,
          0.012,
          0.982,
          0.514,
          0.758,
          0.68,
          0.92,
          0.74,
          0.788,
          0.692,
          0.066,
          0.934,
          0.51,
          0.812,
          0.436,
          0.072,
          0.022,
          0.586,
          0.664,
          0.45,
          0.656,
          0.032,
          0.046,
          0.562,
          0.978,
          0.23,
          0.292,
          0.598,
          0.95,
          0.788,
          0.77,
          0.72,
          0.092,
          0.51,
          0.75,
          0.884,
          0.128,
          0.15,
          0.454,
          0.136,
          0.662,
          0.232,
          0.776,
          0.584,
          0.17,
          0.74,
          0.976,
          0.96,
          0.712,
          0.368,
          0.068,
          0.478,
          0.712,
          0.334,
          0.316,
          0.992,
          0.776,
          0.45,
          0.506,
          0.092,
          0.362,
          0.708,
          0.86,
          0.952,
          0.836,
          0.468,
          0.222,
          0.434,
          0.128,
          0.668,
          0.604,
          0.032,
          0.454,
          0.956,
          0.452,
          0.776,
          0.65,
          0.102,
          0.604,
          0.656,
          0.448,
          0.91,
          0.05,
          0.928,
          0.536,
          0.452,
          0.096,
          0.786,
          0.462,
          0.3,
          0.132,
          0.888,
          0.926,
          0,
          0.318,
          0.128,
          0.788,
          0.424,
          0.434,
          0.734,
          0.37,
          0.214,
          0.284,
          0.116,
          0.216,
          0.918,
          0.972,
          0.946,
          0.462,
          0.792,
          0.428,
          0.938,
          0.93,
          0.5,
          0.306,
          0.352,
          0.344,
          0.836,
          0.77,
          0.856,
          0.106,
          0.892,
          0.866,
          0.046,
          0.972,
          0.728,
          0.602,
          0.262,
          0.64,
          0.544,
          0.66,
          0.9,
          0.084,
          0.298,
          0.966,
          0.908,
          0.48,
          0.586,
          0.048,
          0.27,
          0.952,
          0.484,
          0.294,
          0.578,
          0.374,
          0.03,
          0.958,
          0.018,
          0.086,
          0.85,
          0.492,
          0.846,
          0.496,
          0.03,
          0.344,
          0.796,
          0.054,
          0.108,
          0.142,
          0.782,
          0.092,
          0.374,
          0.956,
          0.92,
          0.908,
          0.472,
          0.748,
          0.942,
          0.602,
          0.002,
          0.106,
          0.996,
          0.228,
          0.804,
          0.146,
          0.99,
          0.664,
          0.748,
          0.816,
          0.946,
          0.792,
          0.158,
          0.044,
          0.674,
          0.298,
          0.818,
          0.39,
          0.028,
          0.514,
          0.838,
          0.03,
          0.626,
          0.474,
          0.564,
          0.956,
          0.79,
          0.732,
          0.476,
          0.112,
          0.792,
          0.9,
          0.168,
          0.776,
          0.864,
          0.978,
          0.41,
          0.882,
          0.852,
          0.594,
          0.562,
          0.808,
          0.174,
          0.512,
          0.21,
          0.716,
          0.586,
          0.926,
          0.278,
          0.84,
          0.096,
          0.62,
          0.83,
          0.982,
          0.328,
          0.266,
          0.844,
          0.324,
          0.572,
          0.1,
          0.03,
          0.012,
          0.862,
          0.034,
          0.694,
          0.984,
          0.504,
          0.398,
          0.242,
          0.29,
          0.152,
          0.812,
          0.658,
          0.728,
          0.552,
          0.522,
          0.02,
          0.104,
          0.85,
          0.182,
          0.48,
          0.302,
          0.736,
          0.268,
          0.926,
          0.462,
          0.296,
          0.672,
          0.51,
          0.33,
          0.02,
          0.206,
          0.596,
          0.168,
          0.594,
          0.994,
          0.236,
          0.678,
          0.46,
          0.334,
          0.002,
          0.89,
          1,
          0.668,
          0.122,
          0.828,
          0.296,
          0.966,
          0.968,
          0.904,
          0.436,
          0.922,
          0.62,
          0.454,
          0.83,
          0.532,
          0.204,
          0.374,
          0.326,
          0.978,
          0.088,
          0.17,
          0.9,
          0.522,
          0.262,
          0.622,
          0.796,
          0.204,
          0.832,
          0.708,
          0.536,
          0.104,
          0.978,
          0.394,
          0.794,
          0.666,
          0.5,
          0.016,
          0.376,
          0.33,
          0.456,
          0.374,
          0.952,
          0.104,
          0.212,
          0.472,
          0.02,
          0.69,
          0.074,
          0.768,
          0.308,
          0.446,
          0.41,
          0.158,
          0.922,
          0.31,
          0.624,
          0.89,
          0.494,
          0.72,
          0.832,
          0.814,
          0.732,
          0.036,
          0.256,
          0.364,
          0.676,
          0.326,
          0.124,
          0.866,
          0.668,
          0.494,
          0.192,
          0.75,
          0.252,
          0.874,
          0.854,
          0.814,
          0.344,
          0.938,
          0.854,
          0.234,
          0.492,
          0.86,
          0.932,
          0.13,
          0.102,
          0.984,
          0.936,
          0.96,
          0.184,
          0.38,
          0.958,
          0.52,
          0.076,
          0.46,
          0.016,
          0.182,
          0.056,
          0.922,
          0.724,
          0.704,
          0.564,
          0.536,
          0.166,
          0.41,
          0.916,
          0.544,
          0.326,
          0.246,
          0.516,
          0.606,
          0.008,
          0.5,
          0.376,
          0.252,
          0.904,
          0.576,
          0.622,
          0.332,
          0.98,
          0.976,
          0.978,
          0.418,
          0.7,
          0.276,
          0.412,
          0.91,
          0.08,
          0.51,
          0.83,
          0.64,
          0.078,
          0.714,
          0.388,
          0.426,
          0.196,
          0.388,
          0.51,
          0.904,
          0.996,
          0.044,
          0.404,
          0.186,
          0.524,
          0.734,
          0.554,
          0.284,
          0.834,
          0.212,
          0.22,
          0.916,
          0.774,
          0.58,
          0.89,
          0.664,
          0.518,
          0.37,
          0.33,
          0.928,
          0.938,
          0.646,
          0.502,
          0.334,
          0.96,
          0.278,
          0.094,
          0.028,
          0.306,
          0.174,
          0.758,
          0.402,
          0.654,
          0.798,
          0.224,
          0.876,
          0.598,
          0.7,
          0.354,
          0.284,
          0.126,
          0.906,
          0.626,
          0.648,
          0.866,
          0.61,
          0.196,
          0.932,
          0.53,
          0.662,
          0.63,
          0.608,
          0.168,
          0.194,
          0.532,
          0.956,
          0.804,
          0.478,
          0.054,
          0.642,
          0.894,
          0.704,
          0.678,
          0.014,
          0.536,
          0.734,
          0.012,
          0.354,
          0.684,
          0.662,
          0.218,
          0.11,
          0.244,
          0.212,
          0.33,
          0.468,
          0.572,
          0.92,
          0.01,
          0.042,
          0.858,
          0.808,
          0.014,
          0.442,
          0.716,
          0.9,
          0.152,
          0.386,
          0.466,
          0.51,
          0.102,
          0.24,
          0.424,
          0.94,
          0.74,
          0.502,
          0.49,
          0.282,
          0.044,
          0.184,
          0.47,
          0.81,
          0.478,
          0.868,
          0.256,
          0.452,
          0.56,
          0.796,
          0.634,
          0.964,
          0.956,
          0.988,
          0.062,
          0.484,
          0.11,
          0.558,
          0.018,
          0.674,
          0.184,
          0.126,
          0.482,
          0.93,
          0.048,
          0.712,
          0.436,
          0.826,
          0.864,
          0.218,
          0.656,
          0.734,
          0.262,
          0.468,
          0.072,
          0.458,
          0.088,
          0.178,
          0.486,
          0.606,
          0.546,
          0.894,
          0.092,
          0.364,
          0.984,
          0.93,
          0.066,
          0.508,
          0.632,
          0.088,
          0.472,
          0.388,
          0.216,
          0.806,
          0.002,
          0.956,
          0.572,
          0.302,
          0.388,
          0.178,
          0.15,
          0.57,
          0.118,
          0.252,
          0.192,
          0.396,
          0.044,
          0.502,
          0.228,
          0.224,
          0.97,
          0.67,
          0.746,
          0.648,
          0.05,
          0.868,
          0.754,
          0.558,
          0.714,
          0.486,
          0.184,
          0.932,
          0.842,
          0.276,
          0.948,
          0.474,
          0.324,
          0.854,
          0.44,
          0.17,
          0.204,
          0.012,
          0.334,
          0.204,
          0.028,
          0.496,
          0.254,
          0.326,
          0.634,
          0.04,
          0.83,
          0.02,
          0.174,
          0.94,
          0.724,
          0.57,
          0.864,
          0.524,
          0.444,
          0.384,
          0.918,
          0.474,
          0.112,
          0.324,
          0.162,
          0.628,
          0.038,
          0.442,
          0.414,
          0.564,
          0.43,
          0.41,
          0.47,
          0.294,
          0.806,
          0.69,
          0.338,
          0.596,
          0.94,
          0.162,
          0.398,
          0.206,
          0.334,
          0.018,
          0.514,
          0.744,
          0.236,
          0.742,
          0.778,
          0.642,
          0.402,
          0.102,
          0.296,
          0.028,
          0.33,
          0.058,
          0.428,
          0.336,
          0.552,
          0.534,
          0.034,
          0.976,
          0.222,
          0.332,
          0.318,
          0.146,
          0.922,
          0.018,
          0.054,
          0.298,
          0.9,
          0.25,
          0.782,
          0.952,
          0.468,
          0.826,
          0.146,
          0,
          0.592,
          0.244,
          0.29,
          0.828,
          0.57,
          0.88,
          0.016,
          0.796,
          0.578,
          0.576,
          0.768,
          0.05,
          0.084,
          0.86,
          0.696,
          0.408,
          0.524,
          0.144,
          0.222,
          0.956,
          0.758,
          0.358,
          0.25,
          0.246,
          0.058,
          0.06,
          0.73,
          0.496,
          0.3,
          0.848,
          0.998,
          0.242,
          0.822,
          0.604,
          0.636,
          1,
          0.372,
          0.618,
          0.108,
          0.682,
          0.846,
          0.202,
          0.018,
          0.586,
          0.814,
          0.01,
          0.588,
          0.428,
          0.278,
          0.994,
          0.584,
          0.436,
          0.554,
          0.46,
          0.764,
          0.168,
          0.284,
          0.524,
          0.34,
          0.356,
          0.54,
          0.582,
          0.816,
          0.786,
          0.65,
          0.712,
          0.48,
          0.676,
          0.594,
          0.06,
          0.734,
          0.79,
          0.536,
          0.468,
          0.538,
          0.398,
          0.8,
          0.04
         ],
         "z": [
          -5.933093150177001,
          42.81654296875013,
          -117.59783276367182,
          -8.793373809240705,
          -7.569433151153561,
          -3.5767910912401817,
          -2.5337833757972703,
          4.934528749237074,
          3.4840023136901834,
          3.9988520304870576,
          6.940273887634277,
          -2.1825653043754016,
          10.171648482360837,
          -33.25867187499989,
          -40.49513671874956,
          -20.867656976623522,
          3.151341470580803,
          -10.558734930725109,
          -2.279778115120621,
          -2.451851430796836,
          -3.904393318214403,
          -4.341741929473869,
          4.427245516815191,
          6.152661229705814,
          3.787828731533949,
          -3.9235622151832388,
          8.074573287048338,
          -0.23397175083161414,
          12.30469428466796,
          5.144712557830815,
          1.3204353041840307,
          0.18034131271363663,
          -2.1969534899933763,
          2.176140311737072,
          5.977758065643343,
          -2.1478354958301793,
          -10.916035474395727,
          -3.662480412872327,
          -1.4154694539565753,
          -1.2404891672359781,
          -6.889708414825407,
          -2.0306477950285853,
          -1.6587339379409798,
          1.1375149549893422,
          10.313187158203135,
          -1.2701263689613143,
          4.259763383283939,
          -0.9290526162269543,
          -5.449168325958254,
          5.070466552734388,
          16.261442570800767,
          -0.2336291902160781,
          8.227027727050768,
          -2.36652392578128,
          4.167412247009281,
          -8.750088657989494,
          -2.8321919476821336,
          4.7153386230468755,
          8.995157958984379,
          3.073144531250364,
          6.806666648651117,
          3.496375416229256,
          -10.480176704864505,
          -0.71232075946196,
          -4.7239143826675445,
          -1.250466121076812,
          11.925764544345213,
          -2.4350588543128993,
          -12.021602503146966,
          -5.757347662440964,
          -2.154245574395759,
          -3.9230024344253422,
          2.3214861320495572,
          26.355302734375073,
          1.0410378540221359,
          -2.7032161941909862,
          2.04365690841675,
          -16.92163493728637,
          -9.826958007812664,
          -4.715977399433257,
          -4.760756573028573,
          0.2714609409088098,
          1.8910132394027812,
          -3.8429646748808466,
          -4.385905887677012,
          -14.360830078125218,
          -1.9831145661926257,
          3.1379476463073672,
          9.65987942572022,
          15.059379533691413,
          2.6938618774414067,
          5.411582469918471,
          3.868979335494913,
          3.962472671813998,
          1.8456186056137085,
          -1.5691916852713632,
          -5.160072806716016,
          -0.21286828824676718,
          -8.178433399200458,
          1.981986354672273,
          -2.5628285425759145,
          -11.391117675781288,
          1.7320506888559066,
          15.434150500488272,
          -10.334449375061041,
          1.129416777379845,
          -6.241617596075429,
          -17.76444506835938,
          1.5982977374496556,
          -15.952437665100092,
          0.19457189735069846,
          -16.975136341857876,
          4.072059966229261,
          -10.72972697857665,
          33.315978027343704,
          3.2443540861511337,
          -0.5754746062660274,
          -0.7348678762309646,
          13.309666234392097,
          10.346810039978038,
          -0.32396503736376303,
          4.758719676971424,
          4.176288462974554,
          -1.1817833875160204,
          0.1492470704421862,
          2.2939982401389045,
          -2.0490043490183893,
          3.331464372283932,
          -6.437693428184815,
          -12.010201454167486,
          11.947478239157704,
          4.61865234375,
          -0.06385903400038728,
          2.792775384979251,
          0.05953383224488107,
          2.9044555461120467,
          2.0173661483764533,
          -5.002779009552,
          -14.387572265624954,
          0.29845688400268955,
          0.7376864503402771,
          -29.795701066894537,
          7.266907531738283,
          -10.709036688537594,
          -6.095790547637932,
          3.3555980458261274,
          -31.54116197509765,
          -8.46998611404419,
          -6.070272935333264,
          -3.4817646092238874,
          1.8959572756223224,
          -0.7834249199956673,
          -4.35207820590972,
          7.166022168884268,
          9.19643542572021,
          -2.5241627697636773,
          -0.43857628175939567,
          14.668141601562525,
          -6.416899431309815,
          0.7966846818542592,
          -20.953309815216073,
          -3.1314193025207544,
          0.2172746837730415,
          -8.67078417968753,
          7.060682864471431,
          -2.325630665627642,
          24.950708959960934,
          2.238135814666748,
          27.6367773437496,
          3.964723544158943,
          5.3935602349792475,
          -2.90487484392699,
          -5.711372852333369,
          -8.058449745194878,
          1.7977187858871275,
          -6.533218273642632,
          4.9447595336914105,
          -4.48957109474037,
          -4.728392471750141,
          -2.9002031544113436,
          -3.065316494294194,
          10.036327632938963,
          -3.7568032670519926,
          -4.262761840606686,
          47.89003417968752,
          -23.637900390624964,
          -7.074308794708259,
          -2.6087000105285654,
          -2.6174854958410663,
          2.19931463016988,
          8.53741416107178,
          4.437375868377671,
          -3.452993057247312,
          4.483433646697989,
          -14.596467761779763,
          -5.092906851348886,
          1.4424168888855036,
          5.976257813415515,
          4.078663183807407,
          -4.7917000554504625,
          -5.3035444490051304,
          -2.640376111183201,
          -6.789177710723891,
          -3.7850151570129356,
          78.04626953124989,
          -1.5722766072769048,
          -4.950728770294177,
          -2.862373512481696,
          -1.2950830045296016,
          -7.811484374999964,
          1.486578319549551,
          -2.051216638576335,
          34.10381508789061,
          -7.965945689239504,
          0.7443847111511275,
          0.5477365814117547,
          4.16586213458865,
          -3.261118423614505,
          1.8126291035435997,
          31.40501147460938,
          10.501897681579578,
          11.246550005798326,
          -2.1057724061050465,
          -0.7883840229984003,
          -83.53540039062455,
          5.7628130184936595,
          3.2602915759917437,
          2.6879351799011033,
          -1.7251654656753317,
          -4.5401983864332465,
          4.5099059992370485,
          -7.306882853302,
          -0.9830861687993888,
          -9.174067382812495,
          12.109660448610839,
          5.878431041229248,
          -1.6812579998550348,
          -3.33781257602692,
          -0.9408809197425967,
          1.9745858867026413,
          -3.336487629669193,
          5.908790111536149,
          -4.841992174786384,
          0.40522207443237335,
          -3.803326015411386,
          -2.2119834218059395,
          -3.521153844122324,
          -6.3240518681457445,
          1.647435516815193,
          -5.039868351383205,
          -4.093515653136677,
          0.6894832316589543,
          -34.016930664062556,
          -19.623636399902352,
          -2.4274669412612866,
          -1.599391979312884,
          4.979105052947972,
          -11.381600354003893,
          -12.403747619628902,
          -1.745600431501913,
          -13.234115490722658,
          3.2665678820417554,
          -2.499787722442619,
          -2.1885610441806023,
          0.7671111446762211,
          -3.3014256199035685,
          -1.892319946144113,
          -12.482094224395752,
          -6.207135609161384,
          5.682395142517095,
          -1.3045279974472805,
          -7.140046392364496,
          -2.6475759100057132,
          -2.0764024807685644,
          2.465674835135502,
          1.1858296407699527,
          -1.9417209381122404,
          -25.36419287109375,
          7.777543160095178,
          23.509685231933588,
          2.0095750929714313,
          -2.66816075697389,
          -25.690378493652332,
          -0.3012602715191406,
          1.8635319494323994,
          1.4768450308090166,
          0.015159071502694133,
          13.307861328125,
          2.616736888885498,
          -0.7290259207534859,
          36.792272583007815,
          2.900273437499891,
          -2.7395073299331614,
          1.391913736286142,
          16.50241577148438,
          2.122153369260502,
          2.023214171596436,
          0.5443033026519686,
          -3.503975402770351,
          0.053195768871887594,
          11.181681045837394,
          -91.69469726562511,
          -44.43741259765625,
          0.1296029905515752,
          2.9066891209636196,
          -0.13376834456937559,
          1.724674272738696,
          12.518292724609353,
          1.024760034596511,
          -2.9054497121333895,
          1.9399471386871596,
          6.1245951647792936,
          4.868766307805345,
          6.204279824432376,
          13.779797654313967,
          -8.991404733459461,
          8.211312590332028,
          2.437947727752686,
          -20.694912109374854,
          -7.313757690429696,
          -3.705617790181691,
          -4.332588678255036,
          -0.40206681329726734,
          -1.957006802520766,
          -2.7451777654457032,
          7.613059520706969,
          -1.0726435906410074,
          4.369477719205804,
          5.12596565521244,
          1.6023096789245699,
          -6.076435528106714,
          8.358615345681159,
          7.909726611338613,
          -0.872456574039461,
          20.499615747070322,
          2.5940318103982634,
          1.0427486259261798,
          -6.053679370880133,
          2.741217440643311,
          -0.885811392421715,
          -14.01543204302979,
          4.581992626176799,
          -15.011872513732897,
          -11.518779413146973,
          -5.185005665081292,
          -2.9045080915832386,
          -3.703815985137936,
          -3.215843122637949,
          -3.014187796661389,
          -1.887047432919303,
          -2.150124589161379,
          -3.8263048699379,
          -8.440785850372322,
          -2.5479833294442074,
          -9.931562117248546,
          6.29949061603395,
          3.2034450285339346,
          1.9130014180986166,
          -4.60779697537231,
          50.671404418945315,
          -5.2805256843566895,
          -1.409619382667529,
          8.03391170501709,
          -1.893202958805091,
          0.4229502081376495,
          11.297568359374964,
          -1.997678068180079,
          18.04752935935548,
          -3.525261592349125,
          -33.85642578124998,
          -2.231575621693196,
          -1.3010183584057984,
          -3.369166827945719,
          -11.967380425567626,
          0.8003311618980433,
          5.469324300955805,
          6.336047302948003,
          -5.575465249395762,
          1.378380760955821,
          0.5050736411105277,
          -0.8877950552223979,
          -0.16373113599658495,
          3.469203465838632,
          -11.446237358850084,
          -4.542961994972217,
          -7.676923358184808,
          18.046906495839835,
          -0.37636413360976917,
          0.3049649093246387,
          1.1805245060729987,
          -19.710829332519523,
          -5.440498828892089,
          5.383495093688964,
          -3.1250738112395027,
          0.7109237296714923,
          0.6491456925964485,
          0.42845809494019704,
          1.0978404661468062,
          7.708048805603028,
          21.125639526367195,
          7.195013052673374,
          -5.188170880680076,
          2.859130116177681,
          -1.9528350879409686,
          1.4878282624496535,
          2.6270922062683155,
          -2.6934285168957786,
          -3.8129167038879643,
          -0.8507872033793831,
          -22.581249999999272,
          -2.3816773973519787,
          -1.927392578124909,
          -2.994575084781644,
          -7.480231774902336,
          -5.828269676544181,
          -19.471127929687555,
          1.338721624111713,
          -11.439380883850106,
          1.2669672795980773,
          2.4086527297199893,
          -3.596123221888945,
          7.3240433099011,
          0.35608279409026977,
          1.379154277557376,
          -3.521592454083219,
          -6.35696582205199,
          -3.785835800652535,
          2.4092772062683423,
          5.311237469940181,
          3.1371680221521956,
          1.0433849239731217,
          21.454917043457044,
          -9.30573485107422,
          -5.233444830875385,
          -1.0761801036861698,
          -4.068881927520749,
          1.6337502119768885,
          -2.196834671730045,
          1.7305847617621453,
          -1.5679256111831705,
          -6.051975825958266,
          4.645044887643309,
          2.6313020175171005,
          0.45227621755429936,
          27.783389782714835,
          -3.528039645216097,
          6.839912906188971,
          6.982441055603033,
          2.602057933807373,
          -0.03666489362811376,
          3.2124757414245266,
          -1.289710530519102,
          0.2643069913511624,
          -0.5871362808172478,
          8.014781153962389,
          2.6765172406823865,
          -3.2118504910659738,
          -1.5486557068863078,
          2.005476774208944,
          4.4008546427917565,
          -0.4464300091035227,
          29.444778027343744,
          -4.907042325992592,
          -12.381177850646964,
          -4.334715990020783,
          -22.258217773437536,
          10.207658303222644,
          -1.3855283848003523,
          2.9677029853073407,
          -1.460045855526289,
          0.08623444699688321,
          2.0501711435182983,
          -4.143038991031688,
          8.608736050720239,
          -3.157890015305128,
          -2.7292418423254503,
          -2.430708442364505,
          -23.03615460205077,
          6.290477085174558,
          0.8410553470956756,
          8.435233116142825,
          17.497911132812476,
          -3.278475983184819,
          14.191460480957033,
          32.30079101562478,
          5.346360629119886,
          -105.36928320312501,
          -12.794745716857904,
          -1.7039680066566518,
          0.3889536225175618,
          15.532487907714852,
          22.65671386718759,
          -8.702875620880121,
          -14.925925438537604,
          -2.430931570264505,
          -4.032182844317617,
          -1.1541274414062173,
          -34.97039062499971,
          -0.7593143982581978,
          -10.330540780334474,
          -2.5690361609191825,
          5.391929149443513,
          -2.5018947527503883,
          -2.296938674659742,
          2.817672875213617,
          7.561266158142075,
          -2.0285100496597295,
          41.676959350585946,
          -3.539094216651904,
          20.876972656249563,
          -5.382495740089411,
          -0.6497274053424462,
          -1.6297755393081559,
          -5.2021498367691095,
          1.2301458293151768,
          1.059745166544758,
          -6.811958793040901,
          5.006491957440147,
          1.7562478514366546,
          -3.8310409626770365,
          -4.9536063125035525,
          -11.746342588653562,
          -6.112709997833264,
          0.012287167092182472,
          -1.4182910156250728,
          -0.16326511505505437,
          38.244762731933605,
          25.228302246093747,
          35.5840493774414,
          1.975457191191822,
          0.8299073525230369,
          4.2599244442749296,
          -0.8599219970703018,
          -6.4201705183410525,
          111.31013994140625,
          12.983178710937523,
          -2.7622556870910273,
          16.824527839355483,
          -0.09388025268310685,
          10.93135583496094,
          0.7452953166198597,
          -3.7621400955581805,
          -3.5400843191909814,
          3.9096719377136253,
          7.045099373260484,
          -4.94200580521607,
          -2.3897672061144988,
          7.4495365927124055,
          2.929822281854257,
          -47.109843261718765,
          4.887336254098244,
          6.995250964355478,
          -5.327816675567618,
          -0.8267863647460985,
          -0.7811121247863753,
          -0.7168480850219794,
          -2.4594044798388666,
          -7.733821716583265,
          0.8052999943542432,
          4.3856807156433035,
          1.2395921281433004,
          -2.8746571545168536,
          -2.6466809549331742,
          43.323639526367174,
          1.8433636163559015,
          8.035998833923344,
          -15.43729069732666,
          -2.267078613281228,
          5.0538294851511125,
          -9.449684268341088,
          -7.14905576248168,
          -4.382741364078527,
          -11.308220863342285,
          -3.220254284458264,
          1.3321450697090143,
          -3.087760285987855,
          26.261186157226575,
          -8.31348302974854,
          -5.2798947615051475,
          3.998236061072987,
          -28.455235585021967,
          12.597078259277339,
          0.8370664884948837,
          -1.807323260689742,
          -4.394754919018737,
          1.9043930519714252,
          5.6201863420104985,
          1.2312050089340119,
          -4.380775725440969,
          -0.6965681285316521,
          -4.566018496856685,
          -2.7432797049331725,
          -2.457703538917542,
          4.16961635424488,
          -3.895477633645754,
          1.8361528060746366,
          -8.050343252716061,
          3.4809892521667507,
          22.801233532714846,
          -9.353521820373544,
          -2.739104116973863,
          -8.409596699981677,
          6.718207835988068,
          1.6897936076354938,
          5.5340935359558046,
          6.542913643493648,
          10.176607299804687,
          -4.38237320489884,
          7.159081026306154,
          -0.5581595720863106,
          0.30436861251831715,
          0.5483774483123511,
          3.107806319963629,
          -5.597590931426993,
          -10.443168672637938,
          2.391354301971461,
          4.465427045135499,
          4.110480785146706,
          2.0769870900667513,
          1.3812365812683254,
          -0.2753585471294002,
          -3.4358895779113823,
          1.947071620330803,
          2.255126916463638,
          3.9460520743969028,
          0.36144120326994766,
          3.0097575187436973,
          5.399787694549559,
          4.204492187499909,
          0.11836149236680171,
          -0.4385303279113657,
          -3.7631048435363823,
          4.904181957190929,
          0.6649844661558575,
          -6.109935891456615,
          -6.322594166304128,
          -3.6484456237815834,
          12.159580528259283,
          -8.487048451232909,
          -3.414543634898365,
          1.5731211128793348,
          -4.329274409942627,
          -5.3046704754066525,
          -17.219746093749563,
          -9.274158691406228,
          46.22728515625022,
          89.35372070312496,
          0.9220504826354841,
          -2.204857349395752,
          0.7363351952707262,
          -24.391843825683594,
          -8.16000599197389,
          -21.269487097167968,
          4.058478119354248,
          -3.305319937872355,
          1.4574812492370484,
          9.567992653808602,
          -12.816495790100078,
          51.24850881347656,
          -17.05261718749989,
          -3.0236442895825064,
          0.45323890443961545,
          6.170538345642086,
          -13.501884394592281,
          4.706172250213626,
          -1.2083813555190943,
          2.5842814445231,
          15.548478801269539,
          -11.336216729278561,
          1.985144972730268,
          -2.5898297244644084,
          1.1712444991684094,
          -3.1664493581848205,
          -2.222021530094139,
          -5.450233450050348,
          -3.1083737898254356,
          -0.25689689460469367,
          -1.7613607845067918,
          -6.539449473419182,
          7.661477710876454,
          -3.282754389741825,
          2.958211815643324,
          -42.693078857421824,
          6.716133300781223,
          3.1035821531433214,
          -6.197745720558174,
          0.2727238751793095,
          -1.1600351240968791,
          9.419794732360828,
          -8.845065518341073,
          -3.3554170573054307,
          -7.455022436309804,
          -2.2135447614523116,
          1.3767805966186586,
          -4.320706332794231,
          37.62662381591797,
          -6.644327130450449,
          -10.311177378692634,
          1.5546792695971305,
          6.6828320312502,
          -31.426868068847654,
          -6.957553374786386,
          7.459176272315176,
          0.43626996335120793,
          0.7289416241683853,
          6.200255601776121,
          6.989870401306149,
          -0.33982140521891324,
          5.8304362296858585,
          15.112343318884314,
          3.1172388810729785,
          4.3831553458917085,
          1.2818335197449073,
          -7.034267843536384,
          7.121392368377684,
          -1.0210198922378595,
          -0.2944468664972817,
          -4.4036205554895105,
          10.741002818298341,
          -2.1995984619140643,
          -59.171699218749836,
          -12.286640624999563,
          -7.4440220140441795,
          -4.546576926544191,
          2.2542796134791274,
          0.40943091765549866,
          -0.34903052911758436,
          -2.0576419287107512,
          3.361436214080811,
          8.125825288321778,
          2.5111731437683034,
          2.6296921464667378,
          -5.9897434744644045,
          -61.730710693359356,
          3.4962936210551447,
          -2.552444616031636,
          -1.6073951219253502,
          17.579589228488288,
          8.65135504970928,
          -1.926907520212552,
          1.5609452482605093,
          -2.1866841770282406,
          0.6996050968933218,
          -53.10267336425781,
          0.22469834279593215,
          -11.892172022247308,
          -1.2004082674331755,
          7.7616096181042735,
          -2.1790036166847813,
          -2.8834113933410777,
          -6.913255056231691,
          -4.293875997833254,
          -1.9213033984613048,
          -0.637446568145748,
          -16.607905944824225,
          -1.0235969617347678,
          2.0854166564636216,
          -27.909316406250127,
          37.64151136474611,
          -2.361734455909726,
          -2.866989460792553,
          -3.9667583685754266,
          1.7454891320495562,
          -26.11197485351562,
          8.872468825665521,
          -7.341280685801991,
          3.815769239768315,
          -1.871806920753471,
          -4.62042649978639,
          -2.112496409379446,
          9.331907995605462,
          -6.9647385320129445,
          -1.564801620811295,
          5.435338057556152,
          3.8194337834167413,
          3.481115574558004,
          3.7170421476745332,
          -1.454848137550357,
          -5.9287737029114,
          1.0966409238525046,
          -2.1849974070815676,
          0.6584085141636535,
          -23.739597167968782,
          10.770914737243658,
          5.9770526134948625,
          -4.1775898933424,
          8.136026445524891,
          -4.033659524489508,
          1.4493007306137144,
          22.916781337890626,
          94.48773046874999,
          -5.805519596510976,
          -2.657988172465764,
          4.439662285369877,
          -1.4007192850577894,
          -2.297641849464412,
          -3.3867485809582547,
          -3.1505885184097338,
          4.769779907226564,
          -2.1078011900207514,
          2.523094947479251,
          -4.20845883142951,
          19.40593756103516,
          5.387325243580818,
          -49.19212890625022,
          106.88505859374982,
          -2.581702070098885,
          6.868590992126457,
          -18.937730824279782,
          -33.0252309350586,
          -0.2777850544738669,
          5.833808422010321,
          3.1060163070436317,
          -22.73060095214845,
          3.0387795509948603,
          4.190392513416754,
          -4.709023048143223,
          -4.393254377784729,
          10.42890770111083,
          7.371741960955802,
          -0.058634045510331134,
          16.138296179199216,
          1.929750751293426,
          -17.2079816494751,
          1.6477638859558397,
          -10.148454976348859,
          1.3799340003558882,
          63.888778845214844,
          0.7502325851058913,
          -7.52976662185668,
          18.80759651611328,
          2.097731446228039,
          2.412977396698011,
          0.4717782228751446,
          -5.366051210877799,
          -6.617302562286369,
          1.39280327072143,
          0.4721253253402722,
          -1.9386081815634668,
          0.2343134765624768,
          -1.3502016179847658,
          8.254313081970196,
          -0.8561330455366658,
          -3.0844849372863905,
          -0.7210927605977417,
          -0.9503104214518032,
          -6.460411549169493,
          -2.3523717166519305,
          62.753945312500036,
          17.675934318847652,
          -12.232122982482906,
          7.699013750915526,
          -2.598854999825562,
          0.1267818417234423,
          -2.2842872869300948,
          -3.833478857208263,
          -2.090508740481681,
          1.579831280449639,
          3.4171325646667583,
          10.510590860290534,
          -0.7813649775036424,
          0.05873712158202693,
          -1.8661570638003298,
          2.825743856633636,
          -19.69800390625005,
          -8.955366880645755,
          -2.87543774204255,
          -0.9463323287660046,
          -96.60308154373169,
          3.4463058830261275,
          2.667083698651112,
          0.5595398730308432,
          17.37046118164062,
          -2.681451926639511,
          4.273420510760502,
          -4.941007598419191,
          3.5784068093950623,
          2.024214012908942,
          -6.773866577911377,
          -2.495612596534727,
          4.172403709393308,
          20.681815429687504,
          -2.3810360818957577,
          -12.83078191510009,
          -4.475261562282327,
          -7.633704494512926,
          6.394114070526115,
          -1.2439969148254306,
          -10.194784746154795,
          -7.044884204877718,
          -1.847477804464404,
          -4.007029388300424,
          -3.36560483474733,
          -4.34211239822389,
          -4.056522310333264,
          -2.846238282747322,
          1.7126080246276842,
          -2.723570470966365,
          -11.060215857482916,
          59.02421874999982,
          -8.539319824218751,
          -2.9435513474426216,
          2.528587201385534,
          -37.678307617187556,
          -1.470259749269104,
          -2.8101374723254366,
          15.347072580235846,
          -3.8672523274028663,
          -2.234054967594176,
          -1.4822680447769017,
          0.019111048030850952,
          13.275229125976551,
          -5.337671201934825,
          -2.2099506743254267,
          -5.013224825176991,
          3.359336376167562,
          -1.9334128729800284,
          -2.5853514475622603,
          -4.952364253692622,
          3.5570047137292136,
          -9.014995493926989,
          -27.41427866455078,
          -2.598943903723864,
          29.33423176269531,
          2.9170012687682743,
          0.9366662394714353,
          3.8233723308776746,
          5.906101244557362,
          -2.593437679636793,
          99.83199047851565,
          -2.1821405525207638,
          -47.58720361328119,
          -15.794287904357901,
          -9.75285513580323,
          5.757436599219886,
          -3.0249352253722748,
          -7.137669580841077,
          1.524491444549568,
          -4.321624309425346,
          -8.290890669708261,
          -3.4090054573919417,
          -1.029841221368173,
          -8.774520956115765,
          2.0178823283386293,
          -22.24717283935547,
          16.99483017578126,
          5.785889138885494,
          13.869566652832049,
          4.217491688690188,
          8.30740677142333,
          -0.4573542341613859,
          14.48897228978268,
          -8.746554219787555,
          2.5186836466980083,
          5.000663280462646,
          -3.1611493467473224,
          6.957477598571785,
          4.774112909393324,
          -2.894020801806562,
          2.446073475838631,
          -7.270956140536384,
          -0.2543923832972723,
          4.281395372643317,
          16.667405175781255,
          -2.070153233253478,
          -1.500606517398836,
          -4.201718820372321,
          1.0527414083111921,
          -13.859255288848885,
          -9.932366533966075,
          3.6401286124971364,
          1.3921655417465217,
          -12.730429687499964,
          -25.152880859374818,
          11.704847725524871,
          35.957366967773424,
          4.055916058807412,
          7.383954682830819,
          -2.7049183960122036,
          5.028736347622072,
          0.41280201853865606,
          -2.737519131622321,
          -4.9303478689956535,
          7.87011461224364,
          1.3760906329574993,
          -3.7098111818738744,
          0.37670081724883175,
          -2.3480771023213833,
          8.437995824743666,
          -0.027200852394116737,
          0.8836859523277383,
          -3.102002312754422,
          3.264734936523439,
          -4.331518046661387,
          -5.24575221267699,
          12.30642851318359,
          -10.86499577545166,
          0.14757200893402,
          14.215417976074178,
          -6.126391866973876,
          1.2540200945911408,
          4.014717965057372,
          -2.817482496624166,
          -25.826850379943835,
          -2.322060108238702,
          -6.6958236726379425,
          -2.4393553241782513,
          8.170758560485837,
          1.8633235685730085,
          0.5337224679184089,
          7.00344037991249,
          -0.26606016021727896,
          -16.20609638189697,
          2.5014279045104786,
          -0.29021763748170315,
          10.186115630798326,
          6.424143379821771,
          13.977290270996093,
          -4.960146813944192,
          0.5186945216636616,
          -1.0239492668522416,
          -3.738823929473881,
          2.2365791512763735,
          2.7679968609000696,
          0.19376378045274123,
          -8.350223574981698,
          -1.9014477371597422,
          -2.3436851873550495,
          7.136788422088614,
          2.60923686994019,
          -6.871857763458252,
          1.1052838420104933,
          5.998404979114866,
          -4.300879790802014,
          -12.452563329162587,
          3.6797842679261237,
          1.4646392560043466,
          -4.129245988497274,
          14.956471732854908,
          -0.3619675935363773,
          -1.1966177225112915,
          -1.3041719187660306,
          4.2341210937497635,
          2.4035501937604806,
          -0.8735477209456803,
          1.5967475540213343,
          -0.7094550068519538,
          8.395772207946777,
          -5.542686941303515,
          -0.11492453194841801,
          11.244350092970222,
          -8.525414778865724,
          0.36867469545421727,
          4.260770606658923,
          -5.343311201934824,
          -0.6780720650166359,
          -2.3981899909973095,
          -1.0004901590347686,
          13.5924780331421,
          -1.5082636590003915,
          2.3942790030419303,
          1.185898109588635,
          -16.536971669006334,
          0.8884227345199633,
          -0.15466582110977356,
          -1.9816523035659657,
          -3.1328527445598127,
          -3.0675465144348095,
          0.3789059220886202,
          3.3825523652105005,
          4.526656908416754,
          3.0155866681823795,
          -0.9790246756362535,
          -4.43634298169971,
          2.8838310058776813,
          -21.90359808502197,
          -10.017883447326653,
          0.9657650846264687,
          7.221850701385506,
          9.305836528745203,
          4.772101879074313,
          14.874192871093783,
          2.3010808168276924,
          4.530796846557365,
          -2.081362173614508,
          -0.7193927146644512,
          0.8923136808776917,
          8.916068077075778,
          -2.6618439395786027,
          -3.727082466583255,
          -0.2506927546691884,
          -6.102687495880133,
          -1.7750716902160661,
          7.4711014950561605,
          -10.77065707916259,
          35.67405091552733,
          10.922594707946786,
          -8.69035046386719,
          -8.003457070007812,
          -3.953526061489498,
          -2.937966323129558,
          4.172195970916761,
          0.5008921024727613,
          4.35096728515623,
          -10.79463721256107,
          14.99460021972655,
          -4.306365935401914,
          -23.413759108886723,
          -4.527983398437527,
          4.2001258196355025,
          -9.46962362869263,
          9.137470703125473,
          1.8155456385387083,
          -6.794927867950435,
          -1.6701719597816407,
          11.812684766540514,
          19.818326262207023,
          8.715882211001457,
          16.592566094238293,
          4.308219432827286,
          -1.42576494513321,
          -11.836711181640624,
          -0.17251798435904675,
          26.23545500732422,
          -139.80034179687482,
          -7.836944136505139,
          0.6687554243980287,
          2.5899270466456983,
          7.879110059440194,
          -8.893059730531121,
          -3.6601735977172893,
          0.8982919499046034,
          3.464727242791753,
          2.293113772283931,
          4.1788290920104885,
          6.662084509277349,
          -4.527214527254358,
          -8.88833543533326,
          -1.5648973792646927,
          9.932945410603025,
          1.3323506276583998,
          -8.659604219512943,
          11.159298317871105,
          -1.1525350809511394,
          7.004554271406619,
          -3.733188376239468,
          4.466569673767083,
          -19.115275598144535,
          -1.9122109199953172,
          -3.8892358367004363,
          18.567668554687486,
          -1.9664488396644515,
          -3.6126791734021992,
          2.8953471183776855,
          -60.064731445312646,
          1.9158855736355918,
          -14.629624975646976,
          -3.7897715593910277,
          -77.25165112304688,
          0.28421583908081516,
          -0.08632715050882211,
          -3.4974295661926362,
          -31.522485144042975,
          -9.233968579864523,
          3.661571603729243,
          10.757017843376445,
          1.823539066936661,
          -0.8457694578285384,
          6.914744170837395,
          11.866411376953124,
          -2.0351652176284745,
          -3.376122141199289,
          -4.265642905131699,
          2.1053417375183017,
          -54.72296875000029,
          0.43655027539023195,
          0.058916142011213424,
          2.046041823048,
          -5.536339283046772,
          2.1968913075712635,
          1.7186648332214247,
          6.900788110565173,
          1.3318593713949554,
          -5.4766503474426145,
          1.8980222502136144,
          1.0997024431136992,
          -10.634991831817615,
          -1.8824466521644467,
          -7.662338169708249,
          -58.709802770996106,
          34.51925377197267,
          -5.462380308380119,
          1.2900155712809749,
          13.564763464355465,
          30.062224121093777,
          -2.6928982192607123,
          -5.230204557989509,
          -1.0224169011879098,
          -3.9857637175941534,
          0.3059458136445983,
          -13.996617694396974,
          9.627234606933598,
          -9.871055921936033,
          -9.833276136779773,
          -4.795979285410652,
          0.1513321901609288,
          1.9241087345886285,
          -1.1573627420082175,
          2.4454687500001455,
          -2.7121822357927385,
          2.5792318221261326,
          -8.70535626470948,
          16.887254094394535,
          0.05529645345654899,
          -0.2613736941909792,
          -21.10421675689696,
          23.532753906250036,
          -3.5643535156250437,
          -2.2182418680191063,
          5.035809366149891,
          -0.3369714123637664,
          3.1636686125183076,
          -50.5796919555664,
          1.7999337906164783,
          -11.349638427734362,
          -14.512103784942639,
          -1.8255702410316417,
          14.885474365234373,
          -2.41680029087064,
          -16.442251525878902,
          -7.506929864044196,
          -2.5528645517578354
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "scene": {
         "aspectmode": "auto",
         "aspectratio": {
          "x": 1,
          "y": 1,
          "z": 1
         },
         "camera": {
          "center": {
           "x": 0,
           "y": 0,
           "z": 0
          },
          "eye": {
           "x": -0.3646226167107854,
           "y": 2.1049426149808084,
           "z": -0.3518052515536641
          },
          "up": {
           "x": 0,
           "y": 0,
           "z": 1
          }
         },
         "xaxis": {
          "title": {
           "text": "mixture fraction"
          },
          "type": "linear"
         },
         "yaxis": {
          "title": {
           "text": "progress variable"
          },
          "type": "linear"
         },
         "zaxis": {
          "title": {
           "text": "PVs"
          },
          "type": "linear"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title Default title text\n",
    "species = 'PVs' #@param {type:\"string\"}\n",
    "\n",
    "# configure_plotly_browser_state()\n",
    "# init_notebook_mode(connected=False)\n",
    "\n",
    "df_t=df_test.loc[df_test['zeta']==zeta_level[1]].sample(frac=0.5)\n",
    "# df_p=df_pred.loc[df_pred['zeta']==zeta_level[1]].sample(frac=0.1)\n",
    "df_p=df_pred.loc[df_t.index]\n",
    "error=df_p[species]-df_t[species]\n",
    "\n",
    "fig_db = {\n",
    "    'data': [       \n",
    "        {'name':'test data from table',\n",
    "         'x': df_t['f'],\n",
    "         'y': df_t['pv'],\n",
    "         'z': df_t[species],\n",
    "         'type':'scatter3d', \n",
    "        'mode': 'markers',\n",
    "          'marker':{\n",
    "              'size':1\n",
    "          }\n",
    "        },\n",
    "        {'name':'prediction from neural networks',\n",
    "         'x': df_p['f'],\n",
    "         'y': df_p['pv'],\n",
    "         'z': df_p[species],\n",
    "         'type':'scatter3d', \n",
    "        'mode': 'markers',\n",
    "          'marker':{\n",
    "              'size':1\n",
    "          },\n",
    "        },\n",
    "        {'name':'error in difference',\n",
    "         'x': df_p['f'],\n",
    "         'y': df_p['pv'],\n",
    "         'z': error,\n",
    "         'type':'scatter3d', \n",
    "         'mode': 'markers',\n",
    "          'marker':{\n",
    "              'size':1\n",
    "          },\n",
    "         }       \n",
    "    ],\n",
    "    'layout': {\n",
    "        'scene':{\n",
    "            'xaxis': {'title':'mixture fraction'},\n",
    "            'yaxis': {'title':'progress variable'},\n",
    "            'zaxis': {'title': species}\n",
    "                 }\n",
    "    }\n",
    "}\n",
    "# iplot(fig_db, filename='multiple-scatter')\n",
    "iplot(fig_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qDcvIQQWHPss",
    "outputId": "c4909ac7-459f-4cb1-e92b-225266eb0d51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xaxis': {}}"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1058
    },
    "colab_type": "code",
    "id": "jSA0-eE4tVGs",
    "outputId": "2e4e69b4-2028-4903-d61b-311cef103161"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18339     428.306366\n",
       "23275    1208.719971\n",
       "20617     366.667419\n",
       "5958      701.695251\n",
       "15998     982.646790\n",
       "8221      675.589355\n",
       "13357    1170.622437\n",
       "3399      889.169128\n",
       "24295     385.650757\n",
       "12075    1484.524414\n",
       "7608      405.936981\n",
       "24011    1151.844116\n",
       "11403     786.547485\n",
       "13271     426.226440\n",
       "16204     568.691162\n",
       "15927     645.248779\n",
       "22713     296.786682\n",
       "22123     813.945801\n",
       "10851     534.735168\n",
       "12908     662.818970\n",
       "23080     340.972839\n",
       "16938     734.988220\n",
       "11526     770.892273\n",
       "7217      465.167877\n",
       "18529     319.734619\n",
       "7708      307.078308\n",
       "20460    1065.076904\n",
       "20437     429.436035\n",
       "11856     364.320374\n",
       "14885     364.325592\n",
       "            ...     \n",
       "16824     619.481079\n",
       "9652      776.821411\n",
       "10779     663.060486\n",
       "9430      544.365601\n",
       "5217      510.356903\n",
       "19653    1194.823120\n",
       "10845     342.816040\n",
       "10388     697.538940\n",
       "16396     285.287170\n",
       "6163      463.656250\n",
       "3318     1012.577393\n",
       "8281      516.662964\n",
       "21290     805.862122\n",
       "19184     353.660919\n",
       "4134      729.435059\n",
       "12471     366.944794\n",
       "7578      471.406006\n",
       "8160      701.033752\n",
       "22843     773.769653\n",
       "17001    1042.269043\n",
       "5798      809.095276\n",
       "21744    1129.346680\n",
       "1299      311.950531\n",
       "24457     518.999084\n",
       "11161     903.850525\n",
       "18238     362.291412\n",
       "22883     337.486511\n",
       "11543     590.172852\n",
       "14465     563.970215\n",
       "5255      475.487915\n",
       "Name: T, Length: 1265, dtype: float32"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p['T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I9sLWYYXAIHw",
    "outputId": "7a7ccb23-4dab-4c4f-e69c-2520ec9546d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1225, 12)"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QLZHo9ZOAONV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fgm_nn_inhouse.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "my_dev",
   "language": "python",
   "name": "my_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
